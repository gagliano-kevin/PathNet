Iteration 1: Loss = 0.5142008066177368
Iteration 2: Loss = 0.5129402279853821
Iteration 3: Loss = 0.5119918584823608
Iteration 4: Loss = 0.5113363862037659
Iteration 5: Loss = 0.5107873678207397
Iteration 6: Loss = 0.5101723670959473
Iteration 7: Loss = 0.5094831585884094
Iteration 8: Loss = 0.5087689757347107
Iteration 9: Loss = 0.5080717206001282
Iteration 10: Loss = 0.5074137449264526
Iteration 11: Loss = 0.5067947506904602
Iteration 12: Loss = 0.5062028169631958
Iteration 13: Loss = 0.5056198239326477
Iteration 14: Loss = 0.5050333142280579
Iteration 15: Loss = 0.5044359564781189
Iteration 16: Loss = 0.5038252472877502
Iteration 17: Loss = 0.5032037496566772
Iteration 18: Loss = 0.5025765299797058
Iteration 19: Loss = 0.5019486546516418
Iteration 20: Loss = 0.5013247728347778
Iteration 21: Loss = 0.5007086396217346
Iteration 22: Loss = 0.500100314617157
Iteration 23: Loss = 0.4994966387748718
Iteration 24: Loss = 0.4988934397697449
Iteration 25: Loss = 0.4982883036136627
Iteration 26: Loss = 0.4976806938648224
Iteration 27: Loss = 0.49707263708114624
Iteration 28: Loss = 0.4964679479598999
Iteration 29: Loss = 0.49586939811706543
Iteration 30: Loss = 0.4952775835990906
Iteration 31: Loss = 0.49469131231307983
Iteration 32: Loss = 0.4941074848175049
Iteration 33: Loss = 0.4935237765312195
Iteration 34: Loss = 0.4929385483264923
Iteration 35: Loss = 0.4923517107963562
Iteration 36: Loss = 0.49176523089408875
Iteration 37: Loss = 0.491180956363678
Iteration 38: Loss = 0.4906003177165985
Iteration 39: Loss = 0.4900233745574951
Iteration 40: Loss = 0.4894487261772156
Iteration 41: Loss = 0.4888754189014435
Iteration 42: Loss = 0.48830294609069824
Iteration 43: Loss = 0.4877319037914276
Iteration 44: Loss = 0.48716288805007935
Iteration 45: Loss = 0.4865972101688385
Iteration 46: Loss = 0.48603492975234985
Iteration 47: Loss = 0.4854756295681
Iteration 48: Loss = 0.4849185347557068
Iteration 49: Loss = 0.48436272144317627
Iteration 50: Loss = 0.4838079512119293
Iteration 51: Loss = 0.483254611492157
Iteration 52: Loss = 0.48270347714424133
Iteration 53: Loss = 0.4821549654006958
Iteration 54: Loss = 0.4816092550754547
Iteration 55: Loss = 0.4810657203197479
Iteration 56: Loss = 0.48052453994750977
Iteration 57: Loss = 0.47998514771461487
Iteration 58: Loss = 0.47944775223731995
Iteration 59: Loss = 0.4789126217365265
Iteration 60: Loss = 0.4783802628517151
Iteration 61: Loss = 0.47785067558288574
Iteration 62: Loss = 0.4773232936859131
Iteration 63: Loss = 0.4767981767654419
Iteration 64: Loss = 0.4762747585773468
Iteration 65: Loss = 0.47575342655181885
Iteration 66: Loss = 0.4752342998981476
Iteration 67: Loss = 0.47471779584884644
Iteration 68: Loss = 0.47420385479927063
Iteration 69: Loss = 0.47369226813316345
Iteration 70: Loss = 0.4731829762458801
Iteration 71: Loss = 0.4726722538471222
Iteration 72: Loss = 0.47215592861175537
Iteration 73: Loss = 0.47163671255111694
Iteration 74: Loss = 0.47112539410591125
Iteration 75: Loss = 0.470635324716568
Iteration 76: Loss = 0.47015777230262756
Iteration 77: Loss = 0.46966809034347534
Iteration 78: Loss = 0.4691692888736725
Iteration 79: Loss = 0.4686814546585083
Iteration 80: Loss = 0.46821239590644836
Iteration 81: Loss = 0.4677494466304779
Iteration 82: Loss = 0.46728214621543884
Iteration 83: Loss = 0.46681299805641174
Iteration 84: Loss = 0.4663533568382263
Iteration 85: Loss = 0.4659077525138855
Iteration 86: Loss = 0.46546661853790283
Iteration 87: Loss = 0.4650224447250366
Iteration 88: Loss = 0.4645804464817047
Iteration 89: Loss = 0.46414873003959656
Iteration 90: Loss = 0.4637267291545868
Iteration 91: Loss = 0.4633079171180725
Iteration 92: Loss = 0.46288928389549255
Iteration 93: Loss = 0.46247410774230957
Iteration 94: Loss = 0.4620676040649414
Iteration 95: Loss = 0.461668461561203
Iteration 96: Loss = 0.46127232909202576
Iteration 97: Loss = 0.460877001285553
Iteration 98: Loss = 0.4604881703853607
Iteration 99: Loss = 0.4601067304611206
Iteration 100: Loss = 0.45972931385040283
Iteration 101: Loss = 0.45935365557670593
Iteration 102: Loss = 0.4589826762676239
Iteration 103: Loss = 0.4586188793182373
Iteration 104: Loss = 0.4582594335079193
Iteration 105: Loss = 0.4579021632671356
Iteration 106: Loss = 0.45754873752593994
Iteration 107: Loss = 0.45720091462135315
Iteration 108: Loss = 0.4568578898906708
Iteration 109: Loss = 0.4565182328224182
Iteration 110: Loss = 0.4561817944049835
Iteration 111: Loss = 0.45584985613822937
Iteration 112: Loss = 0.4555225074291229
Iteration 113: Loss = 0.455198734998703
Iteration 114: Loss = 0.45487818121910095
Iteration 115: Loss = 0.4545615315437317
Iteration 116: Loss = 0.45424938201904297
Iteration 117: Loss = 0.45394060015678406
Iteration 118: Loss = 0.4536345899105072
Iteration 119: Loss = 0.4533323645591736
Iteration 120: Loss = 0.4530341625213623
Iteration 121: Loss = 0.4527391791343689
Iteration 122: Loss = 0.4524473547935486
Iteration 123: Loss = 0.45215916633605957
Iteration 124: Loss = 0.45187437534332275
Iteration 125: Loss = 0.4515921473503113
Iteration 126: Loss = 0.45131319761276245
Iteration 127: Loss = 0.45103803277015686
Iteration 128: Loss = 0.45076555013656616
Iteration 129: Loss = 0.45049571990966797
Iteration 130: Loss = 0.45022886991500854
Iteration 131: Loss = 0.44996514916419983
Iteration 132: Loss = 0.44970428943634033
Iteration 133: Loss = 0.44944608211517334
Iteration 134: Loss = 0.449190616607666
Iteration 135: Loss = 0.4489380121231079
Iteration 136: Loss = 0.4486881196498871
Iteration 137: Loss = 0.44844040274620056
Iteration 138: Loss = 0.44819527864456177
Iteration 139: Loss = 0.4479528069496155
Iteration 140: Loss = 0.44771283864974976
Iteration 141: Loss = 0.447475403547287
Iteration 142: Loss = 0.4472401440143585
Iteration 143: Loss = 0.44700726866722107
Iteration 144: Loss = 0.446776807308197
Iteration 145: Loss = 0.44654861092567444
Iteration 146: Loss = 0.44632232189178467
Iteration 147: Loss = 0.44609832763671875
Iteration 148: Loss = 0.4458765983581543
Iteration 149: Loss = 0.44565674662590027
Iteration 150: Loss = 0.44543910026550293
Iteration 151: Loss = 0.4452235698699951
Iteration 152: Loss = 0.4450097382068634
Iteration 153: Loss = 0.4447978436946869
Iteration 154: Loss = 0.44458797574043274
Iteration 155: Loss = 0.4443801939487457
Iteration 156: Loss = 0.4441738724708557
Iteration 157: Loss = 0.4439692497253418
Iteration 158: Loss = 0.44376689195632935
Iteration 159: Loss = 0.44356608390808105
Iteration 160: Loss = 0.44336631894111633
Iteration 161: Loss = 0.4431687295436859
Iteration 162: Loss = 0.4429728388786316
Iteration 163: Loss = 0.4427783787250519
Iteration 164: Loss = 0.442585289478302
Iteration 165: Loss = 0.4423939883708954
Iteration 166: Loss = 0.4422042965888977
Iteration 167: Loss = 0.4420155882835388
Iteration 168: Loss = 0.44182848930358887
Iteration 169: Loss = 0.4416429400444031
Iteration 170: Loss = 0.44145891070365906
Iteration 171: Loss = 0.4412758946418762
Iteration 172: Loss = 0.4410940110683441
Iteration 173: Loss = 0.4409139156341553
Iteration 174: Loss = 0.4407348036766052
Iteration 175: Loss = 0.4405568838119507
Iteration 176: Loss = 0.4403805434703827
Iteration 177: Loss = 0.44020527601242065
Iteration 178: Loss = 0.4400308132171631
Iteration 179: Loss = 0.43985775113105774
Iteration 180: Loss = 0.4396858811378479
Iteration 181: Loss = 0.43951502442359924
Iteration 182: Loss = 0.4393450915813446
Iteration 183: Loss = 0.4391763210296631
Iteration 184: Loss = 0.43900859355926514
Iteration 185: Loss = 0.43884190917015076
Iteration 186: Loss = 0.4386761784553528
Iteration 187: Loss = 0.4385111629962921
Iteration 188: Loss = 0.43834713101387024
Iteration 189: Loss = 0.43818405270576477
Iteration 190: Loss = 0.43802207708358765
Iteration 191: Loss = 0.4378610849380493
Iteration 192: Loss = 0.4377008080482483
Iteration 193: Loss = 0.4375411570072174
Iteration 194: Loss = 0.43738242983818054
Iteration 195: Loss = 0.437224805355072
Iteration 196: Loss = 0.4370678663253784
Iteration 197: Loss = 0.4369116723537445
Iteration 198: Loss = 0.43675610423088074
Iteration 199: Loss = 0.43660154938697815
Iteration 200: Loss = 0.4364479184150696
Iteration 201: Loss = 0.43629488348960876
Iteration 202: Loss = 0.4361423850059509
Iteration 203: Loss = 0.43599072098731995
Iteration 204: Loss = 0.4358396530151367
Iteration 205: Loss = 0.4356895983219147
Iteration 206: Loss = 0.43553999066352844
Iteration 207: Loss = 0.43539074063301086
Iteration 208: Loss = 0.43524235486984253
Iteration 209: Loss = 0.4350946843624115
Iteration 210: Loss = 0.43494752049446106
Iteration 211: Loss = 0.43480077385902405
Iteration 212: Loss = 0.43465492129325867
Iteration 213: Loss = 0.43450939655303955
Iteration 214: Loss = 0.43436434864997864
Iteration 215: Loss = 0.4342200458049774
Iteration 216: Loss = 0.43439623713493347
Iteration 217: Loss = 0.4339330792427063
Iteration 218: Loss = 0.4337925314903259
Iteration 219: Loss = 0.4336511790752411
Iteration 220: Loss = 0.433510422706604
Iteration 221: Loss = 0.4333701431751251
Iteration 222: Loss = 0.43323013186454773
Iteration 223: Loss = 0.43309056758880615
Iteration 224: Loss = 0.43295153975486755
Iteration 225: Loss = 0.43281272053718567
Iteration 226: Loss = 0.43267467617988586
Iteration 227: Loss = 0.4325372576713562
Iteration 228: Loss = 0.4323999881744385
Iteration 229: Loss = 0.43226295709609985
Iteration 230: Loss = 0.4321267008781433
Iteration 231: Loss = 0.4319911599159241
Iteration 232: Loss = 0.4318554699420929
Iteration 233: Loss = 0.43172016739845276
Iteration 234: Loss = 0.4315854609012604
Iteration 235: Loss = 0.43145129084587097
Iteration 236: Loss = 0.43131735920906067
Iteration 237: Loss = 0.43118369579315186
Iteration 238: Loss = 0.43105071783065796
Iteration 239: Loss = 0.4309179484844208
Iteration 240: Loss = 0.4307857155799866
Iteration 241: Loss = 0.43065398931503296
Iteration 242: Loss = 0.4305226802825928
Iteration 243: Loss = 0.43039175868034363
Iteration 244: Loss = 0.4302612841129303
Iteration 245: Loss = 0.43013128638267517
Iteration 246: Loss = 0.430001825094223
Iteration 247: Loss = 0.42987290024757385
Iteration 248: Loss = 0.42974424362182617
Iteration 249: Loss = 0.42961621284484863
Iteration 250: Loss = 0.4294887185096741
Iteration 251: Loss = 0.4293615520000458
Iteration 252: Loss = 0.42923471331596375
Iteration 253: Loss = 0.4291083514690399
Iteration 254: Loss = 0.42898258566856384
Iteration 255: Loss = 0.4288571774959564
Iteration 256: Loss = 0.4287320673465729
Iteration 257: Loss = 0.42860737442970276
Iteration 258: Loss = 0.42848309874534607
Iteration 259: Loss = 0.42835941910743713
Iteration 260: Loss = 0.4282362163066864
Iteration 261: Loss = 0.42811328172683716
Iteration 262: Loss = 0.42799070477485657
Iteration 263: Loss = 0.42786839604377747
Iteration 264: Loss = 0.42774665355682373
Iteration 265: Loss = 0.42762523889541626
Iteration 266: Loss = 0.42750436067581177
Iteration 267: Loss = 0.4273836612701416
Iteration 268: Loss = 0.42726361751556396
Iteration 269: Loss = 0.4271436929702759
Iteration 270: Loss = 0.4270244240760803
Iteration 271: Loss = 0.42690548300743103
Iteration 272: Loss = 0.4267868101596832
Iteration 273: Loss = 0.4266684651374817
Iteration 274: Loss = 0.42655065655708313
Iteration 275: Loss = 0.4264333248138428
Iteration 276: Loss = 0.4263165295124054
Iteration 277: Loss = 0.426199734210968
Iteration 278: Loss = 0.4260832667350769
Iteration 279: Loss = 0.42596736550331116
Iteration 280: Loss = 0.4258517324924469
Iteration 281: Loss = 0.4257369339466095
Iteration 282: Loss = 0.4256223738193512
Iteration 283: Loss = 0.42550769448280334
Iteration 284: Loss = 0.42539358139038086
Iteration 285: Loss = 0.42527997493743896
Iteration 286: Loss = 0.4251670241355896
Iteration 287: Loss = 0.4250542223453522
Iteration 288: Loss = 0.4249415993690491
Iteration 289: Loss = 0.42482924461364746
Iteration 290: Loss = 0.42471766471862793
Iteration 291: Loss = 0.42460617423057556
Iteration 292: Loss = 0.4244953989982605
Iteration 293: Loss = 0.4243846833705902
Iteration 294: Loss = 0.42427441477775574
Iteration 295: Loss = 0.4241645634174347
Iteration 296: Loss = 0.42405518889427185
Iteration 297: Loss = 0.4239461123943329
Iteration 298: Loss = 0.4238370358943939
Iteration 299: Loss = 0.4237288236618042
Iteration 300: Loss = 0.42362093925476074
Iteration 301: Loss = 0.4235132932662964
Iteration 302: Loss = 0.42340588569641113
Iteration 303: Loss = 0.4232991337776184
Iteration 304: Loss = 0.42319244146347046
Iteration 305: Loss = 0.4230860769748688
Iteration 306: Loss = 0.4229803681373596
Iteration 307: Loss = 0.422875314950943
Iteration 308: Loss = 0.42277002334594727
Iteration 309: Loss = 0.42266517877578735
Iteration 310: Loss = 0.4225613474845886
Iteration 311: Loss = 0.42245715856552124
Iteration 312: Loss = 0.4223537743091583
Iteration 313: Loss = 0.422250360250473
Iteration 314: Loss = 0.42214730381965637
Iteration 315: Loss = 0.42204520106315613
Iteration 316: Loss = 0.4219433069229126
Iteration 317: Loss = 0.42184147238731384
Iteration 318: Loss = 0.421739786863327
Iteration 319: Loss = 0.4216386675834656
Iteration 320: Loss = 0.4215379059314728
Iteration 321: Loss = 0.4214382767677307
Iteration 322: Loss = 0.4213382303714752
Iteration 323: Loss = 0.4212382435798645
Iteration 324: Loss = 0.42113935947418213
Iteration 325: Loss = 0.42104053497314453
Iteration 326: Loss = 0.4209419786930084
Iteration 327: Loss = 0.42084455490112305
Iteration 328: Loss = 0.4207468628883362
Iteration 329: Loss = 0.4206485152244568
Iteration 330: Loss = 0.4205521047115326
Iteration 331: Loss = 0.4204553961753845
Iteration 332: Loss = 0.4203587472438812
Iteration 333: Loss = 0.4202629625797272
Iteration 334: Loss = 0.42016729712486267
Iteration 335: Loss = 0.4200723171234131
Iteration 336: Loss = 0.4199771583080292
Iteration 337: Loss = 0.4198828637599945
Iteration 338: Loss = 0.4197888970375061
Iteration 339: Loss = 0.4196949601173401
Iteration 340: Loss = 0.419601708650589
Iteration 341: Loss = 0.4195086658000946
Iteration 342: Loss = 0.41941606998443604
Iteration 343: Loss = 0.41932377219200134
Iteration 344: Loss = 0.4192321300506592
Iteration 345: Loss = 0.41914018988609314
Iteration 346: Loss = 0.4190492033958435
Iteration 347: Loss = 0.41895872354507446
Iteration 348: Loss = 0.4188680648803711
Iteration 349: Loss = 0.4187776446342468
Iteration 350: Loss = 0.4186883568763733
Iteration 351: Loss = 0.41859912872314453
Iteration 352: Loss = 0.41850948333740234
Iteration 353: Loss = 0.41842105984687805
Iteration 354: Loss = 0.41833236813545227
Iteration 355: Loss = 0.41824424266815186
Iteration 356: Loss = 0.4181569218635559
Iteration 357: Loss = 0.4180690050125122
Iteration 358: Loss = 0.4179820716381073
Iteration 359: Loss = 0.41789597272872925
Iteration 360: Loss = 0.4178086817264557
Iteration 361: Loss = 0.41772302985191345
Iteration 362: Loss = 0.41763702034950256
Iteration 363: Loss = 0.41755127906799316
Iteration 364: Loss = 0.41746678948402405
Iteration 365: Loss = 0.41738197207450867
Iteration 366: Loss = 0.4172971248626709
Iteration 367: Loss = 0.4172135889530182
Iteration 368: Loss = 0.4171295166015625
Iteration 369: Loss = 0.41704580187797546
Iteration 370: Loss = 0.41696324944496155
Iteration 371: Loss = 0.41687992215156555
Iteration 372: Loss = 0.4167974293231964
Iteration 373: Loss = 0.4167157709598541
Iteration 374: Loss = 0.4166331887245178
Iteration 375: Loss = 0.4165521264076233
Iteration 376: Loss = 0.41647112369537354
Iteration 377: Loss = 0.4163893759250641
Iteration 378: Loss = 0.41630905866622925
Iteration 379: Loss = 0.4162288010120392
Iteration 380: Loss = 0.41614866256713867
Iteration 381: Loss = 0.4160688519477844
Iteration 382: Loss = 0.4159894585609436
Iteration 383: Loss = 0.4159102439880371
Iteration 384: Loss = 0.41583195328712463
Iteration 385: Loss = 0.41575342416763306
Iteration 386: Loss = 0.4156753420829773
Iteration 387: Loss = 0.41559723019599915
Iteration 388: Loss = 0.41551971435546875
Iteration 389: Loss = 0.41544264554977417
Iteration 390: Loss = 0.41536563634872437
Iteration 391: Loss = 0.4152888059616089
Iteration 392: Loss = 0.41521233320236206
Iteration 393: Loss = 0.415136456489563
Iteration 394: Loss = 0.41506052017211914
Iteration 395: Loss = 0.41498541831970215
Iteration 396: Loss = 0.41491031646728516
Iteration 397: Loss = 0.41483524441719055
Iteration 398: Loss = 0.414760559797287
Iteration 399: Loss = 0.4146863520145416
Iteration 400: Loss = 0.4146120250225067
Iteration 401: Loss = 0.4145389497280121
Iteration 402: Loss = 0.4144650995731354
Iteration 403: Loss = 0.4143913686275482
Iteration 404: Loss = 0.4143187701702118
Iteration 405: Loss = 0.4142458736896515
Iteration 406: Loss = 0.41417306661605835
Iteration 407: Loss = 0.41410115361213684
Iteration 408: Loss = 0.41402900218963623
Iteration 409: Loss = 0.4139570891857147
Iteration 410: Loss = 0.41388556361198425
Iteration 411: Loss = 0.4138147234916687
Iteration 412: Loss = 0.41374310851097107
Iteration 413: Loss = 0.41367295384407043
Iteration 414: Loss = 0.4136030077934265
Iteration 415: Loss = 0.41353198885917664
Iteration 416: Loss = 0.4134621024131775
Iteration 417: Loss = 0.4133923351764679
Iteration 418: Loss = 0.41332295536994934
Iteration 419: Loss = 0.4132537245750427
Iteration 420: Loss = 0.4131847620010376
Iteration 421: Loss = 0.4131162762641907
Iteration 422: Loss = 0.4130480885505676
Iteration 423: Loss = 0.41297972202301025
Iteration 424: Loss = 0.41291168332099915
Iteration 425: Loss = 0.4128439426422119
Iteration 426: Loss = 0.41277673840522766
Iteration 427: Loss = 0.41270923614501953
Iteration 428: Loss = 0.41264215111732483
Iteration 429: Loss = 0.4125758111476898
Iteration 430: Loss = 0.41250938177108765
Iteration 431: Loss = 0.412442684173584
Iteration 432: Loss = 0.4123765826225281
Iteration 433: Loss = 0.41231071949005127
Iteration 434: Loss = 0.41224515438079834
Iteration 435: Loss = 0.4121798574924469
Iteration 436: Loss = 0.4121147692203522
Iteration 437: Loss = 0.4120497405529022
Iteration 438: Loss = 0.4119856357574463
Iteration 439: Loss = 0.41192078590393066
Iteration 440: Loss = 0.41185635328292847
Iteration 441: Loss = 0.41179266571998596
Iteration 442: Loss = 0.4117286205291748
Iteration 443: Loss = 0.4116654694080353
Iteration 444: Loss = 0.4116020202636719
Iteration 445: Loss = 0.4115385115146637
Iteration 446: Loss = 0.4114755690097809
Iteration 447: Loss = 0.4114128351211548
Iteration 448: Loss = 0.41135039925575256
Iteration 449: Loss = 0.41128841042518616
Iteration 450: Loss = 0.41122639179229736
Iteration 451: Loss = 0.41116461157798767
Iteration 452: Loss = 0.4111027419567108
Iteration 453: Loss = 0.4110416769981384
Iteration 454: Loss = 0.4109804630279541
Iteration 455: Loss = 0.41091933846473694
Iteration 456: Loss = 0.41085901856422424
Iteration 457: Loss = 0.4107983112335205
Iteration 458: Loss = 0.41073790192604065
Iteration 459: Loss = 0.41067755222320557
Iteration 460: Loss = 0.4106181859970093
Iteration 461: Loss = 0.4105583727359772
Iteration 462: Loss = 0.41049858927726746
Iteration 463: Loss = 0.4104391038417816
Iteration 464: Loss = 0.4103802442550659
Iteration 465: Loss = 0.4103214144706726
Iteration 466: Loss = 0.4102625846862793
Iteration 467: Loss = 0.41020339727401733
Iteration 468: Loss = 0.41014522314071655
Iteration 469: Loss = 0.41008689999580383
Iteration 470: Loss = 0.4100287854671478
Iteration 471: Loss = 0.40997084975242615
Iteration 472: Loss = 0.409913033246994
Iteration 473: Loss = 0.40985557436943054
Iteration 474: Loss = 0.40979811549186707
Iteration 475: Loss = 0.40974098443984985
Iteration 476: Loss = 0.40968403220176697
Iteration 477: Loss = 0.40962737798690796
Iteration 478: Loss = 0.4095706641674042
Iteration 479: Loss = 0.40951430797576904
Iteration 480: Loss = 0.40945783257484436
Iteration 481: Loss = 0.4094013571739197
Iteration 482: Loss = 0.40934550762176514
Iteration 483: Loss = 0.40928956866264343
Iteration 484: Loss = 0.4092333912849426
Iteration 485: Loss = 0.4091782867908478
Iteration 486: Loss = 0.4091225862503052
Iteration 487: Loss = 0.409066766500473
Iteration 488: Loss = 0.4090120792388916
Iteration 489: Loss = 0.4089565575122833
Iteration 490: Loss = 0.40890151262283325
Iteration 491: Loss = 0.4088467061519623
Iteration 492: Loss = 0.40879178047180176
Iteration 493: Loss = 0.4087381064891815
Iteration 494: Loss = 0.4086828827857971
Iteration 495: Loss = 0.4086287319660187
Iteration 496: Loss = 0.4085749089717865
Iteration 497: Loss = 0.4085204601287842
Iteration 498: Loss = 0.4084664583206177
Iteration 499: Loss = 0.40841278433799744
Iteration 500: Loss = 0.408359557390213
Iteration 501: Loss = 0.40830621123313904
Iteration 502: Loss = 0.4082525074481964
Iteration 503: Loss = 0.40819886326789856
Iteration 504: Loss = 0.40814727544784546
Iteration 505: Loss = 0.4080931544303894
Iteration 506: Loss = 0.4080401659011841
Iteration 507: Loss = 0.40798765420913696
Iteration 508: Loss = 0.40793487429618835
Iteration 509: Loss = 0.4078824520111084
Iteration 510: Loss = 0.40783047676086426
Iteration 511: Loss = 0.4077776372432709
Iteration 512: Loss = 0.407725989818573
Iteration 513: Loss = 0.4076736569404602
Iteration 514: Loss = 0.40762144327163696
Iteration 515: Loss = 0.40756988525390625
Iteration 516: Loss = 0.4075184166431427
Iteration 517: Loss = 0.4074663519859314
Iteration 518: Loss = 0.40741509199142456
Iteration 519: Loss = 0.4073643088340759
Iteration 520: Loss = 0.4073125720024109
Iteration 521: Loss = 0.40726110339164734
Iteration 522: Loss = 0.4072103202342987
Iteration 523: Loss = 0.40715914964675903
Iteration 524: Loss = 0.4071081280708313
Iteration 525: Loss = 0.4070571959018707
Iteration 526: Loss = 0.40700656175613403
Iteration 527: Loss = 0.406955748796463
Iteration 528: Loss = 0.4069051444530487
Iteration 529: Loss = 0.4068548381328583
Iteration 530: Loss = 0.4068042039871216
Iteration 531: Loss = 0.4067540764808655
Iteration 532: Loss = 0.4067037105560303
Iteration 533: Loss = 0.4066532254219055
Iteration 534: Loss = 0.4066038727760315
Iteration 535: Loss = 0.40655332803726196
Iteration 536: Loss = 0.40650326013565063
Iteration 537: Loss = 0.4064536392688751
Iteration 538: Loss = 0.406403124332428
Iteration 539: Loss = 0.4063533544540405
Iteration 540: Loss = 0.40630337595939636
Iteration 541: Loss = 0.40625354647636414
Iteration 542: Loss = 0.4062039256095886
Iteration 543: Loss = 0.4061543047428131
Iteration 544: Loss = 0.40610501170158386
Iteration 545: Loss = 0.40605536103248596
Iteration 546: Loss = 0.4060058295726776
Iteration 547: Loss = 0.4059564769268036
Iteration 548: Loss = 0.4059067964553833
Iteration 549: Loss = 0.40585777163505554
Iteration 550: Loss = 0.40580853819847107
Iteration 551: Loss = 0.40575915575027466
Iteration 552: Loss = 0.40570974349975586
Iteration 553: Loss = 0.4056607782840729
Iteration 554: Loss = 0.40561163425445557
Iteration 555: Loss = 0.4055621027946472
Iteration 556: Loss = 0.40551289916038513
Iteration 557: Loss = 0.4054638743400574
Iteration 558: Loss = 0.4054146111011505
Iteration 559: Loss = 0.4053656756877899
Iteration 560: Loss = 0.40531638264656067
Iteration 561: Loss = 0.4052673280239105
Iteration 562: Loss = 0.4052184224128723
Iteration 563: Loss = 0.40516915917396545
Iteration 564: Loss = 0.40512028336524963
Iteration 565: Loss = 0.4050711691379547
Iteration 566: Loss = 0.4050218164920807
Iteration 567: Loss = 0.4049733877182007
Iteration 568: Loss = 0.40492358803749084
Iteration 569: Loss = 0.4048747718334198
Iteration 570: Loss = 0.40482527017593384
Iteration 571: Loss = 0.40477636456489563
Iteration 572: Loss = 0.40472716093063354
Iteration 573: Loss = 0.4046776592731476
Iteration 574: Loss = 0.40462836623191833
Iteration 575: Loss = 0.40457892417907715
Iteration 576: Loss = 0.4045296609401703
Iteration 577: Loss = 0.40448033809661865
Iteration 578: Loss = 0.40443071722984314
Iteration 579: Loss = 0.40438076853752136
Iteration 580: Loss = 0.4043318033218384
Iteration 581: Loss = 0.40428200364112854
Iteration 582: Loss = 0.40423211455345154
Iteration 583: Loss = 0.40418344736099243
Iteration 584: Loss = 0.4041321575641632
Iteration 585: Loss = 0.4040825366973877
Iteration 586: Loss = 0.4040326178073883
Iteration 587: Loss = 0.4039818346500397
Iteration 588: Loss = 0.4039325416088104
Iteration 589: Loss = 0.4038819670677185
Iteration 590: Loss = 0.4038310647010803
Iteration 591: Loss = 0.403780996799469
Iteration 592: Loss = 0.40372979640960693
Iteration 593: Loss = 0.40367913246154785
Iteration 594: Loss = 0.40362873673439026
Iteration 595: Loss = 0.40357688069343567
Iteration 596: Loss = 0.4035254120826721
Iteration 597: Loss = 0.40347424149513245
Iteration 598: Loss = 0.4034227132797241
Iteration 599: Loss = 0.40337061882019043
Iteration 600: Loss = 0.4033184349536896
Iteration 601: Loss = 0.4032664895057678
Iteration 602: Loss = 0.4032142758369446
Iteration 603: Loss = 0.40316179394721985
Iteration 604: Loss = 0.40310925245285034
Iteration 605: Loss = 0.4030563533306122
Iteration 606: Loss = 0.40300294756889343
Iteration 607: Loss = 0.4029499888420105
Iteration 608: Loss = 0.40289610624313354
Iteration 609: Loss = 0.4028422236442566
Iteration 610: Loss = 0.4027879238128662
Iteration 611: Loss = 0.40273356437683105
Iteration 612: Loss = 0.40267908573150635
Iteration 613: Loss = 0.40262430906295776
Iteration 614: Loss = 0.40256908535957336
Iteration 615: Loss = 0.4025135636329651
Iteration 616: Loss = 0.4024573564529419
Iteration 617: Loss = 0.4024014174938202
Iteration 618: Loss = 0.4023444950580597
Iteration 619: Loss = 0.40228766202926636
Iteration 620: Loss = 0.40223002433776855
Iteration 621: Loss = 0.40217235684394836
Iteration 622: Loss = 0.40211406350135803
Iteration 623: Loss = 0.40205544233322144
Iteration 624: Loss = 0.4019964337348938
Iteration 625: Loss = 0.40193691849708557
Iteration 626: Loss = 0.40187638998031616
Iteration 627: Loss = 0.4018162488937378
Iteration 628: Loss = 0.4017547070980072
Iteration 629: Loss = 0.4016934335231781
Iteration 630: Loss = 0.4016309082508087
Iteration 631: Loss = 0.40156829357147217
Iteration 632: Loss = 0.4015052616596222
Iteration 633: Loss = 0.40144065022468567
Iteration 634: Loss = 0.4013759195804596
Iteration 635: Loss = 0.4013109803199768
Iteration 636: Loss = 0.40124472975730896
Iteration 637: Loss = 0.40117791295051575
Iteration 638: Loss = 0.4011107087135315
Iteration 639: Loss = 0.40104180574417114
Iteration 640: Loss = 0.40097302198410034
Iteration 641: Loss = 0.40090280771255493
Iteration 642: Loss = 0.40083202719688416
Iteration 643: Loss = 0.4007605016231537
Iteration 644: Loss = 0.40068647265434265
Iteration 645: Loss = 0.4006139934062958
Iteration 646: Loss = 0.4005375802516937
Iteration 647: Loss = 0.4004625678062439
Iteration 648: Loss = 0.4003855884075165
Iteration 649: Loss = 0.40030694007873535
Iteration 650: Loss = 0.40022823214530945
Iteration 651: Loss = 0.4001474380493164
Iteration 652: Loss = 0.4000660479068756
Iteration 653: Loss = 0.3999827206134796
Iteration 654: Loss = 0.3998976945877075
Iteration 655: Loss = 0.3998118042945862
Iteration 656: Loss = 0.3997233510017395
Iteration 657: Loss = 0.39962977170944214
Iteration 658: Loss = 0.3995257019996643
Iteration 659: Loss = 0.39945095777511597
Iteration 660: Loss = 0.3993377983570099
Iteration 661: Loss = 0.39925023913383484
Iteration 662: Loss = 0.39915233850479126
Iteration 663: Loss = 0.39904162287712097
Iteration 664: Loss = 0.39894723892211914
Iteration 665: Loss = 0.3988339602947235
Iteration 666: Loss = 0.39872896671295166
Iteration 667: Loss = 0.3986207842826843
Iteration 668: Loss = 0.3985026776790619
Iteration 669: Loss = 0.3983905017375946
Iteration 670: Loss = 0.398269921541214
Iteration 671: Loss = 0.3981490135192871
Iteration 672: Loss = 0.3980266749858856
Iteration 673: Loss = 0.3978969156742096
Iteration 674: Loss = 0.3977702260017395
Iteration 675: Loss = 0.39763587713241577
Iteration 676: Loss = 0.39750126004219055
Iteration 677: Loss = 0.3973630368709564
Iteration 678: Loss = 0.39721885323524475
Iteration 679: Loss = 0.39707568287849426
Iteration 680: Loss = 0.3969251811504364
Iteration 681: Loss = 0.39677438139915466
Iteration 682: Loss = 0.39661699533462524
Iteration 683: Loss = 0.39645737409591675
Iteration 684: Loss = 0.39629340171813965
Iteration 685: Loss = 0.3961247205734253
Iteration 686: Loss = 0.3959556221961975
Iteration 687: Loss = 0.39577844738960266
Iteration 688: Loss = 0.3956013321876526
Iteration 689: Loss = 0.3954172730445862
Iteration 690: Loss = 0.3952304720878601
Iteration 691: Loss = 0.3950398564338684
Iteration 692: Loss = 0.39484506845474243
Iteration 693: Loss = 0.3946477472782135
Iteration 694: Loss = 0.3944472372531891
Iteration 695: Loss = 0.39424359798431396
Iteration 696: Loss = 0.39403611421585083
Iteration 697: Loss = 0.393827348947525
Iteration 698: Loss = 0.39361572265625
Iteration 699: Loss = 0.3934028744697571
Iteration 700: Loss = 0.3931877017021179
Iteration 701: Loss = 0.39297178387641907
Iteration 702: Loss = 0.3927547037601471
Iteration 703: Loss = 0.3925383985042572
Iteration 704: Loss = 0.39232337474823
Iteration 705: Loss = 0.3921087682247162
Iteration 706: Loss = 0.3918974995613098
Iteration 707: Loss = 0.3916894495487213
Iteration 708: Loss = 0.39148515462875366
Iteration 709: Loss = 0.3912868797779083
Iteration 710: Loss = 0.39109209179878235
Iteration 711: Loss = 0.3909025192260742
Iteration 712: Loss = 0.39072009921073914
Iteration 713: Loss = 0.39054372906684875
Iteration 714: Loss = 0.39037469029426575
Iteration 715: Loss = 0.3902123272418976
Iteration 716: Loss = 0.3900565207004547
Iteration 717: Loss = 0.3899075984954834
Iteration 718: Loss = 0.38976427912712097
Iteration 719: Loss = 0.3896263539791107
Iteration 720: Loss = 0.38949233293533325
Iteration 721: Loss = 0.3893606960773468
Iteration 722: Loss = 0.3892316520214081
Iteration 723: Loss = 0.3891024887561798
Iteration 724: Loss = 0.3889748454093933
Iteration 725: Loss = 0.3888440728187561
Iteration 726: Loss = 0.3887135088443756
Iteration 727: Loss = 0.3885801434516907
Iteration 728: Loss = 0.3884439170360565
Iteration 729: Loss = 0.3883090317249298
Iteration 730: Loss = 0.3881675601005554
Iteration 731: Loss = 0.3880273401737213
Iteration 732: Loss = 0.38788583874702454
Iteration 733: Loss = 0.387742817401886
Iteration 734: Loss = 0.3875998556613922
Iteration 735: Loss = 0.3874572217464447
Iteration 736: Loss = 0.3873140215873718
Iteration 737: Loss = 0.38717231154441833
Iteration 738: Loss = 0.3870309889316559
Iteration 739: Loss = 0.38688966631889343
Iteration 740: Loss = 0.3867497146129608
Iteration 741: Loss = 0.38661059737205505
Iteration 742: Loss = 0.38647204637527466
Iteration 743: Loss = 0.38633379340171814
Iteration 744: Loss = 0.38619542121887207
Iteration 745: Loss = 0.3860588073730469
Iteration 746: Loss = 0.38592198491096497
Iteration 747: Loss = 0.38578471541404724
Iteration 748: Loss = 0.38564854860305786
Iteration 749: Loss = 0.38551008701324463
Iteration 750: Loss = 0.385375052690506
Iteration 751: Loss = 0.3852367103099823
Iteration 752: Loss = 0.3850997984409332
Iteration 753: Loss = 0.3849639892578125
Iteration 754: Loss = 0.3848233222961426
Iteration 755: Loss = 0.38468918204307556
Iteration 756: Loss = 0.38454771041870117
Iteration 757: Loss = 0.3844115436077118
Iteration 758: Loss = 0.3842717707157135
Iteration 759: Loss = 0.3841317892074585
Iteration 760: Loss = 0.3839954137802124
Iteration 761: Loss = 0.38385480642318726
Iteration 762: Loss = 0.3837186098098755
Iteration 763: Loss = 0.38357922434806824
Iteration 764: Loss = 0.38343939185142517
Iteration 765: Loss = 0.3833019435405731
Iteration 766: Loss = 0.3831615149974823
Iteration 767: Loss = 0.3830243945121765
Iteration 768: Loss = 0.3828846514225006
Iteration 769: Loss = 0.38274553418159485
Iteration 770: Loss = 0.38260817527770996
Iteration 771: Loss = 0.38246601819992065
Iteration 772: Loss = 0.3823299705982208
Iteration 773: Loss = 0.38218677043914795
Iteration 774: Loss = 0.3820464611053467
Iteration 775: Loss = 0.3819049894809723
Iteration 776: Loss = 0.38175973296165466
Iteration 777: Loss = 0.38161784410476685
Iteration 778: Loss = 0.3814637362957001
Iteration 779: Loss = 0.38130560517311096
Iteration 780: Loss = 0.3811028301715851
Iteration 781: Loss = 0.38084039092063904
Iteration 782: Loss = 0.38062044978141785
Iteration 783: Loss = 0.3804410398006439
Iteration 784: Loss = 0.3803297281265259
Iteration 785: Loss = 0.38019758462905884
Iteration 786: Loss = 0.38002943992614746
Iteration 787: Loss = 0.379824161529541
Iteration 788: Loss = 0.3795916736125946
Iteration 789: Loss = 0.37938693165779114
Iteration 790: Loss = 0.3792033791542053
Iteration 791: Loss = 0.3790423572063446
Iteration 792: Loss = 0.378885418176651
Iteration 793: Loss = 0.37870660424232483
Iteration 794: Loss = 0.37851178646087646
Iteration 795: Loss = 0.3783091604709625
Iteration 796: Loss = 0.37810540199279785
Iteration 797: Loss = 0.37792032957077026
Iteration 798: Loss = 0.3777403235435486
Iteration 799: Loss = 0.3775670826435089
Iteration 800: Loss = 0.37738826870918274
Iteration 801: Loss = 0.37719643115997314
Iteration 802: Loss = 0.3770023286342621
Iteration 803: Loss = 0.3768044114112854
Iteration 804: Loss = 0.3766135573387146
Iteration 805: Loss = 0.3764314651489258
Iteration 806: Loss = 0.3762477934360504
Iteration 807: Loss = 0.37606289982795715
Iteration 808: Loss = 0.3758748769760132
Iteration 809: Loss = 0.37568122148513794
Iteration 810: Loss = 0.37549176812171936
Iteration 811: Loss = 0.3752988874912262
Iteration 812: Loss = 0.37511563301086426
Iteration 813: Loss = 0.3749256730079651
Iteration 814: Loss = 0.3747369647026062
Iteration 815: Loss = 0.37454819679260254
Iteration 816: Loss = 0.37435540556907654
Iteration 817: Loss = 0.37416404485702515
Iteration 818: Loss = 0.37397265434265137
Iteration 819: Loss = 0.3737829923629761
Iteration 820: Loss = 0.3735926151275635
Iteration 821: Loss = 0.37340250611305237
Iteration 822: Loss = 0.37321045994758606
Iteration 823: Loss = 0.3730173110961914
Iteration 824: Loss = 0.37282437086105347
Iteration 825: Loss = 0.3726310729980469
Iteration 826: Loss = 0.3724382519721985
Iteration 827: Loss = 0.3722454309463501
Iteration 828: Loss = 0.3720515966415405
Iteration 829: Loss = 0.3718574345111847
Iteration 830: Loss = 0.37166300415992737
Iteration 831: Loss = 0.37146785855293274
Iteration 832: Loss = 0.3712722659111023
Iteration 833: Loss = 0.3710767328739166
Iteration 834: Loss = 0.3708809018135071
Iteration 835: Loss = 0.370684415102005
Iteration 836: Loss = 0.37048786878585815
Iteration 837: Loss = 0.3702889084815979
Iteration 838: Loss = 0.37009355425834656
Iteration 839: Loss = 0.3698934018611908
Iteration 840: Loss = 0.3696945309638977
Iteration 841: Loss = 0.36949455738067627
Iteration 842: Loss = 0.3692947030067444
Iteration 843: Loss = 0.3690943717956543
Iteration 844: Loss = 0.36889344453811646
Iteration 845: Loss = 0.368691623210907
Iteration 846: Loss = 0.3684900999069214
Iteration 847: Loss = 0.3682880103588104
Iteration 848: Loss = 0.36808496713638306
Iteration 849: Loss = 0.3678824305534363
Iteration 850: Loss = 0.3676777482032776
Iteration 851: Loss = 0.36747443675994873
Iteration 852: Loss = 0.36726903915405273
Iteration 853: Loss = 0.36706361174583435
Iteration 854: Loss = 0.36685681343078613
Iteration 855: Loss = 0.3666521906852722
Iteration 856: Loss = 0.3664454519748688
Iteration 857: Loss = 0.36623579263687134
Iteration 858: Loss = 0.36602795124053955
Iteration 859: Loss = 0.36581969261169434
Iteration 860: Loss = 0.36560988426208496
Iteration 861: Loss = 0.3653992712497711
Iteration 862: Loss = 0.3651898205280304
Iteration 863: Loss = 0.3649795353412628
Iteration 864: Loss = 0.364766389131546
Iteration 865: Loss = 0.3645561933517456
Iteration 866: Loss = 0.36434292793273926
Iteration 867: Loss = 0.3641316592693329
Iteration 868: Loss = 0.3639167249202728
Iteration 869: Loss = 0.36370158195495605
Iteration 870: Loss = 0.3634907603263855
Iteration 871: Loss = 0.36327147483825684
Iteration 872: Loss = 0.36305636167526245
Iteration 873: Loss = 0.36283889412879944
Iteration 874: Loss = 0.3626251816749573
Iteration 875: Loss = 0.362403005361557
Iteration 876: Loss = 0.362186998128891
Iteration 877: Loss = 0.3619673550128937
Iteration 878: Loss = 0.36174672842025757
Iteration 879: Loss = 0.3615277409553528
Iteration 880: Loss = 0.36130326986312866
Iteration 881: Loss = 0.3610871136188507
Iteration 882: Loss = 0.3608601987361908
Iteration 883: Loss = 0.3606429696083069
Iteration 884: Loss = 0.3604164123535156
Iteration 885: Loss = 0.36019232869148254
Iteration 886: Loss = 0.3599701225757599
Iteration 887: Loss = 0.35974130034446716
Iteration 888: Loss = 0.35952064394950867
Iteration 889: Loss = 0.3592875003814697
Iteration 890: Loss = 0.35906365513801575
Iteration 891: Loss = 0.3588317334651947
Iteration 892: Loss = 0.35860830545425415
Iteration 893: Loss = 0.3583742678165436
Iteration 894: Loss = 0.3581472337245941
Iteration 895: Loss = 0.3579157590866089
Iteration 896: Loss = 0.35768216848373413
Iteration 897: Loss = 0.3574521839618683
Iteration 898: Loss = 0.35721641778945923
Iteration 899: Loss = 0.35698434710502625
Iteration 900: Loss = 0.3567500114440918
Iteration 901: Loss = 0.35651496052742004
Iteration 902: Loss = 0.35627880692481995
Iteration 903: Loss = 0.35604313015937805
Iteration 904: Loss = 0.35580649971961975
Iteration 905: Loss = 0.35556846857070923
Iteration 906: Loss = 0.3553299605846405
Iteration 907: Loss = 0.3550914525985718
Iteration 908: Loss = 0.3548511266708374
Iteration 909: Loss = 0.3546106815338135
Iteration 910: Loss = 0.3543693721294403
Iteration 911: Loss = 0.3541281223297119
Iteration 912: Loss = 0.35388535261154175
Iteration 913: Loss = 0.35364073514938354
Iteration 914: Loss = 0.3533961772918701
Iteration 915: Loss = 0.3531528413295746
Iteration 916: Loss = 0.3529057800769806
Iteration 917: Loss = 0.35265982151031494
Iteration 918: Loss = 0.3524114787578583
Iteration 919: Loss = 0.3521648943424225
Iteration 920: Loss = 0.35191410779953003
Iteration 921: Loss = 0.3516649901866913
Iteration 922: Loss = 0.3514139652252197
Iteration 923: Loss = 0.3511624038219452
Iteration 924: Loss = 0.3509117066860199
Iteration 925: Loss = 0.3506579101085663
Iteration 926: Loss = 0.35040542483329773
Iteration 927: Loss = 0.3501492142677307
Iteration 928: Loss = 0.34989452362060547
Iteration 929: Loss = 0.34963753819465637
Iteration 930: Loss = 0.34938114881515503
Iteration 931: Loss = 0.34912335872650146
Iteration 932: Loss = 0.3488638401031494
Iteration 933: Loss = 0.3486049771308899
Iteration 934: Loss = 0.34834423661231995
Iteration 935: Loss = 0.34808221459388733
Iteration 936: Loss = 0.3478206694126129
Iteration 937: Loss = 0.34755733609199524
Iteration 938: Loss = 0.34729400277137756
Iteration 939: Loss = 0.34702858328819275
Iteration 940: Loss = 0.34676316380500793
Iteration 941: Loss = 0.3464958965778351
Iteration 942: Loss = 0.34622862935066223
Iteration 943: Loss = 0.34596017003059387
Iteration 944: Loss = 0.34569039940834045
Iteration 945: Loss = 0.3454205095767975
Iteration 946: Loss = 0.3451489806175232
Iteration 947: Loss = 0.34487664699554443
Iteration 948: Loss = 0.34460389614105225
Iteration 949: Loss = 0.3443294167518616
Iteration 950: Loss = 0.344054251909256
Iteration 951: Loss = 0.3437782824039459
Iteration 952: Loss = 0.3435012102127075
Iteration 953: Loss = 0.34322378039360046
Iteration 954: Loss = 0.3429447114467621
Iteration 955: Loss = 0.34266558289527893
Iteration 956: Loss = 0.34238603711128235
Iteration 957: Loss = 0.34210264682769775
Iteration 958: Loss = 0.3418194651603699
Iteration 959: Loss = 0.34153512120246887
Iteration 960: Loss = 0.3412513732910156
Iteration 961: Loss = 0.3409642279148102
Iteration 962: Loss = 0.34067973494529724
Iteration 963: Loss = 0.3403896987438202
Iteration 964: Loss = 0.34010419249534607
Iteration 965: Loss = 0.33980998396873474
Iteration 966: Loss = 0.33952653408050537
Iteration 967: Loss = 0.33922693133354187
Iteration 968: Loss = 0.33893710374832153
Iteration 969: Loss = 0.33863985538482666
Iteration 970: Loss = 0.3383485972881317
Iteration 971: Loss = 0.3380484879016876
Iteration 972: Loss = 0.33775296807289124
Iteration 973: Loss = 0.33745306730270386
Iteration 974: Loss = 0.33715564012527466
Iteration 975: Loss = 0.33685338497161865
Iteration 976: Loss = 0.33655494451522827
Iteration 977: Loss = 0.3362490236759186
Iteration 978: Loss = 0.3359491229057312
Iteration 979: Loss = 0.3356408476829529
Iteration 980: Loss = 0.33533865213394165
Iteration 981: Loss = 0.3350270986557007
Iteration 982: Loss = 0.3347233831882477
Iteration 983: Loss = 0.33440929651260376
Iteration 984: Loss = 0.3341015577316284
Iteration 985: Loss = 0.3337869942188263
Iteration 986: Loss = 0.3334777355194092
Iteration 987: Loss = 0.33316028118133545
Iteration 988: Loss = 0.33284711837768555
Iteration 989: Loss = 0.33252832293510437
Iteration 990: Loss = 0.3322147727012634
Iteration 991: Loss = 0.33189278841018677
Iteration 992: Loss = 0.3315752148628235
Iteration 993: Loss = 0.3312505781650543
Iteration 994: Loss = 0.3309330344200134
Iteration 995: Loss = 0.3306044638156891
Iteration 996: Loss = 0.3302825093269348
Iteration 997: Loss = 0.3299533426761627
Iteration 998: Loss = 0.32963109016418457
Iteration 999: Loss = 0.3292972445487976
Iteration 1000: Loss = 0.32896965742111206


Total training time (seconds): 9.31
