Iteration 1: Loss = 0.9050589799880981
Iteration 2: Loss = 0.9006386995315552
Iteration 3: Loss = 0.8962369561195374
Iteration 4: Loss = 0.8918548822402954
Iteration 5: Loss = 0.8874934315681458
Iteration 6: Loss = 0.8831536173820496
Iteration 7: Loss = 0.878836452960968
Iteration 8: Loss = 0.8745429515838623
Iteration 9: Loss = 0.8702742457389832
Iteration 10: Loss = 0.866040825843811
Iteration 11: Loss = 0.8618535399436951
Iteration 12: Loss = 0.8577151298522949
Iteration 13: Loss = 0.8536251187324524
Iteration 14: Loss = 0.8495798707008362
Iteration 15: Loss = 0.845575749874115
Iteration 16: Loss = 0.8416088819503784
Iteration 17: Loss = 0.8376769423484802
Iteration 18: Loss = 0.8337783813476562
Iteration 19: Loss = 0.8299121856689453
Iteration 20: Loss = 0.8260777592658997
Iteration 21: Loss = 0.822275698184967
Iteration 22: Loss = 0.8185059428215027
Iteration 23: Loss = 0.8147685527801514
Iteration 24: Loss = 0.8110645413398743
Iteration 25: Loss = 0.8073939085006714
Iteration 26: Loss = 0.8037571907043457
Iteration 27: Loss = 0.8001551032066345
Iteration 28: Loss = 0.7965878248214722
Iteration 29: Loss = 0.7930558919906616
Iteration 30: Loss = 0.789559543132782
Iteration 31: Loss = 0.7860994935035706
Iteration 32: Loss = 0.7826759219169617
Iteration 33: Loss = 0.7792890667915344
Iteration 34: Loss = 0.7759393453598022
Iteration 35: Loss = 0.772627055644989
Iteration 36: Loss = 0.7693523168563843
Iteration 37: Loss = 0.7661154270172119
Iteration 38: Loss = 0.7629163861274719
Iteration 39: Loss = 0.7597554922103882
Iteration 40: Loss = 0.7566326856613159
Iteration 41: Loss = 0.7535482048988342
Iteration 42: Loss = 0.7505016922950745
Iteration 43: Loss = 0.7474933862686157
Iteration 44: Loss = 0.7445234060287476
Iteration 45: Loss = 0.741591215133667
Iteration 46: Loss = 0.7386969923973083
Iteration 47: Loss = 0.7358405590057373
Iteration 48: Loss = 0.7330217361450195
Iteration 49: Loss = 0.7302401661872864
Iteration 50: Loss = 0.7274957895278931
Iteration 51: Loss = 0.7247881889343262
Iteration 52: Loss = 0.7221173048019409
Iteration 53: Loss = 0.7194828391075134
Iteration 54: Loss = 0.7168843746185303
Iteration 55: Loss = 0.7143217921257019
Iteration 56: Loss = 0.7117944359779358
Iteration 57: Loss = 0.7093023657798767
Iteration 58: Loss = 0.7068449258804321
Iteration 59: Loss = 0.7044219374656677
Iteration 60: Loss = 0.7020331025123596
Iteration 61: Loss = 0.6996778845787048
Iteration 62: Loss = 0.6973560452461243
Iteration 63: Loss = 0.6950668692588806
Iteration 64: Loss = 0.692810595035553
Iteration 65: Loss = 0.6905864477157593
Iteration 66: Loss = 0.6883938312530518
Iteration 67: Loss = 0.6862326860427856
Iteration 68: Loss = 0.6841025948524475
Iteration 69: Loss = 0.6820029020309448
Iteration 70: Loss = 0.6799335479736328
Iteration 71: Loss = 0.6778938174247742
Iteration 72: Loss = 0.6758834719657898
Iteration 73: Loss = 0.6739020943641663
Iteration 74: Loss = 0.6719492077827454
Iteration 75: Loss = 0.6700243949890137
Iteration 76: Loss = 0.6681274175643921
Iteration 77: Loss = 0.6662577390670776
Iteration 78: Loss = 0.6644150614738464
Iteration 79: Loss = 0.6625987887382507
Iteration 80: Loss = 0.6608086228370667
Iteration 81: Loss = 0.6590442657470703
Iteration 82: Loss = 0.657305121421814
Iteration 83: Loss = 0.6555910110473633
Iteration 84: Loss = 0.6539014577865601
Iteration 85: Loss = 0.6522360444068909
Iteration 86: Loss = 0.6505942344665527
Iteration 87: Loss = 0.6489760279655457
Iteration 88: Loss = 0.6473806500434875
Iteration 89: Loss = 0.6458080410957336
Iteration 90: Loss = 0.6442576050758362
Iteration 91: Loss = 0.6427292227745056
Iteration 92: Loss = 0.6412224173545837
Iteration 93: Loss = 0.6397365927696228
Iteration 94: Loss = 0.638271689414978
Iteration 95: Loss = 0.636827290058136
Iteration 96: Loss = 0.635403037071228
Iteration 97: Loss = 0.6339985132217407
Iteration 98: Loss = 0.6326136589050293
Iteration 99: Loss = 0.6312477588653564
Iteration 100: Loss = 0.6299007534980774
Iteration 101: Loss = 0.6285722255706787
Iteration 102: Loss = 0.6272618174552917
Iteration 103: Loss = 0.6259692907333374
Iteration 104: Loss = 0.6246944069862366
Iteration 105: Loss = 0.6234366297721863
Iteration 106: Loss = 0.622195839881897
Iteration 107: Loss = 0.6209717392921448
Iteration 108: Loss = 0.619763970375061
Iteration 109: Loss = 0.6185722947120667
Iteration 110: Loss = 0.6173964142799377
Iteration 111: Loss = 0.61623615026474
Iteration 112: Loss = 0.6150909662246704
Iteration 113: Loss = 0.613960862159729
Iteration 114: Loss = 0.6128454208374023
Iteration 115: Loss = 0.6117444634437561
Iteration 116: Loss = 0.6106577515602112
Iteration 117: Loss = 0.6095849275588989
Iteration 118: Loss = 0.6085258722305298
Iteration 119: Loss = 0.6074803471565247
Iteration 120: Loss = 0.6064479351043701
Iteration 121: Loss = 0.6054285168647766
Iteration 122: Loss = 0.604421854019165
Iteration 123: Loss = 0.6034277677536011
Iteration 124: Loss = 0.6024460792541504
Iteration 125: Loss = 0.6014764308929443
Iteration 126: Loss = 0.6005187034606934
Iteration 127: Loss = 0.5995725989341736
Iteration 128: Loss = 0.5986379384994507
Iteration 129: Loss = 0.5977147221565247
Iteration 130: Loss = 0.5968024134635925
Iteration 131: Loss = 0.5959010720252991
Iteration 132: Loss = 0.5950103998184204
Iteration 133: Loss = 0.5941301584243774
Iteration 134: Loss = 0.5932602882385254
Iteration 135: Loss = 0.5924004316329956
Iteration 136: Loss = 0.5915507078170776
Iteration 137: Loss = 0.5907106995582581
Iteration 138: Loss = 0.5898802280426025
Iteration 139: Loss = 0.5890592336654663
Iteration 140: Loss = 0.5882474780082703
Iteration 141: Loss = 0.5874449610710144
Iteration 142: Loss = 0.5866512060165405
Iteration 143: Loss = 0.5858663320541382
Iteration 144: Loss = 0.5850901007652283
Iteration 145: Loss = 0.5843223333358765
Iteration 146: Loss = 0.5835628509521484
Iteration 147: Loss = 0.5828115940093994
Iteration 148: Loss = 0.5820683836936951
Iteration 149: Loss = 0.5813330411911011
Iteration 150: Loss = 0.5806054472923279
Iteration 151: Loss = 0.5798854827880859
Iteration 152: Loss = 0.5791730880737305
Iteration 153: Loss = 0.5784680247306824
Iteration 154: Loss = 0.5777701139450073
Iteration 155: Loss = 0.5770793557167053
Iteration 156: Loss = 0.5763956308364868
Iteration 157: Loss = 0.5757187008857727
Iteration 158: Loss = 0.5750484466552734
Iteration 159: Loss = 0.5743849277496338
Iteration 160: Loss = 0.5737279057502747
Iteration 161: Loss = 0.5730772018432617
Iteration 162: Loss = 0.572432816028595
Iteration 163: Loss = 0.5717945694923401
Iteration 164: Loss = 0.5711623430252075
Iteration 165: Loss = 0.5705361366271973
Iteration 166: Loss = 0.5699157118797302
Iteration 167: Loss = 0.5693010091781616
Iteration 168: Loss = 0.5686920285224915
Iteration 169: Loss = 0.5680884122848511
Iteration 170: Loss = 0.5674904584884644
Iteration 171: Loss = 0.5668977499008179
Iteration 172: Loss = 0.5663102865219116
Iteration 173: Loss = 0.565727949142456
Iteration 174: Loss = 0.5651506781578064
Iteration 175: Loss = 0.5645784139633179
Iteration 176: Loss = 0.5640110373497009
Iteration 177: Loss = 0.5634483695030212
Iteration 178: Loss = 0.5628905296325684
Iteration 179: Loss = 0.5623372793197632
Iteration 180: Loss = 0.5617884993553162
Iteration 181: Loss = 0.5612441301345825
Iteration 182: Loss = 0.560704231262207
Iteration 183: Loss = 0.5601686239242554
Iteration 184: Loss = 0.559637188911438
Iteration 185: Loss = 0.5591099858283997
Iteration 186: Loss = 0.5585867166519165
Iteration 187: Loss = 0.5580675601959229
Iteration 188: Loss = 0.55755215883255
Iteration 189: Loss = 0.5570406913757324
Iteration 190: Loss = 0.5565330982208252
Iteration 191: Loss = 0.5560290813446045
Iteration 192: Loss = 0.5555287003517151
Iteration 193: Loss = 0.5550318360328674
Iteration 194: Loss = 0.5545384883880615
Iteration 195: Loss = 0.5540486574172974
Iteration 196: Loss = 0.5535621047019958
Iteration 197: Loss = 0.5530788898468018
Iteration 198: Loss = 0.5525988936424255
Iteration 199: Loss = 0.5521220564842224
Iteration 200: Loss = 0.5516483187675476
Iteration 201: Loss = 0.5511776208877563
Iteration 202: Loss = 0.5507099628448486
Iteration 203: Loss = 0.5502451062202454
Iteration 204: Loss = 0.5497832298278809
Iteration 205: Loss = 0.549324095249176
Iteration 206: Loss = 0.5488677620887756
Iteration 207: Loss = 0.5484140515327454
Iteration 208: Loss = 0.54796302318573
Iteration 209: Loss = 0.5475145578384399
Iteration 210: Loss = 0.5470685958862305
Iteration 211: Loss = 0.5466251969337463
Iteration 212: Loss = 0.5461840629577637
Iteration 213: Loss = 0.5457454323768616
Iteration 214: Loss = 0.5453090071678162
Iteration 215: Loss = 0.5448750257492065
Iteration 216: Loss = 0.5444430112838745
Iteration 217: Loss = 0.544013261795044
Iteration 218: Loss = 0.5435856580734253
Iteration 219: Loss = 0.5431600213050842
Iteration 220: Loss = 0.5427364706993103
Iteration 221: Loss = 0.542314887046814
Iteration 222: Loss = 0.5418952107429504
Iteration 223: Loss = 0.541477382183075
Iteration 224: Loss = 0.5410614013671875
Iteration 225: Loss = 0.5406471490859985
Iteration 226: Loss = 0.5402346253395081
Iteration 227: Loss = 0.5398238301277161
Iteration 228: Loss = 0.539414644241333
Iteration 229: Loss = 0.5390070676803589
Iteration 230: Loss = 0.5386010408401489
Iteration 231: Loss = 0.5381964445114136
Iteration 232: Loss = 0.5377934575080872
Iteration 233: Loss = 0.5373917818069458
Iteration 234: Loss = 0.536991536617279
Iteration 235: Loss = 0.5365925431251526
Iteration 236: Loss = 0.536194920539856
Iteration 237: Loss = 0.5357986092567444
Iteration 238: Loss = 0.5354033708572388
Iteration 239: Loss = 0.5350094437599182
Iteration 240: Loss = 0.5346165895462036
Iteration 241: Loss = 0.5342248678207397
Iteration 242: Loss = 0.5338341593742371
Iteration 243: Loss = 0.5334444642066956
Iteration 244: Loss = 0.5330557823181152
Iteration 245: Loss = 0.5326679944992065
Iteration 246: Loss = 0.5322811007499695
Iteration 247: Loss = 0.5318951606750488
Iteration 248: Loss = 0.5315099954605103
Iteration 249: Loss = 0.5311256051063538
Iteration 250: Loss = 0.5307419896125793
Iteration 251: Loss = 0.530359148979187
Iteration 252: Loss = 0.5299769043922424
Iteration 253: Loss = 0.5295953750610352
Iteration 254: Loss = 0.5292144417762756
Iteration 255: Loss = 0.5288340449333191
Iteration 256: Loss = 0.5284543037414551
Iteration 257: Loss = 0.5280750393867493
Iteration 258: Loss = 0.5276962518692017
Iteration 259: Loss = 0.5273178815841675
Iteration 260: Loss = 0.526939868927002
Iteration 261: Loss = 0.5265623927116394
Iteration 262: Loss = 0.526185154914856
Iteration 263: Loss = 0.5258083343505859
Iteration 264: Loss = 0.5254316926002502
Iteration 265: Loss = 0.5250553488731384
Iteration 266: Loss = 0.5246793031692505
Iteration 267: Loss = 0.5243033766746521
Iteration 268: Loss = 0.5239276885986328
Iteration 269: Loss = 0.5235521197319031
Iteration 270: Loss = 0.5231766104698181
Iteration 271: Loss = 0.5228011608123779
Iteration 272: Loss = 0.5224258303642273
Iteration 273: Loss = 0.5220505595207214
Iteration 274: Loss = 0.5216752290725708
Iteration 275: Loss = 0.5212998986244202
Iteration 276: Loss = 0.5209245681762695
Iteration 277: Loss = 0.5205490589141846
Iteration 278: Loss = 0.5201734900474548
Iteration 279: Loss = 0.5197978019714355
Iteration 280: Loss = 0.5194219946861267
Iteration 281: Loss = 0.519045889377594
Iteration 282: Loss = 0.5186696648597717
Iteration 283: Loss = 0.5182932019233704
Iteration 284: Loss = 0.5179165601730347
Iteration 285: Loss = 0.5175395607948303
Iteration 286: Loss = 0.5171623826026917
Iteration 287: Loss = 0.5167847871780396
Iteration 288: Loss = 0.5164068937301636
Iteration 289: Loss = 0.516028642654419
Iteration 290: Loss = 0.5156500339508057
Iteration 291: Loss = 0.5152710676193237
Iteration 292: Loss = 0.5148916840553284
Iteration 293: Loss = 0.5145118236541748
Iteration 294: Loss = 0.5141316056251526
Iteration 295: Loss = 0.5137509107589722
Iteration 296: Loss = 0.5133696794509888
Iteration 297: Loss = 0.5129880905151367
Iteration 298: Loss = 0.5126059651374817
Iteration 299: Loss = 0.5122232437133789
Iteration 300: Loss = 0.5118401050567627
Iteration 301: Loss = 0.5114563703536987
Iteration 302: Loss = 0.5110721588134766
Iteration 303: Loss = 0.5106873512268066
Iteration 304: Loss = 0.5103020071983337
Iteration 305: Loss = 0.5099161267280579
Iteration 306: Loss = 0.5095295906066895
Iteration 307: Loss = 0.5091426372528076
Iteration 308: Loss = 0.5087549686431885
Iteration 309: Loss = 0.5083666443824768
Iteration 310: Loss = 0.5079778432846069
Iteration 311: Loss = 0.5075884461402893
Iteration 312: Loss = 0.5071984529495239
Iteration 313: Loss = 0.506807804107666
Iteration 314: Loss = 0.5064166188240051
Iteration 315: Loss = 0.5060247778892517
Iteration 316: Loss = 0.5056324601173401
Iteration 317: Loss = 0.5052394866943359
Iteration 318: Loss = 0.504845917224884
Iteration 319: Loss = 0.5044518113136292
Iteration 320: Loss = 0.5040571093559265
Iteration 321: Loss = 0.5036618709564209
Iteration 322: Loss = 0.5032660961151123
Iteration 323: Loss = 0.5028697848320007
Iteration 324: Loss = 0.5024729371070862
Iteration 325: Loss = 0.5020756125450134
Iteration 326: Loss = 0.5016778111457825
Iteration 327: Loss = 0.5012794733047485
Iteration 328: Loss = 0.5008807182312012
Iteration 329: Loss = 0.5004814863204956
Iteration 330: Loss = 0.5000818967819214
Iteration 331: Loss = 0.49968186020851135
Iteration 332: Loss = 0.49928152561187744
Iteration 333: Loss = 0.4988808035850525
Iteration 334: Loss = 0.4984797537326813
Iteration 335: Loss = 0.49807843565940857
Iteration 336: Loss = 0.4976768493652344
Iteration 337: Loss = 0.49727505445480347
Iteration 338: Loss = 0.49687299132347107
Iteration 339: Loss = 0.4964708685874939
Iteration 340: Loss = 0.49606853723526
Iteration 341: Loss = 0.49566614627838135
Iteration 342: Loss = 0.4952637255191803
Iteration 343: Loss = 0.4948612451553345
Iteration 344: Loss = 0.4944588541984558
Iteration 345: Loss = 0.49405649304389954
Iteration 346: Loss = 0.4936543107032776
Iteration 347: Loss = 0.4932522177696228
Iteration 348: Loss = 0.4928504526615143
Iteration 349: Loss = 0.4924488961696625
Iteration 350: Loss = 0.49204760789871216
Iteration 351: Loss = 0.4916467070579529
Iteration 352: Loss = 0.4912462830543518
Iteration 353: Loss = 0.49084630608558655
Iteration 354: Loss = 0.4904468357563019
Iteration 355: Loss = 0.49004796147346497
Iteration 356: Loss = 0.48964977264404297
Iteration 357: Loss = 0.48925232887268066
Iteration 358: Loss = 0.48885560035705566
Iteration 359: Loss = 0.48845964670181274
Iteration 360: Loss = 0.488064706325531
Iteration 361: Loss = 0.4876707196235657
Iteration 362: Loss = 0.48727765679359436
Iteration 363: Loss = 0.48688581585884094
Iteration 364: Loss = 0.48649510741233826
Iteration 365: Loss = 0.48610562086105347
Iteration 366: Loss = 0.4857174754142761
Iteration 367: Loss = 0.4853306710720062
Iteration 368: Loss = 0.48494526743888855
Iteration 369: Loss = 0.4845614433288574
Iteration 370: Loss = 0.4841792583465576
Iteration 371: Loss = 0.48379865288734436
Iteration 372: Loss = 0.48341986536979675
Iteration 373: Loss = 0.4830428659915924
Iteration 374: Loss = 0.4826677143573761
Iteration 375: Loss = 0.4822945296764374
Iteration 376: Loss = 0.4819234013557434
Iteration 377: Loss = 0.48155438899993896
Iteration 378: Loss = 0.48118749260902405
Iteration 379: Loss = 0.48082295060157776
Iteration 380: Loss = 0.48046064376831055
Iteration 381: Loss = 0.48010072112083435
Iteration 382: Loss = 0.47974327206611633
Iteration 383: Loss = 0.47938835620880127
Iteration 384: Loss = 0.47903603315353394
Iteration 385: Loss = 0.4786863923072815
Iteration 386: Loss = 0.47833946347236633
Iteration 387: Loss = 0.477995365858078
Iteration 388: Loss = 0.4776540994644165
Iteration 389: Loss = 0.4773157835006714
Iteration 390: Loss = 0.4769805073738098
Iteration 391: Loss = 0.476648211479187
Iteration 392: Loss = 0.4763190448284149
Iteration 393: Loss = 0.47599300742149353
Iteration 394: Loss = 0.47567018866539
Iteration 395: Loss = 0.47535064816474915
Iteration 396: Loss = 0.4750344157218933
Iteration 397: Loss = 0.4747215807437897
Iteration 398: Loss = 0.47441205382347107
Iteration 399: Loss = 0.4741060733795166
Iteration 400: Loss = 0.4738035500049591
Iteration 401: Loss = 0.47350454330444336
Iteration 402: Loss = 0.47320911288261414
Iteration 403: Loss = 0.4729171693325043
Iteration 404: Loss = 0.47262901067733765
Iteration 405: Loss = 0.47234439849853516
Iteration 406: Loss = 0.47206348180770874
Iteration 407: Loss = 0.471786230802536
Iteration 408: Loss = 0.4715127646923065
Iteration 409: Loss = 0.4712429642677307
Iteration 410: Loss = 0.470976859331131
Iteration 411: Loss = 0.47071462869644165
Iteration 412: Loss = 0.4704560339450836
Iteration 413: Loss = 0.47020116448402405
Iteration 414: Loss = 0.4699501395225525
Iteration 415: Loss = 0.469702810049057
Iteration 416: Loss = 0.4694592356681824
Iteration 417: Loss = 0.4692193865776062
Iteration 418: Loss = 0.4689832031726837
Iteration 419: Loss = 0.4687507450580597
Iteration 420: Loss = 0.4685220420360565
Iteration 421: Loss = 0.46829697489738464
Iteration 422: Loss = 0.4680755138397217
Iteration 423: Loss = 0.46785768866539
Iteration 424: Loss = 0.46764346957206726
Iteration 425: Loss = 0.46743279695510864
Iteration 426: Loss = 0.467225581407547
Iteration 427: Loss = 0.4670218825340271
Iteration 428: Loss = 0.4668216407299042
Iteration 429: Loss = 0.46662476658821106
Iteration 430: Loss = 0.4664313495159149
Iteration 431: Loss = 0.46624115109443665
Iteration 432: Loss = 0.4660542607307434
Iteration 433: Loss = 0.46587055921554565
Iteration 434: Loss = 0.46569010615348816
Iteration 435: Loss = 0.4655126631259918
Iteration 436: Loss = 0.4653383493423462
Iteration 437: Loss = 0.46516698598861694
Iteration 438: Loss = 0.46499863266944885
Iteration 439: Loss = 0.4648331105709076
Iteration 440: Loss = 0.46467044949531555
Iteration 441: Loss = 0.46451058983802795
Iteration 442: Loss = 0.46435338258743286
Iteration 443: Loss = 0.46419888734817505
Iteration 444: Loss = 0.4640469253063202
Iteration 445: Loss = 0.4638975262641907
Iteration 446: Loss = 0.46375060081481934
Iteration 447: Loss = 0.4636060893535614
Iteration 448: Loss = 0.4634638726711273
Iteration 449: Loss = 0.4633238911628723
Iteration 450: Loss = 0.46318623423576355
Iteration 451: Loss = 0.46305063366889954
Iteration 452: Loss = 0.46291717886924744
Iteration 453: Loss = 0.4627857804298401
Iteration 454: Loss = 0.46265628933906555
Iteration 455: Loss = 0.46252867579460144
Iteration 456: Loss = 0.46240290999412537
Iteration 457: Loss = 0.4622790515422821
Iteration 458: Loss = 0.4621568024158478
Iteration 459: Loss = 0.46203625202178955
Iteration 460: Loss = 0.46191731095314026
Iteration 461: Loss = 0.46179988980293274
Iteration 462: Loss = 0.461683988571167
Iteration 463: Loss = 0.46156954765319824
Iteration 464: Loss = 0.4614564776420593
Iteration 465: Loss = 0.46134474873542786
Iteration 466: Loss = 0.46123430132865906
Iteration 467: Loss = 0.4611251652240753
Iteration 468: Loss = 0.46101710200309753
Iteration 469: Loss = 0.46091029047966003
Iteration 470: Loss = 0.4608044922351837
Iteration 471: Loss = 0.46069979667663574
Iteration 472: Loss = 0.46059614419937134
Iteration 473: Loss = 0.46049338579177856
Iteration 474: Loss = 0.4603916108608246
Iteration 475: Loss = 0.4602906405925751
Iteration 476: Loss = 0.46019062399864197
Iteration 477: Loss = 0.46009135246276855
Iteration 478: Loss = 0.4599928557872772
Iteration 479: Loss = 0.4598950743675232
Iteration 480: Loss = 0.459798127412796
Iteration 481: Loss = 0.45970168709754944
Iteration 482: Loss = 0.4596060514450073
Iteration 483: Loss = 0.4595109522342682
Iteration 484: Loss = 0.4594164490699768
Iteration 485: Loss = 0.4593225121498108
Iteration 486: Loss = 0.45922917127609253
Iteration 487: Loss = 0.4591362476348877
Iteration 488: Loss = 0.45904383063316345
Iteration 489: Loss = 0.4589518904685974
Iteration 490: Loss = 0.45886045694351196
Iteration 491: Loss = 0.45876944065093994
Iteration 492: Loss = 0.4586787819862366
Iteration 493: Loss = 0.45858851075172424
Iteration 494: Loss = 0.45849859714508057
Iteration 495: Loss = 0.45840907096862793
Iteration 496: Loss = 0.45831987261772156
Iteration 497: Loss = 0.4582310616970062
Iteration 498: Loss = 0.45814248919487
Iteration 499: Loss = 0.45805424451828003
Iteration 500: Loss = 0.45796629786491394
Iteration 501: Loss = 0.4578785300254822
Iteration 502: Loss = 0.45779111981391907
Iteration 503: Loss = 0.45770394802093506
Iteration 504: Loss = 0.45761704444885254
Iteration 505: Loss = 0.45753028988838196
Iteration 506: Loss = 0.45744383335113525
Iteration 507: Loss = 0.4573575556278229
Iteration 508: Loss = 0.4572714567184448
Iteration 509: Loss = 0.4571855664253235
Iteration 510: Loss = 0.4570998549461365
Iteration 511: Loss = 0.4570143520832062
Iteration 512: Loss = 0.45692893862724304
Iteration 513: Loss = 0.4568437933921814
Iteration 514: Loss = 0.4567587375640869
Iteration 515: Loss = 0.45667389035224915
Iteration 516: Loss = 0.4565891623497009
Iteration 517: Loss = 0.4565046429634094
Iteration 518: Loss = 0.4564201533794403
Iteration 519: Loss = 0.4563358724117279
Iteration 520: Loss = 0.45625174045562744
Iteration 521: Loss = 0.45616769790649414
Iteration 522: Loss = 0.4560838043689728
Iteration 523: Loss = 0.45600003004074097
Iteration 524: Loss = 0.4559163749217987
Iteration 525: Loss = 0.45583292841911316
Iteration 526: Loss = 0.4557495713233948
Iteration 527: Loss = 0.45566636323928833
Iteration 528: Loss = 0.45558321475982666
Iteration 529: Loss = 0.4555002450942993
Iteration 530: Loss = 0.4554173946380615
Iteration 531: Loss = 0.4553346335887909
Iteration 532: Loss = 0.4552520513534546
Iteration 533: Loss = 0.4551696181297302
Iteration 534: Loss = 0.455087274312973
Iteration 535: Loss = 0.45500513911247253
Iteration 536: Loss = 0.45492303371429443
Iteration 537: Loss = 0.45484113693237305
Iteration 538: Loss = 0.45475926995277405
Iteration 539: Loss = 0.4546775817871094
Iteration 540: Loss = 0.45459607243537903
Iteration 541: Loss = 0.45451468229293823
Iteration 542: Loss = 0.454433411359787
Iteration 543: Loss = 0.45435234904289246
Iteration 544: Loss = 0.4542714059352875
Iteration 545: Loss = 0.45419052243232727
Iteration 546: Loss = 0.45410987734794617
Iteration 547: Loss = 0.4540293216705322
Iteration 548: Loss = 0.45394885540008545
Iteration 549: Loss = 0.4538686275482178
Iteration 550: Loss = 0.4537883996963501
Iteration 551: Loss = 0.45370835065841675
Iteration 552: Loss = 0.4536285400390625
Iteration 553: Loss = 0.45354875922203064
Iteration 554: Loss = 0.45346924662590027
Iteration 555: Loss = 0.4533897638320923
Iteration 556: Loss = 0.45331043004989624
Iteration 557: Loss = 0.4532313048839569
Iteration 558: Loss = 0.45315229892730713
Iteration 559: Loss = 0.4530733823776245
Iteration 560: Loss = 0.4529947340488434
Iteration 561: Loss = 0.4529161751270294
Iteration 562: Loss = 0.452837735414505
Iteration 563: Loss = 0.4527594745159149
Iteration 564: Loss = 0.4526813328266144
Iteration 565: Loss = 0.4526033103466034
Iteration 566: Loss = 0.45252543687820435
Iteration 567: Loss = 0.452447772026062
Iteration 568: Loss = 0.45237022638320923
Iteration 569: Loss = 0.4522928297519684
Iteration 570: Loss = 0.45221564173698425
Iteration 571: Loss = 0.4521385133266449
Iteration 572: Loss = 0.45206165313720703
Iteration 573: Loss = 0.4519849419593811
Iteration 574: Loss = 0.4519084095954895
Iteration 575: Loss = 0.45183202624320984
Iteration 576: Loss = 0.4517557919025421
Iteration 577: Loss = 0.4516797661781311
Iteration 578: Loss = 0.45160388946533203
Iteration 579: Loss = 0.4515282213687897
Iteration 580: Loss = 0.45145267248153687
Iteration 581: Loss = 0.45137736201286316
Iteration 582: Loss = 0.4513021409511566
Iteration 583: Loss = 0.45122724771499634
Iteration 584: Loss = 0.45115238428115845
Iteration 585: Loss = 0.45107781887054443
Iteration 586: Loss = 0.45100337266921997
Iteration 587: Loss = 0.4509291648864746
Iteration 588: Loss = 0.4508551359176636
Iteration 589: Loss = 0.4507812261581421
Iteration 590: Loss = 0.4507075548171997
Iteration 591: Loss = 0.45063403248786926
Iteration 592: Loss = 0.45056065917015076
Iteration 593: Loss = 0.45048749446868896
Iteration 594: Loss = 0.45041462779045105
Iteration 595: Loss = 0.4503418505191803
Iteration 596: Loss = 0.45026934146881104
Iteration 597: Loss = 0.45019689202308655
Iteration 598: Loss = 0.4501248002052307
Iteration 599: Loss = 0.45005282759666443
Iteration 600: Loss = 0.44998109340667725
Iteration 601: Loss = 0.4499094784259796
Iteration 602: Loss = 0.4498380720615387
Iteration 603: Loss = 0.4497669041156769
Iteration 604: Loss = 0.449695885181427
Iteration 605: Loss = 0.4496251344680786
Iteration 606: Loss = 0.44955453276634216
Iteration 607: Loss = 0.449484258890152
Iteration 608: Loss = 0.44941410422325134
Iteration 609: Loss = 0.4493442177772522
Iteration 610: Loss = 0.4492745101451874
Iteration 611: Loss = 0.4492049813270569
Iteration 612: Loss = 0.44913581013679504
Iteration 613: Loss = 0.4490666687488556
Iteration 614: Loss = 0.4489979147911072
Iteration 615: Loss = 0.4489292502403259
Iteration 616: Loss = 0.44886088371276855
Iteration 617: Loss = 0.4487926959991455
Iteration 618: Loss = 0.4487247169017792
Iteration 619: Loss = 0.4486570656299591
Iteration 620: Loss = 0.4485895335674286
Iteration 621: Loss = 0.44852226972579956
Iteration 622: Loss = 0.44845521450042725
Iteration 623: Loss = 0.44838839769363403
Iteration 624: Loss = 0.44832178950309753
Iteration 625: Loss = 0.4482553005218506
Iteration 626: Loss = 0.4481891691684723
Iteration 627: Loss = 0.4481232166290283
Iteration 628: Loss = 0.44805753231048584
Iteration 629: Loss = 0.4479920566082001
Iteration 630: Loss = 0.44792672991752625
Iteration 631: Loss = 0.4478617012500763
Iteration 632: Loss = 0.44779688119888306
Iteration 633: Loss = 0.4477322995662689
Iteration 634: Loss = 0.4476679861545563
Iteration 635: Loss = 0.44760388135910034
Iteration 636: Loss = 0.4475400149822235
Iteration 637: Loss = 0.44747644662857056
Iteration 638: Loss = 0.44741299748420715
Iteration 639: Loss = 0.4473498463630676
Iteration 640: Loss = 0.4472869336605072
Iteration 641: Loss = 0.4472242295742035
Iteration 642: Loss = 0.4471617043018341
Iteration 643: Loss = 0.44709938764572144
Iteration 644: Loss = 0.44703739881515503
Iteration 645: Loss = 0.44697561860084534
Iteration 646: Loss = 0.4469139575958252
Iteration 647: Loss = 0.4468526244163513
Iteration 648: Loss = 0.4467914402484894
Iteration 649: Loss = 0.44673052430152893
Iteration 650: Loss = 0.4466698467731476
Iteration 651: Loss = 0.44660937786102295
Iteration 652: Loss = 0.4465491473674774
Iteration 653: Loss = 0.4464890956878662
Iteration 654: Loss = 0.4464292526245117
Iteration 655: Loss = 0.4463696777820587
Iteration 656: Loss = 0.4463103115558624
Iteration 657: Loss = 0.4462510943412781
Iteration 658: Loss = 0.4461921751499176
Iteration 659: Loss = 0.44613343477249146
Iteration 660: Loss = 0.4460749328136444
Iteration 661: Loss = 0.44601666927337646
Iteration 662: Loss = 0.4459584951400757
Iteration 663: Loss = 0.44590073823928833
Iteration 664: Loss = 0.44584304094314575
Iteration 665: Loss = 0.4457855820655823
Iteration 666: Loss = 0.4457283914089203
Iteration 667: Loss = 0.445671409368515
Iteration 668: Loss = 0.44561463594436646
Iteration 669: Loss = 0.44555801153182983
Iteration 670: Loss = 0.4455017149448395
Iteration 671: Loss = 0.44544556736946106
Iteration 672: Loss = 0.44538965821266174
Iteration 673: Loss = 0.44533389806747437
Iteration 674: Loss = 0.4452783465385437
Iteration 675: Loss = 0.4452230632305145
Iteration 676: Loss = 0.4451679587364197
Iteration 677: Loss = 0.44511306285858154
Iteration 678: Loss = 0.44505828619003296
Iteration 679: Loss = 0.44500380754470825
Iteration 680: Loss = 0.44494950771331787
Iteration 681: Loss = 0.4448954164981842
Iteration 682: Loss = 0.4448416233062744
Iteration 683: Loss = 0.4447878897190094
Iteration 684: Loss = 0.44473448395729065
Iteration 685: Loss = 0.4446812868118286
Iteration 686: Loss = 0.4446282684803009
Iteration 687: Loss = 0.4445754289627075
Iteration 688: Loss = 0.4445229172706604
Iteration 689: Loss = 0.44447049498558044
Iteration 690: Loss = 0.4444182813167572
Iteration 691: Loss = 0.44436630606651306
Iteration 692: Loss = 0.44431450963020325
Iteration 693: Loss = 0.44426295161247253
Iteration 694: Loss = 0.44421160221099854
Iteration 695: Loss = 0.44416043162345886
Iteration 696: Loss = 0.4441094696521759
Iteration 697: Loss = 0.44405868649482727
Iteration 698: Loss = 0.4440081715583801
Iteration 699: Loss = 0.4439578950405121
Iteration 700: Loss = 0.443907767534256
Iteration 701: Loss = 0.44385775923728943
Iteration 702: Loss = 0.44380810856819153
Iteration 703: Loss = 0.44375860691070557
Iteration 704: Loss = 0.44370928406715393
Iteration 705: Loss = 0.4436601996421814
Iteration 706: Loss = 0.44361135363578796
Iteration 707: Loss = 0.44356265664100647
Iteration 708: Loss = 0.44351422786712646
Iteration 709: Loss = 0.443465918302536
Iteration 710: Loss = 0.44341784715652466
Iteration 711: Loss = 0.44336995482444763
Iteration 712: Loss = 0.4433222711086273
Iteration 713: Loss = 0.4432748556137085
Iteration 714: Loss = 0.44322752952575684
Iteration 715: Loss = 0.4431803822517395
Iteration 716: Loss = 0.44313353300094604
Iteration 717: Loss = 0.44308680295944214
Iteration 718: Loss = 0.44304031133651733
Iteration 719: Loss = 0.44299402832984924
Iteration 720: Loss = 0.4429478347301483
Iteration 721: Loss = 0.44290193915367126
Iteration 722: Loss = 0.44285619258880615
Iteration 723: Loss = 0.442810595035553
Iteration 724: Loss = 0.4427652657032013
Iteration 725: Loss = 0.44272005558013916
Iteration 726: Loss = 0.4426751136779785
Iteration 727: Loss = 0.44263026118278503
Iteration 728: Loss = 0.4425855875015259
Iteration 729: Loss = 0.4425412118434906
Iteration 730: Loss = 0.44249701499938965
Iteration 731: Loss = 0.44245296716690063
Iteration 732: Loss = 0.44240912795066833
Iteration 733: Loss = 0.4423654079437256
Iteration 734: Loss = 0.4423218369483948
Iteration 735: Loss = 0.44227856397628784
Iteration 736: Loss = 0.44223544001579285
Iteration 737: Loss = 0.4421924948692322
Iteration 738: Loss = 0.44214972853660583
Iteration 739: Loss = 0.44210705161094666
Iteration 740: Loss = 0.44206470251083374
Iteration 741: Loss = 0.44202253222465515
Iteration 742: Loss = 0.4419804811477661
Iteration 743: Loss = 0.441938579082489
Iteration 744: Loss = 0.44189685583114624
Iteration 745: Loss = 0.4418553411960602
Iteration 746: Loss = 0.44181400537490845
Iteration 747: Loss = 0.44177281856536865
Iteration 748: Loss = 0.44173187017440796
Iteration 749: Loss = 0.4416910707950592
Iteration 750: Loss = 0.4416504204273224
Iteration 751: Loss = 0.44160985946655273
Iteration 752: Loss = 0.44156956672668457
Iteration 753: Loss = 0.44152945280075073
Iteration 754: Loss = 0.4414895176887512
Iteration 755: Loss = 0.44144973158836365
Iteration 756: Loss = 0.441410094499588
Iteration 757: Loss = 0.4413706660270691
Iteration 758: Loss = 0.44133129715919495
Iteration 759: Loss = 0.4412921965122223
Iteration 760: Loss = 0.4412532448768616
Iteration 761: Loss = 0.4412144422531128
Iteration 762: Loss = 0.44117581844329834
Iteration 763: Loss = 0.4411373734474182
Iteration 764: Loss = 0.44109898805618286
Iteration 765: Loss = 0.44106075167655945
Iteration 766: Loss = 0.44102275371551514
Iteration 767: Loss = 0.44098493456840515
Iteration 768: Loss = 0.4409472644329071
Iteration 769: Loss = 0.440909743309021
Iteration 770: Loss = 0.44087234139442444
Iteration 771: Loss = 0.4408351182937622
Iteration 772: Loss = 0.4407980144023895
Iteration 773: Loss = 0.4407610595226288
Iteration 774: Loss = 0.44072425365448
Iteration 775: Loss = 0.4406876564025879
Iteration 776: Loss = 0.44065120816230774
Iteration 777: Loss = 0.4406149089336395
Iteration 778: Loss = 0.4405786693096161
Iteration 779: Loss = 0.44054269790649414
Iteration 780: Loss = 0.44050681591033936
Iteration 781: Loss = 0.4404710531234741
Iteration 782: Loss = 0.4404354989528656
Iteration 783: Loss = 0.440400093793869
Iteration 784: Loss = 0.440364807844162
Iteration 785: Loss = 0.44032973051071167
Iteration 786: Loss = 0.44029471278190613
Iteration 787: Loss = 0.4402599036693573
Iteration 788: Loss = 0.44022518396377563
Iteration 789: Loss = 0.4401906132698059
Iteration 790: Loss = 0.4401562213897705
Iteration 791: Loss = 0.44012200832366943
Iteration 792: Loss = 0.4400878846645355
Iteration 793: Loss = 0.4400539696216583
Iteration 794: Loss = 0.4400201439857483
Iteration 795: Loss = 0.4399864375591278
Iteration 796: Loss = 0.43995290994644165
Iteration 797: Loss = 0.43991947174072266
Iteration 798: Loss = 0.439886212348938
Iteration 799: Loss = 0.43985307216644287
Iteration 800: Loss = 0.43982014060020447
Iteration 801: Loss = 0.4397872984409332
Iteration 802: Loss = 0.4397546648979187
Iteration 803: Loss = 0.43972212076187134
Iteration 804: Loss = 0.43968966603279114
Iteration 805: Loss = 0.43965739011764526
Iteration 806: Loss = 0.43962523341178894
Iteration 807: Loss = 0.43959319591522217
Iteration 808: Loss = 0.43956130743026733
Iteration 809: Loss = 0.43952956795692444
Iteration 810: Loss = 0.4394979476928711
Iteration 811: Loss = 0.4394664168357849
Iteration 812: Loss = 0.43943512439727783
Iteration 813: Loss = 0.4394039213657379
Iteration 814: Loss = 0.43937286734580994
Iteration 815: Loss = 0.4393419027328491
Iteration 816: Loss = 0.43931102752685547
Iteration 817: Loss = 0.43928033113479614
Iteration 818: Loss = 0.43924975395202637
Iteration 819: Loss = 0.43921923637390137
Iteration 820: Loss = 0.4391888976097107
Iteration 821: Loss = 0.43915867805480957
Iteration 822: Loss = 0.43912866711616516
Iteration 823: Loss = 0.4390987455844879
Iteration 824: Loss = 0.4390689432621002
Iteration 825: Loss = 0.4390392005443573
Iteration 826: Loss = 0.4390096366405487
Iteration 827: Loss = 0.43898022174835205
Iteration 828: Loss = 0.43895086646080017
Iteration 829: Loss = 0.4389216899871826
Iteration 830: Loss = 0.4388926029205322
Iteration 831: Loss = 0.4388635754585266
Iteration 832: Loss = 0.4388347566127777
Iteration 833: Loss = 0.4388059675693512
Iteration 834: Loss = 0.4387774169445038
Iteration 835: Loss = 0.43874895572662354
Iteration 836: Loss = 0.4387205243110657
Iteration 837: Loss = 0.4386923313140869
Iteration 838: Loss = 0.43866419792175293
Iteration 839: Loss = 0.4386362135410309
Iteration 840: Loss = 0.4386082887649536
Iteration 841: Loss = 0.43858057260513306
Iteration 842: Loss = 0.4385528564453125
Iteration 843: Loss = 0.4385252892971039
Iteration 844: Loss = 0.4384979009628296
Iteration 845: Loss = 0.4384705126285553
Iteration 846: Loss = 0.4384433627128601
Iteration 847: Loss = 0.4384162425994873
Iteration 848: Loss = 0.43838927149772644
Iteration 849: Loss = 0.4383624196052551
Iteration 850: Loss = 0.438335657119751
Iteration 851: Loss = 0.43830904364585876
Iteration 852: Loss = 0.4382825195789337
Iteration 853: Loss = 0.4382561445236206
Iteration 854: Loss = 0.43822985887527466
Iteration 855: Loss = 0.4382036626338959
Iteration 856: Loss = 0.43817758560180664
Iteration 857: Loss = 0.4381515681743622
Iteration 858: Loss = 0.43812575936317444
Iteration 859: Loss = 0.4380999803543091
Iteration 860: Loss = 0.43807435035705566
Iteration 861: Loss = 0.438048779964447
Iteration 862: Loss = 0.4380233883857727
Iteration 863: Loss = 0.4379980266094208
Iteration 864: Loss = 0.4379727840423584
Iteration 865: Loss = 0.4379476308822632
Iteration 866: Loss = 0.4379226863384247
Iteration 867: Loss = 0.43789777159690857
Iteration 868: Loss = 0.437872976064682
Iteration 869: Loss = 0.4378482401371002
Iteration 870: Loss = 0.43782368302345276
Iteration 871: Loss = 0.43779921531677246
Iteration 872: Loss = 0.4377748370170593
Iteration 873: Loss = 0.43775054812431335
Iteration 874: Loss = 0.43772634863853455
Iteration 875: Loss = 0.4377022683620453
Iteration 876: Loss = 0.4376783072948456
Iteration 877: Loss = 0.43765440583229065
Iteration 878: Loss = 0.43763065338134766
Iteration 879: Loss = 0.43760696053504944
Iteration 880: Loss = 0.43758338689804077
Iteration 881: Loss = 0.4375598728656769
Iteration 882: Loss = 0.43753644824028015
Iteration 883: Loss = 0.437513142824173
Iteration 884: Loss = 0.43748995661735535
Iteration 885: Loss = 0.4374668598175049
Iteration 886: Loss = 0.4374438226222992
Iteration 887: Loss = 0.43742090463638306
Iteration 888: Loss = 0.43739810585975647
Iteration 889: Loss = 0.43737539649009705
Iteration 890: Loss = 0.4373528063297272
Iteration 891: Loss = 0.4373302757740021
Iteration 892: Loss = 0.43730783462524414
Iteration 893: Loss = 0.43728551268577576
Iteration 894: Loss = 0.43726328015327454
Iteration 895: Loss = 0.4372410774230957
Iteration 896: Loss = 0.4372190833091736
Iteration 897: Loss = 0.43719708919525146
Iteration 898: Loss = 0.4371752142906189
Iteration 899: Loss = 0.4371534287929535
Iteration 900: Loss = 0.43713176250457764
Iteration 901: Loss = 0.4371100962162018
Iteration 902: Loss = 0.43708866834640503
Iteration 903: Loss = 0.4370672106742859
Iteration 904: Loss = 0.4370459020137787
Iteration 905: Loss = 0.43702462315559387
Iteration 906: Loss = 0.437003493309021
Iteration 907: Loss = 0.4369823932647705
Iteration 908: Loss = 0.43696141242980957
Iteration 909: Loss = 0.4369404911994934
Iteration 910: Loss = 0.4369196891784668
Iteration 911: Loss = 0.43689897656440735
Iteration 912: Loss = 0.4368782937526703
Iteration 913: Loss = 0.43685775995254517
Iteration 914: Loss = 0.4368372857570648
Iteration 915: Loss = 0.43681690096855164
Iteration 916: Loss = 0.436796635389328
Iteration 917: Loss = 0.43677636981010437
Iteration 918: Loss = 0.4367562234401703
Iteration 919: Loss = 0.43673619627952576
Iteration 920: Loss = 0.436716228723526
Iteration 921: Loss = 0.4366963505744934
Iteration 922: Loss = 0.4366765320301056
Iteration 923: Loss = 0.4366568624973297
Iteration 924: Loss = 0.43663716316223145
Iteration 925: Loss = 0.4366176128387451
Iteration 926: Loss = 0.43659818172454834
Iteration 927: Loss = 0.4365787208080292
Iteration 928: Loss = 0.43655943870544434
Iteration 929: Loss = 0.4365401864051819
Iteration 930: Loss = 0.436521053314209
Iteration 931: Loss = 0.43650200963020325
Iteration 932: Loss = 0.4364829659461975
Iteration 933: Loss = 0.4364640414714813
Iteration 934: Loss = 0.4364452660083771
Iteration 935: Loss = 0.4364264905452728
Iteration 936: Loss = 0.43640780448913574
Iteration 937: Loss = 0.4363892376422882
Iteration 938: Loss = 0.43637070059776306
Iteration 939: Loss = 0.4363522529602051
Iteration 940: Loss = 0.43633392453193665
Iteration 941: Loss = 0.436315655708313
Iteration 942: Loss = 0.43629735708236694
Iteration 943: Loss = 0.4362792670726776
Iteration 944: Loss = 0.4362611770629883
Iteration 945: Loss = 0.4362432062625885
Iteration 946: Loss = 0.4362253248691559
Iteration 947: Loss = 0.43620747327804565
Iteration 948: Loss = 0.4361896812915802
Iteration 949: Loss = 0.4361719787120819
Iteration 950: Loss = 0.4361543655395508
Iteration 951: Loss = 0.43613681197166443
Iteration 952: Loss = 0.43611931800842285
Iteration 953: Loss = 0.43610185384750366
Iteration 954: Loss = 0.4360845685005188
Iteration 955: Loss = 0.43606728315353394
Iteration 956: Loss = 0.43605008721351624
Iteration 957: Loss = 0.4360330104827881
Iteration 958: Loss = 0.4360159635543823
Iteration 959: Loss = 0.43599897623062134
Iteration 960: Loss = 0.4359820485115051
Iteration 961: Loss = 0.4359651803970337
Iteration 962: Loss = 0.4359484612941742
Iteration 963: Loss = 0.4359317123889923
Iteration 964: Loss = 0.4359150826931
Iteration 965: Loss = 0.4358985126018524
Iteration 966: Loss = 0.435882031917572
Iteration 967: Loss = 0.435865581035614
Iteration 968: Loss = 0.43584921956062317
Iteration 969: Loss = 0.4358329474925995
Iteration 970: Loss = 0.4358167052268982
Iteration 971: Loss = 0.4358004927635193
Iteration 972: Loss = 0.43578439950942993
Iteration 973: Loss = 0.43576836585998535
Iteration 974: Loss = 0.43575242161750793
Iteration 975: Loss = 0.4357365071773529
Iteration 976: Loss = 0.43572068214416504
Iteration 977: Loss = 0.43570488691329956
Iteration 978: Loss = 0.43568921089172363
Iteration 979: Loss = 0.4356735646724701
Iteration 980: Loss = 0.43565794825553894
Iteration 981: Loss = 0.43564242124557495
Iteration 982: Loss = 0.4356270134449005
Iteration 983: Loss = 0.4356115758419037
Iteration 984: Loss = 0.4355962872505188
Iteration 985: Loss = 0.4355810284614563
Iteration 986: Loss = 0.43556585907936096
Iteration 987: Loss = 0.4355506896972656
Iteration 988: Loss = 0.43553563952445984
Iteration 989: Loss = 0.43552061915397644
Iteration 990: Loss = 0.4355056881904602
Iteration 991: Loss = 0.43549078702926636
Iteration 992: Loss = 0.4354759454727173
Iteration 993: Loss = 0.43546125292778015
Iteration 994: Loss = 0.435446560382843
Iteration 995: Loss = 0.43543189764022827
Iteration 996: Loss = 0.4354173243045807
Iteration 997: Loss = 0.4354028105735779
Iteration 998: Loss = 0.4353882968425751
Iteration 999: Loss = 0.4353739619255066
Iteration 1000: Loss = 0.4353596270084381


Total training time (seconds): 9.30
