Iteration 1: Loss = 0.7971780300140381
Iteration 2: Loss = 0.792186439037323
Iteration 3: Loss = 0.787217378616333
Iteration 4: Loss = 0.7822730541229248
Iteration 5: Loss = 0.7773558497428894
Iteration 6: Loss = 0.7724679708480835
Iteration 7: Loss = 0.7676119208335876
Iteration 8: Loss = 0.7627901434898376
Iteration 9: Loss = 0.7580054998397827
Iteration 10: Loss = 0.7532599568367004
Iteration 11: Loss = 0.7485558986663818
Iteration 12: Loss = 0.7438958883285522
Iteration 13: Loss = 0.7392823696136475
Iteration 14: Loss = 0.7347179055213928
Iteration 15: Loss = 0.730204164981842
Iteration 16: Loss = 0.72574383020401
Iteration 17: Loss = 0.7213388681411743
Iteration 18: Loss = 0.716991662979126
Iteration 19: Loss = 0.7127041816711426
Iteration 20: Loss = 0.7084782123565674
Iteration 21: Loss = 0.704315185546875
Iteration 22: Loss = 0.700217068195343
Iteration 23: Loss = 0.6961851716041565
Iteration 24: Loss = 0.692221462726593
Iteration 25: Loss = 0.6883270740509033
Iteration 26: Loss = 0.6845036745071411
Iteration 27: Loss = 0.6807529330253601
Iteration 28: Loss = 0.6770750284194946
Iteration 29: Loss = 0.6734710931777954
Iteration 30: Loss = 0.6699419021606445
Iteration 31: Loss = 0.6664890050888062
Iteration 32: Loss = 0.6631129384040833
Iteration 33: Loss = 0.6598140597343445
Iteration 34: Loss = 0.6565926671028137
Iteration 35: Loss = 0.6534488797187805
Iteration 36: Loss = 0.6503833532333374
Iteration 37: Loss = 0.6473960280418396
Iteration 38: Loss = 0.6444875597953796
Iteration 39: Loss = 0.6416575312614441
Iteration 40: Loss = 0.638906717300415
Iteration 41: Loss = 0.6362351775169373
Iteration 42: Loss = 0.63364177942276
Iteration 43: Loss = 0.6311265826225281
Iteration 44: Loss = 0.6286895275115967
Iteration 45: Loss = 0.6263302564620972
Iteration 46: Loss = 0.6240487098693848
Iteration 47: Loss = 0.6218446493148804
Iteration 48: Loss = 0.6197176575660706
Iteration 49: Loss = 0.6176666021347046
Iteration 50: Loss = 0.6156911253929138
Iteration 51: Loss = 0.6137897968292236
Iteration 52: Loss = 0.611961841583252
Iteration 53: Loss = 0.6102061867713928
Iteration 54: Loss = 0.6085222959518433
Iteration 55: Loss = 0.606908917427063
Iteration 56: Loss = 0.6053639054298401
Iteration 57: Loss = 0.6038860082626343
Iteration 58: Loss = 0.6024733781814575
Iteration 59: Loss = 0.6011243462562561
Iteration 60: Loss = 0.5998364090919495
Iteration 61: Loss = 0.5986071825027466
Iteration 62: Loss = 0.5974345803260803
Iteration 63: Loss = 0.596315860748291
Iteration 64: Loss = 0.5952485203742981
Iteration 65: Loss = 0.5942299365997314
Iteration 66: Loss = 0.5932574272155762
Iteration 67: Loss = 0.5923280715942383
Iteration 68: Loss = 0.5914391875267029
Iteration 69: Loss = 0.590588390827179
Iteration 70: Loss = 0.5897728800773621
Iteration 71: Loss = 0.5889904499053955
Iteration 72: Loss = 0.5882385969161987
Iteration 73: Loss = 0.5875149369239807
Iteration 74: Loss = 0.5868173837661743
Iteration 75: Loss = 0.5861439108848572
Iteration 76: Loss = 0.5854927897453308
Iteration 77: Loss = 0.5848618745803833
Iteration 78: Loss = 0.5842499136924744
Iteration 79: Loss = 0.5836552381515503
Iteration 80: Loss = 0.5830764174461365
Iteration 81: Loss = 0.5825123190879822
Iteration 82: Loss = 0.5819618105888367
Iteration 83: Loss = 0.581423819065094
Iteration 84: Loss = 0.5808975696563721
Iteration 85: Loss = 0.5803819894790649
Iteration 86: Loss = 0.5798765420913696
Iteration 87: Loss = 0.5793803930282593
Iteration 88: Loss = 0.578892707824707
Iteration 89: Loss = 0.5784133076667786
Iteration 90: Loss = 0.5779412984848022
Iteration 91: Loss = 0.5774762630462646
Iteration 92: Loss = 0.5770178437232971
Iteration 93: Loss = 0.5765652656555176
Iteration 94: Loss = 0.5761181712150574
Iteration 95: Loss = 0.5756762623786926
Iteration 96: Loss = 0.5752391219139099
Iteration 97: Loss = 0.5748063921928406
Iteration 98: Loss = 0.5743777751922607
Iteration 99: Loss = 0.5739530324935913
Iteration 100: Loss = 0.5735315680503845
Iteration 101: Loss = 0.5731131434440613
Iteration 102: Loss = 0.5726976990699768
Iteration 103: Loss = 0.5722848176956177
Iteration 104: Loss = 0.5718741416931152
Iteration 105: Loss = 0.5714655518531799
Iteration 106: Loss = 0.5710586905479431
Iteration 107: Loss = 0.57065349817276
Iteration 108: Loss = 0.5702493786811829
Iteration 109: Loss = 0.569846510887146
Iteration 110: Loss = 0.5694445371627808
Iteration 111: Loss = 0.5690433979034424
Iteration 112: Loss = 0.5686428546905518
Iteration 113: Loss = 0.5682429671287537
Iteration 114: Loss = 0.5678432583808899
Iteration 115: Loss = 0.5674437284469604
Iteration 116: Loss = 0.5670444369316101
Iteration 117: Loss = 0.5666450262069702
Iteration 118: Loss = 0.5662456154823303
Iteration 119: Loss = 0.5658459067344666
Iteration 120: Loss = 0.5654458999633789
Iteration 121: Loss = 0.5650455355644226
Iteration 122: Loss = 0.5646446347236633
Iteration 123: Loss = 0.5642432570457458
Iteration 124: Loss = 0.5638412833213806
Iteration 125: Loss = 0.5634387135505676
Iteration 126: Loss = 0.5630354285240173
Iteration 127: Loss = 0.5626315474510193
Iteration 128: Loss = 0.5622267723083496
Iteration 129: Loss = 0.5618211627006531
Iteration 130: Loss = 0.5614147782325745
Iteration 131: Loss = 0.5610076189041138
Iteration 132: Loss = 0.5605996251106262
Iteration 133: Loss = 0.5601906776428223
Iteration 134: Loss = 0.5597808957099915
Iteration 135: Loss = 0.5593701004981995
Iteration 136: Loss = 0.5589584708213806
Iteration 137: Loss = 0.5585459470748901
Iteration 138: Loss = 0.5581324696540833
Iteration 139: Loss = 0.55771803855896
Iteration 140: Loss = 0.5573025941848755
Iteration 141: Loss = 0.5568862557411194
Iteration 142: Loss = 0.5564688444137573
Iteration 143: Loss = 0.5560505390167236
Iteration 144: Loss = 0.5556312799453735
Iteration 145: Loss = 0.5552110075950623
Iteration 146: Loss = 0.5547897219657898
Iteration 147: Loss = 0.5543675422668457
Iteration 148: Loss = 0.5539442896842957
Iteration 149: Loss = 0.5535200834274292
Iteration 150: Loss = 0.5530949234962463
Iteration 151: Loss = 0.5526687502861023
Iteration 152: Loss = 0.5522415637969971
Iteration 153: Loss = 0.5518134832382202
Iteration 154: Loss = 0.5513843894004822
Iteration 155: Loss = 0.5509543418884277
Iteration 156: Loss = 0.5505234003067017
Iteration 157: Loss = 0.5500914454460144
Iteration 158: Loss = 0.5496585965156555
Iteration 159: Loss = 0.5492247939109802
Iteration 160: Loss = 0.5487900376319885
Iteration 161: Loss = 0.5483543872833252
Iteration 162: Loss = 0.547917902469635
Iteration 163: Loss = 0.5474804639816284
Iteration 164: Loss = 0.5470423102378845
Iteration 165: Loss = 0.5466031432151794
Iteration 166: Loss = 0.5461630821228027
Iteration 167: Loss = 0.5457223057746887
Iteration 168: Loss = 0.5452806949615479
Iteration 169: Loss = 0.5448382496833801
Iteration 170: Loss = 0.5443951487541199
Iteration 171: Loss = 0.5439510941505432
Iteration 172: Loss = 0.5435063242912292
Iteration 173: Loss = 0.543060839176178
Iteration 174: Loss = 0.5426145792007446
Iteration 175: Loss = 0.5421675443649292
Iteration 176: Loss = 0.5417198538780212
Iteration 177: Loss = 0.541271448135376
Iteration 178: Loss = 0.5408223271369934
Iteration 179: Loss = 0.5403724908828735
Iteration 180: Loss = 0.5399219989776611
Iteration 181: Loss = 0.5394708514213562
Iteration 182: Loss = 0.539018988609314
Iteration 183: Loss = 0.5385666489601135
Iteration 184: Loss = 0.5381135940551758
Iteration 185: Loss = 0.5376601815223694
Iteration 186: Loss = 0.5372061133384705
Iteration 187: Loss = 0.5367514491081238
Iteration 188: Loss = 0.5362964272499084
Iteration 189: Loss = 0.5358409285545349
Iteration 190: Loss = 0.5353849530220032
Iteration 191: Loss = 0.5349284410476685
Iteration 192: Loss = 0.5344715714454651
Iteration 193: Loss = 0.5340141654014587
Iteration 194: Loss = 0.5335564017295837
Iteration 195: Loss = 0.5330982208251953
Iteration 196: Loss = 0.5326396822929382
Iteration 197: Loss = 0.5321807265281677
Iteration 198: Loss = 0.5317214131355286
Iteration 199: Loss = 0.5312618613243103
Iteration 200: Loss = 0.5308018922805786
Iteration 201: Loss = 0.5303415656089783
Iteration 202: Loss = 0.5298810601234436
Iteration 203: Loss = 0.5294201374053955
Iteration 204: Loss = 0.5289589762687683
Iteration 205: Loss = 0.5284975171089172
Iteration 206: Loss = 0.5280357003211975
Iteration 207: Loss = 0.527573823928833
Iteration 208: Loss = 0.5271118879318237
Iteration 209: Loss = 0.5266497135162354
Iteration 210: Loss = 0.5261873006820679
Iteration 211: Loss = 0.5257248282432556
Iteration 212: Loss = 0.5252620577812195
Iteration 213: Loss = 0.5247991681098938
Iteration 214: Loss = 0.5243363976478577
Iteration 215: Loss = 0.5238734483718872
Iteration 216: Loss = 0.523410439491272
Iteration 217: Loss = 0.5229474306106567
Iteration 218: Loss = 0.522484302520752
Iteration 219: Loss = 0.5220211744308472
Iteration 220: Loss = 0.5215579867362976
Iteration 221: Loss = 0.521094799041748
Iteration 222: Loss = 0.5206315517425537
Iteration 223: Loss = 0.5201683640480042
Iteration 224: Loss = 0.5197051763534546
Iteration 225: Loss = 0.5192421078681946
Iteration 226: Loss = 0.5187790989875793
Iteration 227: Loss = 0.5183161497116089
Iteration 228: Loss = 0.5178534388542175
Iteration 229: Loss = 0.5173906087875366
Iteration 230: Loss = 0.5169280767440796
Iteration 231: Loss = 0.5164657235145569
Iteration 232: Loss = 0.5160033702850342
Iteration 233: Loss = 0.5155412554740906
Iteration 234: Loss = 0.5150790810585022
Iteration 235: Loss = 0.5146173238754272
Iteration 236: Loss = 0.5141558051109314
Iteration 237: Loss = 0.5136942863464355
Iteration 238: Loss = 0.5132328867912292
Iteration 239: Loss = 0.5127717852592468
Iteration 240: Loss = 0.512310802936554
Iteration 241: Loss = 0.5118500590324402
Iteration 242: Loss = 0.5113892555236816
Iteration 243: Loss = 0.5109288096427917
Iteration 244: Loss = 0.510468602180481
Iteration 245: Loss = 0.5100084543228149
Iteration 246: Loss = 0.5095486044883728
Iteration 247: Loss = 0.5090889930725098
Iteration 248: Loss = 0.5086296796798706
Iteration 249: Loss = 0.508170485496521
Iteration 250: Loss = 0.5077115893363953
Iteration 251: Loss = 0.5072529911994934
Iteration 252: Loss = 0.5067946910858154
Iteration 253: Loss = 0.506336510181427
Iteration 254: Loss = 0.505878746509552
Iteration 255: Loss = 0.5054211616516113
Iteration 256: Loss = 0.5049641728401184
Iteration 257: Loss = 0.504507303237915
Iteration 258: Loss = 0.5040509104728699
Iteration 259: Loss = 0.5035948157310486
Iteration 260: Loss = 0.503139078617096
Iteration 261: Loss = 0.5026836395263672
Iteration 262: Loss = 0.5022285580635071
Iteration 263: Loss = 0.5017739534378052
Iteration 264: Loss = 0.5013196468353271
Iteration 265: Loss = 0.5008656978607178
Iteration 266: Loss = 0.500412106513977
Iteration 267: Loss = 0.4999590814113617
Iteration 268: Loss = 0.4995063543319702
Iteration 269: Loss = 0.49905407428741455
Iteration 270: Loss = 0.4986022114753723
Iteration 271: Loss = 0.49815070629119873
Iteration 272: Loss = 0.49769988656044006
Iteration 273: Loss = 0.4972493350505829
Iteration 274: Loss = 0.49679917097091675
Iteration 275: Loss = 0.4963497817516327
Iteration 276: Loss = 0.49590063095092773
Iteration 277: Loss = 0.4954521059989929
Iteration 278: Loss = 0.4950040578842163
Iteration 279: Loss = 0.4945564270019531
Iteration 280: Loss = 0.494109570980072
Iteration 281: Loss = 0.4936630427837372
Iteration 282: Loss = 0.49321699142456055
Iteration 283: Loss = 0.49277159571647644
Iteration 284: Loss = 0.4923267960548401
Iteration 285: Loss = 0.4918823838233948
Iteration 286: Loss = 0.491438627243042
Iteration 287: Loss = 0.49099552631378174
Iteration 288: Loss = 0.4905529320240021
Iteration 289: Loss = 0.4901110529899597
Iteration 290: Loss = 0.4896697700023651
Iteration 291: Loss = 0.4892289936542511
Iteration 292: Loss = 0.4887889325618744
Iteration 293: Loss = 0.488349586725235
Iteration 294: Loss = 0.48791077733039856
Iteration 295: Loss = 0.4874725341796875
Iteration 296: Loss = 0.4870351552963257
Iteration 297: Loss = 0.4865983724594116
Iteration 298: Loss = 0.4861621558666229
Iteration 299: Loss = 0.48572659492492676
Iteration 300: Loss = 0.4852920472621918
Iteration 301: Loss = 0.48485809564590454
Iteration 302: Loss = 0.48442474007606506
Iteration 303: Loss = 0.4839920699596405
Iteration 304: Loss = 0.48356038331985474
Iteration 305: Loss = 0.48312944173812866
Iteration 306: Loss = 0.48269903659820557
Iteration 307: Loss = 0.48226943612098694
Iteration 308: Loss = 0.4818408489227295
Iteration 309: Loss = 0.4814130663871765
Iteration 310: Loss = 0.4809859097003937
Iteration 311: Loss = 0.4805595278739929
Iteration 312: Loss = 0.4801342785358429
Iteration 313: Loss = 0.47970980405807495
Iteration 314: Loss = 0.4792860150337219
Iteration 315: Loss = 0.4788631498813629
Iteration 316: Loss = 0.4784412682056427
Iteration 317: Loss = 0.47802022099494934
Iteration 318: Loss = 0.4776000380516052
Iteration 319: Loss = 0.47718074917793274
Iteration 320: Loss = 0.47676241397857666
Iteration 321: Loss = 0.47634509205818176
Iteration 322: Loss = 0.4759286940097809
Iteration 323: Loss = 0.47551313042640686
Iteration 324: Loss = 0.4750986397266388
Iteration 325: Loss = 0.47468510270118713
Iteration 326: Loss = 0.47427257895469666
Iteration 327: Loss = 0.4738610088825226
Iteration 328: Loss = 0.47345057129859924
Iteration 329: Loss = 0.47304102778434753
Iteration 330: Loss = 0.4726324677467346
Iteration 331: Loss = 0.4722249209880829
Iteration 332: Loss = 0.47181862592697144
Iteration 333: Loss = 0.471413254737854
Iteration 334: Loss = 0.471008837223053
Iteration 335: Loss = 0.47060537338256836
Iteration 336: Loss = 0.47020331025123596
Iteration 337: Loss = 0.46980229020118713
Iteration 338: Loss = 0.4694022238254547
Iteration 339: Loss = 0.46900320053100586
Iteration 340: Loss = 0.4686054587364197
Iteration 341: Loss = 0.4682087004184723
Iteration 342: Loss = 0.4678131639957428
Iteration 343: Loss = 0.46741873025894165
Iteration 344: Loss = 0.46702560782432556
Iteration 345: Loss = 0.4666336178779602
Iteration 346: Loss = 0.4662425220012665
Iteration 347: Loss = 0.46585267782211304
Iteration 348: Loss = 0.4654642641544342
Iteration 349: Loss = 0.4650769531726837
Iteration 350: Loss = 0.46469080448150635
Iteration 351: Loss = 0.4643057882785797
Iteration 352: Loss = 0.4639221131801605
Iteration 353: Loss = 0.4635395407676697
Iteration 354: Loss = 0.46315833926200867
Iteration 355: Loss = 0.46277832984924316
Iteration 356: Loss = 0.4623997211456299
Iteration 357: Loss = 0.46202221512794495
Iteration 358: Loss = 0.46164584159851074
Iteration 359: Loss = 0.461270809173584
Iteration 360: Loss = 0.4608973264694214
Iteration 361: Loss = 0.4605250358581543
Iteration 362: Loss = 0.4601539969444275
Iteration 363: Loss = 0.4597843587398529
Iteration 364: Loss = 0.4594159722328186
Iteration 365: Loss = 0.4590488076210022
Iteration 366: Loss = 0.4586831033229828
Iteration 367: Loss = 0.45831888914108276
Iteration 368: Loss = 0.4579559564590454
Iteration 369: Loss = 0.4575943052768707
Iteration 370: Loss = 0.45723390579223633
Iteration 371: Loss = 0.45687511563301086
Iteration 372: Loss = 0.45651763677597046
Iteration 373: Loss = 0.4561616778373718
Iteration 374: Loss = 0.45580703020095825
Iteration 375: Loss = 0.4554537832736969
Iteration 376: Loss = 0.45510196685791016
Iteration 377: Loss = 0.45475146174430847
Iteration 378: Loss = 0.4544023275375366
Iteration 379: Loss = 0.45405468344688416
Iteration 380: Loss = 0.45370861887931824
Iteration 381: Loss = 0.45336392521858215
Iteration 382: Loss = 0.45302051305770874
Iteration 383: Loss = 0.4526785612106323
Iteration 384: Loss = 0.45233818888664246
Iteration 385: Loss = 0.4519992172718048
Iteration 386: Loss = 0.4516616761684418
Iteration 387: Loss = 0.4513256251811981
Iteration 388: Loss = 0.4509912431240082
Iteration 389: Loss = 0.45065826177597046
Iteration 390: Loss = 0.4503265619277954
Iteration 391: Loss = 0.44999635219573975
Iteration 392: Loss = 0.44966772198677063
Iteration 393: Loss = 0.44934070110321045
Iteration 394: Loss = 0.4490150511264801
Iteration 395: Loss = 0.44869083166122437
Iteration 396: Loss = 0.44836822152137756
Iteration 397: Loss = 0.4480471611022949
Iteration 398: Loss = 0.4477274715900421
Iteration 399: Loss = 0.44740939140319824
Iteration 400: Loss = 0.44709286093711853
Iteration 401: Loss = 0.4467780292034149
Iteration 402: Loss = 0.44646456837654114
Iteration 403: Loss = 0.44615259766578674
Iteration 404: Loss = 0.44584202766418457
Iteration 405: Loss = 0.44553297758102417
Iteration 406: Loss = 0.4452258348464966
Iteration 407: Loss = 0.4449200928211212
Iteration 408: Loss = 0.44461578130722046
Iteration 409: Loss = 0.4443129301071167
Iteration 410: Loss = 0.4440118074417114
Iteration 411: Loss = 0.44371211528778076
Iteration 412: Loss = 0.44341397285461426
Iteration 413: Loss = 0.4431173503398895
Iteration 414: Loss = 0.44282254576683044
Iteration 415: Loss = 0.44252917170524597
Iteration 416: Loss = 0.4422372877597809
Iteration 417: Loss = 0.4419468343257904
Iteration 418: Loss = 0.441658079624176
Iteration 419: Loss = 0.44137102365493774
Iteration 420: Loss = 0.44108545780181885
Iteration 421: Loss = 0.44080132246017456
Iteration 422: Loss = 0.44051870703697205
Iteration 423: Loss = 0.4402378797531128
Iteration 424: Loss = 0.43995848298072815
Iteration 425: Loss = 0.43968063592910767
Iteration 426: Loss = 0.43940451741218567
Iteration 427: Loss = 0.4391297698020935
Iteration 428: Loss = 0.43885675072669983
Iteration 429: Loss = 0.4385853409767151
Iteration 430: Loss = 0.4383153021335602
Iteration 431: Loss = 0.43804681301116943
Iteration 432: Loss = 0.43777987360954285
Iteration 433: Loss = 0.4375147521495819
Iteration 434: Loss = 0.43725118041038513
Iteration 435: Loss = 0.43698909878730774
Iteration 436: Loss = 0.43672850728034973
Iteration 437: Loss = 0.43646934628486633
Iteration 438: Loss = 0.4362117052078247
Iteration 439: Loss = 0.4359559714794159
Iteration 440: Loss = 0.43570178747177124
Iteration 441: Loss = 0.43544909358024597
Iteration 442: Loss = 0.4351978898048401
Iteration 443: Loss = 0.43494799733161926
Iteration 444: Loss = 0.4346998333930969
Iteration 445: Loss = 0.43445321917533875
Iteration 446: Loss = 0.4342081546783447
Iteration 447: Loss = 0.4339646100997925
Iteration 448: Loss = 0.43372243642807007
Iteration 449: Loss = 0.43348202109336853
Iteration 450: Loss = 0.4332429766654968
Iteration 451: Loss = 0.43300527334213257
Iteration 452: Loss = 0.4327690899372101
Iteration 453: Loss = 0.4325345754623413
Iteration 454: Loss = 0.43230170011520386
Iteration 455: Loss = 0.43207013607025146
Iteration 456: Loss = 0.43184009194374084
Iteration 457: Loss = 0.4316113591194153
Iteration 458: Loss = 0.43138402700424194
Iteration 459: Loss = 0.43115854263305664
Iteration 460: Loss = 0.4309345483779907
Iteration 461: Loss = 0.43071192502975464
Iteration 462: Loss = 0.4304906725883484
Iteration 463: Loss = 0.43027082085609436
Iteration 464: Loss = 0.4300523102283478
Iteration 465: Loss = 0.42983534932136536
Iteration 466: Loss = 0.42962008714675903
Iteration 467: Loss = 0.42940616607666016
Iteration 468: Loss = 0.42919355630874634
Iteration 469: Loss = 0.4289822578430176
Iteration 470: Loss = 0.42877256870269775
Iteration 471: Loss = 0.42856425046920776
Iteration 472: Loss = 0.4283573031425476
Iteration 473: Loss = 0.4281517267227173
Iteration 474: Loss = 0.4279475510120392
Iteration 475: Loss = 0.42774492502212524
Iteration 476: Loss = 0.42754366993904114
Iteration 477: Loss = 0.4273436367511749
Iteration 478: Loss = 0.427144855260849
Iteration 479: Loss = 0.4269476532936096
Iteration 480: Loss = 0.4267519414424896
Iteration 481: Loss = 0.42655763030052185
Iteration 482: Loss = 0.4263645112514496
Iteration 483: Loss = 0.42617267370224
Iteration 484: Loss = 0.4259820878505707
Iteration 485: Loss = 0.4257928431034088
Iteration 486: Loss = 0.42560529708862305
Iteration 487: Loss = 0.4254189431667328
Iteration 488: Loss = 0.4252338111400604
Iteration 489: Loss = 0.42504996061325073
Iteration 490: Loss = 0.4248672425746918
Iteration 491: Loss = 0.42468592524528503
Iteration 492: Loss = 0.42450612783432007
Iteration 493: Loss = 0.4243275821208954
Iteration 494: Loss = 0.4241502285003662
Iteration 495: Loss = 0.42397406697273254
Iteration 496: Loss = 0.423799067735672
Iteration 497: Loss = 0.4236252009868622
Iteration 498: Loss = 0.4234529733657837
Iteration 499: Loss = 0.4232819676399231
Iteration 500: Loss = 0.42311209440231323
Iteration 501: Loss = 0.4229433238506317
Iteration 502: Loss = 0.4227756857872009
Iteration 503: Loss = 0.42260923981666565
Iteration 504: Loss = 0.4224441349506378
Iteration 505: Loss = 0.4222802519798279
Iteration 506: Loss = 0.4221173822879791
Iteration 507: Loss = 0.4219556152820587
Iteration 508: Loss = 0.4217952489852905
Iteration 509: Loss = 0.4216358959674835
Iteration 510: Loss = 0.4214775860309601
Iteration 511: Loss = 0.42132052779197693
Iteration 512: Loss = 0.42116454243659973
Iteration 513: Loss = 0.42100989818573
Iteration 514: Loss = 0.4208562672138214
Iteration 515: Loss = 0.4207036793231964
Iteration 516: Loss = 0.420552134513855
Iteration 517: Loss = 0.42040181159973145
Iteration 518: Loss = 0.4202524721622467
Iteration 519: Loss = 0.4201042056083679
Iteration 520: Loss = 0.4199572503566742
Iteration 521: Loss = 0.4198111891746521
Iteration 522: Loss = 0.4196661114692688
Iteration 523: Loss = 0.4195222854614258
Iteration 524: Loss = 0.41937947273254395
Iteration 525: Loss = 0.4192376732826233
Iteration 526: Loss = 0.41909685730934143
Iteration 527: Loss = 0.4189572334289551
Iteration 528: Loss = 0.41881847381591797
Iteration 529: Loss = 0.4186808466911316
Iteration 530: Loss = 0.4185442328453064
Iteration 531: Loss = 0.4184085428714752
Iteration 532: Loss = 0.41827392578125
Iteration 533: Loss = 0.4181402921676636
Iteration 534: Loss = 0.41800764203071594
Iteration 535: Loss = 0.4178757965564728
Iteration 536: Loss = 0.41774505376815796
Iteration 537: Loss = 0.4176153242588043
Iteration 538: Loss = 0.41748639941215515
Iteration 539: Loss = 0.4173585772514343
Iteration 540: Loss = 0.41723164916038513
Iteration 541: Loss = 0.4171055853366852
Iteration 542: Loss = 0.41698047518730164
Iteration 543: Loss = 0.4168562889099121
Iteration 544: Loss = 0.4167329967021942
Iteration 545: Loss = 0.4166104197502136
Iteration 546: Loss = 0.4164890646934509
Iteration 547: Loss = 0.4163685441017151
Iteration 548: Loss = 0.41624876856803894
Iteration 549: Loss = 0.41613006591796875
Iteration 550: Loss = 0.41601210832595825
Iteration 551: Loss = 0.415895015001297
Iteration 552: Loss = 0.4157786965370178
Iteration 553: Loss = 0.4156630337238312
Iteration 554: Loss = 0.4155484437942505
Iteration 555: Loss = 0.4154348075389862
Iteration 556: Loss = 0.41532203555107117
Iteration 557: Loss = 0.41520997881889343
Iteration 558: Loss = 0.41509872674942017
Iteration 559: Loss = 0.4149882197380066
Iteration 560: Loss = 0.41487839818000793
Iteration 561: Loss = 0.41476941108703613
Iteration 562: Loss = 0.41466131806373596
Iteration 563: Loss = 0.4145542085170746
Iteration 564: Loss = 0.4144478738307953
Iteration 565: Loss = 0.41434216499328613
Iteration 566: Loss = 0.4142371118068695
Iteration 567: Loss = 0.4141327738761902
Iteration 568: Loss = 0.41402944922447205
Iteration 569: Loss = 0.4139266908168793
Iteration 570: Loss = 0.4138246476650238
Iteration 571: Loss = 0.41372349858283997
Iteration 572: Loss = 0.41362303495407104
Iteration 573: Loss = 0.41352319717407227
Iteration 574: Loss = 0.41342422366142273
Iteration 575: Loss = 0.41332605481147766
Iteration 576: Loss = 0.41322851181030273
Iteration 577: Loss = 0.41313156485557556
Iteration 578: Loss = 0.41303518414497375
Iteration 579: Loss = 0.4129393696784973
Iteration 580: Loss = 0.41284430027008057
Iteration 581: Loss = 0.4127502739429474
Iteration 582: Loss = 0.4126568138599396
Iteration 583: Loss = 0.41256389021873474
Iteration 584: Loss = 0.41247156262397766
Iteration 585: Loss = 0.41237977147102356
Iteration 586: Loss = 0.41228869557380676
Iteration 587: Loss = 0.41219836473464966
Iteration 588: Loss = 0.41210871934890747
Iteration 589: Loss = 0.41201961040496826
Iteration 590: Loss = 0.41193121671676636
Iteration 591: Loss = 0.41184332966804504
Iteration 592: Loss = 0.4117560088634491
Iteration 593: Loss = 0.4116693139076233
Iteration 594: Loss = 0.4115833044052124
Iteration 595: Loss = 0.4114978015422821
Iteration 596: Loss = 0.4114127457141876
Iteration 597: Loss = 0.41132816672325134
Iteration 598: Loss = 0.4112440347671509
Iteration 599: Loss = 0.4111606478691101
Iteration 600: Loss = 0.41107770800590515
Iteration 601: Loss = 0.4109953045845032
Iteration 602: Loss = 0.4109134376049042
Iteration 603: Loss = 0.41083213686943054
Iteration 604: Loss = 0.4107513427734375
Iteration 605: Loss = 0.4106709659099579
Iteration 606: Loss = 0.4105910360813141
Iteration 607: Loss = 0.4105115234851837
Iteration 608: Loss = 0.4104327857494354
Iteration 609: Loss = 0.4103544354438782
Iteration 610: Loss = 0.41027650237083435
Iteration 611: Loss = 0.41019904613494873
Iteration 612: Loss = 0.410121887922287
Iteration 613: Loss = 0.41004544496536255
Iteration 614: Loss = 0.4099695384502411
Iteration 615: Loss = 0.40989410877227783
Iteration 616: Loss = 0.4098191559314728
Iteration 617: Loss = 0.4097445011138916
Iteration 618: Loss = 0.40967029333114624
Iteration 619: Loss = 0.40959644317626953
Iteration 620: Loss = 0.4095229506492615
Iteration 621: Loss = 0.40945005416870117
Iteration 622: Loss = 0.4093778133392334
Iteration 623: Loss = 0.4093058109283447
Iteration 624: Loss = 0.40923428535461426
Iteration 625: Loss = 0.40916305780410767
Iteration 626: Loss = 0.4090922772884369
Iteration 627: Loss = 0.40902194380760193
Iteration 628: Loss = 0.4089522063732147
Iteration 629: Loss = 0.4088830053806305
Iteration 630: Loss = 0.40881407260894775
Iteration 631: Loss = 0.40874549746513367
Iteration 632: Loss = 0.40867725014686584
Iteration 633: Loss = 0.4086093008518219
Iteration 634: Loss = 0.40854161977767944
Iteration 635: Loss = 0.4084743559360504
Iteration 636: Loss = 0.408407598733902
Iteration 637: Loss = 0.40834149718284607
Iteration 638: Loss = 0.4082755446434021
Iteration 639: Loss = 0.40820983052253723
Iteration 640: Loss = 0.40814441442489624
Iteration 641: Loss = 0.4080792963504791
Iteration 642: Loss = 0.4080146253108978
Iteration 643: Loss = 0.4079503118991852
Iteration 644: Loss = 0.4078862965106964
Iteration 645: Loss = 0.4078225791454315
Iteration 646: Loss = 0.4077593982219696
Iteration 647: Loss = 0.4076964557170868
Iteration 648: Loss = 0.40763378143310547
Iteration 649: Loss = 0.40757158398628235
Iteration 650: Loss = 0.4075096845626831
Iteration 651: Loss = 0.40744805335998535
Iteration 652: Loss = 0.4073867201805115
Iteration 653: Loss = 0.4073255956172943
Iteration 654: Loss = 0.4072645902633667
Iteration 655: Loss = 0.40720388293266296
Iteration 656: Loss = 0.4071435332298279
Iteration 657: Loss = 0.40708380937576294
Iteration 658: Loss = 0.4070242643356323
Iteration 659: Loss = 0.40696486830711365
Iteration 660: Loss = 0.40690580010414124
Iteration 661: Loss = 0.40684694051742554
Iteration 662: Loss = 0.4067883789539337
Iteration 663: Loss = 0.40673017501831055
Iteration 664: Loss = 0.40667229890823364
Iteration 665: Loss = 0.4066146910190582
Iteration 666: Loss = 0.40655726194381714
Iteration 667: Loss = 0.406499981880188
Iteration 668: Loss = 0.4064428508281708
Iteration 669: Loss = 0.4063858687877655
Iteration 670: Loss = 0.40632909536361694
Iteration 671: Loss = 0.40627267956733704
Iteration 672: Loss = 0.4062167704105377
Iteration 673: Loss = 0.40616104006767273
Iteration 674: Loss = 0.4061054289340973
Iteration 675: Loss = 0.4060499668121338
Iteration 676: Loss = 0.40599462389945984
Iteration 677: Loss = 0.4059396982192993
Iteration 678: Loss = 0.40588507056236267
Iteration 679: Loss = 0.40583062171936035
Iteration 680: Loss = 0.40577638149261475
Iteration 681: Loss = 0.4057222306728363
Iteration 682: Loss = 0.40566834807395935
Iteration 683: Loss = 0.40561479330062866
Iteration 684: Loss = 0.4055614173412323
Iteration 685: Loss = 0.40550827980041504
Iteration 686: Loss = 0.40545526146888733
Iteration 687: Loss = 0.4054024815559387
Iteration 688: Loss = 0.40534982085227966
Iteration 689: Loss = 0.4052973985671997
Iteration 690: Loss = 0.4052450656890869
Iteration 691: Loss = 0.40519294142723083
Iteration 692: Loss = 0.40514102578163147
Iteration 693: Loss = 0.40508928894996643
Iteration 694: Loss = 0.40503761172294617
Iteration 695: Loss = 0.40498608350753784
Iteration 696: Loss = 0.404934823513031
Iteration 697: Loss = 0.40488383173942566
Iteration 698: Loss = 0.4048328995704651
Iteration 699: Loss = 0.4047820568084717
Iteration 700: Loss = 0.4047314524650574
Iteration 701: Loss = 0.4046810269355774
Iteration 702: Loss = 0.40463075041770935
Iteration 703: Loss = 0.404580682516098
Iteration 704: Loss = 0.40453070402145386
Iteration 705: Loss = 0.40448087453842163
Iteration 706: Loss = 0.4044312834739685
Iteration 707: Loss = 0.40438178181648254
Iteration 708: Loss = 0.40433239936828613
Iteration 709: Loss = 0.4042830467224121
Iteration 710: Loss = 0.40423378348350525
Iteration 711: Loss = 0.40418484807014465
Iteration 712: Loss = 0.4041362404823303
Iteration 713: Loss = 0.404087632894516
Iteration 714: Loss = 0.4040391147136688
Iteration 715: Loss = 0.4039906859397888
Iteration 716: Loss = 0.40394243597984314
Iteration 717: Loss = 0.4038943350315094
Iteration 718: Loss = 0.4038465917110443
Iteration 719: Loss = 0.403798907995224
Iteration 720: Loss = 0.40375128388404846
Iteration 721: Loss = 0.40370383858680725
Iteration 722: Loss = 0.4036564230918884
Iteration 723: Loss = 0.40360912680625916
Iteration 724: Loss = 0.40356189012527466
Iteration 725: Loss = 0.4035147726535797
Iteration 726: Loss = 0.40346771478652954
Iteration 727: Loss = 0.40342116355895996
Iteration 728: Loss = 0.4033746123313904
Iteration 729: Loss = 0.403328001499176
Iteration 730: Loss = 0.40328145027160645
Iteration 731: Loss = 0.4032350182533264
Iteration 732: Loss = 0.4031887650489807
Iteration 733: Loss = 0.40314266085624695
Iteration 734: Loss = 0.40309685468673706
Iteration 735: Loss = 0.40305113792419434
Iteration 736: Loss = 0.40300554037094116
Iteration 737: Loss = 0.40296000242233276
Iteration 738: Loss = 0.4029143750667572
Iteration 739: Loss = 0.4028688371181488
Iteration 740: Loss = 0.4028233289718628
Iteration 741: Loss = 0.40277794003486633
Iteration 742: Loss = 0.4027327597141266
Iteration 743: Loss = 0.4026879370212555
Iteration 744: Loss = 0.4026431739330292
Iteration 745: Loss = 0.4025982916355133
Iteration 746: Loss = 0.40255337953567505
Iteration 747: Loss = 0.4025084972381592
Iteration 748: Loss = 0.4024638831615448
Iteration 749: Loss = 0.402419775724411
Iteration 750: Loss = 0.40237554907798767
Iteration 751: Loss = 0.4023312032222748
Iteration 752: Loss = 0.40228700637817383
Iteration 753: Loss = 0.4022429287433624
Iteration 754: Loss = 0.40219879150390625
Iteration 755: Loss = 0.4021548330783844
Iteration 756: Loss = 0.40211090445518494
Iteration 757: Loss = 0.4020671546459198
Iteration 758: Loss = 0.4020235240459442
Iteration 759: Loss = 0.4019800126552582
Iteration 760: Loss = 0.401936411857605
Iteration 761: Loss = 0.40189293026924133
Iteration 762: Loss = 0.4018496572971344
Iteration 763: Loss = 0.4018063545227051
Iteration 764: Loss = 0.4017632305622101
Iteration 765: Loss = 0.4017203152179718
Iteration 766: Loss = 0.4016774296760559
Iteration 767: Loss = 0.4016346037387848
Iteration 768: Loss = 0.40159183740615845
Iteration 769: Loss = 0.4015491306781769
Iteration 770: Loss = 0.4015064537525177
Iteration 771: Loss = 0.40146389603614807
Iteration 772: Loss = 0.40142151713371277
Iteration 773: Loss = 0.40137913823127747
Iteration 774: Loss = 0.4013368487358093
Iteration 775: Loss = 0.4012945890426636
Iteration 776: Loss = 0.4012523591518402
Iteration 777: Loss = 0.40121009945869446
Iteration 778: Loss = 0.40116795897483826
Iteration 779: Loss = 0.4011257290840149
Iteration 780: Loss = 0.4010840058326721
Iteration 781: Loss = 0.4010421633720398
Iteration 782: Loss = 0.4010002315044403
Iteration 783: Loss = 0.4009583592414856
Iteration 784: Loss = 0.4009166359901428
Iteration 785: Loss = 0.4008753299713135
Iteration 786: Loss = 0.40083378553390503
Iteration 787: Loss = 0.40079206228256226
Iteration 788: Loss = 0.40075069665908813
Iteration 789: Loss = 0.4007093608379364
Iteration 790: Loss = 0.40066802501678467
Iteration 791: Loss = 0.4006268084049225
Iteration 792: Loss = 0.4005856215953827
Iteration 793: Loss = 0.4005444645881653
Iteration 794: Loss = 0.4005032479763031
Iteration 795: Loss = 0.40046221017837524
Iteration 796: Loss = 0.4004213809967041
Iteration 797: Loss = 0.40038052201271057
Iteration 798: Loss = 0.4003397524356842
Iteration 799: Loss = 0.4002991020679474
Iteration 800: Loss = 0.40025845170021057
Iteration 801: Loss = 0.40021783113479614
Iteration 802: Loss = 0.40017735958099365
Iteration 803: Loss = 0.4001370072364807
Iteration 804: Loss = 0.40009671449661255
Iteration 805: Loss = 0.40005651116371155
Iteration 806: Loss = 0.4000164270401001
Iteration 807: Loss = 0.39997628331184387
Iteration 808: Loss = 0.3999362289905548
Iteration 809: Loss = 0.3998962342739105
Iteration 810: Loss = 0.3998562693595886
Iteration 811: Loss = 0.3998163342475891
Iteration 812: Loss = 0.39977648854255676
Iteration 813: Loss = 0.39973676204681396
Iteration 814: Loss = 0.39969709515571594
Iteration 815: Loss = 0.39965739846229553
Iteration 816: Loss = 0.3996177315711975
Iteration 817: Loss = 0.3995780646800995
Iteration 818: Loss = 0.39953842759132385
Iteration 819: Loss = 0.3994988203048706
Iteration 820: Loss = 0.3994593918323517
Iteration 821: Loss = 0.39941999316215515
Iteration 822: Loss = 0.399380624294281
Iteration 823: Loss = 0.3993413746356964
Iteration 824: Loss = 0.39930224418640137
Iteration 825: Loss = 0.3992631435394287
Iteration 826: Loss = 0.3992241322994232
Iteration 827: Loss = 0.39918506145477295
Iteration 828: Loss = 0.39914605021476746
Iteration 829: Loss = 0.3991070091724396
Iteration 830: Loss = 0.3990679383277893
Iteration 831: Loss = 0.39902904629707336
Iteration 832: Loss = 0.3989902138710022
Iteration 833: Loss = 0.39895135164260864
Iteration 834: Loss = 0.39891257882118225
Iteration 835: Loss = 0.3988737463951111
Iteration 836: Loss = 0.3988349437713623
Iteration 837: Loss = 0.3987961411476135
Iteration 838: Loss = 0.39875733852386475
Iteration 839: Loss = 0.3987186849117279
Iteration 840: Loss = 0.39868006110191345
Iteration 841: Loss = 0.3986417353153229
Iteration 842: Loss = 0.3986033499240875
Iteration 843: Loss = 0.39856499433517456
Iteration 844: Loss = 0.3985266089439392
Iteration 845: Loss = 0.3984883427619934
Iteration 846: Loss = 0.3984500467777252
Iteration 847: Loss = 0.3984117805957794
Iteration 848: Loss = 0.3983735144138336
Iteration 849: Loss = 0.398335337638855
Iteration 850: Loss = 0.3982972204685211
Iteration 851: Loss = 0.39825913310050964
Iteration 852: Loss = 0.39822113513946533
Iteration 853: Loss = 0.3981831669807434
Iteration 854: Loss = 0.3981451988220215
Iteration 855: Loss = 0.39810726046562195
Iteration 856: Loss = 0.3980693221092224
Iteration 857: Loss = 0.3980313837528229
Iteration 858: Loss = 0.39799338579177856
Iteration 859: Loss = 0.39795535802841187
Iteration 860: Loss = 0.397917777299881
Iteration 861: Loss = 0.39788007736206055
Iteration 862: Loss = 0.3978421986103058
Iteration 863: Loss = 0.3978046178817749
Iteration 864: Loss = 0.39776715636253357
Iteration 865: Loss = 0.39772942662239075
Iteration 866: Loss = 0.3976919651031494
Iteration 867: Loss = 0.3976545035839081
Iteration 868: Loss = 0.39761707186698914
Iteration 869: Loss = 0.3975796103477478
Iteration 870: Loss = 0.39754223823547363
Iteration 871: Loss = 0.3975049555301666
Iteration 872: Loss = 0.3974677622318268
Iteration 873: Loss = 0.3974305987358093
Iteration 874: Loss = 0.39739352464675903
Iteration 875: Loss = 0.39735648036003113
Iteration 876: Loss = 0.3973194658756256
Iteration 877: Loss = 0.39728251099586487
Iteration 878: Loss = 0.39724552631378174
Iteration 879: Loss = 0.3972086012363434
Iteration 880: Loss = 0.39717161655426025
Iteration 881: Loss = 0.39713460206985474
Iteration 882: Loss = 0.397097647190094
Iteration 883: Loss = 0.39706066250801086
Iteration 884: Loss = 0.39702364802360535
Iteration 885: Loss = 0.3969866633415222
Iteration 886: Loss = 0.3969497084617615
Iteration 887: Loss = 0.3969130218029022
Iteration 888: Loss = 0.39687618613243103
Iteration 889: Loss = 0.3968394100666046
Iteration 890: Loss = 0.39680272340774536
Iteration 891: Loss = 0.3967660963535309
Iteration 892: Loss = 0.39672958850860596
Iteration 893: Loss = 0.39669308066368103
Iteration 894: Loss = 0.3966565430164337
Iteration 895: Loss = 0.3966200649738312
Iteration 896: Loss = 0.39658358693122864
Iteration 897: Loss = 0.3965471684932709
Iteration 898: Loss = 0.3965107798576355
Iteration 899: Loss = 0.3964744508266449
Iteration 900: Loss = 0.3964381515979767
Iteration 901: Loss = 0.3964018225669861
Iteration 902: Loss = 0.39636555314064026
Iteration 903: Loss = 0.39632922410964966
Iteration 904: Loss = 0.39629310369491577
Iteration 905: Loss = 0.39625686407089233
Iteration 906: Loss = 0.39622068405151367
Iteration 907: Loss = 0.39618441462516785
Iteration 908: Loss = 0.3961481750011444
Iteration 909: Loss = 0.39611196517944336
Iteration 910: Loss = 0.3960759937763214
Iteration 911: Loss = 0.3960399925708771
Iteration 912: Loss = 0.39600393176078796
Iteration 913: Loss = 0.39596790075302124
Iteration 914: Loss = 0.39593198895454407
Iteration 915: Loss = 0.39589637517929077
Iteration 916: Loss = 0.3958604037761688
Iteration 917: Loss = 0.3958246409893036
Iteration 918: Loss = 0.39578887820243835
Iteration 919: Loss = 0.3957531750202179
Iteration 920: Loss = 0.39571747183799744
Iteration 921: Loss = 0.39568179845809937
Iteration 922: Loss = 0.39564621448516846
Iteration 923: Loss = 0.39561063051223755
Iteration 924: Loss = 0.39557504653930664
Iteration 925: Loss = 0.39553946256637573
Iteration 926: Loss = 0.3955039978027344
Iteration 927: Loss = 0.39546850323677063
Iteration 928: Loss = 0.3954330086708069
Iteration 929: Loss = 0.3953975737094879
Iteration 930: Loss = 0.39536210894584656
Iteration 931: Loss = 0.3953265845775604
Iteration 932: Loss = 0.39529111981391907
Iteration 933: Loss = 0.39525556564331055
Iteration 934: Loss = 0.3952205777168274
Iteration 935: Loss = 0.39518529176712036
Iteration 936: Loss = 0.39514994621276855
Iteration 937: Loss = 0.39511463046073914
Iteration 938: Loss = 0.39507946372032166
Iteration 939: Loss = 0.39504438638687134
Iteration 940: Loss = 0.3950093388557434
Iteration 941: Loss = 0.3949742019176483
Iteration 942: Loss = 0.3949390947818756
Iteration 943: Loss = 0.3949040174484253
Iteration 944: Loss = 0.39486896991729736
Iteration 945: Loss = 0.394834041595459
Iteration 946: Loss = 0.3947991132736206
Iteration 947: Loss = 0.39476415514945984
Iteration 948: Loss = 0.39472928643226624
Iteration 949: Loss = 0.39469435811042786
Iteration 950: Loss = 0.3946593999862671
Iteration 951: Loss = 0.3946245312690735
Iteration 952: Loss = 0.39458969235420227
Iteration 953: Loss = 0.39455485343933105
Iteration 954: Loss = 0.39451995491981506
Iteration 955: Loss = 0.39448511600494385
Iteration 956: Loss = 0.3944500982761383
Iteration 957: Loss = 0.3944157063961029
Iteration 958: Loss = 0.3943811058998108
Iteration 959: Loss = 0.39434632658958435
Iteration 960: Loss = 0.3943115770816803
Iteration 961: Loss = 0.3942769169807434
Iteration 962: Loss = 0.3942424952983856
Iteration 963: Loss = 0.3942079246044159
Iteration 964: Loss = 0.3941733241081238
Iteration 965: Loss = 0.3941388428211212
Iteration 966: Loss = 0.39410439133644104
Iteration 967: Loss = 0.39406999945640564
Iteration 968: Loss = 0.39403560757637024
Iteration 969: Loss = 0.39400121569633484
Iteration 970: Loss = 0.39396679401397705
Iteration 971: Loss = 0.39393243193626404
Iteration 972: Loss = 0.3938980996608734
Iteration 973: Loss = 0.39386382699012756
Iteration 974: Loss = 0.3938295543193817
Iteration 975: Loss = 0.39379528164863586
Iteration 976: Loss = 0.3937610983848572
Iteration 977: Loss = 0.39372682571411133
Iteration 978: Loss = 0.3936925530433655
Iteration 979: Loss = 0.39365842938423157
Iteration 980: Loss = 0.3936241567134857
Iteration 981: Loss = 0.39359036087989807
Iteration 982: Loss = 0.3935563266277313
Iteration 983: Loss = 0.39352208375930786
Iteration 984: Loss = 0.3934878706932068
Iteration 985: Loss = 0.3934541344642639
Iteration 986: Loss = 0.3934203088283539
Iteration 987: Loss = 0.3933861553668976
Iteration 988: Loss = 0.39335232973098755
Iteration 989: Loss = 0.3933184742927551
Iteration 990: Loss = 0.3932846784591675
Iteration 991: Loss = 0.3932509124279022
Iteration 992: Loss = 0.39321717619895935
Iteration 993: Loss = 0.39318346977233887
Iteration 994: Loss = 0.3931496739387512
Iteration 995: Loss = 0.3931160569190979
Iteration 996: Loss = 0.3930824100971222
Iteration 997: Loss = 0.3930487632751465
Iteration 998: Loss = 0.39301520586013794
Iteration 999: Loss = 0.3929815888404846
Iteration 1000: Loss = 0.3929480314254761


Total training time (seconds): 10.83
