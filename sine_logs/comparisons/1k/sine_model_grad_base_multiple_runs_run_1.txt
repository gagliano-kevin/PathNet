Iteration 1: Loss = 0.5053606629371643
Iteration 2: Loss = 0.5041282773017883
Iteration 3: Loss = 0.5028738379478455
Iteration 4: Loss = 0.501595675945282
Iteration 5: Loss = 0.500320553779602
Iteration 6: Loss = 0.4990593194961548
Iteration 7: Loss = 0.4978126883506775
Iteration 8: Loss = 0.4965761601924896
Iteration 9: Loss = 0.49534687399864197
Iteration 10: Loss = 0.4941277503967285
Iteration 11: Loss = 0.4929250180721283
Iteration 12: Loss = 0.491743803024292
Iteration 13: Loss = 0.4905834496021271
Iteration 14: Loss = 0.4894469678401947
Iteration 15: Loss = 0.4883357882499695
Iteration 16: Loss = 0.4872555434703827
Iteration 17: Loss = 0.4862123429775238
Iteration 18: Loss = 0.48521119356155396
Iteration 19: Loss = 0.4842565655708313
Iteration 20: Loss = 0.4833490550518036
Iteration 21: Loss = 0.4824892580509186
Iteration 22: Loss = 0.48167723417282104
Iteration 23: Loss = 0.4809098541736603
Iteration 24: Loss = 0.4801846444606781
Iteration 25: Loss = 0.47949376702308655
Iteration 26: Loss = 0.47882896661758423
Iteration 27: Loss = 0.4781811535358429
Iteration 28: Loss = 0.47754108905792236
Iteration 29: Loss = 0.47690096497535706
Iteration 30: Loss = 0.47625523805618286
Iteration 31: Loss = 0.47560012340545654
Iteration 32: Loss = 0.47493451833724976
Iteration 33: Loss = 0.47425952553749084
Iteration 34: Loss = 0.47357824444770813
Iteration 35: Loss = 0.47289496660232544
Iteration 36: Loss = 0.47221389412879944
Iteration 37: Loss = 0.4715389311313629
Iteration 38: Loss = 0.47087347507476807
Iteration 39: Loss = 0.47022005915641785
Iteration 40: Loss = 0.46957993507385254
Iteration 41: Loss = 0.46895307302474976
Iteration 42: Loss = 0.46833905577659607
Iteration 43: Loss = 0.4677368104457855
Iteration 44: Loss = 0.46714499592781067
Iteration 45: Loss = 0.46656185388565063
Iteration 46: Loss = 0.46598583459854126
Iteration 47: Loss = 0.465415894985199
Iteration 48: Loss = 0.46485093235969543
Iteration 49: Loss = 0.464290052652359
Iteration 50: Loss = 0.46373260021209717
Iteration 51: Loss = 0.4631783962249756
Iteration 52: Loss = 0.4626273214817047
Iteration 53: Loss = 0.46207955479621887
Iteration 54: Loss = 0.4615354537963867
Iteration 55: Loss = 0.4609953761100769
Iteration 56: Loss = 0.4604598581790924
Iteration 57: Loss = 0.4599282145500183
Iteration 58: Loss = 0.45937925577163696
Iteration 59: Loss = 0.45884016156196594
Iteration 60: Loss = 0.4583711326122284
Iteration 61: Loss = 0.4579053521156311
Iteration 62: Loss = 0.45741650462150574
Iteration 63: Loss = 0.4569283425807953
Iteration 64: Loss = 0.4564506709575653
Iteration 65: Loss = 0.45597657561302185
Iteration 66: Loss = 0.4555017054080963
Iteration 67: Loss = 0.455038845539093
Iteration 68: Loss = 0.45459720492362976
Iteration 69: Loss = 0.45416635274887085
Iteration 70: Loss = 0.45372888445854187
Iteration 71: Loss = 0.45328205823898315
Iteration 72: Loss = 0.45283788442611694
Iteration 73: Loss = 0.45240581035614014
Iteration 74: Loss = 0.45198389887809753
Iteration 75: Loss = 0.45156586170196533
Iteration 76: Loss = 0.4511511027812958
Iteration 77: Loss = 0.4507421851158142
Iteration 78: Loss = 0.4503379166126251
Iteration 79: Loss = 0.449934720993042
Iteration 80: Loss = 0.4495337903499603
Iteration 81: Loss = 0.4491393566131592
Iteration 82: Loss = 0.44875332713127136
Iteration 83: Loss = 0.44837403297424316
Iteration 84: Loss = 0.4479973018169403
Iteration 85: Loss = 0.4476223886013031
Iteration 86: Loss = 0.44725123047828674
Iteration 87: Loss = 0.44688528776168823
Iteration 88: Loss = 0.44652342796325684
Iteration 89: Loss = 0.4461655616760254
Iteration 90: Loss = 0.44581255316734314
Iteration 91: Loss = 0.44546425342559814
Iteration 92: Loss = 0.4451198875904083
Iteration 93: Loss = 0.4447784423828125
Iteration 94: Loss = 0.4444405138492584
Iteration 95: Loss = 0.4441071152687073
Iteration 96: Loss = 0.4437786936759949
Iteration 97: Loss = 0.4434545636177063
Iteration 98: Loss = 0.443134069442749
Iteration 99: Loss = 0.442817360162735
Iteration 100: Loss = 0.4425047039985657
Iteration 101: Loss = 0.44219622015953064
Iteration 102: Loss = 0.44189149141311646
Iteration 103: Loss = 0.4415905475616455
Iteration 104: Loss = 0.4412935674190521
Iteration 105: Loss = 0.44100114703178406
Iteration 106: Loss = 0.44071245193481445
Iteration 107: Loss = 0.4404272735118866
Iteration 108: Loss = 0.4401458501815796
Iteration 109: Loss = 0.4398685693740845
Iteration 110: Loss = 0.439595103263855
Iteration 111: Loss = 0.4393254220485687
Iteration 112: Loss = 0.4390595555305481
Iteration 113: Loss = 0.43879765272140503
Iteration 114: Loss = 0.4385392367839813
Iteration 115: Loss = 0.43828442692756653
Iteration 116: Loss = 0.43803325295448303
Iteration 117: Loss = 0.4377860426902771
Iteration 118: Loss = 0.43754225969314575
Iteration 119: Loss = 0.43730202317237854
Iteration 120: Loss = 0.4370655119419098
Iteration 121: Loss = 0.43683260679244995
Iteration 122: Loss = 0.43660321831703186
Iteration 123: Loss = 0.4363771378993988
Iteration 124: Loss = 0.4361546039581299
Iteration 125: Loss = 0.4359355866909027
Iteration 126: Loss = 0.4357198476791382
Iteration 127: Loss = 0.43550726771354675
Iteration 128: Loss = 0.43529802560806274
Iteration 129: Loss = 0.43509209156036377
Iteration 130: Loss = 0.4348892867565155
Iteration 131: Loss = 0.43468958139419556
Iteration 132: Loss = 0.4344930946826935
Iteration 133: Loss = 0.43429967761039734
Iteration 134: Loss = 0.4341093897819519
Iteration 135: Loss = 0.4339221119880676
Iteration 136: Loss = 0.43373775482177734
Iteration 137: Loss = 0.43355637788772583
Iteration 138: Loss = 0.43337780237197876
Iteration 139: Loss = 0.43320202827453613
Iteration 140: Loss = 0.4330289363861084
Iteration 141: Loss = 0.43285858631134033
Iteration 142: Loss = 0.43269082903862
Iteration 143: Loss = 0.43252575397491455
Iteration 144: Loss = 0.43236321210861206
Iteration 145: Loss = 0.432203084230423
Iteration 146: Loss = 0.43204569816589355
Iteration 147: Loss = 0.431890606880188
Iteration 148: Loss = 0.43173786997795105
Iteration 149: Loss = 0.4315873384475708
Iteration 150: Loss = 0.43143919110298157
Iteration 151: Loss = 0.4312931299209595
Iteration 152: Loss = 0.4311491847038269
Iteration 153: Loss = 0.4310073256492615
Iteration 154: Loss = 0.430867463350296
Iteration 155: Loss = 0.4307295083999634
Iteration 156: Loss = 0.43059346079826355
Iteration 157: Loss = 0.43045949935913086
Iteration 158: Loss = 0.43032732605934143
Iteration 159: Loss = 0.4301968812942505
Iteration 160: Loss = 0.4300680160522461
Iteration 161: Loss = 0.4299408495426178
Iteration 162: Loss = 0.4298153817653656
Iteration 163: Loss = 0.42969125509262085
Iteration 164: Loss = 0.42956867814064026
Iteration 165: Loss = 0.4294474422931671
Iteration 166: Loss = 0.42932766675949097
Iteration 167: Loss = 0.4292094111442566
Iteration 168: Loss = 0.4290924072265625
Iteration 169: Loss = 0.4289765954017639
Iteration 170: Loss = 0.42886194586753845
Iteration 171: Loss = 0.42874833941459656
Iteration 172: Loss = 0.42863595485687256
Iteration 173: Loss = 0.4285244941711426
Iteration 174: Loss = 0.4284140467643738
Iteration 175: Loss = 0.4283044636249542
Iteration 176: Loss = 0.42819586396217346
Iteration 177: Loss = 0.4280881881713867
Iteration 178: Loss = 0.42798125743865967
Iteration 179: Loss = 0.4278751015663147
Iteration 180: Loss = 0.4277697205543518
Iteration 181: Loss = 0.4276649057865143
Iteration 182: Loss = 0.4275607764720917
Iteration 183: Loss = 0.42745721340179443
Iteration 184: Loss = 0.427354097366333
Iteration 185: Loss = 0.42725154757499695
Iteration 186: Loss = 0.42714959383010864
Iteration 187: Loss = 0.4270481467247009
Iteration 188: Loss = 0.42694705724716187
Iteration 189: Loss = 0.42684632539749146
Iteration 190: Loss = 0.4267459809780121
Iteration 191: Loss = 0.4266459345817566
Iteration 192: Loss = 0.42654621601104736
Iteration 193: Loss = 0.42644667625427246
Iteration 194: Loss = 0.4263472855091095
Iteration 195: Loss = 0.426248162984848
Iteration 196: Loss = 0.42614927887916565
Iteration 197: Loss = 0.4260505139827728
Iteration 198: Loss = 0.42595189809799194
Iteration 199: Loss = 0.42585331201553345
Iteration 200: Loss = 0.42575469613075256
Iteration 201: Loss = 0.4256562292575836
Iteration 202: Loss = 0.4255576431751251
Iteration 203: Loss = 0.425459086894989
Iteration 204: Loss = 0.42536041140556335
Iteration 205: Loss = 0.42526188492774963
Iteration 206: Loss = 0.42516323924064636
Iteration 207: Loss = 0.4250645339488983
Iteration 208: Loss = 0.42496559023857117
Iteration 209: Loss = 0.4248664677143097
Iteration 210: Loss = 0.42476728558540344
Iteration 211: Loss = 0.4246678352355957
Iteration 212: Loss = 0.4245682954788208
Iteration 213: Loss = 0.424468457698822
Iteration 214: Loss = 0.42436838150024414
Iteration 215: Loss = 0.4242681860923767
Iteration 216: Loss = 0.4241677522659302
Iteration 217: Loss = 0.42406708002090454
Iteration 218: Loss = 0.4239659905433655
Iteration 219: Loss = 0.4238646924495697
Iteration 220: Loss = 0.4237629771232605
Iteration 221: Loss = 0.42366108298301697
Iteration 222: Loss = 0.42355877161026
Iteration 223: Loss = 0.4234561026096344
Iteration 224: Loss = 0.4233531355857849
Iteration 225: Loss = 0.42324990034103394
Iteration 226: Loss = 0.4231463670730591
Iteration 227: Loss = 0.423042356967926
Iteration 228: Loss = 0.42293810844421387
Iteration 229: Loss = 0.4228334128856659
Iteration 230: Loss = 0.4227283298969269
Iteration 231: Loss = 0.4226227402687073
Iteration 232: Loss = 0.4225168824195862
Iteration 233: Loss = 0.4224105179309845
Iteration 234: Loss = 0.422303706407547
Iteration 235: Loss = 0.4221965968608856
Iteration 236: Loss = 0.42208921909332275
Iteration 237: Loss = 0.4219813942909241
Iteration 238: Loss = 0.4218730032444
Iteration 239: Loss = 0.4217642843723297
Iteration 240: Loss = 0.4216551184654236
Iteration 241: Loss = 0.42154544591903687
Iteration 242: Loss = 0.4214353561401367
Iteration 243: Loss = 0.4213249087333679
Iteration 244: Loss = 0.42121386528015137
Iteration 245: Loss = 0.4211026430130005
Iteration 246: Loss = 0.42099079489707947
Iteration 247: Loss = 0.42087846994400024
Iteration 248: Loss = 0.42076608538627625
Iteration 249: Loss = 0.42065301537513733
Iteration 250: Loss = 0.4205394983291626
Iteration 251: Loss = 0.420425683259964
Iteration 252: Loss = 0.4203112721443176
Iteration 253: Loss = 0.4201965034008026
Iteration 254: Loss = 0.4200812578201294
Iteration 255: Loss = 0.41996562480926514
Iteration 256: Loss = 0.41984954476356506
Iteration 257: Loss = 0.41973310708999634
Iteration 258: Loss = 0.41961613297462463
Iteration 259: Loss = 0.4194987714290619
Iteration 260: Loss = 0.41938096284866333
Iteration 261: Loss = 0.41926273703575134
Iteration 262: Loss = 0.4191440939903259
Iteration 263: Loss = 0.4190250635147095
Iteration 264: Loss = 0.4189055562019348
Iteration 265: Loss = 0.4187856912612915
Iteration 266: Loss = 0.4186653792858124
Iteration 267: Loss = 0.4185446798801422
Iteration 268: Loss = 0.41842353343963623
Iteration 269: Loss = 0.41830188035964966
Iteration 270: Loss = 0.41817981004714966
Iteration 271: Loss = 0.418057382106781
Iteration 272: Loss = 0.41793444752693176
Iteration 273: Loss = 0.4178110659122467
Iteration 274: Loss = 0.4176872968673706
Iteration 275: Loss = 0.41756314039230347
Iteration 276: Loss = 0.41743847727775574
Iteration 277: Loss = 0.41731342673301697
Iteration 278: Loss = 0.4171878397464752
Iteration 279: Loss = 0.4170619547367096
Iteration 280: Loss = 0.416935533285141
Iteration 281: Loss = 0.4168087840080261
Iteration 282: Loss = 0.41668155789375305
Iteration 283: Loss = 0.41655394434928894
Iteration 284: Loss = 0.416425883769989
Iteration 285: Loss = 0.4162973463535309
Iteration 286: Loss = 0.41616857051849365
Iteration 287: Loss = 0.41603919863700867
Iteration 288: Loss = 0.41590940952301025
Iteration 289: Loss = 0.4157792925834656
Iteration 290: Loss = 0.41564854979515076
Iteration 291: Loss = 0.41551756858825684
Iteration 292: Loss = 0.4153861403465271
Iteration 293: Loss = 0.41525426506996155
Iteration 294: Loss = 0.4151219427585602
Iteration 295: Loss = 0.4149892032146454
Iteration 296: Loss = 0.41485604643821716
Iteration 297: Loss = 0.41472241282463074
Iteration 298: Loss = 0.41458842158317566
Iteration 299: Loss = 0.4144539535045624
Iteration 300: Loss = 0.41431906819343567
Iteration 301: Loss = 0.4141837954521179
Iteration 302: Loss = 0.41404810547828674
Iteration 303: Loss = 0.41391196846961975
Iteration 304: Loss = 0.41377538442611694
Iteration 305: Loss = 0.4136384129524231
Iteration 306: Loss = 0.41350099444389343
Iteration 307: Loss = 0.4133632183074951
Iteration 308: Loss = 0.4132250249385834
Iteration 309: Loss = 0.4130864143371582
Iteration 310: Loss = 0.4129473865032196
Iteration 311: Loss = 0.41280797123908997
Iteration 312: Loss = 0.4126680791378021
Iteration 313: Loss = 0.41252782940864563
Iteration 314: Loss = 0.4123871326446533
Iteration 315: Loss = 0.41224613785743713
Iteration 316: Loss = 0.41210469603538513
Iteration 317: Loss = 0.41196298599243164
Iteration 318: Loss = 0.4118206799030304
Iteration 319: Loss = 0.41167810559272766
Iteration 320: Loss = 0.41153499484062195
Iteration 321: Loss = 0.4113916754722595
Iteration 322: Loss = 0.4112476408481598
Iteration 323: Loss = 0.41110357642173767
Iteration 324: Loss = 0.41095873713493347
Iteration 325: Loss = 0.41081371903419495
Iteration 326: Loss = 0.4106683135032654
Iteration 327: Loss = 0.4105226993560791
Iteration 328: Loss = 0.4103763997554779
Iteration 329: Loss = 0.41022989153862
Iteration 330: Loss = 0.4100828766822815
Iteration 331: Loss = 0.40993553400039673
Iteration 332: Loss = 0.4097880721092224
Iteration 333: Loss = 0.4096398651599884
Iteration 334: Loss = 0.4094915986061096
Iteration 335: Loss = 0.4093426465988159
Iteration 336: Loss = 0.40919360518455505
Iteration 337: Loss = 0.4090441167354584
Iteration 338: Loss = 0.408894419670105
Iteration 339: Loss = 0.40874412655830383
Iteration 340: Loss = 0.40859365463256836
Iteration 341: Loss = 0.40844297409057617
Iteration 342: Loss = 0.408291757106781
Iteration 343: Loss = 0.40814000368118286
Iteration 344: Loss = 0.40798813104629517
Iteration 345: Loss = 0.407835990190506
Iteration 346: Loss = 0.40768352150917053
Iteration 347: Loss = 0.4075305759906769
Iteration 348: Loss = 0.4073774814605713
Iteration 349: Loss = 0.4072238802909851
Iteration 350: Loss = 0.4070700407028198
Iteration 351: Loss = 0.4069158434867859
Iteration 352: Loss = 0.4067615270614624
Iteration 353: Loss = 0.4066065549850464
Iteration 354: Loss = 0.40645137429237366
Iteration 355: Loss = 0.4062959551811218
Iteration 356: Loss = 0.4061402678489685
Iteration 357: Loss = 0.40598416328430176
Iteration 358: Loss = 0.4058278203010559
Iteration 359: Loss = 0.4056711196899414
Iteration 360: Loss = 0.4055141806602478
Iteration 361: Loss = 0.4053569436073303
Iteration 362: Loss = 0.4051995277404785
Iteration 363: Loss = 0.40504172444343567
Iteration 364: Loss = 0.404883474111557
Iteration 365: Loss = 0.4047252833843231
Iteration 366: Loss = 0.4045664668083191
Iteration 367: Loss = 0.4044076204299927
Iteration 368: Loss = 0.40424850583076477
Iteration 369: Loss = 0.4040890634059906
Iteration 370: Loss = 0.4039294421672821
Iteration 371: Loss = 0.40376946330070496
Iteration 372: Loss = 0.4036094844341278
Iteration 373: Loss = 0.4034489393234253
Iteration 374: Loss = 0.403288334608078
Iteration 375: Loss = 0.4031274914741516
Iteration 376: Loss = 0.4029664397239685
Iteration 377: Loss = 0.40280523896217346
Iteration 378: Loss = 0.40264347195625305
Iteration 379: Loss = 0.4024817645549774
Iteration 380: Loss = 0.4023197591304779
Iteration 381: Loss = 0.4021574854850769
Iteration 382: Loss = 0.4019951820373535
Iteration 383: Loss = 0.40183237195014954
Iteration 384: Loss = 0.4016697108745575
Iteration 385: Loss = 0.4015066623687744
Iteration 386: Loss = 0.4013434946537018
Iteration 387: Loss = 0.40118029713630676
Iteration 388: Loss = 0.4010167121887207
Iteration 389: Loss = 0.40085309743881226
Iteration 390: Loss = 0.40068912506103516
Iteration 391: Loss = 0.4005250930786133
Iteration 392: Loss = 0.400361031293869
Iteration 393: Loss = 0.4001966118812561
Iteration 394: Loss = 0.4000321328639984
Iteration 395: Loss = 0.3998674750328064
Iteration 396: Loss = 0.3997025489807129
Iteration 397: Loss = 0.3995376229286194
Iteration 398: Loss = 0.39937248826026917
Iteration 399: Loss = 0.3992071747779846
Iteration 400: Loss = 0.39904171228408813
Iteration 401: Loss = 0.3988761007785797
Iteration 402: Loss = 0.3987103998661041
Iteration 403: Loss = 0.3985446095466614
Iteration 404: Loss = 0.39837875962257385
Iteration 405: Loss = 0.39821290969848633
Iteration 406: Loss = 0.39804700016975403
Iteration 407: Loss = 0.39788079261779785
Iteration 408: Loss = 0.39771467447280884
Iteration 409: Loss = 0.3975484371185303
Iteration 410: Loss = 0.39738190174102783
Iteration 411: Loss = 0.39721548557281494
Iteration 412: Loss = 0.3970491886138916
Iteration 413: Loss = 0.3968825042247772
Iteration 414: Loss = 0.39671576023101807
Iteration 415: Loss = 0.3965490758419037
Iteration 416: Loss = 0.39638233184814453
Iteration 417: Loss = 0.3962155282497406
Iteration 418: Loss = 0.3960486352443695
Iteration 419: Loss = 0.3958817720413208
Iteration 420: Loss = 0.3957149088382721
Iteration 421: Loss = 0.3955479860305786
Iteration 422: Loss = 0.39538121223449707
Iteration 423: Loss = 0.395214319229126
Iteration 424: Loss = 0.3950473368167877
Iteration 425: Loss = 0.3948805630207062
Iteration 426: Loss = 0.39471349120140076
Iteration 427: Loss = 0.3945464789867401
Iteration 428: Loss = 0.3943796157836914
Iteration 429: Loss = 0.3942125141620636
Iteration 430: Loss = 0.3940456509590149
Iteration 431: Loss = 0.3938789367675781
Iteration 432: Loss = 0.39371228218078613
Iteration 433: Loss = 0.3935457170009613
Iteration 434: Loss = 0.393378883600235
Iteration 435: Loss = 0.3932121992111206
Iteration 436: Loss = 0.3930456042289734
Iteration 437: Loss = 0.39287900924682617
Iteration 438: Loss = 0.39271262288093567
Iteration 439: Loss = 0.392544686794281
Iteration 440: Loss = 0.39233148097991943
Iteration 441: Loss = 0.392190545797348
Iteration 442: Loss = 0.3922211527824402
Iteration 443: Loss = 0.3919193744659424
Iteration 444: Loss = 0.3917335271835327
Iteration 445: Loss = 0.3916122317314148
Iteration 446: Loss = 0.3913658857345581
Iteration 447: Loss = 0.39139801263809204
Iteration 448: Loss = 0.3910863995552063
Iteration 449: Loss = 0.3909756541252136
Iteration 450: Loss = 0.3908078372478485
Iteration 451: Loss = 0.39067378640174866
Iteration 452: Loss = 0.39042481780052185
Iteration 453: Loss = 0.39029598236083984
Iteration 454: Loss = 0.3902004659175873
Iteration 455: Loss = 0.38995835185050964
Iteration 456: Loss = 0.38981014490127563
Iteration 457: Loss = 0.3897017240524292
Iteration 458: Loss = 0.3895275592803955
Iteration 459: Loss = 0.389333039522171
Iteration 460: Loss = 0.38920047879219055
Iteration 461: Loss = 0.38906845450401306
Iteration 462: Loss = 0.3888804614543915
Iteration 463: Loss = 0.3887239098548889
Iteration 464: Loss = 0.38859549164772034
Iteration 465: Loss = 0.38842856884002686
Iteration 466: Loss = 0.3882608711719513
Iteration 467: Loss = 0.38812604546546936
Iteration 468: Loss = 0.38797566294670105
Iteration 469: Loss = 0.3878057599067688
Iteration 470: Loss = 0.38766178488731384
Iteration 471: Loss = 0.38752031326293945
Iteration 472: Loss = 0.38735589385032654
Iteration 473: Loss = 0.38720330595970154
Iteration 474: Loss = 0.3870629370212555
Iteration 475: Loss = 0.38690707087516785
Iteration 476: Loss = 0.3867519795894623
Iteration 477: Loss = 0.38660937547683716
Iteration 478: Loss = 0.3864596486091614
Iteration 479: Loss = 0.38630378246307373
Iteration 480: Loss = 0.38615962862968445
Iteration 481: Loss = 0.38601407408714294
Iteration 482: Loss = 0.385860413312912
Iteration 483: Loss = 0.3857133984565735
Iteration 484: Loss = 0.38556987047195435
Iteration 485: Loss = 0.38541924953460693
Iteration 486: Loss = 0.38527020812034607
Iteration 487: Loss = 0.3851277828216553
Iteration 488: Loss = 0.38497984409332275
Iteration 489: Loss = 0.38483119010925293
Iteration 490: Loss = 0.3846879303455353
Iteration 491: Loss = 0.3845424950122833
Iteration 492: Loss = 0.3843950033187866
Iteration 493: Loss = 0.38425323367118835
Iteration 494: Loss = 0.3841078579425812
Iteration 495: Loss = 0.38396209478378296
Iteration 496: Loss = 0.383820503950119
Iteration 497: Loss = 0.38367515802383423
Iteration 498: Loss = 0.3835321366786957
Iteration 499: Loss = 0.3833882808685303
Iteration 500: Loss = 0.3832464814186096
Iteration 501: Loss = 0.38310307264328003
Iteration 502: Loss = 0.3829609155654907
Iteration 503: Loss = 0.382820188999176
Iteration 504: Loss = 0.3826776146888733
Iteration 505: Loss = 0.3825371563434601
Iteration 506: Loss = 0.38239696621894836
Iteration 507: Loss = 0.3822556734085083
Iteration 508: Loss = 0.3821159601211548
Iteration 509: Loss = 0.3819766640663147
Iteration 510: Loss = 0.3818370997905731
Iteration 511: Loss = 0.38169801235198975
Iteration 512: Loss = 0.38155966997146606
Iteration 513: Loss = 0.3814212679862976
Iteration 514: Loss = 0.38128358125686646
Iteration 515: Loss = 0.38114628195762634
Iteration 516: Loss = 0.38100922107696533
Iteration 517: Loss = 0.3808726370334625
Iteration 518: Loss = 0.38073647022247314
Iteration 519: Loss = 0.38060083985328674
Iteration 520: Loss = 0.38046514987945557
Iteration 521: Loss = 0.38033005595207214
Iteration 522: Loss = 0.3801954686641693
Iteration 523: Loss = 0.38006120920181274
Iteration 524: Loss = 0.3799273371696472
Iteration 525: Loss = 0.37979400157928467
Iteration 526: Loss = 0.3796611726284027
Iteration 527: Loss = 0.3795284926891327
Iteration 528: Loss = 0.3793964087963104
Iteration 529: Loss = 0.37926486134529114
Iteration 530: Loss = 0.3791336119174957
Iteration 531: Loss = 0.37900254130363464
Iteration 532: Loss = 0.3788720369338989
Iteration 533: Loss = 0.37874194979667664
Iteration 534: Loss = 0.3786121904850006
Iteration 535: Loss = 0.3784828186035156
Iteration 536: Loss = 0.37835392355918884
Iteration 537: Loss = 0.37822526693344116
Iteration 538: Loss = 0.3780969977378845
Iteration 539: Loss = 0.37796905636787415
Iteration 540: Loss = 0.3778415024280548
Iteration 541: Loss = 0.3777143061161041
Iteration 542: Loss = 0.37758761644363403
Iteration 543: Loss = 0.37746158242225647
Iteration 544: Loss = 0.37733596563339233
Iteration 545: Loss = 0.3772108256816864
Iteration 546: Loss = 0.3770860433578491
Iteration 547: Loss = 0.37696176767349243
Iteration 548: Loss = 0.37683776021003723
Iteration 549: Loss = 0.3767142593860626
Iteration 550: Loss = 0.3765909969806671
Iteration 551: Loss = 0.37646833062171936
Iteration 552: Loss = 0.37634602189064026
Iteration 553: Loss = 0.3762243986129761
Iteration 554: Loss = 0.3761032521724701
Iteration 555: Loss = 0.37598252296447754
Iteration 556: Loss = 0.37586209177970886
Iteration 557: Loss = 0.375742107629776
Iteration 558: Loss = 0.37562280893325806
Iteration 559: Loss = 0.3755035698413849
Iteration 560: Loss = 0.3753848671913147
Iteration 561: Loss = 0.37526676058769226
Iteration 562: Loss = 0.37514904141426086
Iteration 563: Loss = 0.3750317394733429
Iteration 564: Loss = 0.3749149739742279
Iteration 565: Loss = 0.37479883432388306
Iteration 566: Loss = 0.374683141708374
Iteration 567: Loss = 0.37456774711608887
Iteration 568: Loss = 0.3744528889656067
Iteration 569: Loss = 0.37433838844299316
Iteration 570: Loss = 0.3742245137691498
Iteration 571: Loss = 0.3741108477115631
Iteration 572: Loss = 0.3739977777004242
Iteration 573: Loss = 0.3738851249217987
Iteration 574: Loss = 0.3737727105617523
Iteration 575: Loss = 0.37366047501564026
Iteration 576: Loss = 0.3735494017601013
Iteration 577: Loss = 0.3734389543533325
Iteration 578: Loss = 0.37332817912101746
Iteration 579: Loss = 0.3732180893421173
Iteration 580: Loss = 0.37310898303985596
Iteration 581: Loss = 0.37299972772598267
Iteration 582: Loss = 0.37289077043533325
Iteration 583: Loss = 0.3727830946445465
Iteration 584: Loss = 0.37267518043518066
Iteration 585: Loss = 0.37256738543510437
Iteration 586: Loss = 0.37246057391166687
Iteration 587: Loss = 0.3723541796207428
Iteration 588: Loss = 0.37224888801574707
Iteration 589: Loss = 0.3721443712711334
Iteration 590: Loss = 0.37203899025917053
Iteration 591: Loss = 0.3719347417354584
Iteration 592: Loss = 0.3718319833278656
Iteration 593: Loss = 0.37172847986221313
Iteration 594: Loss = 0.37162479758262634
Iteration 595: Loss = 0.37152227759361267
Iteration 596: Loss = 0.3714207708835602
Iteration 597: Loss = 0.37131935358047485
Iteration 598: Loss = 0.37121790647506714
Iteration 599: Loss = 0.3711175322532654
Iteration 600: Loss = 0.37101784348487854
Iteration 601: Loss = 0.3709181547164917
Iteration 602: Loss = 0.3708188235759735
Iteration 603: Loss = 0.3707197606563568
Iteration 604: Loss = 0.3706222474575043
Iteration 605: Loss = 0.3705257475376129
Iteration 606: Loss = 0.3704277276992798
Iteration 607: Loss = 0.3703300654888153
Iteration 608: Loss = 0.37023308873176575
Iteration 609: Loss = 0.3701378107070923
Iteration 610: Loss = 0.37004342675209045
Iteration 611: Loss = 0.36994847655296326
Iteration 612: Loss = 0.36985331773757935
Iteration 613: Loss = 0.36975887417793274
Iteration 614: Loss = 0.36966589093208313
Iteration 615: Loss = 0.3695739209651947
Iteration 616: Loss = 0.36948099732398987
Iteration 617: Loss = 0.36938783526420593
Iteration 618: Loss = 0.36929580569267273
Iteration 619: Loss = 0.36920541524887085
Iteration 620: Loss = 0.36911478638648987
Iteration 621: Loss = 0.3690236210823059
Iteration 622: Loss = 0.3689332902431488
Iteration 623: Loss = 0.3688444495201111
Iteration 624: Loss = 0.36875590682029724
Iteration 625: Loss = 0.3686668872833252
Iteration 626: Loss = 0.3685779869556427
Iteration 627: Loss = 0.36849072575569153
Iteration 628: Loss = 0.3684048056602478
Iteration 629: Loss = 0.36831796169281006
Iteration 630: Loss = 0.36823055148124695
Iteration 631: Loss = 0.3681440055370331
Iteration 632: Loss = 0.36805975437164307
Iteration 633: Loss = 0.367975652217865
Iteration 634: Loss = 0.3678906559944153
Iteration 635: Loss = 0.3678062856197357
Iteration 636: Loss = 0.36772164702415466
Iteration 637: Loss = 0.3676382005214691
Iteration 638: Loss = 0.3675559461116791
Iteration 639: Loss = 0.3674737811088562
Iteration 640: Loss = 0.367391973733902
Iteration 641: Loss = 0.3673097491264343
Iteration 642: Loss = 0.36722785234451294
Iteration 643: Loss = 0.36714667081832886
Iteration 644: Loss = 0.367066890001297
Iteration 645: Loss = 0.3669874966144562
Iteration 646: Loss = 0.36690789461135864
Iteration 647: Loss = 0.36682838201522827
Iteration 648: Loss = 0.3667498528957367
Iteration 649: Loss = 0.3666723072528839
Iteration 650: Loss = 0.36659538745880127
Iteration 651: Loss = 0.36651796102523804
Iteration 652: Loss = 0.3664410412311554
Iteration 653: Loss = 0.3663637042045593
Iteration 654: Loss = 0.3662865459918976
Iteration 655: Loss = 0.3662108778953552
Iteration 656: Loss = 0.36613672971725464
Iteration 657: Loss = 0.3660626709461212
Iteration 658: Loss = 0.3659873604774475
Iteration 659: Loss = 0.36591196060180664
Iteration 660: Loss = 0.365837424993515
Iteration 661: Loss = 0.3657648265361786
Iteration 662: Loss = 0.3656938374042511
Iteration 663: Loss = 0.36562269926071167
Iteration 664: Loss = 0.3655508756637573
Iteration 665: Loss = 0.3654782474040985
Iteration 666: Loss = 0.3654048442840576
Iteration 667: Loss = 0.3653327524662018
Iteration 668: Loss = 0.36526206135749817
Iteration 669: Loss = 0.36519232392311096
Iteration 670: Loss = 0.3651232123374939
Iteration 671: Loss = 0.36505478620529175
Iteration 672: Loss = 0.36498528718948364
Iteration 673: Loss = 0.36491522192955017
Iteration 674: Loss = 0.36484599113464355
Iteration 675: Loss = 0.364777535200119
Iteration 676: Loss = 0.3647095859050751
Iteration 677: Loss = 0.3646424412727356
Iteration 678: Loss = 0.3645767569541931
Iteration 679: Loss = 0.3645111322402954
Iteration 680: Loss = 0.3644459843635559
Iteration 681: Loss = 0.3643829822540283
Iteration 682: Loss = 0.36432087421417236
Iteration 683: Loss = 0.3642564117908478
Iteration 684: Loss = 0.3641911745071411
Iteration 685: Loss = 0.3641252815723419
Iteration 686: Loss = 0.3640579879283905
Iteration 687: Loss = 0.36399054527282715
Iteration 688: Loss = 0.36392509937286377
Iteration 689: Loss = 0.3638620972633362
Iteration 690: Loss = 0.36380138993263245
Iteration 691: Loss = 0.3637421131134033
Iteration 692: Loss = 0.3636820316314697
Iteration 693: Loss = 0.3636232614517212
Iteration 694: Loss = 0.3635646104812622
Iteration 695: Loss = 0.36350321769714355
Iteration 696: Loss = 0.3634413182735443
Iteration 697: Loss = 0.363381564617157
Iteration 698: Loss = 0.3633204698562622
Iteration 699: Loss = 0.3632569909095764
Iteration 700: Loss = 0.3631952404975891
Iteration 701: Loss = 0.3631344437599182
Iteration 702: Loss = 0.3630756735801697
Iteration 703: Loss = 0.3630184233188629
Iteration 704: Loss = 0.3629622757434845
Iteration 705: Loss = 0.36290621757507324
Iteration 706: Loss = 0.3628494143486023
Iteration 707: Loss = 0.3627922832965851
Iteration 708: Loss = 0.3627353310585022
Iteration 709: Loss = 0.3626783490180969
Iteration 710: Loss = 0.3626216948032379
Iteration 711: Loss = 0.3625646233558655
Iteration 712: Loss = 0.36250805854797363
Iteration 713: Loss = 0.362452894449234
Iteration 714: Loss = 0.3623991012573242
Iteration 715: Loss = 0.36234626173973083
Iteration 716: Loss = 0.3622934818267822
Iteration 717: Loss = 0.3622407615184784
Iteration 718: Loss = 0.36218950152397156
Iteration 719: Loss = 0.36213743686676025
Iteration 720: Loss = 0.36208611726760864
Iteration 721: Loss = 0.3620354235172272
Iteration 722: Loss = 0.3619857728481293
Iteration 723: Loss = 0.3619360327720642
Iteration 724: Loss = 0.36188533902168274
Iteration 725: Loss = 0.3618333041667938
Iteration 726: Loss = 0.3617786765098572
Iteration 727: Loss = 0.3617229163646698
Iteration 728: Loss = 0.3616679608821869
Iteration 729: Loss = 0.3616150915622711
Iteration 730: Loss = 0.36156556010246277
Iteration 731: Loss = 0.361518532037735
Iteration 732: Loss = 0.36147215962409973
Iteration 733: Loss = 0.3614251911640167
Iteration 734: Loss = 0.36137694120407104
Iteration 735: Loss = 0.3613274097442627
Iteration 736: Loss = 0.3612770736217499
Iteration 737: Loss = 0.36122632026672363
Iteration 738: Loss = 0.3611777424812317
Iteration 739: Loss = 0.36113157868385315
Iteration 740: Loss = 0.3610875904560089
Iteration 741: Loss = 0.36104536056518555
Iteration 742: Loss = 0.3610057532787323
Iteration 743: Loss = 0.3609693944454193
Iteration 744: Loss = 0.3609302043914795
Iteration 745: Loss = 0.36088302731513977
Iteration 746: Loss = 0.360828161239624
Iteration 747: Loss = 0.3607708811759949
Iteration 748: Loss = 0.3607192933559418
Iteration 749: Loss = 0.3606753349304199
Iteration 750: Loss = 0.36063623428344727
Iteration 751: Loss = 0.36059993505477905
Iteration 752: Loss = 0.360559344291687
Iteration 753: Loss = 0.36051252484321594
Iteration 754: Loss = 0.36046287417411804
Iteration 755: Loss = 0.36041495203971863
Iteration 756: Loss = 0.3603723645210266
Iteration 757: Loss = 0.36033308506011963
Iteration 758: Loss = 0.3602946698665619
Iteration 759: Loss = 0.36025288701057434
Iteration 760: Loss = 0.36021068692207336
Iteration 761: Loss = 0.3601666986942291
Iteration 762: Loss = 0.360122948884964
Iteration 763: Loss = 0.36008045077323914
Iteration 764: Loss = 0.36004015803337097
Iteration 765: Loss = 0.36000216007232666
Iteration 766: Loss = 0.35996419191360474
Iteration 767: Loss = 0.35992658138275146
Iteration 768: Loss = 0.3598859906196594
Iteration 769: Loss = 0.35984542965888977
Iteration 770: Loss = 0.3598029613494873
Iteration 771: Loss = 0.35976147651672363
Iteration 772: Loss = 0.3597216308116913
Iteration 773: Loss = 0.359684020280838
Iteration 774: Loss = 0.359648734331131
Iteration 775: Loss = 0.3596133291721344
Iteration 776: Loss = 0.3595772087574005
Iteration 777: Loss = 0.3595399260520935
Iteration 778: Loss = 0.3595016300678253
Iteration 779: Loss = 0.35946041345596313
Iteration 780: Loss = 0.359418660402298
Iteration 781: Loss = 0.35937899351119995
Iteration 782: Loss = 0.3593422472476959
Iteration 783: Loss = 0.3593060374259949
Iteration 784: Loss = 0.35927054286003113
Iteration 785: Loss = 0.35923585295677185
Iteration 786: Loss = 0.35920119285583496
Iteration 787: Loss = 0.3591648042201996
Iteration 788: Loss = 0.3591277599334717
Iteration 789: Loss = 0.3590914309024811
Iteration 790: Loss = 0.3590547442436218
Iteration 791: Loss = 0.35901859402656555
Iteration 792: Loss = 0.3589833676815033
Iteration 793: Loss = 0.3589485287666321
Iteration 794: Loss = 0.35891473293304443
Iteration 795: Loss = 0.3588808476924896
Iteration 796: Loss = 0.35884806513786316
Iteration 797: Loss = 0.3588159680366516
Iteration 798: Loss = 0.35878315567970276
Iteration 799: Loss = 0.3587507903575897
Iteration 800: Loss = 0.3587169051170349
Iteration 801: Loss = 0.3586829602718353
Iteration 802: Loss = 0.35864824056625366
Iteration 803: Loss = 0.35861334204673767
Iteration 804: Loss = 0.3585797846317291
Iteration 805: Loss = 0.35854628682136536
Iteration 806: Loss = 0.35851407051086426
Iteration 807: Loss = 0.35848116874694824
Iteration 808: Loss = 0.35844752192497253
Iteration 809: Loss = 0.3584138751029968
Iteration 810: Loss = 0.3583811819553375
Iteration 811: Loss = 0.35834845900535583
Iteration 812: Loss = 0.3583163917064667
Iteration 813: Loss = 0.35828539729118347
Iteration 814: Loss = 0.3582538664340973
Iteration 815: Loss = 0.3582225739955902
Iteration 816: Loss = 0.3581920862197876
Iteration 817: Loss = 0.3581620156764984
Iteration 818: Loss = 0.358131468296051
Iteration 819: Loss = 0.35810333490371704
Iteration 820: Loss = 0.3580775260925293
Iteration 821: Loss = 0.35805240273475647
Iteration 822: Loss = 0.35802972316741943
Iteration 823: Loss = 0.35800987482070923
Iteration 824: Loss = 0.35799288749694824
Iteration 825: Loss = 0.3579699993133545
Iteration 826: Loss = 0.3579369783401489
Iteration 827: Loss = 0.3578959107398987
Iteration 828: Loss = 0.3578490912914276
Iteration 829: Loss = 0.35780590772628784
Iteration 830: Loss = 0.35777679085731506
Iteration 831: Loss = 0.35775983333587646
Iteration 832: Loss = 0.3577435612678528
Iteration 833: Loss = 0.35772082209587097
Iteration 834: Loss = 0.357683926820755
Iteration 835: Loss = 0.3576420247554779
Iteration 836: Loss = 0.3576074242591858
Iteration 837: Loss = 0.3575839698314667
Iteration 838: Loss = 0.3575640618801117
Iteration 839: Loss = 0.35754215717315674
Iteration 840: Loss = 0.3575105667114258
Iteration 841: Loss = 0.35747700929641724
Iteration 842: Loss = 0.3574448823928833
Iteration 843: Loss = 0.35741832852363586
Iteration 844: Loss = 0.35739487409591675
Iteration 845: Loss = 0.3573703169822693
Iteration 846: Loss = 0.3573434352874756
Iteration 847: Loss = 0.3573146462440491
Iteration 848: Loss = 0.3572864830493927
Iteration 849: Loss = 0.3572593927383423
Iteration 850: Loss = 0.35723382234573364
Iteration 851: Loss = 0.3572090268135071
Iteration 852: Loss = 0.3571842610836029
Iteration 853: Loss = 0.3571597933769226
Iteration 854: Loss = 0.35713431239128113
Iteration 855: Loss = 0.35710886120796204
Iteration 856: Loss = 0.357082724571228
Iteration 857: Loss = 0.3570570647716522
Iteration 858: Loss = 0.3570323884487152
Iteration 859: Loss = 0.3570086658000946
Iteration 860: Loss = 0.3569848835468292
Iteration 861: Loss = 0.3569604456424713
Iteration 862: Loss = 0.35693585872650146
Iteration 863: Loss = 0.35691121220588684
Iteration 864: Loss = 0.35688677430152893
Iteration 865: Loss = 0.3568626642227173
Iteration 866: Loss = 0.35683923959732056
Iteration 867: Loss = 0.35681602358818054
Iteration 868: Loss = 0.3567923903465271
Iteration 869: Loss = 0.35676950216293335
Iteration 870: Loss = 0.3567466139793396
Iteration 871: Loss = 0.3567233383655548
Iteration 872: Loss = 0.3566996455192566
Iteration 873: Loss = 0.3566758632659912
Iteration 874: Loss = 0.35665223002433777
Iteration 875: Loss = 0.3566291332244873
Iteration 876: Loss = 0.3566064238548279
Iteration 877: Loss = 0.3565841615200043
Iteration 878: Loss = 0.3565620183944702
Iteration 879: Loss = 0.356540322303772
Iteration 880: Loss = 0.3565182685852051
Iteration 881: Loss = 0.3564963638782501
Iteration 882: Loss = 0.3564744293689728
Iteration 883: Loss = 0.35645195841789246
Iteration 884: Loss = 0.3564296066761017
Iteration 885: Loss = 0.35640737414360046
Iteration 886: Loss = 0.35638538002967834
Iteration 887: Loss = 0.35636383295059204
Iteration 888: Loss = 0.3563423752784729
Iteration 889: Loss = 0.3563210666179657
Iteration 890: Loss = 0.35629984736442566
Iteration 891: Loss = 0.35627877712249756
Iteration 892: Loss = 0.35625770688056946
Iteration 893: Loss = 0.35623690485954285
Iteration 894: Loss = 0.35621610283851624
Iteration 895: Loss = 0.35619527101516724
Iteration 896: Loss = 0.3561745584011078
Iteration 897: Loss = 0.3561539947986603
Iteration 898: Loss = 0.3561338782310486
Iteration 899: Loss = 0.3561137020587921
Iteration 900: Loss = 0.3560933768749237
Iteration 901: Loss = 0.3560732305049896
Iteration 902: Loss = 0.3560537099838257
Iteration 903: Loss = 0.35603463649749756
Iteration 904: Loss = 0.3560163378715515
Iteration 905: Loss = 0.3559987246990204
Iteration 906: Loss = 0.35598185658454895
Iteration 907: Loss = 0.355966180562973
Iteration 908: Loss = 0.3559545576572418
Iteration 909: Loss = 0.3559498190879822
Iteration 910: Loss = 0.35595160722732544
Iteration 911: Loss = 0.3559601306915283
Iteration 912: Loss = 0.3559676706790924
Iteration 913: Loss = 0.35595014691352844
Iteration 914: Loss = 0.3558955192565918
Iteration 915: Loss = 0.35582488775253296
Iteration 916: Loss = 0.35578978061676025
Iteration 917: Loss = 0.35579222440719604
Iteration 918: Loss = 0.3558034896850586
Iteration 919: Loss = 0.3557872176170349
Iteration 920: Loss = 0.355743408203125
Iteration 921: Loss = 0.3557044267654419
Iteration 922: Loss = 0.3556920289993286
Iteration 923: Loss = 0.3556922376155853
Iteration 924: Loss = 0.355680912733078
Iteration 925: Loss = 0.35565125942230225
Iteration 926: Loss = 0.3556210696697235
Iteration 927: Loss = 0.35560542345046997
Iteration 928: Loss = 0.3555980920791626
Iteration 929: Loss = 0.3555857539176941
Iteration 930: Loss = 0.3555649220943451
Iteration 931: Loss = 0.35554081201553345
Iteration 932: Loss = 0.3555222153663635
Iteration 933: Loss = 0.3555099666118622
Iteration 934: Loss = 0.35549691319465637
Iteration 935: Loss = 0.35547855496406555
Iteration 936: Loss = 0.3554593622684479
Iteration 937: Loss = 0.35544323921203613
Iteration 938: Loss = 0.3554300367832184
Iteration 939: Loss = 0.3554159104824066
Iteration 940: Loss = 0.35539910197257996
Iteration 941: Loss = 0.355381578207016
Iteration 942: Loss = 0.35536596179008484
Iteration 943: Loss = 0.3553521931171417
Iteration 944: Loss = 0.35533785820007324
Iteration 945: Loss = 0.35532164573669434
Iteration 946: Loss = 0.35530543327331543
Iteration 947: Loss = 0.3552902936935425
Iteration 948: Loss = 0.3552757203578949
Iteration 949: Loss = 0.355260968208313
Iteration 950: Loss = 0.3552458882331848
Iteration 951: Loss = 0.35523083806037903
Iteration 952: Loss = 0.3552161455154419
Iteration 953: Loss = 0.35520192980766296
Iteration 954: Loss = 0.3551877439022064
Iteration 955: Loss = 0.3551733195781708
Iteration 956: Loss = 0.3551586866378784
Iteration 957: Loss = 0.355143666267395
Iteration 958: Loss = 0.35512906312942505
Iteration 959: Loss = 0.35511481761932373
Iteration 960: Loss = 0.3551011383533478
Iteration 961: Loss = 0.35508766770362854
Iteration 962: Loss = 0.35507386922836304
Iteration 963: Loss = 0.35506004095077515
Iteration 964: Loss = 0.35504579544067383
Iteration 965: Loss = 0.35503146052360535
Iteration 966: Loss = 0.35501763224601746
Iteration 967: Loss = 0.3550041615962982
Iteration 968: Loss = 0.35499122738838196
Iteration 969: Loss = 0.35497772693634033
Iteration 970: Loss = 0.3549641966819763
Iteration 971: Loss = 0.3549503684043884
Iteration 972: Loss = 0.3549365699291229
Iteration 973: Loss = 0.35492315888404846
Iteration 974: Loss = 0.3549100458621979
Iteration 975: Loss = 0.3548968434333801
Iteration 976: Loss = 0.35488373041152954
Iteration 977: Loss = 0.3548709452152252
Iteration 978: Loss = 0.3548583388328552
Iteration 979: Loss = 0.3548456132411957
Iteration 980: Loss = 0.3548325002193451
Iteration 981: Loss = 0.3548193871974945
Iteration 982: Loss = 0.3548062741756439
Iteration 983: Loss = 0.3547934591770172
Iteration 984: Loss = 0.35478076338768005
Iteration 985: Loss = 0.35476842522621155
Iteration 986: Loss = 0.35475608706474304
Iteration 987: Loss = 0.3547433912754059
Iteration 988: Loss = 0.354730486869812
Iteration 989: Loss = 0.3547179102897644
Iteration 990: Loss = 0.3547055721282959
Iteration 991: Loss = 0.3546931743621826
Iteration 992: Loss = 0.3546810746192932
Iteration 993: Loss = 0.35466891527175903
Iteration 994: Loss = 0.3546566963195801
Iteration 995: Loss = 0.3546447157859802
Iteration 996: Loss = 0.35463279485702515
Iteration 997: Loss = 0.35462117195129395
Iteration 998: Loss = 0.35460948944091797
Iteration 999: Loss = 0.354597806930542
Iteration 1000: Loss = 0.3545859456062317


Total training time (seconds): 10.69
