Iteration 1: Loss = 0.6305922865867615
Iteration 2: Loss = 0.6295514106750488
Iteration 3: Loss = 0.6285015940666199
Iteration 4: Loss = 0.6274072527885437
Iteration 5: Loss = 0.626271665096283
Iteration 6: Loss = 0.6251051425933838
Iteration 7: Loss = 0.6239195466041565
Iteration 8: Loss = 0.622724175453186
Iteration 9: Loss = 0.6215196847915649
Iteration 10: Loss = 0.6203073859214783
Iteration 11: Loss = 0.6190870404243469
Iteration 12: Loss = 0.61785888671875
Iteration 13: Loss = 0.6166236996650696
Iteration 14: Loss = 0.61538165807724
Iteration 15: Loss = 0.6141318678855896
Iteration 16: Loss = 0.6128753423690796
Iteration 17: Loss = 0.6116126179695129
Iteration 18: Loss = 0.6103434562683105
Iteration 19: Loss = 0.6090676784515381
Iteration 20: Loss = 0.6077859997749329
Iteration 21: Loss = 0.606497585773468
Iteration 22: Loss = 0.6052026152610779
Iteration 23: Loss = 0.6039021611213684
Iteration 24: Loss = 0.6025946736335754
Iteration 25: Loss = 0.6012815833091736
Iteration 26: Loss = 0.599962592124939
Iteration 27: Loss = 0.598637044429779
Iteration 28: Loss = 0.5973042249679565
Iteration 29: Loss = 0.5959653854370117
Iteration 30: Loss = 0.5946193933486938
Iteration 31: Loss = 0.5932661890983582
Iteration 32: Loss = 0.5919050574302673
Iteration 33: Loss = 0.5905361771583557
Iteration 34: Loss = 0.5891596078872681
Iteration 35: Loss = 0.5877740383148193
Iteration 36: Loss = 0.5863786339759827
Iteration 37: Loss = 0.5849735140800476
Iteration 38: Loss = 0.5835579633712769
Iteration 39: Loss = 0.5821317434310913
Iteration 40: Loss = 0.5806947350502014
Iteration 41: Loss = 0.5792470574378967
Iteration 42: Loss = 0.5777881145477295
Iteration 43: Loss = 0.5763171911239624
Iteration 44: Loss = 0.5748342871665955
Iteration 45: Loss = 0.5733382701873779
Iteration 46: Loss = 0.5718291997909546
Iteration 47: Loss = 0.5703065395355225
Iteration 48: Loss = 0.5687698125839233
Iteration 49: Loss = 0.5672190189361572
Iteration 50: Loss = 0.5656536221504211
Iteration 51: Loss = 0.564073383808136
Iteration 52: Loss = 0.5624789595603943
Iteration 53: Loss = 0.5608696341514587
Iteration 54: Loss = 0.5592457056045532
Iteration 55: Loss = 0.5576075911521912
Iteration 56: Loss = 0.5559549927711487
Iteration 57: Loss = 0.5542882680892944
Iteration 58: Loss = 0.552607536315918
Iteration 59: Loss = 0.5509132146835327
Iteration 60: Loss = 0.549205482006073
Iteration 61: Loss = 0.5474845170974731
Iteration 62: Loss = 0.5457505583763123
Iteration 63: Loss = 0.5440038442611694
Iteration 64: Loss = 0.5422446131706238
Iteration 65: Loss = 0.5404732823371887
Iteration 66: Loss = 0.5386898517608643
Iteration 67: Loss = 0.5368943810462952
Iteration 68: Loss = 0.5350876450538635
Iteration 69: Loss = 0.5332693457603455
Iteration 70: Loss = 0.5314399003982544
Iteration 71: Loss = 0.5295997262001038
Iteration 72: Loss = 0.527749240398407
Iteration 73: Loss = 0.5258885025978088
Iteration 74: Loss = 0.5240176320075989
Iteration 75: Loss = 0.5221370458602905
Iteration 76: Loss = 0.5202468037605286
Iteration 77: Loss = 0.518347978591919
Iteration 78: Loss = 0.5164402723312378
Iteration 79: Loss = 0.5145238041877747
Iteration 80: Loss = 0.5125998854637146
Iteration 81: Loss = 0.5106679797172546
Iteration 82: Loss = 0.5087289810180664
Iteration 83: Loss = 0.5067829489707947
Iteration 84: Loss = 0.504830002784729
Iteration 85: Loss = 0.5028707981109619
Iteration 86: Loss = 0.500905454158783
Iteration 87: Loss = 0.4989343285560608
Iteration 88: Loss = 0.4969578981399536
Iteration 89: Loss = 0.49497607350349426
Iteration 90: Loss = 0.4929904043674469
Iteration 91: Loss = 0.49100029468536377
Iteration 92: Loss = 0.4890056848526001
Iteration 93: Loss = 0.48700758814811707
Iteration 94: Loss = 0.4850058853626251
Iteration 95: Loss = 0.4830015301704407
Iteration 96: Loss = 0.4809948205947876
Iteration 97: Loss = 0.47898533940315247
Iteration 98: Loss = 0.47697433829307556
Iteration 99: Loss = 0.47496166825294495
Iteration 100: Loss = 0.47294825315475464
Iteration 101: Loss = 0.4709359109401703
Iteration 102: Loss = 0.46892520785331726
Iteration 103: Loss = 0.46691736578941345
Iteration 104: Loss = 0.4649133086204529
Iteration 105: Loss = 0.4629157483577728
Iteration 106: Loss = 0.460927277803421
Iteration 107: Loss = 0.45895087718963623
Iteration 108: Loss = 0.4569886028766632
Iteration 109: Loss = 0.45504486560821533
Iteration 110: Loss = 0.4531237781047821
Iteration 111: Loss = 0.4512294828891754
Iteration 112: Loss = 0.44936785101890564
Iteration 113: Loss = 0.4475422501564026
Iteration 114: Loss = 0.44575679302215576
Iteration 115: Loss = 0.4440145492553711
Iteration 116: Loss = 0.44231727719306946
Iteration 117: Loss = 0.440667062997818
Iteration 118: Loss = 0.43906331062316895
Iteration 119: Loss = 0.43750399351119995
Iteration 120: Loss = 0.4359874427318573
Iteration 121: Loss = 0.4345114231109619
Iteration 122: Loss = 0.43307334184646606
Iteration 123: Loss = 0.4316714406013489
Iteration 124: Loss = 0.43030306696891785
Iteration 125: Loss = 0.42896705865859985
Iteration 126: Loss = 0.42766281962394714
Iteration 127: Loss = 0.42638951539993286
Iteration 128: Loss = 0.42514660954475403
Iteration 129: Loss = 0.42393383383750916
Iteration 130: Loss = 0.42275065183639526
Iteration 131: Loss = 0.4215970039367676
Iteration 132: Loss = 0.42047232389450073
Iteration 133: Loss = 0.41937553882598877
Iteration 134: Loss = 0.4183066785335541
Iteration 135: Loss = 0.41726526618003845
Iteration 136: Loss = 0.416250616312027
Iteration 137: Loss = 0.4152623414993286
Iteration 138: Loss = 0.41430044174194336
Iteration 139: Loss = 0.41336512565612793
Iteration 140: Loss = 0.41245579719543457
Iteration 141: Loss = 0.4115736186504364
Iteration 142: Loss = 0.41071775555610657
Iteration 143: Loss = 0.4098886251449585
Iteration 144: Loss = 0.40908658504486084
Iteration 145: Loss = 0.4083111584186554
Iteration 146: Loss = 0.4075621962547302
Iteration 147: Loss = 0.40683943033218384
Iteration 148: Loss = 0.4061426520347595
Iteration 149: Loss = 0.40547114610671997
Iteration 150: Loss = 0.4048244059085846
Iteration 151: Loss = 0.4042010009288788
Iteration 152: Loss = 0.40359997749328613
Iteration 153: Loss = 0.4030216634273529
Iteration 154: Loss = 0.4024636745452881
Iteration 155: Loss = 0.40192630887031555
Iteration 156: Loss = 0.4014078974723816
Iteration 157: Loss = 0.400907963514328
Iteration 158: Loss = 0.40042632818222046
Iteration 159: Loss = 0.39996176958084106
Iteration 160: Loss = 0.3995136022567749
Iteration 161: Loss = 0.3990812301635742
Iteration 162: Loss = 0.39866384863853455
Iteration 163: Loss = 0.39826086163520813
Iteration 164: Loss = 0.39787158370018005
Iteration 165: Loss = 0.39749521017074585
Iteration 166: Loss = 0.3971310555934906
Iteration 167: Loss = 0.39677852392196655
Iteration 168: Loss = 0.39643698930740356
Iteration 169: Loss = 0.39610591530799866
Iteration 170: Loss = 0.39578476548194885
Iteration 171: Loss = 0.3954729735851288
Iteration 172: Loss = 0.3951699733734131
Iteration 173: Loss = 0.39487552642822266
Iteration 174: Loss = 0.3945889472961426
Iteration 175: Loss = 0.394309937953949
Iteration 176: Loss = 0.39403796195983887
Iteration 177: Loss = 0.3937724232673645
Iteration 178: Loss = 0.39351293444633484
Iteration 179: Loss = 0.39325910806655884
Iteration 180: Loss = 0.39301052689552307
Iteration 181: Loss = 0.3927668333053589
Iteration 182: Loss = 0.39252763986587524
Iteration 183: Loss = 0.3922925591468811
Iteration 184: Loss = 0.3920614421367645
Iteration 185: Loss = 0.3918337821960449
Iteration 186: Loss = 0.39160966873168945
Iteration 187: Loss = 0.3913886845111847
Iteration 188: Loss = 0.39117053151130676
Iteration 189: Loss = 0.3909550905227661
Iteration 190: Loss = 0.3907420337200165
Iteration 191: Loss = 0.3905317187309265
Iteration 192: Loss = 0.3903234302997589
Iteration 193: Loss = 0.39011698961257935
Iteration 194: Loss = 0.3899123966693878
Iteration 195: Loss = 0.3897095322608948
Iteration 196: Loss = 0.3895082473754883
Iteration 197: Loss = 0.38930848240852356
Iteration 198: Loss = 0.38911014795303345
Iteration 199: Loss = 0.3889131546020508
Iteration 200: Loss = 0.38871732354164124
Iteration 201: Loss = 0.3885226547718048
Iteration 202: Loss = 0.3883289694786072
Iteration 203: Loss = 0.3881362974643707
Iteration 204: Loss = 0.38794443011283875
Iteration 205: Loss = 0.387753427028656
Iteration 206: Loss = 0.3875631093978882
Iteration 207: Loss = 0.3873734772205353
Iteration 208: Loss = 0.3871849477291107
Iteration 209: Loss = 0.3869970738887787
Iteration 210: Loss = 0.3868098855018616
Iteration 211: Loss = 0.38662320375442505
Iteration 212: Loss = 0.38643699884414673
Iteration 213: Loss = 0.3862512707710266
Iteration 214: Loss = 0.3860664665699005
Iteration 215: Loss = 0.38588231801986694
Iteration 216: Loss = 0.3856986165046692
Iteration 217: Loss = 0.38551536202430725
Iteration 218: Loss = 0.38533255457878113
Iteration 219: Loss = 0.38515034317970276
Iteration 220: Loss = 0.38496848940849304
Iteration 221: Loss = 0.38478702306747437
Iteration 222: Loss = 0.3846060633659363
Iteration 223: Loss = 0.38442572951316833
Iteration 224: Loss = 0.38424575328826904
Iteration 225: Loss = 0.38406628370285034
Iteration 226: Loss = 0.3838871717453003
Iteration 227: Loss = 0.3837084472179413
Iteration 228: Loss = 0.383529931306839
Iteration 229: Loss = 0.3833518922328949
Iteration 230: Loss = 0.3831740915775299
Iteration 231: Loss = 0.382996529340744
Iteration 232: Loss = 0.3828195631504059
Iteration 233: Loss = 0.38264304399490356
Iteration 234: Loss = 0.38246679306030273
Iteration 235: Loss = 0.382290780544281
Iteration 236: Loss = 0.3821149468421936
Iteration 237: Loss = 0.3819393217563629
Iteration 238: Loss = 0.38176393508911133
Iteration 239: Loss = 0.3815893530845642
Iteration 240: Loss = 0.38141509890556335
Iteration 241: Loss = 0.381241112947464
Iteration 242: Loss = 0.3810674250125885
Iteration 243: Loss = 0.38089391589164734
Iteration 244: Loss = 0.38072067499160767
Iteration 245: Loss = 0.3805476427078247
Iteration 246: Loss = 0.3803747892379761
Iteration 247: Loss = 0.38020211458206177
Iteration 248: Loss = 0.3800298869609833
Iteration 249: Loss = 0.3798580765724182
Iteration 250: Loss = 0.3796864449977875
Iteration 251: Loss = 0.37951502203941345
Iteration 252: Loss = 0.3793439567089081
Iteration 253: Loss = 0.3791731297969818
Iteration 254: Loss = 0.37900251150131226
Iteration 255: Loss = 0.378832072019577
Iteration 256: Loss = 0.37866175174713135
Iteration 257: Loss = 0.37849146127700806
Iteration 258: Loss = 0.37832149863243103
Iteration 259: Loss = 0.3781519830226898
Iteration 260: Loss = 0.37798261642456055
Iteration 261: Loss = 0.37781327962875366
Iteration 262: Loss = 0.3776441812515259
Iteration 263: Loss = 0.3774752616882324
Iteration 264: Loss = 0.37730640172958374
Iteration 265: Loss = 0.3771378695964813
Iteration 266: Loss = 0.3769693672657013
Iteration 267: Loss = 0.3768009543418884
Iteration 268: Loss = 0.37663307785987854
Iteration 269: Loss = 0.376465380191803
Iteration 270: Loss = 0.37629765272140503
Iteration 271: Loss = 0.3761301040649414
Iteration 272: Loss = 0.37596264481544495
Iteration 273: Loss = 0.37579527497291565
Iteration 274: Loss = 0.3756279945373535
Iteration 275: Loss = 0.37546077370643616
Iteration 276: Loss = 0.37529367208480835
Iteration 277: Loss = 0.3751266300678253
Iteration 278: Loss = 0.3749600052833557
Iteration 279: Loss = 0.3747933506965637
Iteration 280: Loss = 0.37462708353996277
Iteration 281: Loss = 0.3744608461856842
Iteration 282: Loss = 0.374294638633728
Iteration 283: Loss = 0.3741285502910614
Iteration 284: Loss = 0.37396252155303955
Iteration 285: Loss = 0.3737965226173401
Iteration 286: Loss = 0.373630553483963
Iteration 287: Loss = 0.3734646737575531
Iteration 288: Loss = 0.3732990324497223
Iteration 289: Loss = 0.3731335997581482
Iteration 290: Loss = 0.3729681372642517
Iteration 291: Loss = 0.3728027045726776
Iteration 292: Loss = 0.3726375102996826
Iteration 293: Loss = 0.3724723160266876
Iteration 294: Loss = 0.3723072111606598
Iteration 295: Loss = 0.37214210629463196
Iteration 296: Loss = 0.3719770312309265
Iteration 297: Loss = 0.37181201577186584
Iteration 298: Loss = 0.3716469407081604
Iteration 299: Loss = 0.3714819550514221
Iteration 300: Loss = 0.37131696939468384
Iteration 301: Loss = 0.37115222215652466
Iteration 302: Loss = 0.3709878623485565
Iteration 303: Loss = 0.37082329392433167
Iteration 304: Loss = 0.370658814907074
Iteration 305: Loss = 0.3704942762851715
Iteration 306: Loss = 0.3703298568725586
Iteration 307: Loss = 0.37016552686691284
Iteration 308: Loss = 0.3700012266635895
Iteration 309: Loss = 0.36983686685562134
Iteration 310: Loss = 0.3696725368499756
Iteration 311: Loss = 0.36950817704200745
Iteration 312: Loss = 0.36934372782707214
Iteration 313: Loss = 0.3691793382167816
Iteration 314: Loss = 0.3690149188041687
Iteration 315: Loss = 0.3688506484031677
Iteration 316: Loss = 0.3686864376068115
Iteration 317: Loss = 0.3685222566127777
Iteration 318: Loss = 0.36835795640945435
Iteration 319: Loss = 0.36819377541542053
Iteration 320: Loss = 0.3680296242237091
Iteration 321: Loss = 0.3678654730319977
Iteration 322: Loss = 0.36770129203796387
Iteration 323: Loss = 0.3675372004508972
Iteration 324: Loss = 0.3673730492591858
Iteration 325: Loss = 0.367208868265152
Iteration 326: Loss = 0.3670446574687958
Iteration 327: Loss = 0.3668804466724396
Iteration 328: Loss = 0.3667161464691162
Iteration 329: Loss = 0.36655178666114807
Iteration 330: Loss = 0.3663877546787262
Iteration 331: Loss = 0.3662237524986267
Iteration 332: Loss = 0.36605963110923767
Iteration 333: Loss = 0.3658953905105591
Iteration 334: Loss = 0.3657311499118805
Iteration 335: Loss = 0.36556702852249146
Iteration 336: Loss = 0.3654029667377472
Iteration 337: Loss = 0.36523884534835815
Iteration 338: Loss = 0.3650747239589691
Iteration 339: Loss = 0.3649106025695801
Iteration 340: Loss = 0.3647463321685791
Iteration 341: Loss = 0.36458203196525574
Iteration 342: Loss = 0.3644176721572876
Iteration 343: Loss = 0.36425310373306274
Iteration 344: Loss = 0.36408859491348267
Iteration 345: Loss = 0.363924115896225
Iteration 346: Loss = 0.3637595474720001
Iteration 347: Loss = 0.3635948896408081
Iteration 348: Loss = 0.36343029141426086
Iteration 349: Loss = 0.3632658123970032
Iteration 350: Loss = 0.3631010949611664
Iteration 351: Loss = 0.3629363477230072
Iteration 352: Loss = 0.36277154088020325
Iteration 353: Loss = 0.3626067638397217
Iteration 354: Loss = 0.3624419867992401
Iteration 355: Loss = 0.36227715015411377
Iteration 356: Loss = 0.3621124029159546
Iteration 357: Loss = 0.361947625875473
Iteration 358: Loss = 0.36178264021873474
Iteration 359: Loss = 0.3616175353527069
Iteration 360: Loss = 0.3614524006843567
Iteration 361: Loss = 0.36128726601600647
Iteration 362: Loss = 0.3611219823360443
Iteration 363: Loss = 0.3609565496444702
Iteration 364: Loss = 0.3607911169528961
Iteration 365: Loss = 0.360625684261322
Iteration 366: Loss = 0.3604602515697479
Iteration 367: Loss = 0.3602949380874634
Iteration 368: Loss = 0.3601294457912445
Iteration 369: Loss = 0.3599638342857361
Iteration 370: Loss = 0.35979828238487244
Iteration 371: Loss = 0.3596327602863312
Iteration 372: Loss = 0.35946711897850037
Iteration 373: Loss = 0.3593015670776367
Iteration 374: Loss = 0.35913604497909546
Iteration 375: Loss = 0.35897037386894226
Iteration 376: Loss = 0.3588044345378876
Iteration 377: Loss = 0.3586386442184448
Iteration 378: Loss = 0.35847270488739014
Iteration 379: Loss = 0.35830673575401306
Iteration 380: Loss = 0.3581405282020569
Iteration 381: Loss = 0.3579743504524231
Iteration 382: Loss = 0.3578082025051117
Iteration 383: Loss = 0.3576420247554779
Iteration 384: Loss = 0.3574756979942322
Iteration 385: Loss = 0.3573093116283417
Iteration 386: Loss = 0.3571428060531616
Iteration 387: Loss = 0.35697630047798157
Iteration 388: Loss = 0.3568095564842224
Iteration 389: Loss = 0.35664278268814087
Iteration 390: Loss = 0.3564758896827698
Iteration 391: Loss = 0.3563091456890106
Iteration 392: Loss = 0.3561423420906067
Iteration 393: Loss = 0.3559754490852356
Iteration 394: Loss = 0.3558085262775421
Iteration 395: Loss = 0.35564154386520386
Iteration 396: Loss = 0.3554745018482208
Iteration 397: Loss = 0.355307400226593
Iteration 398: Loss = 0.3551402688026428
Iteration 399: Loss = 0.35497307777404785
Iteration 400: Loss = 0.3548057973384857
Iteration 401: Loss = 0.3546384274959564
Iteration 402: Loss = 0.35447096824645996
Iteration 403: Loss = 0.3543034493923187
Iteration 404: Loss = 0.35413578152656555
Iteration 405: Loss = 0.3539680540561676
Iteration 406: Loss = 0.3538001775741577
Iteration 407: Loss = 0.3536323606967926
Iteration 408: Loss = 0.3534645140171051
Iteration 409: Loss = 0.35329657793045044
Iteration 410: Loss = 0.3531278371810913
Iteration 411: Loss = 0.35295718908309937
Iteration 412: Loss = 0.3527834415435791
Iteration 413: Loss = 0.3526061475276947
Iteration 414: Loss = 0.35242587327957153
Iteration 415: Loss = 0.35224223136901855
Iteration 416: Loss = 0.3520543873310089
Iteration 417: Loss = 0.3518618643283844
Iteration 418: Loss = 0.3516632914543152
Iteration 419: Loss = 0.35145920515060425
Iteration 420: Loss = 0.35125231742858887
Iteration 421: Loss = 0.3510455787181854
Iteration 422: Loss = 0.35084038972854614
Iteration 423: Loss = 0.3506357669830322
Iteration 424: Loss = 0.35042864084243774
Iteration 425: Loss = 0.3502172827720642
Iteration 426: Loss = 0.35000163316726685
Iteration 427: Loss = 0.34978190064430237
Iteration 428: Loss = 0.3495563864707947
Iteration 429: Loss = 0.3493240177631378
Iteration 430: Loss = 0.34908536076545715
Iteration 431: Loss = 0.3488372564315796
Iteration 432: Loss = 0.34858062863349915
Iteration 433: Loss = 0.3483160436153412
Iteration 434: Loss = 0.3480410873889923
Iteration 435: Loss = 0.3477535843849182
Iteration 436: Loss = 0.3474530577659607
Iteration 437: Loss = 0.3471417725086212
Iteration 438: Loss = 0.3468173146247864
Iteration 439: Loss = 0.3464805781841278
Iteration 440: Loss = 0.34613385796546936
Iteration 441: Loss = 0.34577861428260803
Iteration 442: Loss = 0.34541311860084534
Iteration 443: Loss = 0.3450373113155365
Iteration 444: Loss = 0.34465083479881287
Iteration 445: Loss = 0.34425947070121765
Iteration 446: Loss = 0.34386146068573
Iteration 447: Loss = 0.3434562385082245
Iteration 448: Loss = 0.3430485725402832
Iteration 449: Loss = 0.3426420986652374
Iteration 450: Loss = 0.3422376811504364
Iteration 451: Loss = 0.34183937311172485
Iteration 452: Loss = 0.3414478898048401
Iteration 453: Loss = 0.34106573462486267
Iteration 454: Loss = 0.34069588780403137
Iteration 455: Loss = 0.34034305810928345
Iteration 456: Loss = 0.3400108218193054
Iteration 457: Loss = 0.3397008180618286
Iteration 458: Loss = 0.3394155204296112
Iteration 459: Loss = 0.33914899826049805
Iteration 460: Loss = 0.33889827132225037
Iteration 461: Loss = 0.3386645019054413
Iteration 462: Loss = 0.3384435772895813
Iteration 463: Loss = 0.3382298946380615
Iteration 464: Loss = 0.33801957964897156
Iteration 465: Loss = 0.33780795335769653
Iteration 466: Loss = 0.3375948965549469
Iteration 467: Loss = 0.337379515171051
Iteration 468: Loss = 0.3371639549732208
Iteration 469: Loss = 0.33694782853126526
Iteration 470: Loss = 0.3367348313331604
Iteration 471: Loss = 0.33652451634407043
Iteration 472: Loss = 0.33631837368011475
Iteration 473: Loss = 0.3361169397830963
Iteration 474: Loss = 0.33591967821121216
Iteration 475: Loss = 0.3357253968715668
Iteration 476: Loss = 0.3355334401130676
Iteration 477: Loss = 0.33534276485443115
Iteration 478: Loss = 0.3351525664329529
Iteration 479: Loss = 0.33496153354644775
Iteration 480: Loss = 0.33476966619491577
Iteration 481: Loss = 0.3345765173435211
Iteration 482: Loss = 0.3343825340270996
Iteration 483: Loss = 0.3341878056526184
Iteration 484: Loss = 0.33399301767349243
Iteration 485: Loss = 0.33379894495010376
Iteration 486: Loss = 0.33360594511032104
Iteration 487: Loss = 0.3334147036075592
Iteration 488: Loss = 0.3332255184650421
Iteration 489: Loss = 0.3330382704734802
Iteration 490: Loss = 0.33285263180732727
Iteration 491: Loss = 0.3326685130596161
Iteration 492: Loss = 0.33248579502105713
Iteration 493: Loss = 0.3323040306568146
Iteration 494: Loss = 0.3321228623390198
Iteration 495: Loss = 0.3319421112537384
Iteration 496: Loss = 0.33176189661026
Iteration 497: Loss = 0.3315819799900055
Iteration 498: Loss = 0.3314022123813629
Iteration 499: Loss = 0.3312227427959442
Iteration 500: Loss = 0.33104363083839417
Iteration 501: Loss = 0.3308647572994232
Iteration 502: Loss = 0.33068668842315674
Iteration 503: Loss = 0.3305091857910156
Iteration 504: Loss = 0.33033204078674316
Iteration 505: Loss = 0.3301553726196289
Iteration 506: Loss = 0.32997927069664
Iteration 507: Loss = 0.3298035264015198
Iteration 508: Loss = 0.3296279311180115
Iteration 509: Loss = 0.3294525742530823
Iteration 510: Loss = 0.32927751541137695
Iteration 511: Loss = 0.32910263538360596
Iteration 512: Loss = 0.3289279341697693
Iteration 513: Loss = 0.32875341176986694
Iteration 514: Loss = 0.32857897877693176
Iteration 515: Loss = 0.32840508222579956
Iteration 516: Loss = 0.32823145389556885
Iteration 517: Loss = 0.32805800437927246
Iteration 518: Loss = 0.3278847932815552
Iteration 519: Loss = 0.3277117908000946
Iteration 520: Loss = 0.32753926515579224
Iteration 521: Loss = 0.32736697793006897
Iteration 522: Loss = 0.3271948993206024
Iteration 523: Loss = 0.3270229399204254
Iteration 524: Loss = 0.32685109972953796
Iteration 525: Loss = 0.32667937874794006
Iteration 526: Loss = 0.32650771737098694
Iteration 527: Loss = 0.3263361155986786
Iteration 528: Loss = 0.3261646330356598
Iteration 529: Loss = 0.3259935975074768
Iteration 530: Loss = 0.3258225619792938
Iteration 531: Loss = 0.3256516456604004
Iteration 532: Loss = 0.32548099756240845
Iteration 533: Loss = 0.3253103494644165
Iteration 534: Loss = 0.3251397907733917
Iteration 535: Loss = 0.32496944069862366
Iteration 536: Loss = 0.32479944825172424
Iteration 537: Loss = 0.3246295154094696
Iteration 538: Loss = 0.32445940375328064
Iteration 539: Loss = 0.3242892324924469
Iteration 540: Loss = 0.3241194784641266
Iteration 541: Loss = 0.3239496946334839
Iteration 542: Loss = 0.32378003001213074
Iteration 543: Loss = 0.3236102759838104
Iteration 544: Loss = 0.32344067096710205
Iteration 545: Loss = 0.323271244764328
Iteration 546: Loss = 0.3231017291545868
Iteration 547: Loss = 0.32293233275413513
Iteration 548: Loss = 0.322763055562973
Iteration 549: Loss = 0.3225937485694885
Iteration 550: Loss = 0.3224245607852936
Iteration 551: Loss = 0.32225537300109863
Iteration 552: Loss = 0.32208627462387085
Iteration 553: Loss = 0.3219171464443207
Iteration 554: Loss = 0.3217480480670929
Iteration 555: Loss = 0.3215789496898651
Iteration 556: Loss = 0.32140985131263733
Iteration 557: Loss = 0.32124072313308716
Iteration 558: Loss = 0.3210715651512146
Iteration 559: Loss = 0.3209023177623749
Iteration 560: Loss = 0.32073333859443665
Iteration 561: Loss = 0.3205643892288208
Iteration 562: Loss = 0.3203953504562378
Iteration 563: Loss = 0.32022625207901
Iteration 564: Loss = 0.32005709409713745
Iteration 565: Loss = 0.31988802552223206
Iteration 566: Loss = 0.3197189271450043
Iteration 567: Loss = 0.31954988837242126
Iteration 568: Loss = 0.31938090920448303
Iteration 569: Loss = 0.31921201944351196
Iteration 570: Loss = 0.3190430700778961
Iteration 571: Loss = 0.3188741207122803
Iteration 572: Loss = 0.3187050223350525
Iteration 573: Loss = 0.3185359239578247
Iteration 574: Loss = 0.3183666467666626
Iteration 575: Loss = 0.3181972801685333
Iteration 576: Loss = 0.3180283308029175
Iteration 577: Loss = 0.31785938143730164
Iteration 578: Loss = 0.31769031286239624
Iteration 579: Loss = 0.31752118468284607
Iteration 580: Loss = 0.3173520863056183
Iteration 581: Loss = 0.3171826899051666
Iteration 582: Loss = 0.3170134723186493
Iteration 583: Loss = 0.31684428453445435
Iteration 584: Loss = 0.3166751563549042
Iteration 585: Loss = 0.3165059983730316
Iteration 586: Loss = 0.3163367509841919
Iteration 587: Loss = 0.3161673843860626
Iteration 588: Loss = 0.31599777936935425
Iteration 589: Loss = 0.3158286511898041
Iteration 590: Loss = 0.31565943360328674
Iteration 591: Loss = 0.31549006700515747
Iteration 592: Loss = 0.3153206706047058
Iteration 593: Loss = 0.3151511549949646
Iteration 594: Loss = 0.3149816393852234
Iteration 595: Loss = 0.3148120045661926
Iteration 596: Loss = 0.31464239954948425
Iteration 597: Loss = 0.3144727647304535
Iteration 598: Loss = 0.31430310010910034
Iteration 599: Loss = 0.3141334354877472
Iteration 600: Loss = 0.31396380066871643
Iteration 601: Loss = 0.3137940764427185
Iteration 602: Loss = 0.31362438201904297
Iteration 603: Loss = 0.31345468759536743
Iteration 604: Loss = 0.3132849335670471
Iteration 605: Loss = 0.3131152093410492
Iteration 606: Loss = 0.3129453659057617
Iteration 607: Loss = 0.312775582075119
Iteration 608: Loss = 0.31260570883750916
Iteration 609: Loss = 0.31243571639060974
Iteration 610: Loss = 0.3122657239437103
Iteration 611: Loss = 0.3120955526828766
Iteration 612: Loss = 0.31192582845687866
Iteration 613: Loss = 0.311755895614624
Iteration 614: Loss = 0.31158578395843506
Iteration 615: Loss = 0.31141555309295654
Iteration 616: Loss = 0.311245322227478
Iteration 617: Loss = 0.3110751509666443
Iteration 618: Loss = 0.3109053373336792
Iteration 619: Loss = 0.31073516607284546
Iteration 620: Loss = 0.31056493520736694
Iteration 621: Loss = 0.31039464473724365
Iteration 622: Loss = 0.310224324464798
Iteration 623: Loss = 0.31005391478538513
Iteration 624: Loss = 0.3098837733268738
Iteration 625: Loss = 0.3097133934497833
Iteration 626: Loss = 0.30954304337501526
Iteration 627: Loss = 0.30937299132347107
Iteration 628: Loss = 0.3092026710510254
Iteration 629: Loss = 0.3090320825576782
Iteration 630: Loss = 0.30886173248291016
Iteration 631: Loss = 0.3086913526058197
Iteration 632: Loss = 0.3085208535194397
Iteration 633: Loss = 0.30835041403770447
Iteration 634: Loss = 0.30817994475364685
Iteration 635: Loss = 0.3080093264579773
Iteration 636: Loss = 0.30783867835998535
Iteration 637: Loss = 0.30766811966896057
Iteration 638: Loss = 0.30749744176864624
Iteration 639: Loss = 0.3073267340660095
Iteration 640: Loss = 0.30715611577033997
Iteration 641: Loss = 0.306985467672348
Iteration 642: Loss = 0.30681484937667847
Iteration 643: Loss = 0.3066442012786865
Iteration 644: Loss = 0.30647337436676025
Iteration 645: Loss = 0.30630260705947876
Iteration 646: Loss = 0.30613231658935547
Iteration 647: Loss = 0.3059616684913635
Iteration 648: Loss = 0.3057907521724701
Iteration 649: Loss = 0.3056197762489319
Iteration 650: Loss = 0.3054496943950653
Iteration 651: Loss = 0.3052794337272644
Iteration 652: Loss = 0.30510881543159485
Iteration 653: Loss = 0.3049377501010895
Iteration 654: Loss = 0.3047671616077423
Iteration 655: Loss = 0.3045967221260071
Iteration 656: Loss = 0.3044261634349823
Iteration 657: Loss = 0.3042558431625366
Iteration 658: Loss = 0.3040850758552551
Iteration 659: Loss = 0.30391407012939453
Iteration 660: Loss = 0.30374351143836975
Iteration 661: Loss = 0.3035728931427002
Iteration 662: Loss = 0.30340227484703064
Iteration 663: Loss = 0.3032315671443939
Iteration 664: Loss = 0.30306097865104675
Iteration 665: Loss = 0.302890419960022
Iteration 666: Loss = 0.3027198910713196
Iteration 667: Loss = 0.3025493323802948
Iteration 668: Loss = 0.30237892270088196
Iteration 669: Loss = 0.30220848321914673
Iteration 670: Loss = 0.30203789472579956
Iteration 671: Loss = 0.3018672466278076
Iteration 672: Loss = 0.3016965091228485
Iteration 673: Loss = 0.3015264868736267
Iteration 674: Loss = 0.3013562858104706
Iteration 675: Loss = 0.3011857271194458
Iteration 676: Loss = 0.30101513862609863
Iteration 677: Loss = 0.30084460973739624
Iteration 678: Loss = 0.3006746470928192
Iteration 679: Loss = 0.3005044758319855
Iteration 680: Loss = 0.3003341257572174
Iteration 681: Loss = 0.30016401410102844
Iteration 682: Loss = 0.2999938428401947
Iteration 683: Loss = 0.2998236119747162
Iteration 684: Loss = 0.2996539771556854
Iteration 685: Loss = 0.2994840145111084
Iteration 686: Loss = 0.2993137836456299
Iteration 687: Loss = 0.2991434931755066
Iteration 688: Loss = 0.29897361993789673
Iteration 689: Loss = 0.2988039255142212
Iteration 690: Loss = 0.2986338436603546
Iteration 691: Loss = 0.29846400022506714
Iteration 692: Loss = 0.29829418659210205
Iteration 693: Loss = 0.29812437295913696
Iteration 694: Loss = 0.29795441031455994
Iteration 695: Loss = 0.29778504371643066
Iteration 696: Loss = 0.2976151406764984
Iteration 697: Loss = 0.2974448800086975
Iteration 698: Loss = 0.2972756028175354
Iteration 699: Loss = 0.29710638523101807
Iteration 700: Loss = 0.29693683981895447
Iteration 701: Loss = 0.29676681756973267
Iteration 702: Loss = 0.2965972125530243
Iteration 703: Loss = 0.2964278757572174
Iteration 704: Loss = 0.2962585389614105
Iteration 705: Loss = 0.29608914256095886
Iteration 706: Loss = 0.295920193195343
Iteration 707: Loss = 0.29575079679489136
Iteration 708: Loss = 0.29558148980140686
Iteration 709: Loss = 0.29541251063346863
Iteration 710: Loss = 0.2952435314655304
Iteration 711: Loss = 0.295074462890625
Iteration 712: Loss = 0.2949056327342987
Iteration 713: Loss = 0.2947368919849396
Iteration 714: Loss = 0.29456812143325806
Iteration 715: Loss = 0.29439952969551086
Iteration 716: Loss = 0.29423093795776367
Iteration 717: Loss = 0.2940623462200165
Iteration 718: Loss = 0.2938937246799469
Iteration 719: Loss = 0.29372501373291016
Iteration 720: Loss = 0.29355621337890625
Iteration 721: Loss = 0.2933880388736725
Iteration 722: Loss = 0.29321980476379395
Iteration 723: Loss = 0.293051540851593
Iteration 724: Loss = 0.29288333654403687
Iteration 725: Loss = 0.2927151918411255
Iteration 726: Loss = 0.2925471365451813
Iteration 727: Loss = 0.2923791706562042
Iteration 728: Loss = 0.29221129417419434
Iteration 729: Loss = 0.2920433580875397
Iteration 730: Loss = 0.291875422000885
Iteration 731: Loss = 0.29170742630958557
Iteration 732: Loss = 0.29153987765312195
Iteration 733: Loss = 0.29137226939201355
Iteration 734: Loss = 0.29120469093322754
Iteration 735: Loss = 0.2910371422767639
Iteration 736: Loss = 0.29086971282958984
Iteration 737: Loss = 0.29070237278938293
Iteration 738: Loss = 0.290535032749176
Iteration 739: Loss = 0.29036766290664673
Iteration 740: Loss = 0.29020026326179504
Iteration 741: Loss = 0.29003265500068665
Iteration 742: Loss = 0.2898654639720917
Iteration 743: Loss = 0.2896985411643982
Iteration 744: Loss = 0.289531409740448
Iteration 745: Loss = 0.2893642485141754
Iteration 746: Loss = 0.28919717669487
Iteration 747: Loss = 0.2890302836894989
Iteration 748: Loss = 0.2888636589050293
Iteration 749: Loss = 0.288697212934494
Iteration 750: Loss = 0.28853023052215576
Iteration 751: Loss = 0.28836333751678467
Iteration 752: Loss = 0.2881963551044464
Iteration 753: Loss = 0.2880304753780365
Iteration 754: Loss = 0.2878642976284027
Iteration 755: Loss = 0.28769755363464355
Iteration 756: Loss = 0.2875305712223053
Iteration 757: Loss = 0.2873638868331909
Iteration 758: Loss = 0.28719788789749146
Iteration 759: Loss = 0.28703153133392334
Iteration 760: Loss = 0.2868654131889343
Iteration 761: Loss = 0.28669941425323486
Iteration 762: Loss = 0.286533385515213
Iteration 763: Loss = 0.28636735677719116
Iteration 764: Loss = 0.2862012982368469
Iteration 765: Loss = 0.2860351800918579
Iteration 766: Loss = 0.2858695089817047
Iteration 767: Loss = 0.28570374846458435
Iteration 768: Loss = 0.2855377793312073
Iteration 769: Loss = 0.28537189960479736
Iteration 770: Loss = 0.2852061986923218
Iteration 771: Loss = 0.28504058718681335
Iteration 772: Loss = 0.2848750650882721
Iteration 773: Loss = 0.28470954298973083
Iteration 774: Loss = 0.2845439612865448
Iteration 775: Loss = 0.284378319978714
Iteration 776: Loss = 0.28421255946159363
Iteration 777: Loss = 0.2840472459793091
Iteration 778: Loss = 0.2838820219039917
Iteration 779: Loss = 0.28371649980545044
Iteration 780: Loss = 0.2835509181022644
Iteration 781: Loss = 0.2833855152130127
Iteration 782: Loss = 0.2832207679748535
Iteration 783: Loss = 0.2830553948879242
Iteration 784: Loss = 0.28289005160331726
Iteration 785: Loss = 0.2827247679233551
Iteration 786: Loss = 0.2825593948364258
Iteration 787: Loss = 0.2823949158191681
Iteration 788: Loss = 0.28222978115081787
Iteration 789: Loss = 0.2820639908313751
Iteration 790: Loss = 0.2818993330001831
Iteration 791: Loss = 0.28173500299453735
Iteration 792: Loss = 0.2815699577331543
Iteration 793: Loss = 0.2814047038555145
Iteration 794: Loss = 0.28124016523361206
Iteration 795: Loss = 0.2810756266117096
Iteration 796: Loss = 0.28091099858283997
Iteration 797: Loss = 0.28074634075164795
Iteration 798: Loss = 0.28058165311813354
Iteration 799: Loss = 0.28041723370552063
Iteration 800: Loss = 0.2802523970603943
Iteration 801: Loss = 0.28008797764778137
Iteration 802: Loss = 0.2799234986305237
Iteration 803: Loss = 0.27975890040397644
Iteration 804: Loss = 0.2795945405960083
Iteration 805: Loss = 0.27943024039268494
Iteration 806: Loss = 0.2792663276195526
Iteration 807: Loss = 0.2791018486022949
Iteration 808: Loss = 0.27893775701522827
Iteration 809: Loss = 0.27877354621887207
Iteration 810: Loss = 0.27860939502716064
Iteration 811: Loss = 0.27844515442848206
Iteration 812: Loss = 0.2782808542251587
Iteration 813: Loss = 0.2781170904636383
Iteration 814: Loss = 0.27795296907424927
Iteration 815: Loss = 0.27778834104537964
Iteration 816: Loss = 0.2776249349117279
Iteration 817: Loss = 0.27746132016181946
Iteration 818: Loss = 0.2772970199584961
Iteration 819: Loss = 0.27713242173194885
Iteration 820: Loss = 0.27696865797042847
Iteration 821: Loss = 0.27680477499961853
Iteration 822: Loss = 0.27664080262184143
Iteration 823: Loss = 0.27647674083709717
Iteration 824: Loss = 0.2763126492500305
Iteration 825: Loss = 0.2761484980583191
Iteration 826: Loss = 0.2759843170642853
Iteration 827: Loss = 0.27582013607025146
Iteration 828: Loss = 0.2756560146808624
Iteration 829: Loss = 0.2754918932914734
Iteration 830: Loss = 0.2753278613090515
Iteration 831: Loss = 0.2751637399196625
Iteration 832: Loss = 0.2749997079372406
Iteration 833: Loss = 0.2748356759548187
Iteration 834: Loss = 0.2746717631816864
Iteration 835: Loss = 0.2745078504085541
Iteration 836: Loss = 0.274343878030777
Iteration 837: Loss = 0.2741798460483551
Iteration 838: Loss = 0.2740156948566437
Iteration 839: Loss = 0.27385130524635315
Iteration 840: Loss = 0.27368682622909546
Iteration 841: Loss = 0.2735234200954437
Iteration 842: Loss = 0.27335938811302185
Iteration 843: Loss = 0.2731947600841522
Iteration 844: Loss = 0.27303004264831543
Iteration 845: Loss = 0.27286624908447266
Iteration 846: Loss = 0.272702157497406
Iteration 847: Loss = 0.2725372612476349
Iteration 848: Loss = 0.2723729610443115
Iteration 849: Loss = 0.272208571434021
Iteration 850: Loss = 0.2720440626144409
Iteration 851: Loss = 0.2718794643878937
Iteration 852: Loss = 0.2717147171497345
Iteration 853: Loss = 0.27155014872550964
Iteration 854: Loss = 0.27138519287109375
Iteration 855: Loss = 0.2712206542491913
Iteration 856: Loss = 0.27105608582496643
Iteration 857: Loss = 0.2708911597728729
Iteration 858: Loss = 0.27072620391845703
Iteration 859: Loss = 0.2705615162849426
Iteration 860: Loss = 0.27039676904678345
Iteration 861: Loss = 0.27023181319236755
Iteration 862: Loss = 0.2700668275356293
Iteration 863: Loss = 0.269901841878891
Iteration 864: Loss = 0.26973679661750793
Iteration 865: Loss = 0.2695716619491577
Iteration 866: Loss = 0.26940640807151794
Iteration 867: Loss = 0.26924094557762146
Iteration 868: Loss = 0.26907581090927124
Iteration 869: Loss = 0.26891064643859863
Iteration 870: Loss = 0.2687453031539917
Iteration 871: Loss = 0.26857990026474
Iteration 872: Loss = 0.26841455698013306
Iteration 873: Loss = 0.2682496905326843
Iteration 874: Loss = 0.26808395981788635
Iteration 875: Loss = 0.26791849732398987
Iteration 876: Loss = 0.26775285601615906
Iteration 877: Loss = 0.2675871253013611
Iteration 878: Loss = 0.26742130517959595
Iteration 879: Loss = 0.26725560426712036
Iteration 880: Loss = 0.2670895457267761
Iteration 881: Loss = 0.26692378520965576
Iteration 882: Loss = 0.2667582035064697
Iteration 883: Loss = 0.26659220457077026
Iteration 884: Loss = 0.2664255201816559
Iteration 885: Loss = 0.26625967025756836
Iteration 886: Loss = 0.2660936415195465
Iteration 887: Loss = 0.2659274935722351
Iteration 888: Loss = 0.2657613754272461
Iteration 889: Loss = 0.2655952572822571
Iteration 890: Loss = 0.26542899012565613
Iteration 891: Loss = 0.2652626633644104
Iteration 892: Loss = 0.26509615778923035
Iteration 893: Loss = 0.26492956280708313
Iteration 894: Loss = 0.26476287841796875
Iteration 895: Loss = 0.26459622383117676
Iteration 896: Loss = 0.2644292414188385
Iteration 897: Loss = 0.26426249742507935
Iteration 898: Loss = 0.26409584283828735
Iteration 899: Loss = 0.26392871141433716
Iteration 900: Loss = 0.2637616693973541
Iteration 901: Loss = 0.26359468698501587
Iteration 902: Loss = 0.26342758536338806
Iteration 903: Loss = 0.2632603049278259
Iteration 904: Loss = 0.2630930244922638
Iteration 905: Loss = 0.2629256248474121
Iteration 906: Loss = 0.26275813579559326
Iteration 907: Loss = 0.26259052753448486
Iteration 908: Loss = 0.26242274045944214
Iteration 909: Loss = 0.2622552216053009
Iteration 910: Loss = 0.2620871663093567
Iteration 911: Loss = 0.26191893219947815
Iteration 912: Loss = 0.2617509663105011
Iteration 913: Loss = 0.2615828216075897
Iteration 914: Loss = 0.26141464710235596
Iteration 915: Loss = 0.2612464129924774
Iteration 916: Loss = 0.2610781788825989
Iteration 917: Loss = 0.26090988516807556
Iteration 918: Loss = 0.2607414424419403
Iteration 919: Loss = 0.2605728805065155
Iteration 920: Loss = 0.26040413975715637
Iteration 921: Loss = 0.2602352797985077
Iteration 922: Loss = 0.26006633043289185
Iteration 923: Loss = 0.2598973512649536
Iteration 924: Loss = 0.25972840189933777
Iteration 925: Loss = 0.25955939292907715
Iteration 926: Loss = 0.25939029455184937
Iteration 927: Loss = 0.259220689535141
Iteration 928: Loss = 0.2590518891811371
Iteration 929: Loss = 0.258882611989975
Iteration 930: Loss = 0.2587129473686218
Iteration 931: Loss = 0.2585432529449463
Iteration 932: Loss = 0.25837358832359314
Iteration 933: Loss = 0.25820401310920715
Iteration 934: Loss = 0.25803446769714355
Iteration 935: Loss = 0.2578648328781128
Iteration 936: Loss = 0.2576949894428253
Iteration 937: Loss = 0.25752487778663635
Iteration 938: Loss = 0.25735461711883545
Iteration 939: Loss = 0.2571842670440674
Iteration 940: Loss = 0.2570147216320038
Iteration 941: Loss = 0.25684431195259094
Iteration 942: Loss = 0.2566729485988617
Iteration 943: Loss = 0.25650253891944885
Iteration 944: Loss = 0.2563318908214569
Iteration 945: Loss = 0.25616100430488586
Iteration 946: Loss = 0.2559904158115387
Iteration 947: Loss = 0.25581955909729004
Iteration 948: Loss = 0.2556486427783966
Iteration 949: Loss = 0.2554780840873718
Iteration 950: Loss = 0.2553066909313202
Iteration 951: Loss = 0.2551354765892029
Iteration 952: Loss = 0.2549641728401184
Iteration 953: Loss = 0.2547926902770996
Iteration 954: Loss = 0.25462105870246887
Iteration 955: Loss = 0.2544492781162262
Iteration 956: Loss = 0.25427743792533875
Iteration 957: Loss = 0.2541057765483856
Iteration 958: Loss = 0.25393369793891907
Iteration 959: Loss = 0.25376179814338684
Iteration 960: Loss = 0.2535896301269531
Iteration 961: Loss = 0.25341710448265076
Iteration 962: Loss = 0.2532448172569275
Iteration 963: Loss = 0.2530727684497833
Iteration 964: Loss = 0.2529001235961914
Iteration 965: Loss = 0.2527277171611786
Iteration 966: Loss = 0.2525547742843628
Iteration 967: Loss = 0.25238221883773804
Iteration 968: Loss = 0.25220954418182373
Iteration 969: Loss = 0.2520363926887512
Iteration 970: Loss = 0.2518629729747772
Iteration 971: Loss = 0.2516895830631256
Iteration 972: Loss = 0.2515162229537964
Iteration 973: Loss = 0.2513430714607239
Iteration 974: Loss = 0.2511690855026245
Iteration 975: Loss = 0.2509952485561371
Iteration 976: Loss = 0.2508213222026825
Iteration 977: Loss = 0.25064733624458313
Iteration 978: Loss = 0.2504729628562927
Iteration 979: Loss = 0.2502986192703247
Iteration 980: Loss = 0.2501242756843567
Iteration 981: Loss = 0.24994990229606628
Iteration 982: Loss = 0.24977514147758484
Iteration 983: Loss = 0.24960079789161682
Iteration 984: Loss = 0.24942627549171448
Iteration 985: Loss = 0.2492511123418808
Iteration 986: Loss = 0.24907685816287994
Iteration 987: Loss = 0.2489020675420761
Iteration 988: Loss = 0.24872629344463348
Iteration 989: Loss = 0.24855142831802368
Iteration 990: Loss = 0.24837626516819
Iteration 991: Loss = 0.24820095300674438
Iteration 992: Loss = 0.24802562594413757
Iteration 993: Loss = 0.247850239276886
Iteration 994: Loss = 0.2476748675107956
Iteration 995: Loss = 0.2474990338087082
Iteration 996: Loss = 0.24732325971126556
Iteration 997: Loss = 0.24714738130569458
Iteration 998: Loss = 0.24697133898735046
Iteration 999: Loss = 0.24679525196552277
Iteration 1000: Loss = 0.24661841988563538


Total training time (seconds): 10.83
