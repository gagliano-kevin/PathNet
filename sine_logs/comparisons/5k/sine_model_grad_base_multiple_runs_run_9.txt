Iteration 1: Loss = 1.1913269758224487
Iteration 2: Loss = 1.188598871231079
Iteration 3: Loss = 1.1858378648757935
Iteration 4: Loss = 1.1830439567565918
Iteration 5: Loss = 1.1802172660827637
Iteration 6: Loss = 1.177358627319336
Iteration 7: Loss = 1.1744675636291504
Iteration 8: Loss = 1.1715443134307861
Iteration 9: Loss = 1.1685881614685059
Iteration 10: Loss = 1.1655975580215454
Iteration 11: Loss = 1.1625723838806152
Iteration 12: Loss = 1.1595100164413452
Iteration 13: Loss = 1.156409502029419
Iteration 14: Loss = 1.153268575668335
Iteration 15: Loss = 1.15008544921875
Iteration 16: Loss = 1.1468580961227417
Iteration 17: Loss = 1.1435834169387817
Iteration 18: Loss = 1.1402599811553955
Iteration 19: Loss = 1.1368839740753174
Iteration 20: Loss = 1.133453369140625
Iteration 21: Loss = 1.1299656629562378
Iteration 22: Loss = 1.1264173984527588
Iteration 23: Loss = 1.1228063106536865
Iteration 24: Loss = 1.1191285848617554
Iteration 25: Loss = 1.1153823137283325
Iteration 26: Loss = 1.1115643978118896
Iteration 27: Loss = 1.107672095298767
Iteration 28: Loss = 1.103701114654541
Iteration 29: Loss = 1.0996487140655518
Iteration 30: Loss = 1.0955129861831665
Iteration 31: Loss = 1.091289758682251
Iteration 32: Loss = 1.0869768857955933
Iteration 33: Loss = 1.0825700759887695
Iteration 34: Loss = 1.0780670642852783
Iteration 35: Loss = 1.073464035987854
Iteration 36: Loss = 1.0687570571899414
Iteration 37: Loss = 1.0639430284500122
Iteration 38: Loss = 1.0590169429779053
Iteration 39: Loss = 1.053977370262146
Iteration 40: Loss = 1.0488197803497314
Iteration 41: Loss = 1.0435410737991333
Iteration 42: Loss = 1.038137674331665
Iteration 43: Loss = 1.0326052904129028
Iteration 44: Loss = 1.026940941810608
Iteration 45: Loss = 1.0211396217346191
Iteration 46: Loss = 1.0151994228363037
Iteration 47: Loss = 1.00911545753479
Iteration 48: Loss = 1.0028835535049438
Iteration 49: Loss = 0.9965008497238159
Iteration 50: Loss = 0.989962637424469
Iteration 51: Loss = 0.983265221118927
Iteration 52: Loss = 0.9764058589935303
Iteration 53: Loss = 0.9693806767463684
Iteration 54: Loss = 0.9621860384941101
Iteration 55: Loss = 0.95481938123703
Iteration 56: Loss = 0.9472856521606445
Iteration 57: Loss = 0.9395884871482849
Iteration 58: Loss = 0.9317265152931213
Iteration 59: Loss = 0.9236987233161926
Iteration 60: Loss = 0.9155048727989197
Iteration 61: Loss = 0.9071446061134338
Iteration 62: Loss = 0.8986178040504456
Iteration 63: Loss = 0.8899258971214294
Iteration 64: Loss = 0.8810696601867676
Iteration 65: Loss = 0.8720521330833435
Iteration 66: Loss = 0.8628749847412109
Iteration 67: Loss = 0.8535428643226624
Iteration 68: Loss = 0.8440588712692261
Iteration 69: Loss = 0.8344289660453796
Iteration 70: Loss = 0.8246590495109558
Iteration 71: Loss = 0.8147568702697754
Iteration 72: Loss = 0.8047308325767517
Iteration 73: Loss = 0.7945902943611145
Iteration 74: Loss = 0.7843467593193054
Iteration 75: Loss = 0.7740131616592407
Iteration 76: Loss = 0.7636036276817322
Iteration 77: Loss = 0.7531341910362244
Iteration 78: Loss = 0.7426226735115051
Iteration 79: Loss = 0.7320889830589294
Iteration 80: Loss = 0.7215548157691956
Iteration 81: Loss = 0.7110424637794495
Iteration 82: Loss = 0.7005769610404968
Iteration 83: Loss = 0.6901856064796448
Iteration 84: Loss = 0.679898202419281
Iteration 85: Loss = 0.6697468161582947
Iteration 86: Loss = 0.6597638130187988
Iteration 87: Loss = 0.6499843001365662
Iteration 88: Loss = 0.640443742275238
Iteration 89: Loss = 0.6311783790588379
Iteration 90: Loss = 0.622225284576416
Iteration 91: Loss = 0.6136191487312317
Iteration 92: Loss = 0.6053952574729919
Iteration 93: Loss = 0.5975860357284546
Iteration 94: Loss = 0.5902219414710999
Iteration 95: Loss = 0.5833286046981812
Iteration 96: Loss = 0.5769289135932922
Iteration 97: Loss = 0.5710389614105225
Iteration 98: Loss = 0.5656704902648926
Iteration 99: Loss = 0.5608278512954712
Iteration 100: Loss = 0.5565096139907837
Iteration 101: Loss = 0.5527068972587585
Iteration 102: Loss = 0.5494040250778198
Iteration 103: Loss = 0.5465788841247559
Iteration 104: Loss = 0.5442030429840088
Iteration 105: Loss = 0.5422425866127014
Iteration 106: Loss = 0.5406591892242432
Iteration 107: Loss = 0.5394110679626465
Iteration 108: Loss = 0.5384545922279358
Iteration 109: Loss = 0.5377442836761475
Iteration 110: Loss = 0.5372360944747925
Iteration 111: Loss = 0.536886990070343
Iteration 112: Loss = 0.5366560220718384
Iteration 113: Loss = 0.5365068316459656
Iteration 114: Loss = 0.5364066362380981
Iteration 115: Loss = 0.53632652759552
Iteration 116: Loss = 0.5362440943717957
Iteration 117: Loss = 0.5361408591270447
Iteration 118: Loss = 0.5360032916069031
Iteration 119: Loss = 0.5358222723007202
Iteration 120: Loss = 0.5355924367904663
Iteration 121: Loss = 0.5353121161460876
Iteration 122: Loss = 0.5349826812744141
Iteration 123: Loss = 0.5346072316169739
Iteration 124: Loss = 0.5341910123825073
Iteration 125: Loss = 0.533740222454071
Iteration 126: Loss = 0.5332613587379456
Iteration 127: Loss = 0.5327615737915039
Iteration 128: Loss = 0.53224778175354
Iteration 129: Loss = 0.5317262411117554
Iteration 130: Loss = 0.5312027335166931
Iteration 131: Loss = 0.530682384967804
Iteration 132: Loss = 0.5301690697669983
Iteration 133: Loss = 0.5296663045883179
Iteration 134: Loss = 0.5291764736175537
Iteration 135: Loss = 0.5287010073661804
Iteration 136: Loss = 0.5282407999038696
Iteration 137: Loss = 0.5277960896492004
Iteration 138: Loss = 0.5273663997650146
Iteration 139: Loss = 0.5269511938095093
Iteration 140: Loss = 0.5265491604804993
Iteration 141: Loss = 0.5261589884757996
Iteration 142: Loss = 0.525779128074646
Iteration 143: Loss = 0.5254079699516296
Iteration 144: Loss = 0.5250440835952759
Iteration 145: Loss = 0.5246858596801758
Iteration 146: Loss = 0.5243319272994995
Iteration 147: Loss = 0.5239810943603516
Iteration 148: Loss = 0.5236321687698364
Iteration 149: Loss = 0.5232841968536377
Iteration 150: Loss = 0.5229364633560181
Iteration 151: Loss = 0.5225883722305298
Iteration 152: Loss = 0.5222396850585938
Iteration 153: Loss = 0.5218899250030518
Iteration 154: Loss = 0.5215391516685486
Iteration 155: Loss = 0.5211870074272156
Iteration 156: Loss = 0.5208338499069214
Iteration 157: Loss = 0.5204796195030212
Iteration 158: Loss = 0.5201245546340942
Iteration 159: Loss = 0.5197687149047852
Iteration 160: Loss = 0.5194123387336731
Iteration 161: Loss = 0.5190557837486267
Iteration 162: Loss = 0.5186992883682251
Iteration 163: Loss = 0.518342912197113
Iteration 164: Loss = 0.5179870128631592
Iteration 165: Loss = 0.5176317095756531
Iteration 166: Loss = 0.517277181148529
Iteration 167: Loss = 0.5169233679771423
Iteration 168: Loss = 0.5165702700614929
Iteration 169: Loss = 0.5162182450294495
Iteration 170: Loss = 0.5158670544624329
Iteration 171: Loss = 0.515516996383667
Iteration 172: Loss = 0.5151678323745728
Iteration 173: Loss = 0.5148196220397949
Iteration 174: Loss = 0.5144723057746887
Iteration 175: Loss = 0.514125645160675
Iteration 176: Loss = 0.5137796998023987
Iteration 177: Loss = 0.5134345293045044
Iteration 178: Loss = 0.5130899548530579
Iteration 179: Loss = 0.5127460956573486
Iteration 180: Loss = 0.5124027729034424
Iteration 181: Loss = 0.5120599865913391
Iteration 182: Loss = 0.5117177367210388
Iteration 183: Loss = 0.5113760232925415
Iteration 184: Loss = 0.5110346078872681
Iteration 185: Loss = 0.5106937289237976
Iteration 186: Loss = 0.5103533864021301
Iteration 187: Loss = 0.5100135207176208
Iteration 188: Loss = 0.5096741318702698
Iteration 189: Loss = 0.5093352794647217
Iteration 190: Loss = 0.5089969635009766
Iteration 191: Loss = 0.5086591243743896
Iteration 192: Loss = 0.5083217620849609
Iteration 193: Loss = 0.5079848766326904
Iteration 194: Loss = 0.5076485872268677
Iteration 195: Loss = 0.5073128342628479
Iteration 196: Loss = 0.5069776177406311
Iteration 197: Loss = 0.5066431164741516
Iteration 198: Loss = 0.5063092708587646
Iteration 199: Loss = 0.5059760212898254
Iteration 200: Loss = 0.5056435465812683
Iteration 201: Loss = 0.5053114295005798
Iteration 202: Loss = 0.5049799084663391
Iteration 203: Loss = 0.5046490430831909
Iteration 204: Loss = 0.5043187737464905
Iteration 205: Loss = 0.5039891600608826
Iteration 206: Loss = 0.5036601424217224
Iteration 207: Loss = 0.5033318400382996
Iteration 208: Loss = 0.5030041337013245
Iteration 209: Loss = 0.5026771426200867
Iteration 210: Loss = 0.5023505091667175
Iteration 211: Loss = 0.5020245313644409
Iteration 212: Loss = 0.5016993284225464
Iteration 213: Loss = 0.5013749003410339
Iteration 214: Loss = 0.5010509490966797
Iteration 215: Loss = 0.5007277131080627
Iteration 216: Loss = 0.5004051327705383
Iteration 217: Loss = 0.5000832676887512
Iteration 218: Loss = 0.49976202845573425
Iteration 219: Loss = 0.4994412362575531
Iteration 220: Loss = 0.4991210997104645
Iteration 221: Loss = 0.49880167841911316
Iteration 222: Loss = 0.4984828531742096
Iteration 223: Loss = 0.4981647729873657
Iteration 224: Loss = 0.49784743785858154
Iteration 225: Loss = 0.4975307881832123
Iteration 226: Loss = 0.4972149133682251
Iteration 227: Loss = 0.4968996047973633
Iteration 228: Loss = 0.496584951877594
Iteration 229: Loss = 0.49627095460891724
Iteration 230: Loss = 0.49595770239830017
Iteration 231: Loss = 0.4956451654434204
Iteration 232: Loss = 0.49533331394195557
Iteration 233: Loss = 0.49502208828926086
Iteration 234: Loss = 0.4947117567062378
Iteration 235: Loss = 0.49440208077430725
Iteration 236: Loss = 0.4940928518772125
Iteration 237: Loss = 0.4937843680381775
Iteration 238: Loss = 0.49347665905952454
Iteration 239: Loss = 0.49316972494125366
Iteration 240: Loss = 0.49286359548568726
Iteration 241: Loss = 0.492558091878891
Iteration 242: Loss = 0.49225345253944397
Iteration 243: Loss = 0.4919494688510895
Iteration 244: Loss = 0.4916461706161499
Iteration 245: Loss = 0.49134349822998047
Iteration 246: Loss = 0.4910416007041931
Iteration 247: Loss = 0.49074044823646545
Iteration 248: Loss = 0.4904399812221527
Iteration 249: Loss = 0.49014031887054443
Iteration 250: Loss = 0.48984137177467346
Iteration 251: Loss = 0.48954319953918457
Iteration 252: Loss = 0.4892459213733673
Iteration 253: Loss = 0.4889492094516754
Iteration 254: Loss = 0.4886532425880432
Iteration 255: Loss = 0.4883579611778259
Iteration 256: Loss = 0.4880635440349579
Iteration 257: Loss = 0.48776987195014954
Iteration 258: Loss = 0.4874769449234009
Iteration 259: Loss = 0.4871848225593567
Iteration 260: Loss = 0.48689350485801697
Iteration 261: Loss = 0.486602783203125
Iteration 262: Loss = 0.4863128066062927
Iteration 263: Loss = 0.4860236346721649
Iteration 264: Loss = 0.4857352375984192
Iteration 265: Loss = 0.4854477047920227
Iteration 266: Loss = 0.4851609766483307
Iteration 267: Loss = 0.48487505316734314
Iteration 268: Loss = 0.4845898747444153
Iteration 269: Loss = 0.4843055307865143
Iteration 270: Loss = 0.4840218126773834
Iteration 271: Loss = 0.4837389588356018
Iteration 272: Loss = 0.4834567904472351
Iteration 273: Loss = 0.48317548632621765
Iteration 274: Loss = 0.4828949570655823
Iteration 275: Loss = 0.48261526226997375
Iteration 276: Loss = 0.4823363423347473
Iteration 277: Loss = 0.48205825686454773
Iteration 278: Loss = 0.4817809760570526
Iteration 279: Loss = 0.4815044701099396
Iteration 280: Loss = 0.4812287390232086
Iteration 281: Loss = 0.48095375299453735
Iteration 282: Loss = 0.48067963123321533
Iteration 283: Loss = 0.48040634393692017
Iteration 284: Loss = 0.48013389110565186
Iteration 285: Loss = 0.479862242937088
Iteration 286: Loss = 0.479591429233551
Iteration 287: Loss = 0.47932127118110657
Iteration 288: Loss = 0.47905194759368896
Iteration 289: Loss = 0.47878342866897583
Iteration 290: Loss = 0.4785158634185791
Iteration 291: Loss = 0.47824913263320923
Iteration 292: Loss = 0.4779832661151886
Iteration 293: Loss = 0.4777182340621948
Iteration 294: Loss = 0.4774540662765503
Iteration 295: Loss = 0.4771905839443207
Iteration 296: Loss = 0.47692787647247314
Iteration 297: Loss = 0.47666600346565247
Iteration 298: Loss = 0.47640496492385864
Iteration 299: Loss = 0.4761447608470917
Iteration 300: Loss = 0.47588545083999634
Iteration 301: Loss = 0.4756268560886383
Iteration 302: Loss = 0.47536924481391907
Iteration 303: Loss = 0.47511255741119385
Iteration 304: Loss = 0.47485649585723877
Iteration 305: Loss = 0.47460129857063293
Iteration 306: Loss = 0.47434693574905396
Iteration 307: Loss = 0.474093496799469
Iteration 308: Loss = 0.4738408327102661
Iteration 309: Loss = 0.4735890328884125
Iteration 310: Loss = 0.4733380973339081
Iteration 311: Loss = 0.4730880856513977
Iteration 312: Loss = 0.47283878922462463
Iteration 313: Loss = 0.47259023785591125
Iteration 314: Loss = 0.4723425805568695
Iteration 315: Loss = 0.472095787525177
Iteration 316: Loss = 0.4718499779701233
Iteration 317: Loss = 0.4716049134731293
Iteration 318: Loss = 0.4713607728481293
Iteration 319: Loss = 0.4711175560951233
Iteration 320: Loss = 0.470875084400177
Iteration 321: Loss = 0.4706333875656128
Iteration 322: Loss = 0.4703925549983978
Iteration 323: Loss = 0.47015252709388733
Iteration 324: Loss = 0.4699133634567261
Iteration 325: Loss = 0.4696749746799469
Iteration 326: Loss = 0.4694375693798065
Iteration 327: Loss = 0.4692010283470154
Iteration 328: Loss = 0.4689655005931854
Iteration 329: Loss = 0.46873071789741516
Iteration 330: Loss = 0.46849673986434937
Iteration 331: Loss = 0.4682636857032776
Iteration 332: Loss = 0.4680314064025879
Iteration 333: Loss = 0.4678000509738922
Iteration 334: Loss = 0.4675695598125458
Iteration 335: Loss = 0.46733999252319336
Iteration 336: Loss = 0.467111200094223
Iteration 337: Loss = 0.4668833017349243
Iteration 338: Loss = 0.46665623784065247
Iteration 339: Loss = 0.46643000841140747
Iteration 340: Loss = 0.4662047326564789
Iteration 341: Loss = 0.4659803807735443
Iteration 342: Loss = 0.4657568633556366
Iteration 343: Loss = 0.4655342400074005
Iteration 344: Loss = 0.46531248092651367
Iteration 345: Loss = 0.4650915861129761
Iteration 346: Loss = 0.4648715853691101
Iteration 347: Loss = 0.46465232968330383
Iteration 348: Loss = 0.4644339382648468
Iteration 349: Loss = 0.4642164409160614
Iteration 350: Loss = 0.46399974822998047
Iteration 351: Loss = 0.46378400921821594
Iteration 352: Loss = 0.46356916427612305
Iteration 353: Loss = 0.46335524320602417
Iteration 354: Loss = 0.4631422460079193
Iteration 355: Loss = 0.4629301428794861
Iteration 356: Loss = 0.46271875500679016
Iteration 357: Loss = 0.4625082314014435
Iteration 358: Loss = 0.46229860186576843
Iteration 359: Loss = 0.46208980679512024
Iteration 360: Loss = 0.4618819057941437
Iteration 361: Loss = 0.46167489886283875
Iteration 362: Loss = 0.46146878600120544
Iteration 363: Loss = 0.461263507604599
Iteration 364: Loss = 0.46105921268463135
Iteration 365: Loss = 0.46085572242736816
Iteration 366: Loss = 0.4606531262397766
Iteration 367: Loss = 0.4604513645172119
Iteration 368: Loss = 0.4602506160736084
Iteration 369: Loss = 0.46005064249038696
Iteration 370: Loss = 0.45985156297683716
Iteration 371: Loss = 0.45965343713760376
Iteration 372: Loss = 0.45945611596107483
Iteration 373: Loss = 0.45925959944725037
Iteration 374: Loss = 0.45906391739845276
Iteration 375: Loss = 0.4588690996170044
Iteration 376: Loss = 0.45867523550987244
Iteration 377: Loss = 0.4584822356700897
Iteration 378: Loss = 0.458290159702301
Iteration 379: Loss = 0.4580989480018616
Iteration 380: Loss = 0.45790866017341614
Iteration 381: Loss = 0.45771923661231995
Iteration 382: Loss = 0.4575306475162506
Iteration 383: Loss = 0.45734280347824097
Iteration 384: Loss = 0.45715585350990295
Iteration 385: Loss = 0.45696982741355896
Iteration 386: Loss = 0.45678460597991943
Iteration 387: Loss = 0.45660024881362915
Iteration 388: Loss = 0.4564168155193329
Iteration 389: Loss = 0.4562344253063202
Iteration 390: Loss = 0.45605283975601196
Iteration 391: Loss = 0.4558720290660858
Iteration 392: Loss = 0.4556920826435089
Iteration 393: Loss = 0.4555129408836365
Iteration 394: Loss = 0.45533472299575806
Iteration 395: Loss = 0.4551573395729065
Iteration 396: Loss = 0.4549808204174042
Iteration 397: Loss = 0.4548051357269287
Iteration 398: Loss = 0.45463037490844727
Iteration 399: Loss = 0.4544564485549927
Iteration 400: Loss = 0.45428332686424255
Iteration 401: Loss = 0.45411112904548645
Iteration 402: Loss = 0.453939825296402
Iteration 403: Loss = 0.45376935601234436
Iteration 404: Loss = 0.4535997211933136
Iteration 405: Loss = 0.45343098044395447
Iteration 406: Loss = 0.45326313376426697
Iteration 407: Loss = 0.45309609174728394
Iteration 408: Loss = 0.4529299736022949
Iteration 409: Loss = 0.4527646005153656
Iteration 410: Loss = 0.45260003209114075
Iteration 411: Loss = 0.4524362087249756
Iteration 412: Loss = 0.45227330923080444
Iteration 413: Loss = 0.45211145281791687
Iteration 414: Loss = 0.451950341463089
Iteration 415: Loss = 0.45179012417793274
Iteration 416: Loss = 0.45163074135780334
Iteration 417: Loss = 0.4514722228050232
Iteration 418: Loss = 0.4513145089149475
Iteration 419: Loss = 0.4511575400829315
Iteration 420: Loss = 0.4510014057159424
Iteration 421: Loss = 0.4508460760116577
Iteration 422: Loss = 0.4506915807723999
Iteration 423: Loss = 0.45053794980049133
Iteration 424: Loss = 0.45038512349128723
Iteration 425: Loss = 0.4502332806587219
Iteration 426: Loss = 0.45008227229118347
Iteration 427: Loss = 0.44993215799331665
Iteration 428: Loss = 0.44978275895118713
Iteration 429: Loss = 0.4496341645717621
Iteration 430: Loss = 0.4494863450527191
Iteration 431: Loss = 0.449339359998703
Iteration 432: Loss = 0.44919323921203613
Iteration 433: Loss = 0.44904792308807373
Iteration 434: Loss = 0.4489034116268158
Iteration 435: Loss = 0.4487597346305847
Iteration 436: Loss = 0.4486168920993805
Iteration 437: Loss = 0.4484749436378479
Iteration 438: Loss = 0.4483336806297302
Iteration 439: Loss = 0.44819319248199463
Iteration 440: Loss = 0.44805362820625305
Iteration 441: Loss = 0.44791480898857117
Iteration 442: Loss = 0.44777679443359375
Iteration 443: Loss = 0.4476395845413208
Iteration 444: Loss = 0.44750311970710754
Iteration 445: Loss = 0.4473675489425659
Iteration 446: Loss = 0.4472326934337616
Iteration 447: Loss = 0.44709861278533936
Iteration 448: Loss = 0.4469652771949768
Iteration 449: Loss = 0.44683289527893066
Iteration 450: Loss = 0.44670119881629944
Iteration 451: Loss = 0.44657033681869507
Iteration 452: Loss = 0.44644030928611755
Iteration 453: Loss = 0.44631099700927734
Iteration 454: Loss = 0.4461825489997864
Iteration 455: Loss = 0.4460548162460327
Iteration 456: Loss = 0.44592785835266113
Iteration 457: Loss = 0.44580161571502686
Iteration 458: Loss = 0.4456760883331299
Iteration 459: Loss = 0.44555139541625977
Iteration 460: Loss = 0.44542744755744934
Iteration 461: Loss = 0.4453044533729553
Iteration 462: Loss = 0.44518211483955383
Iteration 463: Loss = 0.4450606405735016
Iteration 464: Loss = 0.4449399709701538
Iteration 465: Loss = 0.44482001662254333
Iteration 466: Loss = 0.4447007179260254
Iteration 467: Loss = 0.4445822238922119
Iteration 468: Loss = 0.44446441531181335
Iteration 469: Loss = 0.44434741139411926
Iteration 470: Loss = 0.4442311227321625
Iteration 471: Loss = 0.444115549325943
Iteration 472: Loss = 0.4440007507801056
Iteration 473: Loss = 0.4438868761062622
Iteration 474: Loss = 0.44377368688583374
Iteration 475: Loss = 0.44366127252578735
Iteration 476: Loss = 0.4435495138168335
Iteration 477: Loss = 0.44343847036361694
Iteration 478: Loss = 0.4433281421661377
Iteration 479: Loss = 0.44321855902671814
Iteration 480: Loss = 0.4431097209453583
Iteration 481: Loss = 0.44300156831741333
Iteration 482: Loss = 0.4428941011428833
Iteration 483: Loss = 0.44278740882873535
Iteration 484: Loss = 0.4426814615726471
Iteration 485: Loss = 0.4425762891769409
Iteration 486: Loss = 0.44247177243232727
Iteration 487: Loss = 0.44236794114112854
Iteration 488: Loss = 0.4422648251056671
Iteration 489: Loss = 0.442162424325943
Iteration 490: Loss = 0.4420607089996338
Iteration 491: Loss = 0.4419596791267395
Iteration 492: Loss = 0.44185930490493774
Iteration 493: Loss = 0.4417596161365509
Iteration 494: Loss = 0.44166073203086853
Iteration 495: Loss = 0.4415624141693115
Iteration 496: Loss = 0.4414648413658142
Iteration 497: Loss = 0.441368043422699
Iteration 498: Loss = 0.4412718117237091
Iteration 499: Loss = 0.44117632508277893
Iteration 500: Loss = 0.44108152389526367
Iteration 501: Loss = 0.44098731875419617
Iteration 502: Loss = 0.44089382886886597
Iteration 503: Loss = 0.4408010244369507
Iteration 504: Loss = 0.44070884585380554
Iteration 505: Loss = 0.4406173527240753
Iteration 506: Loss = 0.44052645564079285
Iteration 507: Loss = 0.44043615460395813
Iteration 508: Loss = 0.44034653902053833
Iteration 509: Loss = 0.4402576684951782
Iteration 510: Loss = 0.44016942381858826
Iteration 511: Loss = 0.4400818347930908
Iteration 512: Loss = 0.4399949014186859
Iteration 513: Loss = 0.439908504486084
Iteration 514: Loss = 0.4398229420185089
Iteration 515: Loss = 0.43973785638809204
Iteration 516: Loss = 0.4396534562110901
Iteration 517: Loss = 0.4395695924758911
Iteration 518: Loss = 0.4394862949848175
Iteration 519: Loss = 0.43940362334251404
Iteration 520: Loss = 0.4393216669559479
Iteration 521: Loss = 0.4392402768135071
Iteration 522: Loss = 0.4391595423221588
Iteration 523: Loss = 0.4390794336795807
Iteration 524: Loss = 0.4389999210834503
Iteration 525: Loss = 0.4389210045337677
Iteration 526: Loss = 0.43884265422821045
Iteration 527: Loss = 0.43876489996910095
Iteration 528: Loss = 0.4386877119541168
Iteration 529: Loss = 0.43861109018325806
Iteration 530: Loss = 0.43853500485420227
Iteration 531: Loss = 0.4384596049785614
Iteration 532: Loss = 0.4383847117424011
Iteration 533: Loss = 0.4383104145526886
Iteration 534: Loss = 0.438236802816391
Iteration 535: Loss = 0.438163697719574
Iteration 536: Loss = 0.4380912482738495
Iteration 537: Loss = 0.4380192458629608
Iteration 538: Loss = 0.4379478991031647
Iteration 539: Loss = 0.43787696957588196
Iteration 540: Loss = 0.4378066658973694
Iteration 541: Loss = 0.437736839056015
Iteration 542: Loss = 0.4376676082611084
Iteration 543: Loss = 0.4375988841056824
Iteration 544: Loss = 0.4375307559967041
Iteration 545: Loss = 0.43746325373649597
Iteration 546: Loss = 0.43739625811576843
Iteration 547: Loss = 0.43732979893684387
Iteration 548: Loss = 0.4372638463973999
Iteration 549: Loss = 0.4371984302997589
Iteration 550: Loss = 0.4371335506439209
Iteration 551: Loss = 0.4370691776275635
Iteration 552: Loss = 0.4370051920413971
Iteration 553: Loss = 0.43694180250167847
Iteration 554: Loss = 0.43687891960144043
Iteration 555: Loss = 0.4368164837360382
Iteration 556: Loss = 0.43675467371940613
Iteration 557: Loss = 0.43669334053993225
Iteration 558: Loss = 0.43663260340690613
Iteration 559: Loss = 0.43657228350639343
Iteration 560: Loss = 0.4365125298500061
Iteration 561: Loss = 0.436453253030777
Iteration 562: Loss = 0.4363943934440613
Iteration 563: Loss = 0.4363360106945038
Iteration 564: Loss = 0.4362781345844269
Iteration 565: Loss = 0.436220645904541
Iteration 566: Loss = 0.43616369366645813
Iteration 567: Loss = 0.43610718846321106
Iteration 568: Loss = 0.43605127930641174
Iteration 569: Loss = 0.43599584698677063
Iteration 570: Loss = 0.43594086170196533
Iteration 571: Loss = 0.435886412858963
Iteration 572: Loss = 0.4358324110507965
Iteration 573: Loss = 0.43577879667282104
Iteration 574: Loss = 0.4357256293296814
Iteration 575: Loss = 0.43567290902137756
Iteration 576: Loss = 0.43562060594558716
Iteration 577: Loss = 0.43556874990463257
Iteration 578: Loss = 0.4355173408985138
Iteration 579: Loss = 0.43546637892723083
Iteration 580: Loss = 0.4354158639907837
Iteration 581: Loss = 0.4353659152984619
Iteration 582: Loss = 0.4353163540363312
Iteration 583: Loss = 0.43526721000671387
Iteration 584: Loss = 0.43521854281425476
Iteration 585: Loss = 0.4351702630519867
Iteration 586: Loss = 0.43512237071990967
Iteration 587: Loss = 0.4350748360157013
Iteration 588: Loss = 0.43502774834632874
Iteration 589: Loss = 0.43498101830482483
Iteration 590: Loss = 0.4349347651004791
Iteration 591: Loss = 0.4348888695240021
Iteration 592: Loss = 0.43484339118003845
Iteration 593: Loss = 0.4347985088825226
Iteration 594: Loss = 0.4347538948059082
Iteration 595: Loss = 0.4347098469734192
Iteration 596: Loss = 0.4346660375595093
Iteration 597: Loss = 0.4346226751804352
Iteration 598: Loss = 0.4345797002315521
Iteration 599: Loss = 0.43453705310821533
Iteration 600: Loss = 0.4344947636127472
Iteration 601: Loss = 0.4344528317451477
Iteration 602: Loss = 0.43441128730773926
Iteration 603: Loss = 0.43437010049819946
Iteration 604: Loss = 0.4343293309211731
Iteration 605: Loss = 0.43428900837898254
Iteration 606: Loss = 0.43424904346466064
Iteration 607: Loss = 0.4342094659805298
Iteration 608: Loss = 0.43417027592658997
Iteration 609: Loss = 0.4341314136981964
Iteration 610: Loss = 0.43409281969070435
Iteration 611: Loss = 0.4340546429157257
Iteration 612: Loss = 0.43401676416397095
Iteration 613: Loss = 0.43397918343544006
Iteration 614: Loss = 0.4339420199394226
Iteration 615: Loss = 0.43390509486198425
Iteration 616: Loss = 0.43386849761009216
Iteration 617: Loss = 0.43383240699768066
Iteration 618: Loss = 0.43379658460617065
Iteration 619: Loss = 0.4337611496448517
Iteration 620: Loss = 0.4337259829044342
Iteration 621: Loss = 0.43369120359420776
Iteration 622: Loss = 0.43365663290023804
Iteration 623: Loss = 0.43362247943878174
Iteration 624: Loss = 0.43358853459358215
Iteration 625: Loss = 0.43355491757392883
Iteration 626: Loss = 0.4335215985774994
Iteration 627: Loss = 0.4334885776042938
Iteration 628: Loss = 0.4334559142589569
Iteration 629: Loss = 0.4334234893321991
Iteration 630: Loss = 0.4333914816379547
Iteration 631: Loss = 0.4333597719669342
Iteration 632: Loss = 0.4333282709121704
Iteration 633: Loss = 0.43329715728759766
Iteration 634: Loss = 0.4332663416862488
Iteration 635: Loss = 0.43323570489883423
Iteration 636: Loss = 0.43320542573928833
Iteration 637: Loss = 0.43317535519599915
Iteration 638: Loss = 0.4331456124782562
Iteration 639: Loss = 0.43311607837677
Iteration 640: Loss = 0.4330868422985077
Iteration 641: Loss = 0.43305790424346924
Iteration 642: Loss = 0.4330293536186218
Iteration 643: Loss = 0.4330011010169983
Iteration 644: Loss = 0.43297308683395386
Iteration 645: Loss = 0.4329453408718109
Iteration 646: Loss = 0.43291783332824707
Iteration 647: Loss = 0.4328906238079071
Iteration 648: Loss = 0.43286368250846863
Iteration 649: Loss = 0.43283697962760925
Iteration 650: Loss = 0.43281054496765137
Iteration 651: Loss = 0.4327842593193054
Iteration 652: Loss = 0.43275830149650574
Iteration 653: Loss = 0.43273255228996277
Iteration 654: Loss = 0.4327071011066437
Iteration 655: Loss = 0.43268197774887085
Iteration 656: Loss = 0.43265706300735474
Iteration 657: Loss = 0.4326324462890625
Iteration 658: Loss = 0.43260806798934937
Iteration 659: Loss = 0.43258386850357056
Iteration 660: Loss = 0.43255990743637085
Iteration 661: Loss = 0.43253618478775024
Iteration 662: Loss = 0.43251273036003113
Iteration 663: Loss = 0.4324894845485687
Iteration 664: Loss = 0.43246644735336304
Iteration 665: Loss = 0.4324435889720917
Iteration 666: Loss = 0.4324209690093994
Iteration 667: Loss = 0.43239861726760864
Iteration 668: Loss = 0.432376503944397
Iteration 669: Loss = 0.4323546290397644
Iteration 670: Loss = 0.43233293294906616
Iteration 671: Loss = 0.432311475276947
Iteration 672: Loss = 0.4322902262210846
Iteration 673: Loss = 0.4322691559791565
Iteration 674: Loss = 0.4322483539581299
Iteration 675: Loss = 0.43222764134407043
Iteration 676: Loss = 0.4322071969509125
Iteration 677: Loss = 0.43218693137168884
Iteration 678: Loss = 0.43216678500175476
Iteration 679: Loss = 0.43214696645736694
Iteration 680: Loss = 0.43212735652923584
Iteration 681: Loss = 0.4321078360080719
Iteration 682: Loss = 0.43208855390548706
Iteration 683: Loss = 0.43206948041915894
Iteration 684: Loss = 0.43205058574676514
Iteration 685: Loss = 0.43203186988830566
Iteration 686: Loss = 0.4320133328437805
Iteration 687: Loss = 0.4319950342178345
Iteration 688: Loss = 0.4319767951965332
Iteration 689: Loss = 0.43195879459381104
Iteration 690: Loss = 0.4319409430027008
Iteration 691: Loss = 0.4319232106208801
Iteration 692: Loss = 0.4319057762622833
Iteration 693: Loss = 0.43188852071762085
Iteration 694: Loss = 0.43187153339385986
Iteration 695: Loss = 0.4318546652793884
Iteration 696: Loss = 0.43183794617652893
Iteration 697: Loss = 0.43182146549224854
Iteration 698: Loss = 0.43180498480796814
Iteration 699: Loss = 0.4317888617515564
Iteration 700: Loss = 0.43177276849746704
Iteration 701: Loss = 0.4317568242549896
Iteration 702: Loss = 0.4317410886287689
Iteration 703: Loss = 0.43172547221183777
Iteration 704: Loss = 0.43171000480651855
Iteration 705: Loss = 0.43169477581977844
Iteration 706: Loss = 0.4316796362400055
Iteration 707: Loss = 0.43166473507881165
Iteration 708: Loss = 0.43164998292922974
Iteration 709: Loss = 0.43163537979125977
Iteration 710: Loss = 0.4316209554672241
Iteration 711: Loss = 0.43160662055015564
Iteration 712: Loss = 0.4315923750400543
Iteration 713: Loss = 0.43157827854156494
Iteration 714: Loss = 0.4315643608570099
Iteration 715: Loss = 0.431550532579422
Iteration 716: Loss = 0.43153679370880127
Iteration 717: Loss = 0.43152332305908203
Iteration 718: Loss = 0.4315098226070404
Iteration 719: Loss = 0.43149659037590027
Iteration 720: Loss = 0.43148353695869446
Iteration 721: Loss = 0.4314706027507782
Iteration 722: Loss = 0.4314578175544739
Iteration 723: Loss = 0.4314452111721039
Iteration 724: Loss = 0.4314326345920563
Iteration 725: Loss = 0.431420236825943
Iteration 726: Loss = 0.4314078986644745
Iteration 727: Loss = 0.4313957691192627
Iteration 728: Loss = 0.4313836991786957
Iteration 729: Loss = 0.4313717782497406
Iteration 730: Loss = 0.4313598573207855
Iteration 731: Loss = 0.43134814500808716
Iteration 732: Loss = 0.43133652210235596
Iteration 733: Loss = 0.4313249886035919
Iteration 734: Loss = 0.431313693523407
Iteration 735: Loss = 0.4313024878501892
Iteration 736: Loss = 0.4312913417816162
Iteration 737: Loss = 0.4312804043292999
Iteration 738: Loss = 0.43126946687698364
Iteration 739: Loss = 0.4312587380409241
Iteration 740: Loss = 0.4312480390071869
Iteration 741: Loss = 0.43123745918273926
Iteration 742: Loss = 0.4312269985675812
Iteration 743: Loss = 0.43121662735939026
Iteration 744: Loss = 0.4312063455581665
Iteration 745: Loss = 0.4311961233615875
Iteration 746: Loss = 0.43118607997894287
Iteration 747: Loss = 0.431176096200943
Iteration 748: Loss = 0.43116623163223267
Iteration 749: Loss = 0.4311564564704895
Iteration 750: Loss = 0.4311468303203583
Iteration 751: Loss = 0.43113720417022705
Iteration 752: Loss = 0.43112778663635254
Iteration 753: Loss = 0.43111833930015564
Iteration 754: Loss = 0.43110910058021545
Iteration 755: Loss = 0.43109989166259766
Iteration 756: Loss = 0.431090772151947
Iteration 757: Loss = 0.43108171224594116
Iteration 758: Loss = 0.4310727119445801
Iteration 759: Loss = 0.4310638904571533
Iteration 760: Loss = 0.4310550391674042
Iteration 761: Loss = 0.4310464560985565
Iteration 762: Loss = 0.4310378432273865
Iteration 763: Loss = 0.431029349565506
Iteration 764: Loss = 0.43102094531059265
Iteration 765: Loss = 0.4310126006603241
Iteration 766: Loss = 0.4310043156147003
Iteration 767: Loss = 0.4309961497783661
Iteration 768: Loss = 0.43098801374435425
Iteration 769: Loss = 0.43097996711730957
Iteration 770: Loss = 0.43097203969955444
Iteration 771: Loss = 0.4309641122817993
Iteration 772: Loss = 0.43095630407333374
Iteration 773: Loss = 0.43094855546951294
Iteration 774: Loss = 0.4309408664703369
Iteration 775: Loss = 0.43093323707580566
Iteration 776: Loss = 0.43092578649520874
Iteration 777: Loss = 0.4309183657169342
Iteration 778: Loss = 0.43091103434562683
Iteration 779: Loss = 0.4309037923812866
Iteration 780: Loss = 0.430896520614624
Iteration 781: Loss = 0.43088939785957336
Iteration 782: Loss = 0.4308823049068451
Iteration 783: Loss = 0.4308752417564392
Iteration 784: Loss = 0.4308682382106781
Iteration 785: Loss = 0.4308612644672394
Iteration 786: Loss = 0.430854469537735
Iteration 787: Loss = 0.4308475852012634
Iteration 788: Loss = 0.4308408498764038
Iteration 789: Loss = 0.43083417415618896
Iteration 790: Loss = 0.43082761764526367
Iteration 791: Loss = 0.43082112073898315
Iteration 792: Loss = 0.430814653635025
Iteration 793: Loss = 0.43080827593803406
Iteration 794: Loss = 0.43080198764801025
Iteration 795: Loss = 0.4307957589626312
Iteration 796: Loss = 0.4307895004749298
Iteration 797: Loss = 0.43078336119651794
Iteration 798: Loss = 0.43077725172042847
Iteration 799: Loss = 0.43077123165130615
Iteration 800: Loss = 0.43076521158218384
Iteration 801: Loss = 0.4307592511177063
Iteration 802: Loss = 0.43075329065322876
Iteration 803: Loss = 0.430747389793396
Iteration 804: Loss = 0.43074163794517517
Iteration 805: Loss = 0.43073588609695435
Iteration 806: Loss = 0.43073028326034546
Iteration 807: Loss = 0.43072471022605896
Iteration 808: Loss = 0.43071919679641724
Iteration 809: Loss = 0.4307136833667755
Iteration 810: Loss = 0.43070825934410095
Iteration 811: Loss = 0.43070292472839355
Iteration 812: Loss = 0.43069756031036377
Iteration 813: Loss = 0.43069225549697876
Iteration 814: Loss = 0.4306870102882385
Iteration 815: Loss = 0.4306817650794983
Iteration 816: Loss = 0.43067657947540283
Iteration 817: Loss = 0.4306715130805969
Iteration 818: Loss = 0.430666446685791
Iteration 819: Loss = 0.4306614398956299
Iteration 820: Loss = 0.43065646290779114
Iteration 821: Loss = 0.43065160512924194
Iteration 822: Loss = 0.43064677715301514
Iteration 823: Loss = 0.4306419789791107
Iteration 824: Loss = 0.4306372106075287
Iteration 825: Loss = 0.4306325316429138
Iteration 826: Loss = 0.43062788248062134
Iteration 827: Loss = 0.43062320351600647
Iteration 828: Loss = 0.4306185841560364
Iteration 829: Loss = 0.43061402440071106
Iteration 830: Loss = 0.43060949444770813
Iteration 831: Loss = 0.43060502409935
Iteration 832: Loss = 0.4306005537509918
Iteration 833: Loss = 0.43059608340263367
Iteration 834: Loss = 0.43059176206588745
Iteration 835: Loss = 0.430587500333786
Iteration 836: Loss = 0.4305833578109741
Iteration 837: Loss = 0.43057912588119507
Iteration 838: Loss = 0.43057501316070557
Iteration 839: Loss = 0.4305708706378937
Iteration 840: Loss = 0.43056681752204895
Iteration 841: Loss = 0.4305627644062042
Iteration 842: Loss = 0.4305587410926819
Iteration 843: Loss = 0.4305547773838043
Iteration 844: Loss = 0.43055084347724915
Iteration 845: Loss = 0.43054690957069397
Iteration 846: Loss = 0.43054303526878357
Iteration 847: Loss = 0.43053916096687317
Iteration 848: Loss = 0.43053534626960754
Iteration 849: Loss = 0.4305315613746643
Iteration 850: Loss = 0.43052783608436584
Iteration 851: Loss = 0.4305241107940674
Iteration 852: Loss = 0.4305204749107361
Iteration 853: Loss = 0.4305168390274048
Iteration 854: Loss = 0.4305132329463959
Iteration 855: Loss = 0.4305097460746765
Iteration 856: Loss = 0.4305061399936676
Iteration 857: Loss = 0.43050265312194824
Iteration 858: Loss = 0.4304991662502289
Iteration 859: Loss = 0.4304957091808319
Iteration 860: Loss = 0.4304923117160797
Iteration 861: Loss = 0.4304888844490051
Iteration 862: Loss = 0.4304855167865753
Iteration 863: Loss = 0.4304821491241455
Iteration 864: Loss = 0.4304787516593933
Iteration 865: Loss = 0.4304754436016083
Iteration 866: Loss = 0.43047216534614563
Iteration 867: Loss = 0.43046897649765015
Iteration 868: Loss = 0.43046578764915466
Iteration 869: Loss = 0.4304625988006592
Iteration 870: Loss = 0.4304594397544861
Iteration 871: Loss = 0.4304563105106354
Iteration 872: Loss = 0.43045318126678467
Iteration 873: Loss = 0.43045011162757874
Iteration 874: Loss = 0.4304470717906952
Iteration 875: Loss = 0.43044403195381165
Iteration 876: Loss = 0.4304410219192505
Iteration 877: Loss = 0.43043798208236694
Iteration 878: Loss = 0.4304350018501282
Iteration 879: Loss = 0.4304320812225342
Iteration 880: Loss = 0.430429071187973
Iteration 881: Loss = 0.43042615056037903
Iteration 882: Loss = 0.4304232895374298
Iteration 883: Loss = 0.4304203987121582
Iteration 884: Loss = 0.43041762709617615
Iteration 885: Loss = 0.4304148554801941
Iteration 886: Loss = 0.43041208386421204
Iteration 887: Loss = 0.43040934205055237
Iteration 888: Loss = 0.4304066598415375
Iteration 889: Loss = 0.4304039180278778
Iteration 890: Loss = 0.4304012060165405
Iteration 891: Loss = 0.430398553609848
Iteration 892: Loss = 0.4303959012031555
Iteration 893: Loss = 0.430393248796463
Iteration 894: Loss = 0.4303906261920929
Iteration 895: Loss = 0.4303880035877228
Iteration 896: Loss = 0.43038544058799744
Iteration 897: Loss = 0.4303828179836273
Iteration 898: Loss = 0.43038028478622437
Iteration 899: Loss = 0.4303778111934662
Iteration 900: Loss = 0.4303753972053528
Iteration 901: Loss = 0.4303729832172394
Iteration 902: Loss = 0.4303705394268036
Iteration 903: Loss = 0.4303681552410126
Iteration 904: Loss = 0.43036574125289917
Iteration 905: Loss = 0.4303634464740753
Iteration 906: Loss = 0.4303610920906067
Iteration 907: Loss = 0.4303587079048157
Iteration 908: Loss = 0.43035638332366943
Iteration 909: Loss = 0.4303540289402008
Iteration 910: Loss = 0.43035173416137695
Iteration 911: Loss = 0.4303494989871979
Iteration 912: Loss = 0.43034717440605164
Iteration 913: Loss = 0.4303448796272278
Iteration 914: Loss = 0.43034258484840393
Iteration 915: Loss = 0.43034034967422485
Iteration 916: Loss = 0.43033814430236816
Iteration 917: Loss = 0.4303358793258667
Iteration 918: Loss = 0.4303337037563324
Iteration 919: Loss = 0.43033158779144287
Iteration 920: Loss = 0.4303293526172638
Iteration 921: Loss = 0.43032723665237427
Iteration 922: Loss = 0.4303250014781952
Iteration 923: Loss = 0.43032294511795044
Iteration 924: Loss = 0.43032076954841614
Iteration 925: Loss = 0.4303186535835266
Iteration 926: Loss = 0.4303165376186371
Iteration 927: Loss = 0.43031442165374756
Iteration 928: Loss = 0.4303123354911804
Iteration 929: Loss = 0.43031030893325806
Iteration 930: Loss = 0.43030816316604614
Iteration 931: Loss = 0.4303061366081238
Iteration 932: Loss = 0.43030405044555664
Iteration 933: Loss = 0.4303020238876343
Iteration 934: Loss = 0.4303000271320343
Iteration 935: Loss = 0.4302980303764343
Iteration 936: Loss = 0.4302960932254791
Iteration 937: Loss = 0.4302941560745239
Iteration 938: Loss = 0.4302922189235687
Iteration 939: Loss = 0.4302902817726135
Iteration 940: Loss = 0.4302883744239807
Iteration 941: Loss = 0.4302864372730255
Iteration 942: Loss = 0.43028461933135986
Iteration 943: Loss = 0.43028268218040466
Iteration 944: Loss = 0.4302808344364166
Iteration 945: Loss = 0.4302789270877838
Iteration 946: Loss = 0.4302770495414734
Iteration 947: Loss = 0.43027517199516296
Iteration 948: Loss = 0.4302733838558197
Iteration 949: Loss = 0.4302714765071869
Iteration 950: Loss = 0.43026965856552124
Iteration 951: Loss = 0.4302678406238556
Iteration 952: Loss = 0.4302661120891571
Iteration 953: Loss = 0.43026435375213623
Iteration 954: Loss = 0.43026265501976013
Iteration 955: Loss = 0.43026092648506165
Iteration 956: Loss = 0.43025925755500793
Iteration 957: Loss = 0.43025749921798706
Iteration 958: Loss = 0.43025580048561096
Iteration 959: Loss = 0.43025410175323486
Iteration 960: Loss = 0.43025240302085876
Iteration 961: Loss = 0.43025073409080505
Iteration 962: Loss = 0.4302491247653961
Iteration 963: Loss = 0.43024739623069763
Iteration 964: Loss = 0.4302457869052887
Iteration 965: Loss = 0.4302441477775574
Iteration 966: Loss = 0.43024247884750366
Iteration 967: Loss = 0.43024083971977234
Iteration 968: Loss = 0.430239200592041
Iteration 969: Loss = 0.43023765087127686
Iteration 970: Loss = 0.4302360415458679
Iteration 971: Loss = 0.43023449182510376
Iteration 972: Loss = 0.4302330017089844
Iteration 973: Loss = 0.4302314817905426
Iteration 974: Loss = 0.4302300214767456
Iteration 975: Loss = 0.43022850155830383
Iteration 976: Loss = 0.43022698163986206
Iteration 977: Loss = 0.4302254915237427
Iteration 978: Loss = 0.43022406101226807
Iteration 979: Loss = 0.4302225708961487
Iteration 980: Loss = 0.4302211403846741
Iteration 981: Loss = 0.4302196204662323
Iteration 982: Loss = 0.4302181899547577
Iteration 983: Loss = 0.4302167594432831
Iteration 984: Loss = 0.4302152991294861
Iteration 985: Loss = 0.4302138686180115
Iteration 986: Loss = 0.43021246790885925
Iteration 987: Loss = 0.43021100759506226
Iteration 988: Loss = 0.4302096366882324
Iteration 989: Loss = 0.4302081763744354
Iteration 990: Loss = 0.430206835269928
Iteration 991: Loss = 0.43020549416542053
Iteration 992: Loss = 0.4302041530609131
Iteration 993: Loss = 0.43020281195640564
Iteration 994: Loss = 0.4302014708518982
Iteration 995: Loss = 0.43020015954971313
Iteration 996: Loss = 0.4301988184452057
Iteration 997: Loss = 0.43019750714302063
Iteration 998: Loss = 0.4301961660385132
Iteration 999: Loss = 0.4301948547363281
Iteration 1000: Loss = 0.43019354343414307
Iteration 1001: Loss = 0.4301922619342804
Iteration 1002: Loss = 0.43019095063209534
Iteration 1003: Loss = 0.43018966913223267
Iteration 1004: Loss = 0.4301883280277252
Iteration 1005: Loss = 0.43018704652786255
Iteration 1006: Loss = 0.4301857352256775
Iteration 1007: Loss = 0.4301845133304596
Iteration 1008: Loss = 0.4301832318305969
Iteration 1009: Loss = 0.4301820695400238
Iteration 1010: Loss = 0.4301808178424835
Iteration 1011: Loss = 0.430179625749588
Iteration 1012: Loss = 0.4301784634590149
Iteration 1013: Loss = 0.430177241563797
Iteration 1014: Loss = 0.4301760792732239
Iteration 1015: Loss = 0.43017491698265076
Iteration 1016: Loss = 0.43017375469207764
Iteration 1017: Loss = 0.4301726520061493
Iteration 1018: Loss = 0.43017148971557617
Iteration 1019: Loss = 0.43017035722732544
Iteration 1020: Loss = 0.43016916513442993
Iteration 1021: Loss = 0.4301680624485016
Iteration 1022: Loss = 0.43016690015792847
Iteration 1023: Loss = 0.43016576766967773
Iteration 1024: Loss = 0.430164635181427
Iteration 1025: Loss = 0.4301634728908539
Iteration 1026: Loss = 0.43016237020492554
Iteration 1027: Loss = 0.4301612377166748
Iteration 1028: Loss = 0.43016013503074646
Iteration 1029: Loss = 0.4301590323448181
Iteration 1030: Loss = 0.43015792965888977
Iteration 1031: Loss = 0.4301569163799286
Iteration 1032: Loss = 0.430155873298645
Iteration 1033: Loss = 0.43015486001968384
Iteration 1034: Loss = 0.43015381693840027
Iteration 1035: Loss = 0.4301527738571167
Iteration 1036: Loss = 0.43015173077583313
Iteration 1037: Loss = 0.43015074729919434
Iteration 1038: Loss = 0.43014973402023315
Iteration 1039: Loss = 0.43014875054359436
Iteration 1040: Loss = 0.4301477372646332
Iteration 1041: Loss = 0.4301466941833496
Iteration 1042: Loss = 0.4301457107067108
Iteration 1043: Loss = 0.430144727230072
Iteration 1044: Loss = 0.4301437437534332
Iteration 1045: Loss = 0.43014273047447205
Iteration 1046: Loss = 0.43014171719551086
Iteration 1047: Loss = 0.43014073371887207
Iteration 1048: Loss = 0.4301397204399109
Iteration 1049: Loss = 0.4301387369632721
Iteration 1050: Loss = 0.4301377534866333
Iteration 1051: Loss = 0.4301367700099945
Iteration 1052: Loss = 0.4301358759403229
Iteration 1053: Loss = 0.4301348924636841
Iteration 1054: Loss = 0.43013396859169006
Iteration 1055: Loss = 0.43013298511505127
Iteration 1056: Loss = 0.430132120847702
Iteration 1057: Loss = 0.430131196975708
Iteration 1058: Loss = 0.4301302433013916
Iteration 1059: Loss = 0.4301293194293976
Iteration 1060: Loss = 0.43012842535972595
Iteration 1061: Loss = 0.4301275312900543
Iteration 1062: Loss = 0.4301265776157379
Iteration 1063: Loss = 0.4301256835460663
Iteration 1064: Loss = 0.4301247298717499
Iteration 1065: Loss = 0.43012386560440063
Iteration 1066: Loss = 0.43012291193008423
Iteration 1067: Loss = 0.4301220774650574
Iteration 1068: Loss = 0.43012112379074097
Iteration 1069: Loss = 0.4301202595233917
Iteration 1070: Loss = 0.4301193356513977
Iteration 1071: Loss = 0.4301184415817261
Iteration 1072: Loss = 0.43011754751205444
Iteration 1073: Loss = 0.4301166236400604
Iteration 1074: Loss = 0.4301157593727112
Iteration 1075: Loss = 0.43011489510536194
Iteration 1076: Loss = 0.43011409044265747
Iteration 1077: Loss = 0.4301132559776306
Iteration 1078: Loss = 0.43011242151260376
Iteration 1079: Loss = 0.4301116168498993
Iteration 1080: Loss = 0.4301108121871948
Iteration 1081: Loss = 0.4301099479198456
Iteration 1082: Loss = 0.4301092326641083
Iteration 1083: Loss = 0.43010836839675903
Iteration 1084: Loss = 0.43010759353637695
Iteration 1085: Loss = 0.4301067590713501
Iteration 1086: Loss = 0.4301060140132904
Iteration 1087: Loss = 0.4301052391529083
Iteration 1088: Loss = 0.43010449409484863
Iteration 1089: Loss = 0.4301036298274994
Iteration 1090: Loss = 0.4301028251647949
Iteration 1091: Loss = 0.43010202050209045
Iteration 1092: Loss = 0.43010127544403076
Iteration 1093: Loss = 0.43010053038597107
Iteration 1094: Loss = 0.4300997257232666
Iteration 1095: Loss = 0.4300989806652069
Iteration 1096: Loss = 0.43009814620018005
Iteration 1097: Loss = 0.430097371339798
Iteration 1098: Loss = 0.4300966262817383
Iteration 1099: Loss = 0.4300958812236786
Iteration 1100: Loss = 0.4300951361656189
Iteration 1101: Loss = 0.4300944209098816
Iteration 1102: Loss = 0.4300936460494995
Iteration 1103: Loss = 0.4300929605960846
Iteration 1104: Loss = 0.4300922155380249
Iteration 1105: Loss = 0.4300915002822876
Iteration 1106: Loss = 0.4300908148288727
Iteration 1107: Loss = 0.430090069770813
Iteration 1108: Loss = 0.43008938431739807
Iteration 1109: Loss = 0.43008869886398315
Iteration 1110: Loss = 0.43008798360824585
Iteration 1111: Loss = 0.43008723855018616
Iteration 1112: Loss = 0.43008655309677124
Iteration 1113: Loss = 0.43008583784103394
Iteration 1114: Loss = 0.4300851821899414
Iteration 1115: Loss = 0.4300844371318817
Iteration 1116: Loss = 0.4300837516784668
Iteration 1117: Loss = 0.4300830662250519
Iteration 1118: Loss = 0.4300823509693146
Iteration 1119: Loss = 0.43008166551589966
Iteration 1120: Loss = 0.43008092045783997
Iteration 1121: Loss = 0.43008023500442505
Iteration 1122: Loss = 0.4300795793533325
Iteration 1123: Loss = 0.4300788938999176
Iteration 1124: Loss = 0.4300781786441803
Iteration 1125: Loss = 0.43007752299308777
Iteration 1126: Loss = 0.43007683753967285
Iteration 1127: Loss = 0.4300761818885803
Iteration 1128: Loss = 0.4300754964351654
Iteration 1129: Loss = 0.43007490038871765
Iteration 1130: Loss = 0.4300742745399475
Iteration 1131: Loss = 0.430073618888855
Iteration 1132: Loss = 0.43007293343544006
Iteration 1133: Loss = 0.4300723373889923
Iteration 1134: Loss = 0.4300716519355774
Iteration 1135: Loss = 0.430071085691452
Iteration 1136: Loss = 0.4300704002380371
Iteration 1137: Loss = 0.4300696849822998
Iteration 1138: Loss = 0.43006908893585205
Iteration 1139: Loss = 0.4300684630870819
Iteration 1140: Loss = 0.43006783723831177
Iteration 1141: Loss = 0.4300672113895416
Iteration 1142: Loss = 0.4300665855407715
Iteration 1143: Loss = 0.43006592988967896
Iteration 1144: Loss = 0.4300653338432312
Iteration 1145: Loss = 0.43006467819213867
Iteration 1146: Loss = 0.43006402254104614
Iteration 1147: Loss = 0.4300634264945984
Iteration 1148: Loss = 0.43006277084350586
Iteration 1149: Loss = 0.4300621747970581
Iteration 1150: Loss = 0.4300615191459656
Iteration 1151: Loss = 0.4300609230995178
Iteration 1152: Loss = 0.4300602376461029
Iteration 1153: Loss = 0.43005967140197754
Iteration 1154: Loss = 0.4300590455532074
Iteration 1155: Loss = 0.43005847930908203
Iteration 1156: Loss = 0.4300578832626343
Iteration 1157: Loss = 0.43005722761154175
Iteration 1158: Loss = 0.43005669116973877
Iteration 1159: Loss = 0.430056095123291
Iteration 1160: Loss = 0.43005549907684326
Iteration 1161: Loss = 0.4300549030303955
Iteration 1162: Loss = 0.43005430698394775
Iteration 1163: Loss = 0.4300537705421448
Iteration 1164: Loss = 0.43005314469337463
Iteration 1165: Loss = 0.43005257844924927
Iteration 1166: Loss = 0.4300520122051239
Iteration 1167: Loss = 0.43005144596099854
Iteration 1168: Loss = 0.4300508499145508
Iteration 1169: Loss = 0.4300502836704254
Iteration 1170: Loss = 0.43004968762397766
Iteration 1171: Loss = 0.4300491213798523
Iteration 1172: Loss = 0.43004852533340454
Iteration 1173: Loss = 0.4300478994846344
Iteration 1174: Loss = 0.4300473928451538
Iteration 1175: Loss = 0.43004682660102844
Iteration 1176: Loss = 0.4300462007522583
Iteration 1177: Loss = 0.43004560470581055
Iteration 1178: Loss = 0.4300450384616852
Iteration 1179: Loss = 0.4300445020198822
Iteration 1180: Loss = 0.43004387617111206
Iteration 1181: Loss = 0.4300433397293091
Iteration 1182: Loss = 0.43004271388053894
Iteration 1183: Loss = 0.43004220724105835
Iteration 1184: Loss = 0.43004167079925537
Iteration 1185: Loss = 0.4300411343574524
Iteration 1186: Loss = 0.430040568113327
Iteration 1187: Loss = 0.43004003167152405
Iteration 1188: Loss = 0.43003955483436584
Iteration 1189: Loss = 0.4300389289855957
Iteration 1190: Loss = 0.4300383925437927
Iteration 1191: Loss = 0.43003785610198975
Iteration 1192: Loss = 0.43003731966018677
Iteration 1193: Loss = 0.4300368130207062
Iteration 1194: Loss = 0.4300362765789032
Iteration 1195: Loss = 0.4300357401371002
Iteration 1196: Loss = 0.43003520369529724
Iteration 1197: Loss = 0.4300346076488495
Iteration 1198: Loss = 0.4300341308116913
Iteration 1199: Loss = 0.4300335943698883
Iteration 1200: Loss = 0.43003302812576294
Iteration 1201: Loss = 0.43003249168395996
Iteration 1202: Loss = 0.43003198504447937
Iteration 1203: Loss = 0.430031418800354
Iteration 1204: Loss = 0.4300309121608734
Iteration 1205: Loss = 0.4300304055213928
Iteration 1206: Loss = 0.43002983927726746
Iteration 1207: Loss = 0.4300293028354645
Iteration 1208: Loss = 0.4300287961959839
Iteration 1209: Loss = 0.4300282597541809
Iteration 1210: Loss = 0.43002772331237793
Iteration 1211: Loss = 0.43002718687057495
Iteration 1212: Loss = 0.43002673983573914
Iteration 1213: Loss = 0.43002620339393616
Iteration 1214: Loss = 0.4300256669521332
Iteration 1215: Loss = 0.430025190114975
Iteration 1216: Loss = 0.4300247132778168
Iteration 1217: Loss = 0.4300242066383362
Iteration 1218: Loss = 0.430023729801178
Iteration 1219: Loss = 0.4300232231616974
Iteration 1220: Loss = 0.4300227165222168
Iteration 1221: Loss = 0.430022269487381
Iteration 1222: Loss = 0.4300217628479004
Iteration 1223: Loss = 0.4300212562084198
Iteration 1224: Loss = 0.430020809173584
Iteration 1225: Loss = 0.430020272731781
Iteration 1226: Loss = 0.4300197958946228
Iteration 1227: Loss = 0.430019348859787
Iteration 1228: Loss = 0.4300188422203064
Iteration 1229: Loss = 0.4300183355808258
Iteration 1230: Loss = 0.4300178587436676
Iteration 1231: Loss = 0.4300173819065094
Iteration 1232: Loss = 0.4300168752670288
Iteration 1233: Loss = 0.4300163686275482
Iteration 1234: Loss = 0.4300159215927124
Iteration 1235: Loss = 0.4300154447555542
Iteration 1236: Loss = 0.4300149977207184
Iteration 1237: Loss = 0.4300144910812378
Iteration 1238: Loss = 0.4300139844417572
Iteration 1239: Loss = 0.430013507604599
Iteration 1240: Loss = 0.4300130307674408
Iteration 1241: Loss = 0.4300124943256378
Iteration 1242: Loss = 0.430012047290802
Iteration 1243: Loss = 0.43001148104667664
Iteration 1244: Loss = 0.4300110638141632
Iteration 1245: Loss = 0.4300105571746826
Iteration 1246: Loss = 0.4300100803375244
Iteration 1247: Loss = 0.4300096333026886
Iteration 1248: Loss = 0.43000921607017517
Iteration 1249: Loss = 0.43000873923301697
Iteration 1250: Loss = 0.4300082325935364
Iteration 1251: Loss = 0.43000778555870056
Iteration 1252: Loss = 0.4300072491168976
Iteration 1253: Loss = 0.43000683188438416
Iteration 1254: Loss = 0.43000635504722595
Iteration 1255: Loss = 0.43000590801239014
Iteration 1256: Loss = 0.4300054609775543
Iteration 1257: Loss = 0.4300049841403961
Iteration 1258: Loss = 0.4300045073032379
Iteration 1259: Loss = 0.4300040602684021
Iteration 1260: Loss = 0.4300036132335663
Iteration 1261: Loss = 0.4300030767917633
Iteration 1262: Loss = 0.4300026595592499
Iteration 1263: Loss = 0.4300021827220917
Iteration 1264: Loss = 0.43000176548957825
Iteration 1265: Loss = 0.43000125885009766
Iteration 1266: Loss = 0.43000081181526184
Iteration 1267: Loss = 0.43000033497810364
Iteration 1268: Loss = 0.4299998879432678
Iteration 1269: Loss = 0.42999938130378723
Iteration 1270: Loss = 0.4299989640712738
Iteration 1271: Loss = 0.4299984872341156
Iteration 1272: Loss = 0.4299980401992798
Iteration 1273: Loss = 0.4299975633621216
Iteration 1274: Loss = 0.42999714612960815
Iteration 1275: Loss = 0.42999663949012756
Iteration 1276: Loss = 0.42999622225761414
Iteration 1277: Loss = 0.4299957752227783
Iteration 1278: Loss = 0.4299952983856201
Iteration 1279: Loss = 0.42999494075775146
Iteration 1280: Loss = 0.42999452352523804
Iteration 1281: Loss = 0.4299940764904022
Iteration 1282: Loss = 0.4299936294555664
Iteration 1283: Loss = 0.429993212223053
Iteration 1284: Loss = 0.42999276518821716
Iteration 1285: Loss = 0.4299923777580261
Iteration 1286: Loss = 0.4299919307231903
Iteration 1287: Loss = 0.4299915134906769
Iteration 1288: Loss = 0.42999109625816345
Iteration 1289: Loss = 0.42999064922332764
Iteration 1290: Loss = 0.4299902617931366
Iteration 1291: Loss = 0.42998984456062317
Iteration 1292: Loss = 0.42998936772346497
Iteration 1293: Loss = 0.42998895049095154
Iteration 1294: Loss = 0.4299885630607605
Iteration 1295: Loss = 0.4299881160259247
Iteration 1296: Loss = 0.42998766899108887
Iteration 1297: Loss = 0.4299872815608978
Iteration 1298: Loss = 0.4299868047237396
Iteration 1299: Loss = 0.42998644709587097
Iteration 1300: Loss = 0.42998602986335754
Iteration 1301: Loss = 0.42998555302619934
Iteration 1302: Loss = 0.4299851655960083
Iteration 1303: Loss = 0.4299847483634949
Iteration 1304: Loss = 0.42998433113098145
Iteration 1305: Loss = 0.429983913898468
Iteration 1306: Loss = 0.429983526468277
Iteration 1307: Loss = 0.4299830496311188
Iteration 1308: Loss = 0.42998263239860535
Iteration 1309: Loss = 0.4299822449684143
Iteration 1310: Loss = 0.4299818277359009
Iteration 1311: Loss = 0.42998144030570984
Iteration 1312: Loss = 0.4299810230731964
Iteration 1313: Loss = 0.42998072504997253
Iteration 1314: Loss = 0.4299802780151367
Iteration 1315: Loss = 0.42997992038726807
Iteration 1316: Loss = 0.4299795627593994
Iteration 1317: Loss = 0.4299791157245636
Iteration 1318: Loss = 0.42997878789901733
Iteration 1319: Loss = 0.4299784004688263
Iteration 1320: Loss = 0.4299781024456024
Iteration 1321: Loss = 0.4299776554107666
Iteration 1322: Loss = 0.42997729778289795
Iteration 1323: Loss = 0.4299769699573517
Iteration 1324: Loss = 0.4299764931201935
Iteration 1325: Loss = 0.4299761652946472
Iteration 1326: Loss = 0.4299757778644562
Iteration 1327: Loss = 0.4299754202365875
Iteration 1328: Loss = 0.42997506260871887
Iteration 1329: Loss = 0.4299747049808502
Iteration 1330: Loss = 0.42997434735298157
Iteration 1331: Loss = 0.42997393012046814
Iteration 1332: Loss = 0.4299735724925995
Iteration 1333: Loss = 0.42997321486473083
Iteration 1334: Loss = 0.4299728274345398
Iteration 1335: Loss = 0.42997246980667114
Iteration 1336: Loss = 0.4299721121788025
Iteration 1337: Loss = 0.42997175455093384
Iteration 1338: Loss = 0.4299713969230652
Iteration 1339: Loss = 0.42997100949287415
Iteration 1340: Loss = 0.4299706518650055
Iteration 1341: Loss = 0.42997029423713684
Iteration 1342: Loss = 0.4299699068069458
Iteration 1343: Loss = 0.42996954917907715
Iteration 1344: Loss = 0.4299691319465637
Iteration 1345: Loss = 0.42996877431869507
Iteration 1346: Loss = 0.4299684464931488
Iteration 1347: Loss = 0.42996811866760254
Iteration 1348: Loss = 0.4299677312374115
Iteration 1349: Loss = 0.42996737360954285
Iteration 1350: Loss = 0.4299670457839966
Iteration 1351: Loss = 0.4299667179584503
Iteration 1352: Loss = 0.42996639013290405
Iteration 1353: Loss = 0.4299660325050354
Iteration 1354: Loss = 0.42996570467948914
Iteration 1355: Loss = 0.42996540665626526
Iteration 1356: Loss = 0.4299650192260742
Iteration 1357: Loss = 0.42996475100517273
Iteration 1358: Loss = 0.4299643635749817
Iteration 1359: Loss = 0.4299640357494354
Iteration 1360: Loss = 0.42996373772621155
Iteration 1361: Loss = 0.4299633800983429
Iteration 1362: Loss = 0.429963082075119
Iteration 1363: Loss = 0.42996275424957275
Iteration 1364: Loss = 0.4299623668193817
Iteration 1365: Loss = 0.42996206879615784
Iteration 1366: Loss = 0.42996183037757874
Iteration 1367: Loss = 0.4299614727497101
Iteration 1368: Loss = 0.42996111512184143
Iteration 1369: Loss = 0.42996081709861755
Iteration 1370: Loss = 0.4299604892730713
Iteration 1371: Loss = 0.429960161447525
Iteration 1372: Loss = 0.42995983362197876
Iteration 1373: Loss = 0.4299595057964325
Iteration 1374: Loss = 0.4299592077732086
Iteration 1375: Loss = 0.42995887994766235
Iteration 1376: Loss = 0.4299585521221161
Iteration 1377: Loss = 0.4299582242965698
Iteration 1378: Loss = 0.42995789647102356
Iteration 1379: Loss = 0.4299575686454773
Iteration 1380: Loss = 0.42995724081993103
Iteration 1381: Loss = 0.42995691299438477
Iteration 1382: Loss = 0.4299565851688385
Iteration 1383: Loss = 0.4299562871456146
Iteration 1384: Loss = 0.4299558997154236
Iteration 1385: Loss = 0.4299556016921997
Iteration 1386: Loss = 0.4299553334712982
Iteration 1387: Loss = 0.4299549460411072
Iteration 1388: Loss = 0.4299546182155609
Iteration 1389: Loss = 0.42995432019233704
Iteration 1390: Loss = 0.42995399236679077
Iteration 1391: Loss = 0.4299536943435669
Iteration 1392: Loss = 0.429953396320343
Iteration 1393: Loss = 0.42995303869247437
Iteration 1394: Loss = 0.42995280027389526
Iteration 1395: Loss = 0.429952472448349
Iteration 1396: Loss = 0.42995208501815796
Iteration 1397: Loss = 0.4299517869949341
Iteration 1398: Loss = 0.4299514591693878
Iteration 1399: Loss = 0.42995119094848633
Iteration 1400: Loss = 0.42995086312294006
Iteration 1401: Loss = 0.4299505949020386
Iteration 1402: Loss = 0.4299502670764923
Iteration 1403: Loss = 0.42994993925094604
Iteration 1404: Loss = 0.42994964122772217
Iteration 1405: Loss = 0.4299493730068207
Iteration 1406: Loss = 0.4299490451812744
Iteration 1407: Loss = 0.42994871735572815
Iteration 1408: Loss = 0.4299483895301819
Iteration 1409: Loss = 0.429948091506958
Iteration 1410: Loss = 0.42994779348373413
Iteration 1411: Loss = 0.42994746565818787
Iteration 1412: Loss = 0.429947167634964
Iteration 1413: Loss = 0.4299468398094177
Iteration 1414: Loss = 0.42994657158851624
Iteration 1415: Loss = 0.42994624376296997
Iteration 1416: Loss = 0.4299459159374237
Iteration 1417: Loss = 0.4299456477165222
Iteration 1418: Loss = 0.42994534969329834
Iteration 1419: Loss = 0.42994505167007446
Iteration 1420: Loss = 0.4299447238445282
Iteration 1421: Loss = 0.42994439601898193
Iteration 1422: Loss = 0.42994412779808044
Iteration 1423: Loss = 0.42994382977485657
Iteration 1424: Loss = 0.4299435019493103
Iteration 1425: Loss = 0.42994314432144165
Iteration 1426: Loss = 0.42994287610054016
Iteration 1427: Loss = 0.4299425780773163
Iteration 1428: Loss = 0.42994225025177
Iteration 1429: Loss = 0.42994192242622375
Iteration 1430: Loss = 0.4299415946006775
Iteration 1431: Loss = 0.4299412667751312
Iteration 1432: Loss = 0.42994093894958496
Iteration 1433: Loss = 0.4299406409263611
Iteration 1434: Loss = 0.42994028329849243
Iteration 1435: Loss = 0.42994001507759094
Iteration 1436: Loss = 0.4299396872520447
Iteration 1437: Loss = 0.4299393892288208
Iteration 1438: Loss = 0.4299390912055969
Iteration 1439: Loss = 0.42993876338005066
Iteration 1440: Loss = 0.429938405752182
Iteration 1441: Loss = 0.42993810772895813
Iteration 1442: Loss = 0.42993786931037903
Iteration 1443: Loss = 0.42993757128715515
Iteration 1444: Loss = 0.4299372434616089
Iteration 1445: Loss = 0.429936945438385
Iteration 1446: Loss = 0.42993664741516113
Iteration 1447: Loss = 0.42993637919425964
Iteration 1448: Loss = 0.429936021566391
Iteration 1449: Loss = 0.4299357235431671
Iteration 1450: Loss = 0.42993542551994324
Iteration 1451: Loss = 0.42993515729904175
Iteration 1452: Loss = 0.4299347996711731
Iteration 1453: Loss = 0.4299345016479492
Iteration 1454: Loss = 0.42993420362472534
Iteration 1455: Loss = 0.42993390560150146
Iteration 1456: Loss = 0.4299336075782776
Iteration 1457: Loss = 0.4299333393573761
Iteration 1458: Loss = 0.42993301153182983
Iteration 1459: Loss = 0.42993271350860596
Iteration 1460: Loss = 0.42993244528770447
Iteration 1461: Loss = 0.4299321472644806
Iteration 1462: Loss = 0.4299318492412567
Iteration 1463: Loss = 0.42993152141571045
Iteration 1464: Loss = 0.42993125319480896
Iteration 1465: Loss = 0.4299308955669403
Iteration 1466: Loss = 0.42993059754371643
Iteration 1467: Loss = 0.42993029952049255
Iteration 1468: Loss = 0.4299300014972687
Iteration 1469: Loss = 0.4299296736717224
Iteration 1470: Loss = 0.4299294054508209
Iteration 1471: Loss = 0.42992910742759705
Iteration 1472: Loss = 0.4299287497997284
Iteration 1473: Loss = 0.4299284815788269
Iteration 1474: Loss = 0.42992812395095825
Iteration 1475: Loss = 0.42992785573005676
Iteration 1476: Loss = 0.4299274981021881
Iteration 1477: Loss = 0.4299272298812866
Iteration 1478: Loss = 0.42992690205574036
Iteration 1479: Loss = 0.4299266040325165
Iteration 1480: Loss = 0.4299262762069702
Iteration 1481: Loss = 0.42992597818374634
Iteration 1482: Loss = 0.4299256205558777
Iteration 1483: Loss = 0.4299253523349762
Iteration 1484: Loss = 0.4299250841140747
Iteration 1485: Loss = 0.42992475628852844
Iteration 1486: Loss = 0.42992445826530457
Iteration 1487: Loss = 0.4299241602420807
Iteration 1488: Loss = 0.4299238920211792
Iteration 1489: Loss = 0.4299235939979553
Iteration 1490: Loss = 0.42992329597473145
Iteration 1491: Loss = 0.4299229681491852
Iteration 1492: Loss = 0.4299226701259613
Iteration 1493: Loss = 0.4299224317073822
Iteration 1494: Loss = 0.42992207407951355
Iteration 1495: Loss = 0.42992183566093445
Iteration 1496: Loss = 0.4299215078353882
Iteration 1497: Loss = 0.4299212098121643
Iteration 1498: Loss = 0.4299209415912628
Iteration 1499: Loss = 0.42992061376571655
Iteration 1500: Loss = 0.4299203157424927
Iteration 1501: Loss = 0.4299200475215912
Iteration 1502: Loss = 0.4299197494983673
Iteration 1503: Loss = 0.42991945147514343
Iteration 1504: Loss = 0.42991918325424194
Iteration 1505: Loss = 0.42991888523101807
Iteration 1506: Loss = 0.4299185872077942
Iteration 1507: Loss = 0.4299183189868927
Iteration 1508: Loss = 0.42991796135902405
Iteration 1509: Loss = 0.42991769313812256
Iteration 1510: Loss = 0.42991742491722107
Iteration 1511: Loss = 0.4299171566963196
Iteration 1512: Loss = 0.4299167990684509
Iteration 1513: Loss = 0.42991653084754944
Iteration 1514: Loss = 0.42991626262664795
Iteration 1515: Loss = 0.4299159646034241
Iteration 1516: Loss = 0.4299156069755554
Iteration 1517: Loss = 0.42991533875465393
Iteration 1518: Loss = 0.42991501092910767
Iteration 1519: Loss = 0.42991477251052856
Iteration 1520: Loss = 0.4299145042896271
Iteration 1521: Loss = 0.4299141764640808
Iteration 1522: Loss = 0.4299139082431793
Iteration 1523: Loss = 0.42991358041763306
Iteration 1524: Loss = 0.42991331219673157
Iteration 1525: Loss = 0.4299129545688629
Iteration 1526: Loss = 0.4299127161502838
Iteration 1527: Loss = 0.42991238832473755
Iteration 1528: Loss = 0.42991212010383606
Iteration 1529: Loss = 0.4299117922782898
Iteration 1530: Loss = 0.4299114942550659
Iteration 1531: Loss = 0.4299112558364868
Iteration 1532: Loss = 0.4299109876155853
Iteration 1533: Loss = 0.42991068959236145
Iteration 1534: Loss = 0.4299103617668152
Iteration 1535: Loss = 0.4299101233482361
Iteration 1536: Loss = 0.4299098253250122
Iteration 1537: Loss = 0.4299095869064331
Iteration 1538: Loss = 0.42990925908088684
Iteration 1539: Loss = 0.42990899085998535
Iteration 1540: Loss = 0.42990872263908386
Iteration 1541: Loss = 0.42990842461586
Iteration 1542: Loss = 0.42990821599960327
Iteration 1543: Loss = 0.4299079179763794
Iteration 1544: Loss = 0.4299076497554779
Iteration 1545: Loss = 0.42990735173225403
Iteration 1546: Loss = 0.4299071133136749
Iteration 1547: Loss = 0.42990678548812866
Iteration 1548: Loss = 0.42990657687187195
Iteration 1549: Loss = 0.4299062490463257
Iteration 1550: Loss = 0.4299059808254242
Iteration 1551: Loss = 0.4299057424068451
Iteration 1552: Loss = 0.4299054443836212
Iteration 1553: Loss = 0.4299052059650421
Iteration 1554: Loss = 0.429904967546463
Iteration 1555: Loss = 0.4299047291278839
Iteration 1556: Loss = 0.42990440130233765
Iteration 1557: Loss = 0.42990410327911377
Iteration 1558: Loss = 0.42990386486053467
Iteration 1559: Loss = 0.4299035370349884
Iteration 1560: Loss = 0.4299033284187317
Iteration 1561: Loss = 0.4299030601978302
Iteration 1562: Loss = 0.4299027919769287
Iteration 1563: Loss = 0.42990249395370483
Iteration 1564: Loss = 0.42990222573280334
Iteration 1565: Loss = 0.42990195751190186
Iteration 1566: Loss = 0.429901659488678
Iteration 1567: Loss = 0.4299014210700989
Iteration 1568: Loss = 0.4299011826515198
Iteration 1569: Loss = 0.4299008548259735
Iteration 1570: Loss = 0.4299006164073944
Iteration 1571: Loss = 0.42990031838417053
Iteration 1572: Loss = 0.42990002036094666
Iteration 1573: Loss = 0.42989981174468994
Iteration 1574: Loss = 0.42989951372146606
Iteration 1575: Loss = 0.42989927530288696
Iteration 1576: Loss = 0.4298989772796631
Iteration 1577: Loss = 0.429898738861084
Iteration 1578: Loss = 0.4298984408378601
Iteration 1579: Loss = 0.42989814281463623
Iteration 1580: Loss = 0.42989787459373474
Iteration 1581: Loss = 0.42989763617515564
Iteration 1582: Loss = 0.42989733815193176
Iteration 1583: Loss = 0.42989709973335266
Iteration 1584: Loss = 0.42989683151245117
Iteration 1585: Loss = 0.4298965334892273
Iteration 1586: Loss = 0.4298962354660034
Iteration 1587: Loss = 0.4298959970474243
Iteration 1588: Loss = 0.4298957288265228
Iteration 1589: Loss = 0.4298955202102661
Iteration 1590: Loss = 0.42989522218704224
Iteration 1591: Loss = 0.42989498376846313
Iteration 1592: Loss = 0.42989474534988403
Iteration 1593: Loss = 0.42989447712898254
Iteration 1594: Loss = 0.42989423871040344
Iteration 1595: Loss = 0.42989400029182434
Iteration 1596: Loss = 0.42989376187324524
Iteration 1597: Loss = 0.42989352345466614
Iteration 1598: Loss = 0.42989328503608704
Iteration 1599: Loss = 0.42989298701286316
Iteration 1600: Loss = 0.42989274859428406
Iteration 1601: Loss = 0.42989251017570496
Iteration 1602: Loss = 0.42989227175712585
Iteration 1603: Loss = 0.42989206314086914
Iteration 1604: Loss = 0.42989179491996765
Iteration 1605: Loss = 0.42989155650138855
Iteration 1606: Loss = 0.42989128828048706
Iteration 1607: Loss = 0.42989104986190796
Iteration 1608: Loss = 0.42989081144332886
Iteration 1609: Loss = 0.42989057302474976
Iteration 1610: Loss = 0.42989033460617065
Iteration 1611: Loss = 0.42989012598991394
Iteration 1612: Loss = 0.42988985776901245
Iteration 1613: Loss = 0.42988961935043335
Iteration 1614: Loss = 0.42988938093185425
Iteration 1615: Loss = 0.42988911271095276
Iteration 1616: Loss = 0.42988884449005127
Iteration 1617: Loss = 0.42988866567611694
Iteration 1618: Loss = 0.42988839745521545
Iteration 1619: Loss = 0.42988812923431396
Iteration 1620: Loss = 0.42988792061805725
Iteration 1621: Loss = 0.42988768219947815
Iteration 1622: Loss = 0.4298873841762543
Iteration 1623: Loss = 0.42988717555999756
Iteration 1624: Loss = 0.42988690733909607
Iteration 1625: Loss = 0.42988669872283936
Iteration 1626: Loss = 0.4298864006996155
Iteration 1627: Loss = 0.4298861622810364
Iteration 1628: Loss = 0.4298858940601349
Iteration 1629: Loss = 0.42988574504852295
Iteration 1630: Loss = 0.42988547682762146
Iteration 1631: Loss = 0.42988520860671997
Iteration 1632: Loss = 0.42988497018814087
Iteration 1633: Loss = 0.42988476157188416
Iteration 1634: Loss = 0.42988449335098267
Iteration 1635: Loss = 0.4298843443393707
Iteration 1636: Loss = 0.429884135723114
Iteration 1637: Loss = 0.4298838675022125
Iteration 1638: Loss = 0.4298836290836334
Iteration 1639: Loss = 0.4298834502696991
Iteration 1640: Loss = 0.4298831820487976
Iteration 1641: Loss = 0.4298830032348633
Iteration 1642: Loss = 0.4298827648162842
Iteration 1643: Loss = 0.4298825263977051
Iteration 1644: Loss = 0.42988231778144836
Iteration 1645: Loss = 0.42988210916519165
Iteration 1646: Loss = 0.42988187074661255
Iteration 1647: Loss = 0.42988166213035583
Iteration 1648: Loss = 0.42988139390945435
Iteration 1649: Loss = 0.42988118529319763
Iteration 1650: Loss = 0.4298809766769409
Iteration 1651: Loss = 0.42988070845603943
Iteration 1652: Loss = 0.4298805594444275
Iteration 1653: Loss = 0.4298803210258484
Iteration 1654: Loss = 0.4298800826072693
Iteration 1655: Loss = 0.4298798739910126
Iteration 1656: Loss = 0.42987969517707825
Iteration 1657: Loss = 0.4298795163631439
Iteration 1658: Loss = 0.4298792779445648
Iteration 1659: Loss = 0.4298790991306305
Iteration 1660: Loss = 0.429878830909729
Iteration 1661: Loss = 0.4298786520957947
Iteration 1662: Loss = 0.42987844347953796
Iteration 1663: Loss = 0.42987823486328125
Iteration 1664: Loss = 0.42987802624702454
Iteration 1665: Loss = 0.4298778772354126
Iteration 1666: Loss = 0.4298775792121887
Iteration 1667: Loss = 0.4298774003982544
Iteration 1668: Loss = 0.42987722158432007
Iteration 1669: Loss = 0.42987701296806335
Iteration 1670: Loss = 0.42987683415412903
Iteration 1671: Loss = 0.4298765957355499
Iteration 1672: Loss = 0.4298763871192932
Iteration 1673: Loss = 0.4298761785030365
Iteration 1674: Loss = 0.4298759698867798
Iteration 1675: Loss = 0.42987579107284546
Iteration 1676: Loss = 0.42987558245658875
Iteration 1677: Loss = 0.42987534403800964
Iteration 1678: Loss = 0.4298751950263977
Iteration 1679: Loss = 0.429874986410141
Iteration 1680: Loss = 0.4298747777938843
Iteration 1681: Loss = 0.42987459897994995
Iteration 1682: Loss = 0.42987439036369324
Iteration 1683: Loss = 0.42987415194511414
Iteration 1684: Loss = 0.4298739731311798
Iteration 1685: Loss = 0.42987382411956787
Iteration 1686: Loss = 0.42987358570098877
Iteration 1687: Loss = 0.42987334728240967
Iteration 1688: Loss = 0.42987319827079773
Iteration 1689: Loss = 0.42987293004989624
Iteration 1690: Loss = 0.4298727512359619
Iteration 1691: Loss = 0.4298725426197052
Iteration 1692: Loss = 0.4298723340034485
Iteration 1693: Loss = 0.42987218499183655
Iteration 1694: Loss = 0.42987197637557983
Iteration 1695: Loss = 0.42987170815467834
Iteration 1696: Loss = 0.4298715889453888
Iteration 1697: Loss = 0.4298713803291321
Iteration 1698: Loss = 0.429871141910553
Iteration 1699: Loss = 0.42987093329429626
Iteration 1700: Loss = 0.42987072467803955
Iteration 1701: Loss = 0.4298705458641052
Iteration 1702: Loss = 0.4298703670501709
Iteration 1703: Loss = 0.4298701286315918
Iteration 1704: Loss = 0.4298698902130127
Iteration 1705: Loss = 0.42986974120140076
Iteration 1706: Loss = 0.42986950278282166
Iteration 1707: Loss = 0.42986932396888733
Iteration 1708: Loss = 0.4298691749572754
Iteration 1709: Loss = 0.4298689067363739
Iteration 1710: Loss = 0.4298687279224396
Iteration 1711: Loss = 0.4298684895038605
Iteration 1712: Loss = 0.42986828088760376
Iteration 1713: Loss = 0.42986807227134705
Iteration 1714: Loss = 0.4298678934574127
Iteration 1715: Loss = 0.4298677146434784
Iteration 1716: Loss = 0.4298675060272217
Iteration 1717: Loss = 0.42986729741096497
Iteration 1718: Loss = 0.42986711859703064
Iteration 1719: Loss = 0.42986688017845154
Iteration 1720: Loss = 0.4298667311668396
Iteration 1721: Loss = 0.4298664927482605
Iteration 1722: Loss = 0.4298662841320038
Iteration 1723: Loss = 0.4298660457134247
Iteration 1724: Loss = 0.42986586689949036
Iteration 1725: Loss = 0.4298657178878784
Iteration 1726: Loss = 0.4298654794692993
Iteration 1727: Loss = 0.429865300655365
Iteration 1728: Loss = 0.42986512184143066
Iteration 1729: Loss = 0.42986494302749634
Iteration 1730: Loss = 0.42986467480659485
Iteration 1731: Loss = 0.4298644959926605
Iteration 1732: Loss = 0.4298643171787262
Iteration 1733: Loss = 0.42986413836479187
Iteration 1734: Loss = 0.42986398935317993
Iteration 1735: Loss = 0.4298637807369232
Iteration 1736: Loss = 0.4298635721206665
Iteration 1737: Loss = 0.42986342310905457
Iteration 1738: Loss = 0.42986318469047546
Iteration 1739: Loss = 0.4298630356788635
Iteration 1740: Loss = 0.4298628568649292
Iteration 1741: Loss = 0.4298626780509949
Iteration 1742: Loss = 0.4298625588417053
Iteration 1743: Loss = 0.4298623204231262
Iteration 1744: Loss = 0.4298621416091919
Iteration 1745: Loss = 0.42986196279525757
Iteration 1746: Loss = 0.42986175417900085
Iteration 1747: Loss = 0.4298616349697113
Iteration 1748: Loss = 0.42986148595809937
Iteration 1749: Loss = 0.42986130714416504
Iteration 1750: Loss = 0.42986103892326355
Iteration 1751: Loss = 0.4298608899116516
Iteration 1752: Loss = 0.4298607409000397
Iteration 1753: Loss = 0.42986056208610535
Iteration 1754: Loss = 0.429860383272171
Iteration 1755: Loss = 0.4298601746559143
Iteration 1756: Loss = 0.42985999584198
Iteration 1757: Loss = 0.42985984683036804
Iteration 1758: Loss = 0.4298596680164337
Iteration 1759: Loss = 0.4298594892024994
Iteration 1760: Loss = 0.4298592805862427
Iteration 1761: Loss = 0.42985910177230835
Iteration 1762: Loss = 0.4298589527606964
Iteration 1763: Loss = 0.4298588037490845
Iteration 1764: Loss = 0.42985859513282776
Iteration 1765: Loss = 0.42985838651657104
Iteration 1766: Loss = 0.4298582375049591
Iteration 1767: Loss = 0.4298580288887024
Iteration 1768: Loss = 0.42985787987709045
Iteration 1769: Loss = 0.42985767126083374
Iteration 1770: Loss = 0.4298575222492218
Iteration 1771: Loss = 0.4298573136329651
Iteration 1772: Loss = 0.42985713481903076
Iteration 1773: Loss = 0.4298569858074188
Iteration 1774: Loss = 0.4298568069934845
Iteration 1775: Loss = 0.42985665798187256
Iteration 1776: Loss = 0.42985647916793823
Iteration 1777: Loss = 0.4298563301563263
Iteration 1778: Loss = 0.42985615134239197
Iteration 1779: Loss = 0.42985594272613525
Iteration 1780: Loss = 0.4298557937145233
Iteration 1781: Loss = 0.4298556447029114
Iteration 1782: Loss = 0.4298554062843323
Iteration 1783: Loss = 0.4298553168773651
Iteration 1784: Loss = 0.4298551082611084
Iteration 1785: Loss = 0.42985498905181885
Iteration 1786: Loss = 0.4298548102378845
Iteration 1787: Loss = 0.4298545718193054
Iteration 1788: Loss = 0.42985445261001587
Iteration 1789: Loss = 0.42985427379608154
Iteration 1790: Loss = 0.4298540949821472
Iteration 1791: Loss = 0.42985400557518005
Iteration 1792: Loss = 0.4298538565635681
Iteration 1793: Loss = 0.4298536479473114
Iteration 1794: Loss = 0.4298534691333771
Iteration 1795: Loss = 0.42985326051712036
Iteration 1796: Loss = 0.4298531115055084
Iteration 1797: Loss = 0.4298529326915741
Iteration 1798: Loss = 0.42985278367996216
Iteration 1799: Loss = 0.4298526644706726
Iteration 1800: Loss = 0.4298523962497711
Iteration 1801: Loss = 0.4298522472381592
Iteration 1802: Loss = 0.42985206842422485
Iteration 1803: Loss = 0.4298518896102905
Iteration 1804: Loss = 0.42985180020332336
Iteration 1805: Loss = 0.42985162138938904
Iteration 1806: Loss = 0.4298514425754547
Iteration 1807: Loss = 0.4298512637615204
Iteration 1808: Loss = 0.42985111474990845
Iteration 1809: Loss = 0.4298509657382965
Iteration 1810: Loss = 0.4298507571220398
Iteration 1811: Loss = 0.42985060811042786
Iteration 1812: Loss = 0.42985039949417114
Iteration 1813: Loss = 0.4298502504825592
Iteration 1814: Loss = 0.42985010147094727
Iteration 1815: Loss = 0.42984986305236816
Iteration 1816: Loss = 0.4298498034477234
Iteration 1817: Loss = 0.4298495352268219
Iteration 1818: Loss = 0.42984938621520996
Iteration 1819: Loss = 0.429849237203598
Iteration 1820: Loss = 0.4298490583896637
Iteration 1821: Loss = 0.42984890937805176
Iteration 1822: Loss = 0.42984873056411743
Iteration 1823: Loss = 0.4298485517501831
Iteration 1824: Loss = 0.42984846234321594
Iteration 1825: Loss = 0.42984822392463684
Iteration 1826: Loss = 0.4298480451107025
Iteration 1827: Loss = 0.42984792590141296
Iteration 1828: Loss = 0.42984768748283386
Iteration 1829: Loss = 0.4298475384712219
Iteration 1830: Loss = 0.42984738945961
Iteration 1831: Loss = 0.42984724044799805
Iteration 1832: Loss = 0.42984703183174133
Iteration 1833: Loss = 0.4298468828201294
Iteration 1834: Loss = 0.42984673380851746
Iteration 1835: Loss = 0.42984655499458313
Iteration 1836: Loss = 0.4298464059829712
Iteration 1837: Loss = 0.42984622716903687
Iteration 1838: Loss = 0.4298460781574249
Iteration 1839: Loss = 0.429845929145813
Iteration 1840: Loss = 0.42984575033187866
Iteration 1841: Loss = 0.4298456013202667
Iteration 1842: Loss = 0.4298454225063324
Iteration 1843: Loss = 0.4298452138900757
Iteration 1844: Loss = 0.42984509468078613
Iteration 1845: Loss = 0.4298449456691742
Iteration 1846: Loss = 0.42984476685523987
Iteration 1847: Loss = 0.42984458804130554
Iteration 1848: Loss = 0.4298444390296936
Iteration 1849: Loss = 0.4298442602157593
Iteration 1850: Loss = 0.42984411120414734
Iteration 1851: Loss = 0.4298439621925354
Iteration 1852: Loss = 0.4298437535762787
Iteration 1853: Loss = 0.42984360456466675
Iteration 1854: Loss = 0.4298434555530548
Iteration 1855: Loss = 0.42984333634376526
Iteration 1856: Loss = 0.4298431873321533
Iteration 1857: Loss = 0.4298429489135742
Iteration 1858: Loss = 0.4298427999019623
Iteration 1859: Loss = 0.42984265089035034
Iteration 1860: Loss = 0.4298425018787384
Iteration 1861: Loss = 0.4298423230648041
Iteration 1862: Loss = 0.4298422038555145
Iteration 1863: Loss = 0.4298420548439026
Iteration 1864: Loss = 0.4298418462276459
Iteration 1865: Loss = 0.4298417270183563
Iteration 1866: Loss = 0.429841548204422
Iteration 1867: Loss = 0.42984136939048767
Iteration 1868: Loss = 0.4298412501811981
Iteration 1869: Loss = 0.4298410713672638
Iteration 1870: Loss = 0.42984092235565186
Iteration 1871: Loss = 0.4298408329486847
Iteration 1872: Loss = 0.4298405945301056
Iteration 1873: Loss = 0.42984044551849365
Iteration 1874: Loss = 0.4298402965068817
Iteration 1875: Loss = 0.4298401176929474
Iteration 1876: Loss = 0.42983996868133545
Iteration 1877: Loss = 0.4298398494720459
Iteration 1878: Loss = 0.4298396706581116
Iteration 1879: Loss = 0.42983952164649963
Iteration 1880: Loss = 0.4298393428325653
Iteration 1881: Loss = 0.42983919382095337
Iteration 1882: Loss = 0.42983901500701904
Iteration 1883: Loss = 0.4298388659954071
Iteration 1884: Loss = 0.42983874678611755
Iteration 1885: Loss = 0.4298385977745056
Iteration 1886: Loss = 0.4298384487628937
Iteration 1887: Loss = 0.42983824014663696
Iteration 1888: Loss = 0.4298381209373474
Iteration 1889: Loss = 0.4298379421234131
Iteration 1890: Loss = 0.42983782291412354
Iteration 1891: Loss = 0.4298376739025116
Iteration 1892: Loss = 0.42983749508857727
Iteration 1893: Loss = 0.4298373758792877
Iteration 1894: Loss = 0.4298372268676758
Iteration 1895: Loss = 0.42983704805374146
Iteration 1896: Loss = 0.4298369288444519
Iteration 1897: Loss = 0.4298367500305176
Iteration 1898: Loss = 0.42983657121658325
Iteration 1899: Loss = 0.4298364520072937
Iteration 1900: Loss = 0.4298362731933594
Iteration 1901: Loss = 0.42983612418174744
Iteration 1902: Loss = 0.4298360049724579
Iteration 1903: Loss = 0.42983588576316833
Iteration 1904: Loss = 0.429835706949234
Iteration 1905: Loss = 0.42983555793762207
Iteration 1906: Loss = 0.42983540892601013
Iteration 1907: Loss = 0.4298352301120758
Iteration 1908: Loss = 0.42983511090278625
Iteration 1909: Loss = 0.42983490228652954
Iteration 1910: Loss = 0.42983478307724
Iteration 1911: Loss = 0.42983466386795044
Iteration 1912: Loss = 0.4298344850540161
Iteration 1913: Loss = 0.4298343360424042
Iteration 1914: Loss = 0.42983415722846985
Iteration 1915: Loss = 0.4298340082168579
Iteration 1916: Loss = 0.42983385920524597
Iteration 1917: Loss = 0.4298337399959564
Iteration 1918: Loss = 0.4298335611820221
Iteration 1919: Loss = 0.42983338236808777
Iteration 1920: Loss = 0.429833322763443
Iteration 1921: Loss = 0.42983314394950867
Iteration 1922: Loss = 0.42983293533325195
Iteration 1923: Loss = 0.4298327565193176
Iteration 1924: Loss = 0.4298326373100281
Iteration 1925: Loss = 0.4298325181007385
Iteration 1926: Loss = 0.4298323392868042
Iteration 1927: Loss = 0.4298321604728699
Iteration 1928: Loss = 0.42983201146125793
Iteration 1929: Loss = 0.4298318922519684
Iteration 1930: Loss = 0.42983168363571167
Iteration 1931: Loss = 0.4298315644264221
Iteration 1932: Loss = 0.4298313856124878
Iteration 1933: Loss = 0.42983129620552063
Iteration 1934: Loss = 0.4298311471939087
Iteration 1935: Loss = 0.42983096837997437
Iteration 1936: Loss = 0.42983078956604004
Iteration 1937: Loss = 0.4298306703567505
Iteration 1938: Loss = 0.42983049154281616
Iteration 1939: Loss = 0.4298303425312042
Iteration 1940: Loss = 0.4298301935195923
Iteration 1941: Loss = 0.42983004450798035
Iteration 1942: Loss = 0.4298298954963684
Iteration 1943: Loss = 0.4298297166824341
Iteration 1944: Loss = 0.42982959747314453
Iteration 1945: Loss = 0.4298294186592102
Iteration 1946: Loss = 0.42982932925224304
Iteration 1947: Loss = 0.4298291504383087
Iteration 1948: Loss = 0.42982903122901917
Iteration 1949: Loss = 0.4298289120197296
Iteration 1950: Loss = 0.4298287034034729
Iteration 1951: Loss = 0.42982861399650574
Iteration 1952: Loss = 0.4298284351825714
Iteration 1953: Loss = 0.4298282563686371
Iteration 1954: Loss = 0.4298281967639923
Iteration 1955: Loss = 0.4298279881477356
Iteration 1956: Loss = 0.42982783913612366
Iteration 1957: Loss = 0.4298276901245117
Iteration 1958: Loss = 0.42982757091522217
Iteration 1959: Loss = 0.4298274517059326
Iteration 1960: Loss = 0.4298272728919983
Iteration 1961: Loss = 0.42982718348503113
Iteration 1962: Loss = 0.4298270046710968
Iteration 1963: Loss = 0.42982688546180725
Iteration 1964: Loss = 0.4298267066478729
Iteration 1965: Loss = 0.4298265874385834
Iteration 1966: Loss = 0.42982643842697144
Iteration 1967: Loss = 0.4298262596130371
Iteration 1968: Loss = 0.42982614040374756
Iteration 1969: Loss = 0.429826021194458
Iteration 1970: Loss = 0.42982587218284607
Iteration 1971: Loss = 0.42982569336891174
Iteration 1972: Loss = 0.4298255741596222
Iteration 1973: Loss = 0.42982539534568787
Iteration 1974: Loss = 0.4298252761363983
Iteration 1975: Loss = 0.4298251271247864
Iteration 1976: Loss = 0.4298250079154968
Iteration 1977: Loss = 0.4298248589038849
Iteration 1978: Loss = 0.42982470989227295
Iteration 1979: Loss = 0.429824560880661
Iteration 1980: Loss = 0.4298244118690491
Iteration 1981: Loss = 0.4298242926597595
Iteration 1982: Loss = 0.4298240840435028
Iteration 1983: Loss = 0.42982396483421326
Iteration 1984: Loss = 0.4298238456249237
Iteration 1985: Loss = 0.42982369661331177
Iteration 1986: Loss = 0.4298235774040222
Iteration 1987: Loss = 0.4298233985900879
Iteration 1988: Loss = 0.4298233091831207
Iteration 1989: Loss = 0.429823100566864
Iteration 1990: Loss = 0.42982298135757446
Iteration 1991: Loss = 0.42982280254364014
Iteration 1992: Loss = 0.4298226833343506
Iteration 1993: Loss = 0.42982250452041626
Iteration 1994: Loss = 0.4298224151134491
Iteration 1995: Loss = 0.42982223629951477
Iteration 1996: Loss = 0.4298221170902252
Iteration 1997: Loss = 0.4298219382762909
Iteration 1998: Loss = 0.42982181906700134
Iteration 1999: Loss = 0.42982161045074463
Iteration 2000: Loss = 0.42982152104377747
Iteration 2001: Loss = 0.42982134222984314
Iteration 2002: Loss = 0.4298211932182312
Iteration 2003: Loss = 0.42982110381126404
Iteration 2004: Loss = 0.4298209846019745
Iteration 2005: Loss = 0.42982086539268494
Iteration 2006: Loss = 0.4298206567764282
Iteration 2007: Loss = 0.42982056736946106
Iteration 2008: Loss = 0.4298204481601715
Iteration 2009: Loss = 0.42982029914855957
Iteration 2010: Loss = 0.42982015013694763
Iteration 2011: Loss = 0.4298200309276581
Iteration 2012: Loss = 0.42981985211372375
Iteration 2013: Loss = 0.4298197627067566
Iteration 2014: Loss = 0.42981961369514465
Iteration 2015: Loss = 0.4298195540904999
Iteration 2016: Loss = 0.42981940507888794
Iteration 2017: Loss = 0.429819256067276
Iteration 2018: Loss = 0.4298190772533417
Iteration 2019: Loss = 0.4298189580440521
Iteration 2020: Loss = 0.4298188090324402
Iteration 2021: Loss = 0.429818719625473
Iteration 2022: Loss = 0.4298185706138611
Iteration 2023: Loss = 0.42981845140457153
Iteration 2024: Loss = 0.42981836199760437
Iteration 2025: Loss = 0.4298182427883148
Iteration 2026: Loss = 0.42981818318367004
Iteration 2027: Loss = 0.4298180043697357
Iteration 2028: Loss = 0.42981788516044617
Iteration 2029: Loss = 0.42981770634651184
Iteration 2030: Loss = 0.4298176169395447
Iteration 2031: Loss = 0.42981743812561035
Iteration 2032: Loss = 0.4298173189163208
Iteration 2033: Loss = 0.42981722950935364
Iteration 2034: Loss = 0.4298170804977417
Iteration 2035: Loss = 0.42981696128845215
Iteration 2036: Loss = 0.4298168420791626
Iteration 2037: Loss = 0.42981669306755066
Iteration 2038: Loss = 0.42981651425361633
Iteration 2039: Loss = 0.4298163950443268
Iteration 2040: Loss = 0.429816335439682
Iteration 2041: Loss = 0.42981618642807007
Iteration 2042: Loss = 0.42981603741645813
Iteration 2043: Loss = 0.4298158884048462
Iteration 2044: Loss = 0.42981579899787903
Iteration 2045: Loss = 0.4298156499862671
Iteration 2046: Loss = 0.42981550097465515
Iteration 2047: Loss = 0.429815411567688
Iteration 2048: Loss = 0.4298153221607208
Iteration 2049: Loss = 0.4298151731491089
Iteration 2050: Loss = 0.42981499433517456
Iteration 2051: Loss = 0.429814875125885
Iteration 2052: Loss = 0.42981475591659546
Iteration 2053: Loss = 0.4298146069049835
Iteration 2054: Loss = 0.42981451749801636
Iteration 2055: Loss = 0.42981433868408203
Iteration 2056: Loss = 0.42981427907943726
Iteration 2057: Loss = 0.42981410026550293
Iteration 2058: Loss = 0.4298139810562134
Iteration 2059: Loss = 0.42981386184692383
Iteration 2060: Loss = 0.4298137128353119
Iteration 2061: Loss = 0.42981359362602234
Iteration 2062: Loss = 0.429813414812088
Iteration 2063: Loss = 0.42981329560279846
Iteration 2064: Loss = 0.4298132359981537
Iteration 2065: Loss = 0.42981305718421936
Iteration 2066: Loss = 0.4298129379749298
Iteration 2067: Loss = 0.42981284856796265
Iteration 2068: Loss = 0.42981263995170593
Iteration 2069: Loss = 0.4298125207424164
Iteration 2070: Loss = 0.42981240153312683
Iteration 2071: Loss = 0.4298122823238373
Iteration 2072: Loss = 0.4298121929168701
Iteration 2073: Loss = 0.42981207370758057
Iteration 2074: Loss = 0.429811954498291
Iteration 2075: Loss = 0.42981183528900146
Iteration 2076: Loss = 0.4298116862773895
Iteration 2077: Loss = 0.4298115670681
Iteration 2078: Loss = 0.42981138825416565
Iteration 2079: Loss = 0.4298112988471985
Iteration 2080: Loss = 0.42981117963790894
Iteration 2081: Loss = 0.4298110902309418
Iteration 2082: Loss = 0.4298109710216522
Iteration 2083: Loss = 0.42981085181236267
Iteration 2084: Loss = 0.4298107326030731
Iteration 2085: Loss = 0.4298105835914612
Iteration 2086: Loss = 0.429810494184494
Iteration 2087: Loss = 0.42981037497520447
Iteration 2088: Loss = 0.42981022596359253
Iteration 2089: Loss = 0.429810106754303
Iteration 2090: Loss = 0.4298099875450134
Iteration 2091: Loss = 0.42980989813804626
Iteration 2092: Loss = 0.4298097491264343
Iteration 2093: Loss = 0.42980965971946716
Iteration 2094: Loss = 0.4298095107078552
Iteration 2095: Loss = 0.4298093914985657
Iteration 2096: Loss = 0.4298093020915985
Iteration 2097: Loss = 0.4298091530799866
Iteration 2098: Loss = 0.429809033870697
Iteration 2099: Loss = 0.42980891466140747
Iteration 2100: Loss = 0.4298087954521179
Iteration 2101: Loss = 0.429808646440506
Iteration 2102: Loss = 0.4298085868358612
Iteration 2103: Loss = 0.42980846762657166
Iteration 2104: Loss = 0.4298083186149597
Iteration 2105: Loss = 0.42980822920799255
Iteration 2106: Loss = 0.4298080503940582
Iteration 2107: Loss = 0.42980796098709106
Iteration 2108: Loss = 0.4298078417778015
Iteration 2109: Loss = 0.42980772256851196
Iteration 2110: Loss = 0.4298075735569
Iteration 2111: Loss = 0.42980748414993286
Iteration 2112: Loss = 0.4298073947429657
Iteration 2113: Loss = 0.42980721592903137
Iteration 2114: Loss = 0.4298071265220642
Iteration 2115: Loss = 0.42980703711509705
Iteration 2116: Loss = 0.4298068881034851
Iteration 2117: Loss = 0.42980676889419556
Iteration 2118: Loss = 0.4298066794872284
Iteration 2119: Loss = 0.42980650067329407
Iteration 2120: Loss = 0.4298064112663269
Iteration 2121: Loss = 0.42980629205703735
Iteration 2122: Loss = 0.4298061728477478
Iteration 2123: Loss = 0.42980602383613586
Iteration 2124: Loss = 0.4298059046268463
Iteration 2125: Loss = 0.42980581521987915
Iteration 2126: Loss = 0.4298056662082672
Iteration 2127: Loss = 0.42980560660362244
Iteration 2128: Loss = 0.4298054575920105
Iteration 2129: Loss = 0.42980530858039856
Iteration 2130: Loss = 0.429805189371109
Iteration 2131: Loss = 0.42980504035949707
Iteration 2132: Loss = 0.4298049509525299
Iteration 2133: Loss = 0.42980483174324036
Iteration 2134: Loss = 0.4298047125339508
Iteration 2135: Loss = 0.42980459332466125
Iteration 2136: Loss = 0.4298044443130493
Iteration 2137: Loss = 0.42980432510375977
Iteration 2138: Loss = 0.4298042356967926
Iteration 2139: Loss = 0.42980411648750305
Iteration 2140: Loss = 0.4298039972782135
Iteration 2141: Loss = 0.42980390787124634
Iteration 2142: Loss = 0.4298036992549896
Iteration 2143: Loss = 0.4298035502433777
Iteration 2144: Loss = 0.42980343103408813
Iteration 2145: Loss = 0.42980340123176575
Iteration 2146: Loss = 0.4298032522201538
Iteration 2147: Loss = 0.42980310320854187
Iteration 2148: Loss = 0.4298030138015747
Iteration 2149: Loss = 0.42980289459228516
Iteration 2150: Loss = 0.4298027455806732
Iteration 2151: Loss = 0.42980268597602844
Iteration 2152: Loss = 0.4298025369644165
Iteration 2153: Loss = 0.42980241775512695
Iteration 2154: Loss = 0.4298023283481598
Iteration 2155: Loss = 0.4298022389411926
Iteration 2156: Loss = 0.4298021197319031
Iteration 2157: Loss = 0.4298020005226135
Iteration 2158: Loss = 0.429801881313324
Iteration 2159: Loss = 0.42980173230171204
Iteration 2160: Loss = 0.42980170249938965
Iteration 2161: Loss = 0.4298015534877777
Iteration 2162: Loss = 0.42980140447616577
Iteration 2163: Loss = 0.429801344871521
Iteration 2164: Loss = 0.42980122566223145
Iteration 2165: Loss = 0.4298010766506195
Iteration 2166: Loss = 0.42980095744132996
Iteration 2167: Loss = 0.429800808429718
Iteration 2168: Loss = 0.42980074882507324
Iteration 2169: Loss = 0.4298006594181061
Iteration 2170: Loss = 0.42980051040649414
Iteration 2171: Loss = 0.429800420999527
Iteration 2172: Loss = 0.4298003613948822
Iteration 2173: Loss = 0.4298001825809479
Iteration 2174: Loss = 0.4298001229763031
Iteration 2175: Loss = 0.42979997396469116
Iteration 2176: Loss = 0.4297998547554016
Iteration 2177: Loss = 0.42979973554611206
Iteration 2178: Loss = 0.4297996759414673
Iteration 2179: Loss = 0.42979952692985535
Iteration 2180: Loss = 0.42979946732521057
Iteration 2181: Loss = 0.429799348115921
Iteration 2182: Loss = 0.4297991991043091
Iteration 2183: Loss = 0.4297991096973419
Iteration 2184: Loss = 0.42979896068573
Iteration 2185: Loss = 0.4297989010810852
Iteration 2186: Loss = 0.4297987222671509
Iteration 2187: Loss = 0.42979857325553894
Iteration 2188: Loss = 0.42979851365089417
Iteration 2189: Loss = 0.429798424243927
Iteration 2190: Loss = 0.42979830503463745
Iteration 2191: Loss = 0.4297981858253479
Iteration 2192: Loss = 0.42979803681373596
Iteration 2193: Loss = 0.4297979474067688
Iteration 2194: Loss = 0.42979785799980164
Iteration 2195: Loss = 0.4297977387905121
Iteration 2196: Loss = 0.4297976493835449
Iteration 2197: Loss = 0.42979755997657776
Iteration 2198: Loss = 0.42979738116264343
Iteration 2199: Loss = 0.4297972619533539
Iteration 2200: Loss = 0.4297971725463867
Iteration 2201: Loss = 0.42979705333709717
Iteration 2202: Loss = 0.42979690432548523
Iteration 2203: Loss = 0.42979684472084045
Iteration 2204: Loss = 0.4297966957092285
Iteration 2205: Loss = 0.42979660630226135
Iteration 2206: Loss = 0.4297965168952942
Iteration 2207: Loss = 0.42979639768600464
Iteration 2208: Loss = 0.4297962784767151
Iteration 2209: Loss = 0.42979615926742554
Iteration 2210: Loss = 0.429796040058136
Iteration 2211: Loss = 0.42979592084884644
Iteration 2212: Loss = 0.4297958314418793
Iteration 2213: Loss = 0.42979568243026733
Iteration 2214: Loss = 0.4297955632209778
Iteration 2215: Loss = 0.4297954738140106
Iteration 2216: Loss = 0.42979535460472107
Iteration 2217: Loss = 0.4297952651977539
Iteration 2218: Loss = 0.42979517579078674
Iteration 2219: Loss = 0.4297949969768524
Iteration 2220: Loss = 0.4297948479652405
Iteration 2221: Loss = 0.4297947883605957
Iteration 2222: Loss = 0.42979466915130615
Iteration 2223: Loss = 0.4297945201396942
Iteration 2224: Loss = 0.42979443073272705
Iteration 2225: Loss = 0.4297943115234375
Iteration 2226: Loss = 0.4297942519187927
Iteration 2227: Loss = 0.4297940731048584
Iteration 2228: Loss = 0.42979398369789124
Iteration 2229: Loss = 0.4297938346862793
Iteration 2230: Loss = 0.42979374527931213
Iteration 2231: Loss = 0.4297935962677002
Iteration 2232: Loss = 0.42979350686073303
Iteration 2233: Loss = 0.4297933876514435
Iteration 2234: Loss = 0.4297932982444763
Iteration 2235: Loss = 0.42979317903518677
Iteration 2236: Loss = 0.42979303002357483
Iteration 2237: Loss = 0.4297929108142853
Iteration 2238: Loss = 0.4297928214073181
Iteration 2239: Loss = 0.42979276180267334
Iteration 2240: Loss = 0.4297925531864166
Iteration 2241: Loss = 0.42979252338409424
Iteration 2242: Loss = 0.4297923743724823
Iteration 2243: Loss = 0.42979228496551514
Iteration 2244: Loss = 0.429792195558548
Iteration 2245: Loss = 0.42979204654693604
Iteration 2246: Loss = 0.4297919273376465
Iteration 2247: Loss = 0.42979180812835693
Iteration 2248: Loss = 0.4297916293144226
Iteration 2249: Loss = 0.42979156970977783
Iteration 2250: Loss = 0.4297914206981659
Iteration 2251: Loss = 0.4297913610935211
Iteration 2252: Loss = 0.42979127168655396
Iteration 2253: Loss = 0.42979109287261963
Iteration 2254: Loss = 0.42979100346565247
Iteration 2255: Loss = 0.4297908842563629
Iteration 2256: Loss = 0.42979076504707336
Iteration 2257: Loss = 0.4297906458377838
Iteration 2258: Loss = 0.42979055643081665
Iteration 2259: Loss = 0.4297904670238495
Iteration 2260: Loss = 0.42979034781455994
Iteration 2261: Loss = 0.4297901690006256
Iteration 2262: Loss = 0.42979010939598083
Iteration 2263: Loss = 0.4297899603843689
Iteration 2264: Loss = 0.42978981137275696
Iteration 2265: Loss = 0.4297897219657898
Iteration 2266: Loss = 0.42978957295417786
Iteration 2267: Loss = 0.4297895133495331
Iteration 2268: Loss = 0.42978936433792114
Iteration 2269: Loss = 0.4297892153263092
Iteration 2270: Loss = 0.42978912591934204
Iteration 2271: Loss = 0.4297890067100525
Iteration 2272: Loss = 0.4297889173030853
Iteration 2273: Loss = 0.42978882789611816
Iteration 2274: Loss = 0.4297887086868286
Iteration 2275: Loss = 0.4297885596752167
Iteration 2276: Loss = 0.4297884702682495
Iteration 2277: Loss = 0.4297883212566376
Iteration 2278: Loss = 0.429788202047348
Iteration 2279: Loss = 0.42978808283805847
Iteration 2280: Loss = 0.42978793382644653
Iteration 2281: Loss = 0.42978784441947937
Iteration 2282: Loss = 0.4297877550125122
Iteration 2283: Loss = 0.42978760600090027
Iteration 2284: Loss = 0.4297875463962555
Iteration 2285: Loss = 0.42978742718696594
Iteration 2286: Loss = 0.4297873377799988
Iteration 2287: Loss = 0.42978718876838684
Iteration 2288: Loss = 0.4297870099544525
Iteration 2289: Loss = 0.42978689074516296
Iteration 2290: Loss = 0.4297868311405182
Iteration 2291: Loss = 0.42978671193122864
Iteration 2292: Loss = 0.4297865927219391
Iteration 2293: Loss = 0.42978644371032715
Iteration 2294: Loss = 0.4297863245010376
Iteration 2295: Loss = 0.42978620529174805
Iteration 2296: Loss = 0.42978614568710327
Iteration 2297: Loss = 0.42978599667549133
Iteration 2298: Loss = 0.4297858476638794
Iteration 2299: Loss = 0.42978569865226746
Iteration 2300: Loss = 0.4297856390476227
Iteration 2301: Loss = 0.42978551983833313
Iteration 2302: Loss = 0.4297853708267212
Iteration 2303: Loss = 0.42978528141975403
Iteration 2304: Loss = 0.4297851622104645
Iteration 2305: Loss = 0.4297850430011749
Iteration 2306: Loss = 0.4297849237918854
Iteration 2307: Loss = 0.4297848343849182
Iteration 2308: Loss = 0.4297846555709839
Iteration 2309: Loss = 0.42978453636169434
Iteration 2310: Loss = 0.4297844171524048
Iteration 2311: Loss = 0.4297843277454376
Iteration 2312: Loss = 0.42978423833847046
Iteration 2313: Loss = 0.4297841489315033
Iteration 2314: Loss = 0.42978397011756897
Iteration 2315: Loss = 0.4297838807106018
Iteration 2316: Loss = 0.42978373169898987
Iteration 2317: Loss = 0.4297836422920227
Iteration 2318: Loss = 0.42978352308273315
Iteration 2319: Loss = 0.4297833740711212
Iteration 2320: Loss = 0.42978325486183167
Iteration 2321: Loss = 0.4297831654548645
Iteration 2322: Loss = 0.42978304624557495
Iteration 2323: Loss = 0.4297829270362854
Iteration 2324: Loss = 0.42978277802467346
Iteration 2325: Loss = 0.4297827184200287
Iteration 2326: Loss = 0.42978259921073914
Iteration 2327: Loss = 0.4297824800014496
Iteration 2328: Loss = 0.4297823905944824
Iteration 2329: Loss = 0.42978230118751526
Iteration 2330: Loss = 0.4297822117805481
Iteration 2331: Loss = 0.42978209257125854
Iteration 2332: Loss = 0.4297819435596466
Iteration 2333: Loss = 0.42978182435035706
Iteration 2334: Loss = 0.4297817349433899
Iteration 2335: Loss = 0.42978164553642273
Iteration 2336: Loss = 0.42978158593177795
Iteration 2337: Loss = 0.429781436920166
Iteration 2338: Loss = 0.42978134751319885
Iteration 2339: Loss = 0.4297812581062317
Iteration 2340: Loss = 0.42978113889694214
Iteration 2341: Loss = 0.4297810196876526
Iteration 2342: Loss = 0.42978090047836304
Iteration 2343: Loss = 0.4297808110713959
Iteration 2344: Loss = 0.42978066205978394
Iteration 2345: Loss = 0.42978060245513916
Iteration 2346: Loss = 0.4297804534435272
Iteration 2347: Loss = 0.42978036403656006
Iteration 2348: Loss = 0.4297802746295929
Iteration 2349: Loss = 0.42978015542030334
Iteration 2350: Loss = 0.4297800362110138
Iteration 2351: Loss = 0.42977991700172424
Iteration 2352: Loss = 0.42977985739707947
Iteration 2353: Loss = 0.4297797381877899
Iteration 2354: Loss = 0.42977961897850037
Iteration 2355: Loss = 0.4297794997692108
Iteration 2356: Loss = 0.42977941036224365
Iteration 2357: Loss = 0.4297792911529541
Iteration 2358: Loss = 0.42977920174598694
Iteration 2359: Loss = 0.4297790825366974
Iteration 2360: Loss = 0.42977896332740784
Iteration 2361: Loss = 0.4297788739204407
Iteration 2362: Loss = 0.4297787845134735
Iteration 2363: Loss = 0.4297786355018616
Iteration 2364: Loss = 0.4297785460948944
Iteration 2365: Loss = 0.42977845668792725
Iteration 2366: Loss = 0.4297783672809601
Iteration 2367: Loss = 0.42977821826934814
Iteration 2368: Loss = 0.4297780990600586
Iteration 2369: Loss = 0.4297780394554138
Iteration 2370: Loss = 0.42977795004844666
Iteration 2371: Loss = 0.42977777123451233
Iteration 2372: Loss = 0.42977771162986755
Iteration 2373: Loss = 0.4297775626182556
Iteration 2374: Loss = 0.42977750301361084
Iteration 2375: Loss = 0.4297773838043213
Iteration 2376: Loss = 0.4297773241996765
Iteration 2377: Loss = 0.4297771155834198
Iteration 2378: Loss = 0.42977702617645264
Iteration 2379: Loss = 0.4297769367694855
Iteration 2380: Loss = 0.4297768473625183
Iteration 2381: Loss = 0.42977672815322876
Iteration 2382: Loss = 0.4297766089439392
Iteration 2383: Loss = 0.42977648973464966
Iteration 2384: Loss = 0.4297764301300049
Iteration 2385: Loss = 0.42977631092071533
Iteration 2386: Loss = 0.4297761917114258
Iteration 2387: Loss = 0.42977607250213623
Iteration 2388: Loss = 0.42977598309516907
Iteration 2389: Loss = 0.42977583408355713
Iteration 2390: Loss = 0.42977574467658997
Iteration 2391: Loss = 0.4297756552696228
Iteration 2392: Loss = 0.42977556586265564
Iteration 2393: Loss = 0.4297754466533661
Iteration 2394: Loss = 0.4297753572463989
Iteration 2395: Loss = 0.429775208234787
Iteration 2396: Loss = 0.4297751486301422
Iteration 2397: Loss = 0.42977505922317505
Iteration 2398: Loss = 0.4297749102115631
Iteration 2399: Loss = 0.42977479100227356
Iteration 2400: Loss = 0.4297747313976288
Iteration 2401: Loss = 0.42977455258369446
Iteration 2402: Loss = 0.4297744333744049
Iteration 2403: Loss = 0.42977437376976013
Iteration 2404: Loss = 0.4297742545604706
Iteration 2405: Loss = 0.4297741651535034
Iteration 2406: Loss = 0.42977404594421387
Iteration 2407: Loss = 0.4297739267349243
Iteration 2408: Loss = 0.42977386713027954
Iteration 2409: Loss = 0.42977374792099
Iteration 2410: Loss = 0.4297736585140228
Iteration 2411: Loss = 0.4297735393047333
Iteration 2412: Loss = 0.4297734200954437
Iteration 2413: Loss = 0.4297733008861542
Iteration 2414: Loss = 0.429773211479187
Iteration 2415: Loss = 0.42977309226989746
Iteration 2416: Loss = 0.4297730326652527
Iteration 2417: Loss = 0.42977288365364075
Iteration 2418: Loss = 0.4297727644443512
Iteration 2419: Loss = 0.42977264523506165
Iteration 2420: Loss = 0.42977258563041687
Iteration 2421: Loss = 0.42977243661880493
Iteration 2422: Loss = 0.42977240681648254
Iteration 2423: Loss = 0.429772287607193
Iteration 2424: Loss = 0.42977213859558105
Iteration 2425: Loss = 0.4297720789909363
Iteration 2426: Loss = 0.42977195978164673
Iteration 2427: Loss = 0.4297718405723572
Iteration 2428: Loss = 0.4297718107700348
Iteration 2429: Loss = 0.42977166175842285
Iteration 2430: Loss = 0.4297715425491333
Iteration 2431: Loss = 0.4297715127468109
Iteration 2432: Loss = 0.429771363735199
Iteration 2433: Loss = 0.4297712445259094
Iteration 2434: Loss = 0.42977121472358704
Iteration 2435: Loss = 0.4297710657119751
Iteration 2436: Loss = 0.42977097630500793
Iteration 2437: Loss = 0.42977088689804077
Iteration 2438: Loss = 0.4297707676887512
Iteration 2439: Loss = 0.42977064847946167
Iteration 2440: Loss = 0.4297705590724945
Iteration 2441: Loss = 0.42977043986320496
Iteration 2442: Loss = 0.4297703206539154
Iteration 2443: Loss = 0.42977023124694824
Iteration 2444: Loss = 0.42977017164230347
Iteration 2445: Loss = 0.4297700524330139
Iteration 2446: Loss = 0.42976999282836914
Iteration 2447: Loss = 0.4297698438167572
Iteration 2448: Loss = 0.4297697842121124
Iteration 2449: Loss = 0.4297696650028229
Iteration 2450: Loss = 0.4297695755958557
Iteration 2451: Loss = 0.4297693967819214
Iteration 2452: Loss = 0.429769366979599
Iteration 2453: Loss = 0.42976921796798706
Iteration 2454: Loss = 0.4297691285610199
Iteration 2455: Loss = 0.42976903915405273
Iteration 2456: Loss = 0.42976894974708557
Iteration 2457: Loss = 0.429768830537796
Iteration 2458: Loss = 0.42976871132850647
Iteration 2459: Loss = 0.4297686517238617
Iteration 2460: Loss = 0.42976850271224976
Iteration 2461: Loss = 0.4297684133052826
Iteration 2462: Loss = 0.4297683835029602
Iteration 2463: Loss = 0.4297682046890259
Iteration 2464: Loss = 0.42976808547973633
Iteration 2465: Loss = 0.42976799607276917
Iteration 2466: Loss = 0.4297679364681244
Iteration 2467: Loss = 0.4297678470611572
Iteration 2468: Loss = 0.4297677278518677
Iteration 2469: Loss = 0.4297676086425781
Iteration 2470: Loss = 0.42976751923561096
Iteration 2471: Loss = 0.4297674000263214
Iteration 2472: Loss = 0.42976731061935425
Iteration 2473: Loss = 0.4297672212123871
Iteration 2474: Loss = 0.42976710200309753
Iteration 2475: Loss = 0.42976701259613037
Iteration 2476: Loss = 0.4297668933868408
Iteration 2477: Loss = 0.42976677417755127
Iteration 2478: Loss = 0.4297666847705841
Iteration 2479: Loss = 0.42976659536361694
Iteration 2480: Loss = 0.4297664761543274
Iteration 2481: Loss = 0.42976632714271545
Iteration 2482: Loss = 0.42976629734039307
Iteration 2483: Loss = 0.4297661781311035
Iteration 2484: Loss = 0.42976605892181396
Iteration 2485: Loss = 0.4297659695148468
Iteration 2486: Loss = 0.42976588010787964
Iteration 2487: Loss = 0.4297657608985901
Iteration 2488: Loss = 0.42976564168930054
Iteration 2489: Loss = 0.4297655522823334
Iteration 2490: Loss = 0.4297654330730438
Iteration 2491: Loss = 0.42976534366607666
Iteration 2492: Loss = 0.4297652542591095
Iteration 2493: Loss = 0.42976513504981995
Iteration 2494: Loss = 0.4297650158405304
Iteration 2495: Loss = 0.42976492643356323
Iteration 2496: Loss = 0.4297648072242737
Iteration 2497: Loss = 0.4297647178173065
Iteration 2498: Loss = 0.42976462841033936
Iteration 2499: Loss = 0.4297645390033722
Iteration 2500: Loss = 0.42976438999176025
Iteration 2501: Loss = 0.4297642707824707
Iteration 2502: Loss = 0.4297642111778259
Iteration 2503: Loss = 0.429764062166214
Iteration 2504: Loss = 0.4297639727592468
Iteration 2505: Loss = 0.42976391315460205
Iteration 2506: Loss = 0.4297637641429901
Iteration 2507: Loss = 0.42976367473602295
Iteration 2508: Loss = 0.4297635853290558
Iteration 2509: Loss = 0.42976346611976624
Iteration 2510: Loss = 0.4297633767127991
Iteration 2511: Loss = 0.4297632575035095
Iteration 2512: Loss = 0.42976313829421997
Iteration 2513: Loss = 0.4297630786895752
Iteration 2514: Loss = 0.42976289987564087
Iteration 2515: Loss = 0.4297628402709961
Iteration 2516: Loss = 0.42976272106170654
Iteration 2517: Loss = 0.4297626316547394
Iteration 2518: Loss = 0.42976251244544983
Iteration 2519: Loss = 0.42976242303848267
Iteration 2520: Loss = 0.4297623634338379
Iteration 2521: Loss = 0.42976224422454834
Iteration 2522: Loss = 0.4297621250152588
Iteration 2523: Loss = 0.42976197600364685
Iteration 2524: Loss = 0.42976197600364685
Iteration 2525: Loss = 0.42976176738739014
Iteration 2526: Loss = 0.42976170778274536
Iteration 2527: Loss = 0.4297615587711334
Iteration 2528: Loss = 0.42976146936416626
Iteration 2529: Loss = 0.4297613501548767
Iteration 2530: Loss = 0.42976123094558716
Iteration 2531: Loss = 0.42976114153862
Iteration 2532: Loss = 0.4297611117362976
Iteration 2533: Loss = 0.4297609329223633
Iteration 2534: Loss = 0.4297609329223633
Iteration 2535: Loss = 0.42976078391075134
Iteration 2536: Loss = 0.4297606945037842
Iteration 2537: Loss = 0.42976054549217224
Iteration 2538: Loss = 0.42976048588752747
Iteration 2539: Loss = 0.4297604262828827
Iteration 2540: Loss = 0.42976024746894836
Iteration 2541: Loss = 0.429760217666626
Iteration 2542: Loss = 0.4297601282596588
Iteration 2543: Loss = 0.42976006865501404
Iteration 2544: Loss = 0.4297599494457245
Iteration 2545: Loss = 0.42975983023643494
Iteration 2546: Loss = 0.4297597408294678
Iteration 2547: Loss = 0.4297596514225006
Iteration 2548: Loss = 0.42975959181785583
Iteration 2549: Loss = 0.42975950241088867
Iteration 2550: Loss = 0.4297593832015991
Iteration 2551: Loss = 0.42975932359695435
Iteration 2552: Loss = 0.4297592043876648
Iteration 2553: Loss = 0.42975911498069763
Iteration 2554: Loss = 0.42975902557373047
Iteration 2555: Loss = 0.4297589063644409
Iteration 2556: Loss = 0.42975881695747375
Iteration 2557: Loss = 0.429758757352829
Iteration 2558: Loss = 0.4297586679458618
Iteration 2559: Loss = 0.42975854873657227
Iteration 2560: Loss = 0.4297584295272827
Iteration 2561: Loss = 0.42975834012031555
Iteration 2562: Loss = 0.4297582805156708
Iteration 2563: Loss = 0.4297581911087036
Iteration 2564: Loss = 0.42975813150405884
Iteration 2565: Loss = 0.4297579824924469
Iteration 2566: Loss = 0.4297579228878021
Iteration 2567: Loss = 0.4297577738761902
Iteration 2568: Loss = 0.4297577440738678
Iteration 2569: Loss = 0.42975759506225586
Iteration 2570: Loss = 0.42975756525993347
Iteration 2571: Loss = 0.4297574758529663
Iteration 2572: Loss = 0.42975732684135437
Iteration 2573: Loss = 0.4297572672367096
Iteration 2574: Loss = 0.42975714802742004
Iteration 2575: Loss = 0.42975708842277527
Iteration 2576: Loss = 0.4297569692134857
Iteration 2577: Loss = 0.42975687980651855
Iteration 2578: Loss = 0.429756760597229
Iteration 2579: Loss = 0.42975670099258423
Iteration 2580: Loss = 0.42975661158561707
Iteration 2581: Loss = 0.4297565221786499
Iteration 2582: Loss = 0.4297564625740051
Iteration 2583: Loss = 0.4297563135623932
Iteration 2584: Loss = 0.4297562539577484
Iteration 2585: Loss = 0.42975616455078125
Iteration 2586: Loss = 0.4297560751438141
Iteration 2587: Loss = 0.4297559857368469
Iteration 2588: Loss = 0.42975592613220215
Iteration 2589: Loss = 0.4297558069229126
Iteration 2590: Loss = 0.42975568771362305
Iteration 2591: Loss = 0.4297555983066559
Iteration 2592: Loss = 0.4297555088996887
Iteration 2593: Loss = 0.4297553598880768
Iteration 2594: Loss = 0.4297552704811096
Iteration 2595: Loss = 0.42975518107414246
Iteration 2596: Loss = 0.4297551214694977
Iteration 2597: Loss = 0.4297550618648529
Iteration 2598: Loss = 0.42975497245788574
Iteration 2599: Loss = 0.4297548830509186
Iteration 2600: Loss = 0.42975476384162903
Iteration 2601: Loss = 0.42975470423698425
Iteration 2602: Loss = 0.4297545552253723
Iteration 2603: Loss = 0.42975449562072754
Iteration 2604: Loss = 0.429754376411438
Iteration 2605: Loss = 0.4297542870044708
Iteration 2606: Loss = 0.42975419759750366
Iteration 2607: Loss = 0.4297540783882141
Iteration 2608: Loss = 0.42975398898124695
Iteration 2609: Loss = 0.4297538697719574
Iteration 2610: Loss = 0.4297538101673126
Iteration 2611: Loss = 0.42975372076034546
Iteration 2612: Loss = 0.4297536611557007
Iteration 2613: Loss = 0.42975354194641113
Iteration 2614: Loss = 0.4297534227371216
Iteration 2615: Loss = 0.4297533631324768
Iteration 2616: Loss = 0.42975330352783203
Iteration 2617: Loss = 0.4297531843185425
Iteration 2618: Loss = 0.42975306510925293
Iteration 2619: Loss = 0.42975300550460815
Iteration 2620: Loss = 0.4297528564929962
Iteration 2621: Loss = 0.42975279688835144
Iteration 2622: Loss = 0.4297526776790619
Iteration 2623: Loss = 0.4297526180744171
Iteration 2624: Loss = 0.42975249886512756
Iteration 2625: Loss = 0.4297524094581604
Iteration 2626: Loss = 0.42975232005119324
Iteration 2627: Loss = 0.4297522306442261
Iteration 2628: Loss = 0.4297521412372589
Iteration 2629: Loss = 0.42975208163261414
Iteration 2630: Loss = 0.4297519028186798
Iteration 2631: Loss = 0.4297519028186798
Iteration 2632: Loss = 0.42975175380706787
Iteration 2633: Loss = 0.4297516345977783
Iteration 2634: Loss = 0.42975157499313354
Iteration 2635: Loss = 0.4297514259815216
Iteration 2636: Loss = 0.42975136637687683
Iteration 2637: Loss = 0.42975130677223206
Iteration 2638: Loss = 0.4297511875629425
Iteration 2639: Loss = 0.42975106835365295
Iteration 2640: Loss = 0.4297509789466858
Iteration 2641: Loss = 0.42975088953971863
Iteration 2642: Loss = 0.42975080013275146
Iteration 2643: Loss = 0.4297506809234619
Iteration 2644: Loss = 0.4297506809234619
Iteration 2645: Loss = 0.42975053191185
Iteration 2646: Loss = 0.4297504127025604
Iteration 2647: Loss = 0.4297502934932709
Iteration 2648: Loss = 0.4297502636909485
Iteration 2649: Loss = 0.42975011467933655
Iteration 2650: Loss = 0.4297500252723694
Iteration 2651: Loss = 0.4297499358654022
Iteration 2652: Loss = 0.42974981665611267
Iteration 2653: Loss = 0.4297497570514679
Iteration 2654: Loss = 0.42974966764450073
Iteration 2655: Loss = 0.42974957823753357
Iteration 2656: Loss = 0.4297495186328888
Iteration 2657: Loss = 0.42974936962127686
Iteration 2658: Loss = 0.4297492802143097
Iteration 2659: Loss = 0.42974913120269775
Iteration 2660: Loss = 0.429749071598053
Iteration 2661: Loss = 0.4297489821910858
Iteration 2662: Loss = 0.42974889278411865
Iteration 2663: Loss = 0.4297487735748291
Iteration 2664: Loss = 0.4297487139701843
Iteration 2665: Loss = 0.4297485947608948
Iteration 2666: Loss = 0.42974853515625
Iteration 2667: Loss = 0.42974838614463806
Iteration 2668: Loss = 0.4297482967376709
Iteration 2669: Loss = 0.4297482371330261
Iteration 2670: Loss = 0.42974814772605896
Iteration 2671: Loss = 0.429747998714447
Iteration 2672: Loss = 0.42974793910980225
Iteration 2673: Loss = 0.4297477900981903
Iteration 2674: Loss = 0.4297477602958679
Iteration 2675: Loss = 0.42974764108657837
Iteration 2676: Loss = 0.4297475218772888
Iteration 2677: Loss = 0.42974743247032166
Iteration 2678: Loss = 0.4297473132610321
Iteration 2679: Loss = 0.42974725365638733
Iteration 2680: Loss = 0.4297471344470978
Iteration 2681: Loss = 0.429747074842453
Iteration 2682: Loss = 0.42974698543548584
Iteration 2683: Loss = 0.4297468662261963
Iteration 2684: Loss = 0.4297467768192291
Iteration 2685: Loss = 0.4297466576099396
Iteration 2686: Loss = 0.42974650859832764
Iteration 2687: Loss = 0.42974644899368286
Iteration 2688: Loss = 0.4297463893890381
Iteration 2689: Loss = 0.4297462999820709
Iteration 2690: Loss = 0.4297461211681366
Iteration 2691: Loss = 0.4297460913658142
Iteration 2692: Loss = 0.42974597215652466
Iteration 2693: Loss = 0.4297458827495575
Iteration 2694: Loss = 0.4297458231449127
Iteration 2695: Loss = 0.4297456741333008
Iteration 2696: Loss = 0.429745614528656
Iteration 2697: Loss = 0.42974552512168884
Iteration 2698: Loss = 0.4297454059123993
Iteration 2699: Loss = 0.42974525690078735
Iteration 2700: Loss = 0.4297451674938202
Iteration 2701: Loss = 0.4297451078891754
Iteration 2702: Loss = 0.42974501848220825
Iteration 2703: Loss = 0.4297448694705963
Iteration 2704: Loss = 0.42974480986595154
Iteration 2705: Loss = 0.4297447204589844
Iteration 2706: Loss = 0.4297446012496948
Iteration 2707: Loss = 0.42974451184272766
Iteration 2708: Loss = 0.4297444224357605
Iteration 2709: Loss = 0.42974433302879333
Iteration 2710: Loss = 0.42974427342414856
Iteration 2711: Loss = 0.429744154214859
Iteration 2712: Loss = 0.42974403500556946
Iteration 2713: Loss = 0.4297439455986023
Iteration 2714: Loss = 0.42974379658699036
Iteration 2715: Loss = 0.4297437071800232
Iteration 2716: Loss = 0.4297436475753784
Iteration 2717: Loss = 0.42974355816841125
Iteration 2718: Loss = 0.4297434687614441
Iteration 2719: Loss = 0.42974334955215454
Iteration 2720: Loss = 0.42974328994750977
Iteration 2721: Loss = 0.4297432005405426
Iteration 2722: Loss = 0.42974308133125305
Iteration 2723: Loss = 0.42974305152893066
Iteration 2724: Loss = 0.4297429025173187
Iteration 2725: Loss = 0.4297427833080292
Iteration 2726: Loss = 0.429742693901062
Iteration 2727: Loss = 0.4297426640987396
Iteration 2728: Loss = 0.4297425150871277
Iteration 2729: Loss = 0.4297424554824829
Iteration 2730: Loss = 0.42974233627319336
Iteration 2731: Loss = 0.4297422468662262
Iteration 2732: Loss = 0.4297421872615814
Iteration 2733: Loss = 0.42974209785461426
Iteration 2734: Loss = 0.4297419786453247
Iteration 2735: Loss = 0.42974188923835754
Iteration 2736: Loss = 0.42974182963371277
Iteration 2737: Loss = 0.4297417104244232
Iteration 2738: Loss = 0.42974162101745605
Iteration 2739: Loss = 0.4297415614128113
Iteration 2740: Loss = 0.42974141240119934
Iteration 2741: Loss = 0.42974135279655457
Iteration 2742: Loss = 0.4297412633895874
Iteration 2743: Loss = 0.42974114418029785
Iteration 2744: Loss = 0.4297410845756531
Iteration 2745: Loss = 0.4297409653663635
Iteration 2746: Loss = 0.429740846157074
Iteration 2747: Loss = 0.4297407865524292
Iteration 2748: Loss = 0.42974066734313965
Iteration 2749: Loss = 0.4297406077384949
Iteration 2750: Loss = 0.4297405183315277
Iteration 2751: Loss = 0.42974042892456055
Iteration 2752: Loss = 0.429740309715271
Iteration 2753: Loss = 0.42974022030830383
Iteration 2754: Loss = 0.42974013090133667
Iteration 2755: Loss = 0.4297400414943695
Iteration 2756: Loss = 0.42973992228507996
Iteration 2757: Loss = 0.4297398626804352
Iteration 2758: Loss = 0.42973974347114563
Iteration 2759: Loss = 0.42973968386650085
Iteration 2760: Loss = 0.4297395646572113
Iteration 2761: Loss = 0.42973950505256653
Iteration 2762: Loss = 0.4297393560409546
Iteration 2763: Loss = 0.4297393262386322
Iteration 2764: Loss = 0.42973920702934265
Iteration 2765: Loss = 0.4297391474246979
Iteration 2766: Loss = 0.4297390580177307
Iteration 2767: Loss = 0.42973893880844116
Iteration 2768: Loss = 0.4297388195991516
Iteration 2769: Loss = 0.42973875999450684
Iteration 2770: Loss = 0.4297386705875397
Iteration 2771: Loss = 0.4297385513782501
Iteration 2772: Loss = 0.42973849177360535
Iteration 2773: Loss = 0.4297383725643158
Iteration 2774: Loss = 0.429738312959671
Iteration 2775: Loss = 0.42973819375038147
Iteration 2776: Loss = 0.4297381341457367
Iteration 2777: Loss = 0.42973798513412476
Iteration 2778: Loss = 0.4297378659248352
Iteration 2779: Loss = 0.42973780632019043
Iteration 2780: Loss = 0.42973774671554565
Iteration 2781: Loss = 0.4297375977039337
Iteration 2782: Loss = 0.42973747849464417
Iteration 2783: Loss = 0.4297374188899994
Iteration 2784: Loss = 0.4297373592853546
Iteration 2785: Loss = 0.42973724007606506
Iteration 2786: Loss = 0.4297371506690979
Iteration 2787: Loss = 0.42973703145980835
Iteration 2788: Loss = 0.4297369420528412
Iteration 2789: Loss = 0.4297368824481964
Iteration 2790: Loss = 0.42973679304122925
Iteration 2791: Loss = 0.4297367036342621
Iteration 2792: Loss = 0.4297366142272949
Iteration 2793: Loss = 0.42973652482032776
Iteration 2794: Loss = 0.4297364056110382
Iteration 2795: Loss = 0.42973631620407104
Iteration 2796: Loss = 0.4297362267971039
Iteration 2797: Loss = 0.42973607778549194
Iteration 2798: Loss = 0.42973601818084717
Iteration 2799: Loss = 0.4297358989715576
Iteration 2800: Loss = 0.42973583936691284
Iteration 2801: Loss = 0.4297357201576233
Iteration 2802: Loss = 0.4297356605529785
Iteration 2803: Loss = 0.42973557114601135
Iteration 2804: Loss = 0.4297354817390442
Iteration 2805: Loss = 0.42973536252975464
Iteration 2806: Loss = 0.42973530292510986
Iteration 2807: Loss = 0.4297351539134979
Iteration 2808: Loss = 0.42973509430885315
Iteration 2809: Loss = 0.429735004901886
Iteration 2810: Loss = 0.42973488569259644
Iteration 2811: Loss = 0.4297347664833069
Iteration 2812: Loss = 0.4297347366809845
Iteration 2813: Loss = 0.42973464727401733
Iteration 2814: Loss = 0.4297344982624054
Iteration 2815: Loss = 0.42973440885543823
Iteration 2816: Loss = 0.42973431944847107
Iteration 2817: Loss = 0.4297342300415039
Iteration 2818: Loss = 0.42973414063453674
Iteration 2819: Loss = 0.42973408102989197
Iteration 2820: Loss = 0.42973393201828003
Iteration 2821: Loss = 0.42973384261131287
Iteration 2822: Loss = 0.4297337532043457
Iteration 2823: Loss = 0.42973363399505615
Iteration 2824: Loss = 0.4297335743904114
Iteration 2825: Loss = 0.42973342537879944
Iteration 2826: Loss = 0.42973339557647705
Iteration 2827: Loss = 0.4297332763671875
Iteration 2828: Loss = 0.42973315715789795
Iteration 2829: Loss = 0.4297330677509308
Iteration 2830: Loss = 0.4297329783439636
Iteration 2831: Loss = 0.42973288893699646
Iteration 2832: Loss = 0.4297328591346741
Iteration 2833: Loss = 0.42973271012306213
Iteration 2834: Loss = 0.4297325909137726
Iteration 2835: Loss = 0.42973247170448303
Iteration 2836: Loss = 0.42973241209983826
Iteration 2837: Loss = 0.4297322928905487
Iteration 2838: Loss = 0.42973223328590393
Iteration 2839: Loss = 0.4297321140766144
Iteration 2840: Loss = 0.4297320246696472
Iteration 2841: Loss = 0.42973190546035767
Iteration 2842: Loss = 0.4297318756580353
Iteration 2843: Loss = 0.4297317564487457
Iteration 2844: Loss = 0.4297316074371338
Iteration 2845: Loss = 0.429731547832489
Iteration 2846: Loss = 0.42973145842552185
Iteration 2847: Loss = 0.4297313094139099
Iteration 2848: Loss = 0.42973124980926514
Iteration 2849: Loss = 0.429731160402298
Iteration 2850: Loss = 0.4297310709953308
Iteration 2851: Loss = 0.42973098158836365
Iteration 2852: Loss = 0.4297308325767517
Iteration 2853: Loss = 0.4297308027744293
Iteration 2854: Loss = 0.4297306537628174
Iteration 2855: Loss = 0.4297305643558502
Iteration 2856: Loss = 0.42973047494888306
Iteration 2857: Loss = 0.4297304153442383
Iteration 2858: Loss = 0.4297303557395935
Iteration 2859: Loss = 0.42973023653030396
Iteration 2860: Loss = 0.4297301173210144
Iteration 2861: Loss = 0.42973002791404724
Iteration 2862: Loss = 0.4297299087047577
Iteration 2863: Loss = 0.4297298192977905
Iteration 2864: Loss = 0.42972972989082336
Iteration 2865: Loss = 0.4297295808792114
Iteration 2866: Loss = 0.42972952127456665
Iteration 2867: Loss = 0.4297294318675995
Iteration 2868: Loss = 0.42972931265830994
Iteration 2869: Loss = 0.4297291338443756
Iteration 2870: Loss = 0.4297291338443756
Iteration 2871: Loss = 0.42972901463508606
Iteration 2872: Loss = 0.4297289550304413
Iteration 2873: Loss = 0.4297288656234741
Iteration 2874: Loss = 0.42972874641418457
Iteration 2875: Loss = 0.429728627204895
Iteration 2876: Loss = 0.42972850799560547
Iteration 2877: Loss = 0.4297283887863159
Iteration 2878: Loss = 0.4297283887863159
Iteration 2879: Loss = 0.429728239774704
Iteration 2880: Loss = 0.42972812056541443
Iteration 2881: Loss = 0.42972806096076965
Iteration 2882: Loss = 0.4297279715538025
Iteration 2883: Loss = 0.42972785234451294
Iteration 2884: Loss = 0.4297277629375458
Iteration 2885: Loss = 0.4297276735305786
Iteration 2886: Loss = 0.4297275245189667
Iteration 2887: Loss = 0.4297274053096771
Iteration 2888: Loss = 0.42972734570503235
Iteration 2889: Loss = 0.4297272562980652
Iteration 2890: Loss = 0.429727166891098
Iteration 2891: Loss = 0.42972710728645325
Iteration 2892: Loss = 0.4297269582748413
Iteration 2893: Loss = 0.42972686886787415
Iteration 2894: Loss = 0.429726779460907
Iteration 2895: Loss = 0.4297266900539398
Iteration 2896: Loss = 0.42972660064697266
Iteration 2897: Loss = 0.4297265410423279
Iteration 2898: Loss = 0.42972639203071594
Iteration 2899: Loss = 0.42972633242607117
Iteration 2900: Loss = 0.42972618341445923
Iteration 2901: Loss = 0.42972609400749207
Iteration 2902: Loss = 0.4297260046005249
Iteration 2903: Loss = 0.42972585558891296
Iteration 2904: Loss = 0.4297257661819458
Iteration 2905: Loss = 0.42972567677497864
Iteration 2906: Loss = 0.42972561717033386
Iteration 2907: Loss = 0.4297255277633667
Iteration 2908: Loss = 0.42972540855407715
Iteration 2909: Loss = 0.4297252893447876
Iteration 2910: Loss = 0.42972517013549805
Iteration 2911: Loss = 0.4297250807285309
Iteration 2912: Loss = 0.4297249913215637
Iteration 2913: Loss = 0.42972490191459656
Iteration 2914: Loss = 0.4297248125076294
Iteration 2915: Loss = 0.42972466349601746
Iteration 2916: Loss = 0.4297245442867279
Iteration 2917: Loss = 0.42972445487976074
Iteration 2918: Loss = 0.42972439527511597
Iteration 2919: Loss = 0.4297242760658264
Iteration 2920: Loss = 0.42972418665885925
Iteration 2921: Loss = 0.4297240972518921
Iteration 2922: Loss = 0.4297240376472473
Iteration 2923: Loss = 0.4297238886356354
Iteration 2924: Loss = 0.429723858833313
Iteration 2925: Loss = 0.4297236502170563
Iteration 2926: Loss = 0.4297235608100891
Iteration 2927: Loss = 0.42972347140312195
Iteration 2928: Loss = 0.4297233819961548
Iteration 2929: Loss = 0.42972332239151
Iteration 2930: Loss = 0.42972320318222046
Iteration 2931: Loss = 0.4297231137752533
Iteration 2932: Loss = 0.42972299456596375
Iteration 2933: Loss = 0.4297229051589966
Iteration 2934: Loss = 0.4297228157520294
Iteration 2935: Loss = 0.42972269654273987
Iteration 2936: Loss = 0.42972254753112793
Iteration 2937: Loss = 0.4297224283218384
Iteration 2938: Loss = 0.4297223389148712
Iteration 2939: Loss = 0.42972227931022644
Iteration 2940: Loss = 0.42972221970558167
Iteration 2941: Loss = 0.4297221302986145
Iteration 2942: Loss = 0.42972198128700256
Iteration 2943: Loss = 0.429721862077713
Iteration 2944: Loss = 0.42972180247306824
Iteration 2945: Loss = 0.4297216534614563
Iteration 2946: Loss = 0.42972156405448914
Iteration 2947: Loss = 0.4297214448451996
Iteration 2948: Loss = 0.4297213852405548
Iteration 2949: Loss = 0.42972126603126526
Iteration 2950: Loss = 0.4297211468219757
Iteration 2951: Loss = 0.42972105741500854
Iteration 2952: Loss = 0.4297209680080414
Iteration 2953: Loss = 0.42972084879875183
Iteration 2954: Loss = 0.42972081899642944
Iteration 2955: Loss = 0.4297206699848175
Iteration 2956: Loss = 0.42972055077552795
Iteration 2957: Loss = 0.4297204315662384
Iteration 2958: Loss = 0.429720401763916
Iteration 2959: Loss = 0.42972028255462646
Iteration 2960: Loss = 0.4297201931476593
Iteration 2961: Loss = 0.42972007393836975
Iteration 2962: Loss = 0.4297199845314026
Iteration 2963: Loss = 0.42971980571746826
Iteration 2964: Loss = 0.4297197461128235
Iteration 2965: Loss = 0.42971962690353394
Iteration 2966: Loss = 0.429719477891922
Iteration 2967: Loss = 0.4297194182872772
Iteration 2968: Loss = 0.42971932888031006
Iteration 2969: Loss = 0.4297192692756653
Iteration 2970: Loss = 0.42971912026405334
Iteration 2971: Loss = 0.42971906065940857
Iteration 2972: Loss = 0.4297189712524414
Iteration 2973: Loss = 0.42971885204315186
Iteration 2974: Loss = 0.4297187328338623
Iteration 2975: Loss = 0.42971858382225037
Iteration 2976: Loss = 0.4297185242176056
Iteration 2977: Loss = 0.4297184348106384
Iteration 2978: Loss = 0.4297183156013489
Iteration 2979: Loss = 0.42971816658973694
Iteration 2980: Loss = 0.42971813678741455
Iteration 2981: Loss = 0.429718017578125
Iteration 2982: Loss = 0.42971789836883545
Iteration 2983: Loss = 0.4297177791595459
Iteration 2984: Loss = 0.4297177195549011
Iteration 2985: Loss = 0.4297176003456116
Iteration 2986: Loss = 0.429717481136322
Iteration 2987: Loss = 0.42971742153167725
Iteration 2988: Loss = 0.4297172725200653
Iteration 2989: Loss = 0.42971715331077576
Iteration 2990: Loss = 0.429717093706131
Iteration 2991: Loss = 0.42971694469451904
Iteration 2992: Loss = 0.4297168552875519
Iteration 2993: Loss = 0.4297167658805847
Iteration 2994: Loss = 0.42971667647361755
Iteration 2995: Loss = 0.429716557264328
Iteration 2996: Loss = 0.4297164976596832
Iteration 2997: Loss = 0.4297163486480713
Iteration 2998: Loss = 0.4297162592411041
Iteration 2999: Loss = 0.42971616983413696
Iteration 3000: Loss = 0.429716020822525
Iteration 3001: Loss = 0.42971593141555786
Iteration 3002: Loss = 0.4297158122062683
Iteration 3003: Loss = 0.42971572279930115
Iteration 3004: Loss = 0.4297155737876892
Iteration 3005: Loss = 0.42971548438072205
Iteration 3006: Loss = 0.42971542477607727
Iteration 3007: Loss = 0.4297153353691101
Iteration 3008: Loss = 0.42971521615982056
Iteration 3009: Loss = 0.4297151565551758
Iteration 3010: Loss = 0.42971497774124146
Iteration 3011: Loss = 0.4297149181365967
Iteration 3012: Loss = 0.42971473932266235
Iteration 3013: Loss = 0.4297146499156952
Iteration 3014: Loss = 0.429714560508728
Iteration 3015: Loss = 0.4297144412994385
Iteration 3016: Loss = 0.4297143518924713
Iteration 3017: Loss = 0.42971423268318176
Iteration 3018: Loss = 0.429714173078537
Iteration 3019: Loss = 0.42971402406692505
Iteration 3020: Loss = 0.4297139048576355
Iteration 3021: Loss = 0.42971381545066833
Iteration 3022: Loss = 0.42971375584602356
Iteration 3023: Loss = 0.42971354722976685
Iteration 3024: Loss = 0.42971351742744446
Iteration 3025: Loss = 0.4297133684158325
Iteration 3026: Loss = 0.42971330881118774
Iteration 3027: Loss = 0.4297132194042206
Iteration 3028: Loss = 0.4297131299972534
Iteration 3029: Loss = 0.42971301078796387
Iteration 3030: Loss = 0.4297128915786743
Iteration 3031: Loss = 0.42971280217170715
Iteration 3032: Loss = 0.42971271276474
Iteration 3033: Loss = 0.42971259355545044
Iteration 3034: Loss = 0.4297125041484833
Iteration 3035: Loss = 0.4297124147415161
Iteration 3036: Loss = 0.4297122657299042
Iteration 3037: Loss = 0.4297121465206146
Iteration 3038: Loss = 0.42971205711364746
Iteration 3039: Loss = 0.4297120273113251
Iteration 3040: Loss = 0.42971181869506836
Iteration 3041: Loss = 0.42971178889274597
Iteration 3042: Loss = 0.42971163988113403
Iteration 3043: Loss = 0.42971155047416687
Iteration 3044: Loss = 0.4297114610671997
Iteration 3045: Loss = 0.42971137166023254
Iteration 3046: Loss = 0.4297111928462982
Iteration 3047: Loss = 0.42971116304397583
Iteration 3048: Loss = 0.4297110438346863
Iteration 3049: Loss = 0.4297109544277191
Iteration 3050: Loss = 0.42971083521842957
Iteration 3051: Loss = 0.42971071600914
Iteration 3052: Loss = 0.42971062660217285
Iteration 3053: Loss = 0.4297105371952057
Iteration 3054: Loss = 0.42971038818359375
Iteration 3055: Loss = 0.429710328578949
Iteration 3056: Loss = 0.4297102093696594
Iteration 3057: Loss = 0.4297100901603699
Iteration 3058: Loss = 0.4297100305557251
Iteration 3059: Loss = 0.42970988154411316
Iteration 3060: Loss = 0.4297097325325012
Iteration 3061: Loss = 0.42970967292785645
Iteration 3062: Loss = 0.4297095835208893
Iteration 3063: Loss = 0.4297095239162445
Iteration 3064: Loss = 0.42970940470695496
Iteration 3065: Loss = 0.4297092854976654
Iteration 3066: Loss = 0.42970919609069824
Iteration 3067: Loss = 0.4297090470790863
Iteration 3068: Loss = 0.42970898747444153
Iteration 3069: Loss = 0.4297088384628296
Iteration 3070: Loss = 0.4297087490558624
Iteration 3071: Loss = 0.42970868945121765
Iteration 3072: Loss = 0.4297085702419281
Iteration 3073: Loss = 0.42970845103263855
Iteration 3074: Loss = 0.4297083020210266
Iteration 3075: Loss = 0.42970818281173706
Iteration 3076: Loss = 0.4297080934047699
Iteration 3077: Loss = 0.42970800399780273
Iteration 3078: Loss = 0.42970794439315796
Iteration 3079: Loss = 0.4297078251838684
Iteration 3080: Loss = 0.42970767617225647
Iteration 3081: Loss = 0.4297075867652893
Iteration 3082: Loss = 0.42970743775367737
Iteration 3083: Loss = 0.4297073483467102
Iteration 3084: Loss = 0.4297073185443878
Iteration 3085: Loss = 0.42970722913742065
Iteration 3086: Loss = 0.42970702052116394
Iteration 3087: Loss = 0.4297069311141968
Iteration 3088: Loss = 0.4297069013118744
Iteration 3089: Loss = 0.42970672249794006
Iteration 3090: Loss = 0.4297066628932953
Iteration 3091: Loss = 0.42970654368400574
Iteration 3092: Loss = 0.4297063946723938
Iteration 3093: Loss = 0.42970630526542664
Iteration 3094: Loss = 0.4297062158584595
Iteration 3095: Loss = 0.4297061562538147
Iteration 3096: Loss = 0.42970600724220276
Iteration 3097: Loss = 0.4297058880329132
Iteration 3098: Loss = 0.42970576882362366
Iteration 3099: Loss = 0.4297056794166565
Iteration 3100: Loss = 0.42970559000968933
Iteration 3101: Loss = 0.42970553040504456
Iteration 3102: Loss = 0.42970532178878784
Iteration 3103: Loss = 0.42970529198646545
Iteration 3104: Loss = 0.4297051727771759
Iteration 3105: Loss = 0.42970502376556396
Iteration 3106: Loss = 0.4297049641609192
Iteration 3107: Loss = 0.42970481514930725
Iteration 3108: Loss = 0.4297047257423401
Iteration 3109: Loss = 0.42970460653305054
Iteration 3110: Loss = 0.4297045171260834
Iteration 3111: Loss = 0.4297043979167938
Iteration 3112: Loss = 0.4297042787075043
Iteration 3113: Loss = 0.4297041893005371
Iteration 3114: Loss = 0.42970409989356995
Iteration 3115: Loss = 0.4297039806842804
Iteration 3116: Loss = 0.42970386147499084
Iteration 3117: Loss = 0.4297037422657013
Iteration 3118: Loss = 0.4297036826610565
Iteration 3119: Loss = 0.4297035336494446
Iteration 3120: Loss = 0.4297034740447998
Iteration 3121: Loss = 0.42970332503318787
Iteration 3122: Loss = 0.4297032058238983
Iteration 3123: Loss = 0.42970314621925354
Iteration 3124: Loss = 0.4297029972076416
Iteration 3125: Loss = 0.42970290780067444
Iteration 3126: Loss = 0.4297028183937073
Iteration 3127: Loss = 0.42970266938209534
Iteration 3128: Loss = 0.4297025799751282
Iteration 3129: Loss = 0.4297024607658386
Iteration 3130: Loss = 0.4297023415565491
Iteration 3131: Loss = 0.4297022521495819
Iteration 3132: Loss = 0.42970219254493713
Iteration 3133: Loss = 0.4297020435333252
Iteration 3134: Loss = 0.42970189452171326
Iteration 3135: Loss = 0.4297018349170685
Iteration 3136: Loss = 0.42970171570777893
Iteration 3137: Loss = 0.4297015964984894
Iteration 3138: Loss = 0.42970147728919983
Iteration 3139: Loss = 0.42970141768455505
Iteration 3140: Loss = 0.4297013282775879
Iteration 3141: Loss = 0.42970117926597595
Iteration 3142: Loss = 0.4297010898590088
Iteration 3143: Loss = 0.42970094084739685
Iteration 3144: Loss = 0.4297008216381073
Iteration 3145: Loss = 0.4297007620334625
Iteration 3146: Loss = 0.429700642824173
Iteration 3147: Loss = 0.4297005534172058
Iteration 3148: Loss = 0.42970040440559387
Iteration 3149: Loss = 0.4297003149986267
Iteration 3150: Loss = 0.42970016598701477
Iteration 3151: Loss = 0.4297000765800476
Iteration 3152: Loss = 0.42969998717308044
Iteration 3153: Loss = 0.4296998977661133
Iteration 3154: Loss = 0.4296998083591461
Iteration 3155: Loss = 0.4296996593475342
Iteration 3156: Loss = 0.4296995997428894
Iteration 3157: Loss = 0.4296994209289551
Iteration 3158: Loss = 0.4296993613243103
Iteration 3159: Loss = 0.42969921231269836
Iteration 3160: Loss = 0.4296991527080536
Iteration 3161: Loss = 0.4296990633010864
Iteration 3162: Loss = 0.4296989142894745
Iteration 3163: Loss = 0.42969879508018494
Iteration 3164: Loss = 0.42969873547554016
Iteration 3165: Loss = 0.42969855666160583
Iteration 3166: Loss = 0.42969852685928345
Iteration 3167: Loss = 0.4296983778476715
Iteration 3168: Loss = 0.42969825863838196
Iteration 3169: Loss = 0.4296981692314148
Iteration 3170: Loss = 0.42969805002212524
Iteration 3171: Loss = 0.4296979010105133
Iteration 3172: Loss = 0.42969781160354614
Iteration 3173: Loss = 0.429697722196579
Iteration 3174: Loss = 0.42969760298728943
Iteration 3175: Loss = 0.42969754338264465
Iteration 3176: Loss = 0.4296973943710327
Iteration 3177: Loss = 0.42969727516174316
Iteration 3178: Loss = 0.429697185754776
Iteration 3179: Loss = 0.42969709634780884
Iteration 3180: Loss = 0.4296968877315521
Iteration 3181: Loss = 0.42969682812690735
Iteration 3182: Loss = 0.4296967089176178
Iteration 3183: Loss = 0.42969661951065063
Iteration 3184: Loss = 0.4296964704990387
Iteration 3185: Loss = 0.42969638109207153
Iteration 3186: Loss = 0.429696261882782
Iteration 3187: Loss = 0.4296961724758148
Iteration 3188: Loss = 0.42969611287117004
Iteration 3189: Loss = 0.4296959638595581
Iteration 3190: Loss = 0.42969587445259094
Iteration 3191: Loss = 0.4296957850456238
Iteration 3192: Loss = 0.42969560623168945
Iteration 3193: Loss = 0.4296955168247223
Iteration 3194: Loss = 0.42969539761543274
Iteration 3195: Loss = 0.4296953082084656
Iteration 3196: Loss = 0.429695188999176
Iteration 3197: Loss = 0.42969509959220886
Iteration 3198: Loss = 0.4296949803829193
Iteration 3199: Loss = 0.42969489097595215
Iteration 3200: Loss = 0.4296947419643402
Iteration 3201: Loss = 0.42969462275505066
Iteration 3202: Loss = 0.4296945631504059
Iteration 3203: Loss = 0.42969441413879395
Iteration 3204: Loss = 0.4296942949295044
Iteration 3205: Loss = 0.42969420552253723
Iteration 3206: Loss = 0.4296940863132477
Iteration 3207: Loss = 0.42969393730163574
Iteration 3208: Loss = 0.4296938478946686
Iteration 3209: Loss = 0.4296937882900238
Iteration 3210: Loss = 0.4296936094760895
Iteration 3211: Loss = 0.4296935498714447
Iteration 3212: Loss = 0.42969340085983276
Iteration 3213: Loss = 0.4296933114528656
Iteration 3214: Loss = 0.42969319224357605
Iteration 3215: Loss = 0.4296930730342865
Iteration 3216: Loss = 0.42969295382499695
Iteration 3217: Loss = 0.429692804813385
Iteration 3218: Loss = 0.42969274520874023
Iteration 3219: Loss = 0.4296926259994507
Iteration 3220: Loss = 0.42969250679016113
Iteration 3221: Loss = 0.4296923875808716
Iteration 3222: Loss = 0.4296922981739044
Iteration 3223: Loss = 0.42969220876693726
Iteration 3224: Loss = 0.4296921193599701
Iteration 3225: Loss = 0.4296919107437134
Iteration 3226: Loss = 0.42969179153442383
Iteration 3227: Loss = 0.42969170212745667
Iteration 3228: Loss = 0.4296916425228119
Iteration 3229: Loss = 0.42969149351119995
Iteration 3230: Loss = 0.4296913743019104
Iteration 3231: Loss = 0.4296913146972656
Iteration 3232: Loss = 0.4296911656856537
Iteration 3233: Loss = 0.42969104647636414
Iteration 3234: Loss = 0.429690957069397
Iteration 3235: Loss = 0.42969080805778503
Iteration 3236: Loss = 0.42969071865081787
Iteration 3237: Loss = 0.42969056963920593
Iteration 3238: Loss = 0.42969048023223877
Iteration 3239: Loss = 0.4296903908252716
Iteration 3240: Loss = 0.42969024181365967
Iteration 3241: Loss = 0.4296901524066925
Iteration 3242: Loss = 0.42969003319740295
Iteration 3243: Loss = 0.4296899437904358
Iteration 3244: Loss = 0.42968979477882385
Iteration 3245: Loss = 0.4296897053718567
Iteration 3246: Loss = 0.42968952655792236
Iteration 3247: Loss = 0.4296894967556
Iteration 3248: Loss = 0.42968928813934326
Iteration 3249: Loss = 0.4296891987323761
Iteration 3250: Loss = 0.4296891391277313
Iteration 3251: Loss = 0.4296889901161194
Iteration 3252: Loss = 0.4296889007091522
Iteration 3253: Loss = 0.42968878149986267
Iteration 3254: Loss = 0.4296886622905731
Iteration 3255: Loss = 0.42968860268592834
Iteration 3256: Loss = 0.4296884536743164
Iteration 3257: Loss = 0.4296882748603821
Iteration 3258: Loss = 0.4296882152557373
Iteration 3259: Loss = 0.42968806624412537
Iteration 3260: Loss = 0.4296879470348358
Iteration 3261: Loss = 0.42968785762786865
Iteration 3262: Loss = 0.4296876788139343
Iteration 3263: Loss = 0.42968761920928955
Iteration 3264: Loss = 0.4296875
Iteration 3265: Loss = 0.42968738079071045
Iteration 3266: Loss = 0.4296872913837433
Iteration 3267: Loss = 0.4296872019767761
Iteration 3268: Loss = 0.4296870529651642
Iteration 3269: Loss = 0.429686963558197
Iteration 3270: Loss = 0.42968684434890747
Iteration 3271: Loss = 0.42968669533729553
Iteration 3272: Loss = 0.42968663573265076
Iteration 3273: Loss = 0.4296865165233612
Iteration 3274: Loss = 0.4296863377094269
Iteration 3275: Loss = 0.42968621850013733
Iteration 3276: Loss = 0.42968615889549255
Iteration 3277: Loss = 0.429686039686203
Iteration 3278: Loss = 0.4296859800815582
Iteration 3279: Loss = 0.4296857714653015
Iteration 3280: Loss = 0.42968568205833435
Iteration 3281: Loss = 0.4296855330467224
Iteration 3282: Loss = 0.4296853840351105
Iteration 3283: Loss = 0.4296852946281433
Iteration 3284: Loss = 0.42968520522117615
Iteration 3285: Loss = 0.4296850562095642
Iteration 3286: Loss = 0.42968499660491943
Iteration 3287: Loss = 0.4296848773956299
Iteration 3288: Loss = 0.42968475818634033
Iteration 3289: Loss = 0.4296846389770508
Iteration 3290: Loss = 0.4296845495700836
Iteration 3291: Loss = 0.4296844005584717
Iteration 3292: Loss = 0.42968425154685974
Iteration 3293: Loss = 0.4296841323375702
Iteration 3294: Loss = 0.42968401312828064
Iteration 3295: Loss = 0.4296839237213135
Iteration 3296: Loss = 0.4296838343143463
Iteration 3297: Loss = 0.42968371510505676
Iteration 3298: Loss = 0.4296835958957672
Iteration 3299: Loss = 0.42968347668647766
Iteration 3300: Loss = 0.4296833872795105
Iteration 3301: Loss = 0.42968326807022095
Iteration 3302: Loss = 0.4296831786632538
Iteration 3303: Loss = 0.42968297004699707
Iteration 3304: Loss = 0.4296828508377075
Iteration 3305: Loss = 0.42968276143074036
Iteration 3306: Loss = 0.4296826422214508
Iteration 3307: Loss = 0.42968255281448364
Iteration 3308: Loss = 0.4296824038028717
Iteration 3309: Loss = 0.42968231439590454
Iteration 3310: Loss = 0.429682195186615
Iteration 3311: Loss = 0.42968207597732544
Iteration 3312: Loss = 0.4296819567680359
Iteration 3313: Loss = 0.42968183755874634
Iteration 3314: Loss = 0.4296816885471344
Iteration 3315: Loss = 0.42968159914016724
Iteration 3316: Loss = 0.4296814799308777
Iteration 3317: Loss = 0.42968133091926575
Iteration 3318: Loss = 0.42968127131462097
Iteration 3319: Loss = 0.42968109250068665
Iteration 3320: Loss = 0.4296810030937195
Iteration 3321: Loss = 0.42968085408210754
Iteration 3322: Loss = 0.4296807646751404
Iteration 3323: Loss = 0.4296806752681732
Iteration 3324: Loss = 0.4296805262565613
Iteration 3325: Loss = 0.42968040704727173
Iteration 3326: Loss = 0.42968031764030457
Iteration 3327: Loss = 0.4296801686286926
Iteration 3328: Loss = 0.4296800494194031
Iteration 3329: Loss = 0.4296799600124359
Iteration 3330: Loss = 0.429679811000824
Iteration 3331: Loss = 0.4296797513961792
Iteration 3332: Loss = 0.4296795725822449
Iteration 3333: Loss = 0.4296794831752777
Iteration 3334: Loss = 0.42967933416366577
Iteration 3335: Loss = 0.429679274559021
Iteration 3336: Loss = 0.42967909574508667
Iteration 3337: Loss = 0.4296790063381195
Iteration 3338: Loss = 0.42967888712882996
Iteration 3339: Loss = 0.42967870831489563
Iteration 3340: Loss = 0.42967864871025085
Iteration 3341: Loss = 0.4296785593032837
Iteration 3342: Loss = 0.42967841029167175
Iteration 3343: Loss = 0.4296782910823822
Iteration 3344: Loss = 0.42967817187309265
Iteration 3345: Loss = 0.4296781122684479
Iteration 3346: Loss = 0.4296779930591583
Iteration 3347: Loss = 0.4296778440475464
Iteration 3348: Loss = 0.42967769503593445
Iteration 3349: Loss = 0.4296775460243225
Iteration 3350: Loss = 0.42967748641967773
Iteration 3351: Loss = 0.4296773672103882
Iteration 3352: Loss = 0.42967721819877625
Iteration 3353: Loss = 0.4296771287918091
Iteration 3354: Loss = 0.42967694997787476
Iteration 3355: Loss = 0.4296768605709076
Iteration 3356: Loss = 0.42967674136161804
Iteration 3357: Loss = 0.4296766221523285
Iteration 3358: Loss = 0.42967650294303894
Iteration 3359: Loss = 0.4296763837337494
Iteration 3360: Loss = 0.4296762943267822
Iteration 3361: Loss = 0.4296761751174927
Iteration 3362: Loss = 0.42967602610588074
Iteration 3363: Loss = 0.4296759366989136
Iteration 3364: Loss = 0.429675817489624
Iteration 3365: Loss = 0.4296756386756897
Iteration 3366: Loss = 0.42967554926872253
Iteration 3367: Loss = 0.4296754002571106
Iteration 3368: Loss = 0.42967525124549866
Iteration 3369: Loss = 0.4296751618385315
Iteration 3370: Loss = 0.42967504262924194
Iteration 3371: Loss = 0.4296749532222748
Iteration 3372: Loss = 0.42967480421066284
Iteration 3373: Loss = 0.4296747148036957
Iteration 3374: Loss = 0.4296746253967285
Iteration 3375: Loss = 0.4296744763851166
Iteration 3376: Loss = 0.429674357175827
Iteration 3377: Loss = 0.4296742379665375
Iteration 3378: Loss = 0.42967408895492554
Iteration 3379: Loss = 0.429673969745636
Iteration 3380: Loss = 0.42967385053634644
Iteration 3381: Loss = 0.4296737313270569
Iteration 3382: Loss = 0.42967361211776733
Iteration 3383: Loss = 0.4296734929084778
Iteration 3384: Loss = 0.42967334389686584
Iteration 3385: Loss = 0.4296732544898987
Iteration 3386: Loss = 0.42967313528060913
Iteration 3387: Loss = 0.4296730160713196
Iteration 3388: Loss = 0.4296729266643524
Iteration 3389: Loss = 0.4296727478504181
Iteration 3390: Loss = 0.42967259883880615
Iteration 3391: Loss = 0.4296725392341614
Iteration 3392: Loss = 0.4296724200248718
Iteration 3393: Loss = 0.4296723008155823
Iteration 3394: Loss = 0.42967215180397034
Iteration 3395: Loss = 0.4296720623970032
Iteration 3396: Loss = 0.42967188358306885
Iteration 3397: Loss = 0.4296717345714569
Iteration 3398: Loss = 0.42967167496681213
Iteration 3399: Loss = 0.4296715259552002
Iteration 3400: Loss = 0.42967143654823303
Iteration 3401: Loss = 0.4296712875366211
Iteration 3402: Loss = 0.42967113852500916
Iteration 3403: Loss = 0.429671049118042
Iteration 3404: Loss = 0.42967092990875244
Iteration 3405: Loss = 0.4296708106994629
Iteration 3406: Loss = 0.4296707212924957
Iteration 3407: Loss = 0.4296705722808838
Iteration 3408: Loss = 0.42967042326927185
Iteration 3409: Loss = 0.4296703040599823
Iteration 3410: Loss = 0.42967018485069275
Iteration 3411: Loss = 0.4296700060367584
Iteration 3412: Loss = 0.42966994643211365
Iteration 3413: Loss = 0.4296698570251465
Iteration 3414: Loss = 0.42966967821121216
Iteration 3415: Loss = 0.429669588804245
Iteration 3416: Loss = 0.42966943979263306
Iteration 3417: Loss = 0.4296693205833435
Iteration 3418: Loss = 0.42966920137405396
Iteration 3419: Loss = 0.4296691119670868
Iteration 3420: Loss = 0.42966893315315247
Iteration 3421: Loss = 0.4296688139438629
Iteration 3422: Loss = 0.42966872453689575
Iteration 3423: Loss = 0.4296685755252838
Iteration 3424: Loss = 0.42966845631599426
Iteration 3425: Loss = 0.4296683371067047
Iteration 3426: Loss = 0.42966821789741516
Iteration 3427: Loss = 0.42966803908348083
Iteration 3428: Loss = 0.42966800928115845
Iteration 3429: Loss = 0.4296678304672241
Iteration 3430: Loss = 0.42966771125793457
Iteration 3431: Loss = 0.42966756224632263
Iteration 3432: Loss = 0.4296674430370331
Iteration 3433: Loss = 0.4296673536300659
Iteration 3434: Loss = 0.4296671748161316
Iteration 3435: Loss = 0.42966705560684204
Iteration 3436: Loss = 0.42966699600219727
Iteration 3437: Loss = 0.4296668469905853
Iteration 3438: Loss = 0.4296667277812958
Iteration 3439: Loss = 0.42966657876968384
Iteration 3440: Loss = 0.4296664297580719
Iteration 3441: Loss = 0.42966634035110474
Iteration 3442: Loss = 0.4296661913394928
Iteration 3443: Loss = 0.42966610193252563
Iteration 3444: Loss = 0.4296659529209137
Iteration 3445: Loss = 0.42966586351394653
Iteration 3446: Loss = 0.429665744304657
Iteration 3447: Loss = 0.42966556549072266
Iteration 3448: Loss = 0.4296654760837555
Iteration 3449: Loss = 0.42966535687446594
Iteration 3450: Loss = 0.429665207862854
Iteration 3451: Loss = 0.42966511845588684
Iteration 3452: Loss = 0.4296649694442749
Iteration 3453: Loss = 0.42966485023498535
Iteration 3454: Loss = 0.4296647310256958
Iteration 3455: Loss = 0.42966458201408386
Iteration 3456: Loss = 0.4296644330024719
Iteration 3457: Loss = 0.42966434359550476
Iteration 3458: Loss = 0.4296642243862152
Iteration 3459: Loss = 0.42966407537460327
Iteration 3460: Loss = 0.42966392636299133
Iteration 3461: Loss = 0.4296638071537018
Iteration 3462: Loss = 0.42966368794441223
Iteration 3463: Loss = 0.4296635389328003
Iteration 3464: Loss = 0.42966341972351074
Iteration 3465: Loss = 0.4296633303165436
Iteration 3466: Loss = 0.42966318130493164
Iteration 3467: Loss = 0.4296630620956421
Iteration 3468: Loss = 0.4296629726886749
Iteration 3469: Loss = 0.429662823677063
Iteration 3470: Loss = 0.42966267466545105
Iteration 3471: Loss = 0.4296625554561615
Iteration 3472: Loss = 0.42966243624687195
Iteration 3473: Loss = 0.4296623170375824
Iteration 3474: Loss = 0.42966219782829285
Iteration 3475: Loss = 0.4296620488166809
Iteration 3476: Loss = 0.42966192960739136
Iteration 3477: Loss = 0.4296617805957794
Iteration 3478: Loss = 0.42966169118881226
Iteration 3479: Loss = 0.4296615719795227
Iteration 3480: Loss = 0.4296613931655884
Iteration 3481: Loss = 0.42966127395629883
Iteration 3482: Loss = 0.4296611249446869
Iteration 3483: Loss = 0.4296610355377197
Iteration 3484: Loss = 0.4296608865261078
Iteration 3485: Loss = 0.429660826921463
Iteration 3486: Loss = 0.4296606481075287
Iteration 3487: Loss = 0.42966052889823914
Iteration 3488: Loss = 0.4296604096889496
Iteration 3489: Loss = 0.42966026067733765
Iteration 3490: Loss = 0.4296601414680481
Iteration 3491: Loss = 0.42966002225875854
Iteration 3492: Loss = 0.4296598732471466
Iteration 3493: Loss = 0.42965972423553467
Iteration 3494: Loss = 0.4296596050262451
Iteration 3495: Loss = 0.42965948581695557
Iteration 3496: Loss = 0.42965933680534363
Iteration 3497: Loss = 0.42965924739837646
Iteration 3498: Loss = 0.4296591281890869
Iteration 3499: Loss = 0.429658979177475
Iteration 3500: Loss = 0.42965877056121826
Iteration 3501: Loss = 0.42965877056121826
Iteration 3502: Loss = 0.42965856194496155
Iteration 3503: Loss = 0.429658442735672
Iteration 3504: Loss = 0.42965832352638245
Iteration 3505: Loss = 0.4296582341194153
Iteration 3506: Loss = 0.42965808510780334
Iteration 3507: Loss = 0.4296579658985138
Iteration 3508: Loss = 0.42965781688690186
Iteration 3509: Loss = 0.4296576678752899
Iteration 3510: Loss = 0.42965754866600037
Iteration 3511: Loss = 0.4296574294567108
Iteration 3512: Loss = 0.4296572208404541
Iteration 3513: Loss = 0.42965713143348694
Iteration 3514: Loss = 0.4296570420265198
Iteration 3515: Loss = 0.42965689301490784
Iteration 3516: Loss = 0.4296568036079407
Iteration 3517: Loss = 0.4296567142009735
Iteration 3518: Loss = 0.4296565055847168
Iteration 3519: Loss = 0.42965632677078247
Iteration 3520: Loss = 0.4296562373638153
Iteration 3521: Loss = 0.42965611815452576
Iteration 3522: Loss = 0.4296559989452362
Iteration 3523: Loss = 0.42965584993362427
Iteration 3524: Loss = 0.4296557903289795
Iteration 3525: Loss = 0.42965567111968994
Iteration 3526: Loss = 0.4296554923057556
Iteration 3527: Loss = 0.42965540289878845
Iteration 3528: Loss = 0.4296552240848541
Iteration 3529: Loss = 0.4296550452709198
Iteration 3530: Loss = 0.42965492606163025
Iteration 3531: Loss = 0.4296548068523407
Iteration 3532: Loss = 0.42965468764305115
Iteration 3533: Loss = 0.4296545684337616
Iteration 3534: Loss = 0.42965444922447205
Iteration 3535: Loss = 0.4296543002128601
Iteration 3536: Loss = 0.42965424060821533
Iteration 3537: Loss = 0.4296540915966034
Iteration 3538: Loss = 0.42965391278266907
Iteration 3539: Loss = 0.4296538233757019
Iteration 3540: Loss = 0.4296536147594452
Iteration 3541: Loss = 0.429653525352478
Iteration 3542: Loss = 0.4296533763408661
Iteration 3543: Loss = 0.42965325713157654
Iteration 3544: Loss = 0.4296531081199646
Iteration 3545: Loss = 0.42965295910835266
Iteration 3546: Loss = 0.4296528697013855
Iteration 3547: Loss = 0.42965275049209595
Iteration 3548: Loss = 0.429652601480484
Iteration 3549: Loss = 0.42965248227119446
Iteration 3550: Loss = 0.42965230345726013
Iteration 3551: Loss = 0.42965221405029297
Iteration 3552: Loss = 0.42965206503868103
Iteration 3553: Loss = 0.4296519458293915
Iteration 3554: Loss = 0.42965182662010193
Iteration 3555: Loss = 0.42965167760849
Iteration 3556: Loss = 0.4296515882015228
Iteration 3557: Loss = 0.4296514093875885
Iteration 3558: Loss = 0.42965129017829895
Iteration 3559: Loss = 0.4296511113643646
Iteration 3560: Loss = 0.42965102195739746
Iteration 3561: Loss = 0.42965084314346313
Iteration 3562: Loss = 0.4296506941318512
Iteration 3563: Loss = 0.42965060472488403
Iteration 3564: Loss = 0.4296504557132721
Iteration 3565: Loss = 0.42965033650398254
Iteration 3566: Loss = 0.429650217294693
Iteration 3567: Loss = 0.42965009808540344
Iteration 3568: Loss = 0.4296499490737915
Iteration 3569: Loss = 0.42964982986450195
Iteration 3570: Loss = 0.42964968085289
Iteration 3571: Loss = 0.4296495318412781
Iteration 3572: Loss = 0.42964935302734375
Iteration 3573: Loss = 0.429649293422699
Iteration 3574: Loss = 0.4296491742134094
Iteration 3575: Loss = 0.4296490550041199
Iteration 3576: Loss = 0.42964890599250793
Iteration 3577: Loss = 0.4296486973762512
Iteration 3578: Loss = 0.42964860796928406
Iteration 3579: Loss = 0.4296484589576721
Iteration 3580: Loss = 0.4296483099460602
Iteration 3581: Loss = 0.42964819073677063
Iteration 3582: Loss = 0.42964810132980347
Iteration 3583: Loss = 0.42964795231819153
Iteration 3584: Loss = 0.429647833108902
Iteration 3585: Loss = 0.42964768409729004
Iteration 3586: Loss = 0.4296475350856781
Iteration 3587: Loss = 0.42964738607406616
Iteration 3588: Loss = 0.4296472370624542
Iteration 3589: Loss = 0.4296470880508423
Iteration 3590: Loss = 0.42964696884155273
Iteration 3591: Loss = 0.4296468496322632
Iteration 3592: Loss = 0.429646760225296
Iteration 3593: Loss = 0.4296465814113617
Iteration 3594: Loss = 0.42964643239974976
Iteration 3595: Loss = 0.4296463131904602
Iteration 3596: Loss = 0.42964619398117065
Iteration 3597: Loss = 0.42964601516723633
Iteration 3598: Loss = 0.4296458661556244
Iteration 3599: Loss = 0.4296457767486572
Iteration 3600: Loss = 0.4296456277370453
Iteration 3601: Loss = 0.4296455383300781
Iteration 3602: Loss = 0.4296453595161438
Iteration 3603: Loss = 0.42964527010917664
Iteration 3604: Loss = 0.4296450614929199
Iteration 3605: Loss = 0.42964497208595276
Iteration 3606: Loss = 0.42964479327201843
Iteration 3607: Loss = 0.4296446740627289
Iteration 3608: Loss = 0.42964452505111694
Iteration 3609: Loss = 0.4296444356441498
Iteration 3610: Loss = 0.42964428663253784
Iteration 3611: Loss = 0.4296441674232483
Iteration 3612: Loss = 0.42964401841163635
Iteration 3613: Loss = 0.4296438694000244
Iteration 3614: Loss = 0.42964375019073486
Iteration 3615: Loss = 0.42964357137680054
Iteration 3616: Loss = 0.4296434819698334
Iteration 3617: Loss = 0.42964333295822144
Iteration 3618: Loss = 0.4296431839466095
Iteration 3619: Loss = 0.42964303493499756
Iteration 3620: Loss = 0.4296428859233856
Iteration 3621: Loss = 0.42964279651641846
Iteration 3622: Loss = 0.42964261770248413
Iteration 3623: Loss = 0.42964252829551697
Iteration 3624: Loss = 0.42964231967926025
Iteration 3625: Loss = 0.4296422004699707
Iteration 3626: Loss = 0.42964208126068115
Iteration 3627: Loss = 0.4296419620513916
Iteration 3628: Loss = 0.4296417832374573
Iteration 3629: Loss = 0.4296416938304901
Iteration 3630: Loss = 0.4296415448188782
Iteration 3631: Loss = 0.42964136600494385
Iteration 3632: Loss = 0.4296412765979767
Iteration 3633: Loss = 0.42964115738868713
Iteration 3634: Loss = 0.4296409487724304
Iteration 3635: Loss = 0.42964085936546326
Iteration 3636: Loss = 0.42964068055152893
Iteration 3637: Loss = 0.4296405613422394
Iteration 3638: Loss = 0.42964041233062744
Iteration 3639: Loss = 0.4296402931213379
Iteration 3640: Loss = 0.4296402037143707
Iteration 3641: Loss = 0.4296400249004364
Iteration 3642: Loss = 0.42963990569114685
Iteration 3643: Loss = 0.42963969707489014
Iteration 3644: Loss = 0.429639607667923
Iteration 3645: Loss = 0.42963945865631104
Iteration 3646: Loss = 0.4296393096446991
Iteration 3647: Loss = 0.42963922023773193
Iteration 3648: Loss = 0.42963907122612
Iteration 3649: Loss = 0.42963892221450806
Iteration 3650: Loss = 0.42963874340057373
Iteration 3651: Loss = 0.4296386241912842
Iteration 3652: Loss = 0.42963850498199463
Iteration 3653: Loss = 0.4296383559703827
Iteration 3654: Loss = 0.42963817715644836
Iteration 3655: Loss = 0.4296380877494812
Iteration 3656: Loss = 0.42963793873786926
Iteration 3657: Loss = 0.4296378195285797
Iteration 3658: Loss = 0.4296376407146454
Iteration 3659: Loss = 0.42963749170303345
Iteration 3660: Loss = 0.4296374022960663
Iteration 3661: Loss = 0.42963719367980957
Iteration 3662: Loss = 0.4296371042728424
Iteration 3663: Loss = 0.42963701486587524
Iteration 3664: Loss = 0.4296368360519409
Iteration 3665: Loss = 0.429636687040329
Iteration 3666: Loss = 0.42963653802871704
Iteration 3667: Loss = 0.4296364188194275
Iteration 3668: Loss = 0.42963626980781555
Iteration 3669: Loss = 0.429636150598526
Iteration 3670: Loss = 0.4296359717845917
Iteration 3671: Loss = 0.4296358525753021
Iteration 3672: Loss = 0.4296357035636902
Iteration 3673: Loss = 0.42963555455207825
Iteration 3674: Loss = 0.4296354353427887
Iteration 3675: Loss = 0.42963528633117676
Iteration 3676: Loss = 0.4296351671218872
Iteration 3677: Loss = 0.42963501811027527
Iteration 3678: Loss = 0.4296348989009857
Iteration 3679: Loss = 0.429634690284729
Iteration 3680: Loss = 0.42963457107543945
Iteration 3681: Loss = 0.4296344816684723
Iteration 3682: Loss = 0.42963430285453796
Iteration 3683: Loss = 0.429634153842926
Iteration 3684: Loss = 0.4296340048313141
Iteration 3685: Loss = 0.42963388562202454
Iteration 3686: Loss = 0.4296337068080902
Iteration 3687: Loss = 0.42963358759880066
Iteration 3688: Loss = 0.4296334981918335
Iteration 3689: Loss = 0.4296332895755768
Iteration 3690: Loss = 0.4296332001686096
Iteration 3691: Loss = 0.4296330213546753
Iteration 3692: Loss = 0.42963287234306335
Iteration 3693: Loss = 0.4296327531337738
Iteration 3694: Loss = 0.42963263392448425
Iteration 3695: Loss = 0.4296324551105499
Iteration 3696: Loss = 0.429632306098938
Iteration 3697: Loss = 0.4296322166919708
Iteration 3698: Loss = 0.4296320080757141
Iteration 3699: Loss = 0.42963188886642456
Iteration 3700: Loss = 0.429631769657135
Iteration 3701: Loss = 0.4296315908432007
Iteration 3702: Loss = 0.42963147163391113
Iteration 3703: Loss = 0.4296312928199768
Iteration 3704: Loss = 0.42963114380836487
Iteration 3705: Loss = 0.4296310544013977
Iteration 3706: Loss = 0.429630845785141
Iteration 3707: Loss = 0.4296307861804962
Iteration 3708: Loss = 0.4296305477619171
Iteration 3709: Loss = 0.42963048815727234
Iteration 3710: Loss = 0.4296302795410156
Iteration 3711: Loss = 0.42963019013404846
Iteration 3712: Loss = 0.4296300709247589
Iteration 3713: Loss = 0.4296298921108246
Iteration 3714: Loss = 0.42962974309921265
Iteration 3715: Loss = 0.4296295642852783
Iteration 3716: Loss = 0.42962944507598877
Iteration 3717: Loss = 0.42962929606437683
Iteration 3718: Loss = 0.42962920665740967
Iteration 3719: Loss = 0.42962902784347534
Iteration 3720: Loss = 0.4296288788318634
Iteration 3721: Loss = 0.42962872982025146
Iteration 3722: Loss = 0.4296286106109619
Iteration 3723: Loss = 0.4296284317970276
Iteration 3724: Loss = 0.42962831258773804
Iteration 3725: Loss = 0.4296281635761261
Iteration 3726: Loss = 0.4296279847621918
Iteration 3727: Loss = 0.4296278655529022
Iteration 3728: Loss = 0.4296277165412903
Iteration 3729: Loss = 0.42962756752967834
Iteration 3730: Loss = 0.4296274483203888
Iteration 3731: Loss = 0.42962729930877686
Iteration 3732: Loss = 0.4296271502971649
Iteration 3733: Loss = 0.429627001285553
Iteration 3734: Loss = 0.42962685227394104
Iteration 3735: Loss = 0.4296266734600067
Iteration 3736: Loss = 0.42962655425071716
Iteration 3737: Loss = 0.4296264350414276
Iteration 3738: Loss = 0.4296262860298157
Iteration 3739: Loss = 0.42962613701820374
Iteration 3740: Loss = 0.4296259880065918
Iteration 3741: Loss = 0.42962589859962463
Iteration 3742: Loss = 0.42962566018104553
Iteration 3743: Loss = 0.429625540971756
Iteration 3744: Loss = 0.42962536215782166
Iteration 3745: Loss = 0.4296252429485321
Iteration 3746: Loss = 0.42962509393692017
Iteration 3747: Loss = 0.4296249449253082
Iteration 3748: Loss = 0.4296248257160187
Iteration 3749: Loss = 0.42962464690208435
Iteration 3750: Loss = 0.4296245276927948
Iteration 3751: Loss = 0.42962437868118286
Iteration 3752: Loss = 0.42962419986724854
Iteration 3753: Loss = 0.429624080657959
Iteration 3754: Loss = 0.42962396144866943
Iteration 3755: Loss = 0.4296237826347351
Iteration 3756: Loss = 0.42962363362312317
Iteration 3757: Loss = 0.4296235144138336
Iteration 3758: Loss = 0.4296233057975769
Iteration 3759: Loss = 0.42962321639060974
Iteration 3760: Loss = 0.4296230375766754
Iteration 3761: Loss = 0.4296228885650635
Iteration 3762: Loss = 0.42962273955345154
Iteration 3763: Loss = 0.429622620344162
Iteration 3764: Loss = 0.42962247133255005
Iteration 3765: Loss = 0.4296222925186157
Iteration 3766: Loss = 0.42962220311164856
Iteration 3767: Loss = 0.4296220541000366
Iteration 3768: Loss = 0.4296218454837799
Iteration 3769: Loss = 0.42962169647216797
Iteration 3770: Loss = 0.4296215772628784
Iteration 3771: Loss = 0.4296213984489441
Iteration 3772: Loss = 0.42962127923965454
Iteration 3773: Loss = 0.4296211004257202
Iteration 3774: Loss = 0.42962098121643066
Iteration 3775: Loss = 0.4296208322048187
Iteration 3776: Loss = 0.429620623588562
Iteration 3777: Loss = 0.42962050437927246
Iteration 3778: Loss = 0.4296203851699829
Iteration 3779: Loss = 0.42962023615837097
Iteration 3780: Loss = 0.42962005734443665
Iteration 3781: Loss = 0.4296199381351471
Iteration 3782: Loss = 0.42961981892585754
Iteration 3783: Loss = 0.4296196401119232
Iteration 3784: Loss = 0.4296194314956665
Iteration 3785: Loss = 0.42961931228637695
Iteration 3786: Loss = 0.4296191930770874
Iteration 3787: Loss = 0.4296190142631531
Iteration 3788: Loss = 0.4296188950538635
Iteration 3789: Loss = 0.4296187460422516
Iteration 3790: Loss = 0.42961856722831726
Iteration 3791: Loss = 0.4296184480190277
Iteration 3792: Loss = 0.4296182692050934
Iteration 3793: Loss = 0.42961814999580383
Iteration 3794: Loss = 0.4296180009841919
Iteration 3795: Loss = 0.42961782217025757
Iteration 3796: Loss = 0.429617702960968
Iteration 3797: Loss = 0.4296175241470337
Iteration 3798: Loss = 0.42961737513542175
Iteration 3799: Loss = 0.4296172261238098
Iteration 3800: Loss = 0.42961710691452026
Iteration 3801: Loss = 0.4296169877052307
Iteration 3802: Loss = 0.4296167492866516
Iteration 3803: Loss = 0.4296166002750397
Iteration 3804: Loss = 0.4296164810657501
Iteration 3805: Loss = 0.4296162724494934
Iteration 3806: Loss = 0.42961621284484863
Iteration 3807: Loss = 0.4296160340309143
Iteration 3808: Loss = 0.42961588501930237
Iteration 3809: Loss = 0.42961573600769043
Iteration 3810: Loss = 0.4296155273914337
Iteration 3811: Loss = 0.4296153783798218
Iteration 3812: Loss = 0.42961522936820984
Iteration 3813: Loss = 0.4296150803565979
Iteration 3814: Loss = 0.42961499094963074
Iteration 3815: Loss = 0.4296148121356964
Iteration 3816: Loss = 0.4296146631240845
Iteration 3817: Loss = 0.4296145439147949
Iteration 3818: Loss = 0.4296143651008606
Iteration 3819: Loss = 0.4296141564846039
Iteration 3820: Loss = 0.42961400747299194
Iteration 3821: Loss = 0.4296138882637024
Iteration 3822: Loss = 0.42961370944976807
Iteration 3823: Loss = 0.4296136200428009
Iteration 3824: Loss = 0.4296134412288666
Iteration 3825: Loss = 0.42961326241493225
Iteration 3826: Loss = 0.4296130836009979
Iteration 3827: Loss = 0.42961299419403076
Iteration 3828: Loss = 0.42961278557777405
Iteration 3829: Loss = 0.4296126365661621
Iteration 3830: Loss = 0.42961251735687256
Iteration 3831: Loss = 0.42961230874061584
Iteration 3832: Loss = 0.4296121895313263
Iteration 3833: Loss = 0.42961204051971436
Iteration 3834: Loss = 0.4296118915081024
Iteration 3835: Loss = 0.4296117424964905
Iteration 3836: Loss = 0.42961156368255615
Iteration 3837: Loss = 0.4296114444732666
Iteration 3838: Loss = 0.4296112656593323
Iteration 3839: Loss = 0.4296111464500427
Iteration 3840: Loss = 0.4296109974384308
Iteration 3841: Loss = 0.42961084842681885
Iteration 3842: Loss = 0.4296106696128845
Iteration 3843: Loss = 0.4296104907989502
Iteration 3844: Loss = 0.42961037158966064
Iteration 3845: Loss = 0.42961013317108154
Iteration 3846: Loss = 0.4296100437641144
Iteration 3847: Loss = 0.42960989475250244
Iteration 3848: Loss = 0.4296096861362457
Iteration 3849: Loss = 0.4296095669269562
Iteration 3850: Loss = 0.42960941791534424
Iteration 3851: Loss = 0.4296092689037323
Iteration 3852: Loss = 0.42960911989212036
Iteration 3853: Loss = 0.42960891127586365
Iteration 3854: Loss = 0.4296087920665741
Iteration 3855: Loss = 0.42960861325263977
Iteration 3856: Loss = 0.42960846424102783
Iteration 3857: Loss = 0.4296083450317383
Iteration 3858: Loss = 0.42960819602012634
Iteration 3859: Loss = 0.42960792779922485
Iteration 3860: Loss = 0.4296078085899353
Iteration 3861: Loss = 0.42960768938064575
Iteration 3862: Loss = 0.4296075701713562
Iteration 3863: Loss = 0.4296073615550995
Iteration 3864: Loss = 0.42960724234580994
Iteration 3865: Loss = 0.4296070635318756
Iteration 3866: Loss = 0.4296068847179413
Iteration 3867: Loss = 0.42960673570632935
Iteration 3868: Loss = 0.429606556892395
Iteration 3869: Loss = 0.42960643768310547
Iteration 3870: Loss = 0.42960625886917114
Iteration 3871: Loss = 0.429606169462204
Iteration 3872: Loss = 0.42960599064826965
Iteration 3873: Loss = 0.4296058118343353
Iteration 3874: Loss = 0.4296056628227234
Iteration 3875: Loss = 0.4296054542064667
Iteration 3876: Loss = 0.4296053647994995
Iteration 3877: Loss = 0.4296052157878876
Iteration 3878: Loss = 0.42960497736930847
Iteration 3879: Loss = 0.4296048581600189
Iteration 3880: Loss = 0.4296046793460846
Iteration 3881: Loss = 0.42960456013679504
Iteration 3882: Loss = 0.4296043813228607
Iteration 3883: Loss = 0.4296042323112488
Iteration 3884: Loss = 0.4296039938926697
Iteration 3885: Loss = 0.4296038746833801
Iteration 3886: Loss = 0.4296037256717682
Iteration 3887: Loss = 0.42960360646247864
Iteration 3888: Loss = 0.4296034574508667
Iteration 3889: Loss = 0.4296032786369324
Iteration 3890: Loss = 0.42960312962532043
Iteration 3891: Loss = 0.4296029806137085
Iteration 3892: Loss = 0.42960280179977417
Iteration 3893: Loss = 0.42960262298583984
Iteration 3894: Loss = 0.4296025037765503
Iteration 3895: Loss = 0.4296022951602936
Iteration 3896: Loss = 0.42960214614868164
Iteration 3897: Loss = 0.4296020269393921
Iteration 3898: Loss = 0.4296018183231354
Iteration 3899: Loss = 0.4296016991138458
Iteration 3900: Loss = 0.4296015501022339
Iteration 3901: Loss = 0.4296013414859772
Iteration 3902: Loss = 0.42960119247436523
Iteration 3903: Loss = 0.4296010434627533
Iteration 3904: Loss = 0.42960086464881897
Iteration 3905: Loss = 0.42960071563720703
Iteration 3906: Loss = 0.4296005666255951
Iteration 3907: Loss = 0.42960041761398315
Iteration 3908: Loss = 0.42960020899772644
Iteration 3909: Loss = 0.4296000897884369
Iteration 3910: Loss = 0.42959991097450256
Iteration 3911: Loss = 0.4295997619628906
Iteration 3912: Loss = 0.4295996129512787
Iteration 3913: Loss = 0.42959943413734436
Iteration 3914: Loss = 0.4295993149280548
Iteration 3915: Loss = 0.4295991063117981
Iteration 3916: Loss = 0.42959898710250854
Iteration 3917: Loss = 0.4295988082885742
Iteration 3918: Loss = 0.4295986294746399
Iteration 3919: Loss = 0.42959845066070557
Iteration 3920: Loss = 0.429598331451416
Iteration 3921: Loss = 0.4295981228351593
Iteration 3922: Loss = 0.42959800362586975
Iteration 3923: Loss = 0.42959776520729065
Iteration 3924: Loss = 0.4295976459980011
Iteration 3925: Loss = 0.42959749698638916
Iteration 3926: Loss = 0.42959731817245483
Iteration 3927: Loss = 0.4295971691608429
Iteration 3928: Loss = 0.42959702014923096
Iteration 3929: Loss = 0.429596871137619
Iteration 3930: Loss = 0.4295967221260071
Iteration 3931: Loss = 0.42959651350975037
Iteration 3932: Loss = 0.4295963644981384
Iteration 3933: Loss = 0.4295961856842041
Iteration 3934: Loss = 0.42959603667259216
Iteration 3935: Loss = 0.4295958876609802
Iteration 3936: Loss = 0.4295957088470459
Iteration 3937: Loss = 0.42959555983543396
Iteration 3938: Loss = 0.42959538102149963
Iteration 3939: Loss = 0.4295951724052429
Iteration 3940: Loss = 0.42959505319595337
Iteration 3941: Loss = 0.42959484457969666
Iteration 3942: Loss = 0.4295947551727295
Iteration 3943: Loss = 0.4295945465564728
Iteration 3944: Loss = 0.42959439754486084
Iteration 3945: Loss = 0.4295942187309265
Iteration 3946: Loss = 0.4295940697193146
Iteration 3947: Loss = 0.42959389090538025
Iteration 3948: Loss = 0.4295937418937683
Iteration 3949: Loss = 0.4295935332775116
Iteration 3950: Loss = 0.42959344387054443
Iteration 3951: Loss = 0.42959320545196533
Iteration 3952: Loss = 0.42959311604499817
Iteration 3953: Loss = 0.42959290742874146
Iteration 3954: Loss = 0.42959269881248474
Iteration 3955: Loss = 0.4295925498008728
Iteration 3956: Loss = 0.42959243059158325
Iteration 3957: Loss = 0.4295922517776489
Iteration 3958: Loss = 0.429592102766037
Iteration 3959: Loss = 0.42959192395210266
Iteration 3960: Loss = 0.42959174513816833
Iteration 3961: Loss = 0.4295916259288788
Iteration 3962: Loss = 0.42959144711494446
Iteration 3963: Loss = 0.4295912981033325
Iteration 3964: Loss = 0.4295910894870758
Iteration 3965: Loss = 0.42959094047546387
Iteration 3966: Loss = 0.4295908212661743
Iteration 3967: Loss = 0.4295906126499176
Iteration 3968: Loss = 0.42959046363830566
Iteration 3969: Loss = 0.42959025502204895
Iteration 3970: Loss = 0.42959004640579224
Iteration 3971: Loss = 0.4295899569988251
Iteration 3972: Loss = 0.42958974838256836
Iteration 3973: Loss = 0.42958956956863403
Iteration 3974: Loss = 0.4295894503593445
Iteration 3975: Loss = 0.42958930134773254
Iteration 3976: Loss = 0.42958909273147583
Iteration 3977: Loss = 0.4295889735221863
Iteration 3978: Loss = 0.42958876490592957
Iteration 3979: Loss = 0.4295886158943176
Iteration 3980: Loss = 0.4295884072780609
Iteration 3981: Loss = 0.42958828806877136
Iteration 3982: Loss = 0.42958810925483704
Iteration 3983: Loss = 0.4295879602432251
Iteration 3984: Loss = 0.42958778142929077
Iteration 3985: Loss = 0.42958763241767883
Iteration 3986: Loss = 0.4295874536037445
Iteration 3987: Loss = 0.4295872449874878
Iteration 3988: Loss = 0.42958709597587585
Iteration 3989: Loss = 0.42958691716194153
Iteration 3990: Loss = 0.4295867681503296
Iteration 3991: Loss = 0.42958661913871765
Iteration 3992: Loss = 0.42958638072013855
Iteration 3993: Loss = 0.4295862317085266
Iteration 3994: Loss = 0.4295860826969147
Iteration 3995: Loss = 0.42958593368530273
Iteration 3996: Loss = 0.4295857548713684
Iteration 3997: Loss = 0.42958563566207886
Iteration 3998: Loss = 0.42958545684814453
Iteration 3999: Loss = 0.4295853078365326
Iteration 4000: Loss = 0.4295850694179535
Iteration 4001: Loss = 0.42958492040634155
Iteration 4002: Loss = 0.4295847415924072
Iteration 4003: Loss = 0.4295845925807953
Iteration 4004: Loss = 0.42958441376686096
Iteration 4005: Loss = 0.429584264755249
Iteration 4006: Loss = 0.4295840859413147
Iteration 4007: Loss = 0.42958393692970276
Iteration 4008: Loss = 0.42958372831344604
Iteration 4009: Loss = 0.4295835793018341
Iteration 4010: Loss = 0.42958343029022217
Iteration 4011: Loss = 0.42958328127861023
Iteration 4012: Loss = 0.42958304286003113
Iteration 4013: Loss = 0.42958295345306396
Iteration 4014: Loss = 0.42958277463912964
Iteration 4015: Loss = 0.4295826256275177
Iteration 4016: Loss = 0.4295823574066162
Iteration 4017: Loss = 0.42958226799964905
Iteration 4018: Loss = 0.42958202958106995
Iteration 4019: Loss = 0.4295819103717804
Iteration 4020: Loss = 0.42958176136016846
Iteration 4021: Loss = 0.42958155274391174
Iteration 4022: Loss = 0.4295814037322998
Iteration 4023: Loss = 0.4295812249183655
Iteration 4024: Loss = 0.42958104610443115
Iteration 4025: Loss = 0.4295808970928192
Iteration 4026: Loss = 0.4295807480812073
Iteration 4027: Loss = 0.42958056926727295
Iteration 4028: Loss = 0.42958036065101624
Iteration 4029: Loss = 0.4295802414417267
Iteration 4030: Loss = 0.42958003282546997
Iteration 4031: Loss = 0.42957988381385803
Iteration 4032: Loss = 0.4295796751976013
Iteration 4033: Loss = 0.4295794665813446
Iteration 4034: Loss = 0.42957937717437744
Iteration 4035: Loss = 0.4295792281627655
Iteration 4036: Loss = 0.4295790493488312
Iteration 4037: Loss = 0.42957887053489685
Iteration 4038: Loss = 0.42957863211631775
Iteration 4039: Loss = 0.4295785129070282
Iteration 4040: Loss = 0.42957836389541626
Iteration 4041: Loss = 0.42957812547683716
Iteration 4042: Loss = 0.4295780658721924
Iteration 4043: Loss = 0.4295778274536133
Iteration 4044: Loss = 0.42957764863967896
Iteration 4045: Loss = 0.42957746982574463
Iteration 4046: Loss = 0.4295772910118103
Iteration 4047: Loss = 0.42957717180252075
Iteration 4048: Loss = 0.42957693338394165
Iteration 4049: Loss = 0.4295767843723297
Iteration 4050: Loss = 0.4295766055583954
Iteration 4051: Loss = 0.4295765161514282
Iteration 4052: Loss = 0.4295763075351715
Iteration 4053: Loss = 0.4295761287212372
Iteration 4054: Loss = 0.42957594990730286
Iteration 4055: Loss = 0.4295758008956909
Iteration 4056: Loss = 0.4295756220817566
Iteration 4057: Loss = 0.42957544326782227
Iteration 4058: Loss = 0.42957526445388794
Iteration 4059: Loss = 0.429575115442276
Iteration 4060: Loss = 0.4295748770236969
Iteration 4061: Loss = 0.42957472801208496
Iteration 4062: Loss = 0.42957454919815063
Iteration 4063: Loss = 0.4295744001865387
Iteration 4064: Loss = 0.42957425117492676
Iteration 4065: Loss = 0.4295741021633148
Iteration 4066: Loss = 0.4295738637447357
Iteration 4067: Loss = 0.4295737147331238
Iteration 4068: Loss = 0.42957353591918945
Iteration 4069: Loss = 0.42957332730293274
Iteration 4070: Loss = 0.4295732378959656
Iteration 4071: Loss = 0.42957302927970886
Iteration 4072: Loss = 0.4295728802680969
Iteration 4073: Loss = 0.4295727014541626
Iteration 4074: Loss = 0.42957252264022827
Iteration 4075: Loss = 0.42957234382629395
Iteration 4076: Loss = 0.42957213521003723
Iteration 4077: Loss = 0.4295719861984253
Iteration 4078: Loss = 0.42957180738449097
Iteration 4079: Loss = 0.42957165837287903
Iteration 4080: Loss = 0.4295714497566223
Iteration 4081: Loss = 0.42957133054733276
Iteration 4082: Loss = 0.42957112193107605
Iteration 4083: Loss = 0.4295709431171417
Iteration 4084: Loss = 0.429570734500885
Iteration 4085: Loss = 0.4295705556869507
Iteration 4086: Loss = 0.42957040667533875
Iteration 4087: Loss = 0.4295702874660492
Iteration 4088: Loss = 0.4295700192451477
Iteration 4089: Loss = 0.42956990003585815
Iteration 4090: Loss = 0.42956972122192383
Iteration 4091: Loss = 0.4295695424079895
Iteration 4092: Loss = 0.4295693635940552
Iteration 4093: Loss = 0.42956918478012085
Iteration 4094: Loss = 0.4295690059661865
Iteration 4095: Loss = 0.4295688569545746
Iteration 4096: Loss = 0.42956867814064026
Iteration 4097: Loss = 0.42956846952438354
Iteration 4098: Loss = 0.429568350315094
Iteration 4099: Loss = 0.4295681416988373
Iteration 4100: Loss = 0.42956802248954773
Iteration 4101: Loss = 0.429567813873291
Iteration 4102: Loss = 0.4295676350593567
Iteration 4103: Loss = 0.42956745624542236
Iteration 4104: Loss = 0.42956727743148804
Iteration 4105: Loss = 0.4295670986175537
Iteration 4106: Loss = 0.4295669198036194
Iteration 4107: Loss = 0.42956680059432983
Iteration 4108: Loss = 0.42956656217575073
Iteration 4109: Loss = 0.4295663833618164
Iteration 4110: Loss = 0.42956623435020447
Iteration 4111: Loss = 0.42956608533859253
Iteration 4112: Loss = 0.4295658469200134
Iteration 4113: Loss = 0.4295656979084015
Iteration 4114: Loss = 0.42956551909446716
Iteration 4115: Loss = 0.4295653700828552
Iteration 4116: Loss = 0.4295651316642761
Iteration 4117: Loss = 0.4295650124549866
Iteration 4118: Loss = 0.42956483364105225
Iteration 4119: Loss = 0.42956459522247314
Iteration 4120: Loss = 0.4295644760131836
Iteration 4121: Loss = 0.4295642375946045
Iteration 4122: Loss = 0.42956408858299255
Iteration 4123: Loss = 0.4295639097690582
Iteration 4124: Loss = 0.4295637607574463
Iteration 4125: Loss = 0.42956361174583435
Iteration 4126: Loss = 0.42956337332725525
Iteration 4127: Loss = 0.42956316471099854
Iteration 4128: Loss = 0.4295630156993866
Iteration 4129: Loss = 0.42956286668777466
Iteration 4130: Loss = 0.42956268787384033
Iteration 4131: Loss = 0.429562509059906
Iteration 4132: Loss = 0.42956236004829407
Iteration 4133: Loss = 0.42956212162971497
Iteration 4134: Loss = 0.429561972618103
Iteration 4135: Loss = 0.4295617640018463
Iteration 4136: Loss = 0.429561585187912
Iteration 4137: Loss = 0.42956140637397766
Iteration 4138: Loss = 0.42956122756004333
Iteration 4139: Loss = 0.4295611083507538
Iteration 4140: Loss = 0.42956089973449707
Iteration 4141: Loss = 0.42956066131591797
Iteration 4142: Loss = 0.42956051230430603
Iteration 4143: Loss = 0.4295603930950165
Iteration 4144: Loss = 0.4295601546764374
Iteration 4145: Loss = 0.42955994606018066
Iteration 4146: Loss = 0.4295598268508911
Iteration 4147: Loss = 0.4295596778392792
Iteration 4148: Loss = 0.42955946922302246
Iteration 4149: Loss = 0.42955926060676575
Iteration 4150: Loss = 0.4295590817928314
Iteration 4151: Loss = 0.4295589327812195
Iteration 4152: Loss = 0.42955878376960754
Iteration 4153: Loss = 0.4295586049556732
Iteration 4154: Loss = 0.4295583665370941
Iteration 4155: Loss = 0.4295582175254822
Iteration 4156: Loss = 0.42955800890922546
Iteration 4157: Loss = 0.42955783009529114
Iteration 4158: Loss = 0.4295576512813568
Iteration 4159: Loss = 0.4295574426651001
Iteration 4160: Loss = 0.42955732345581055
Iteration 4161: Loss = 0.42955708503723145
Iteration 4162: Loss = 0.4295569360256195
Iteration 4163: Loss = 0.4295567572116852
Iteration 4164: Loss = 0.42955654859542847
Iteration 4165: Loss = 0.4295564293861389
Iteration 4166: Loss = 0.4295562207698822
Iteration 4167: Loss = 0.42955607175827026
Iteration 4168: Loss = 0.42955583333969116
Iteration 4169: Loss = 0.42955565452575684
Iteration 4170: Loss = 0.4295555055141449
Iteration 4171: Loss = 0.4295552968978882
Iteration 4172: Loss = 0.42955514788627625
Iteration 4173: Loss = 0.42955493927001953
Iteration 4174: Loss = 0.4295547604560852
Iteration 4175: Loss = 0.4295545220375061
Iteration 4176: Loss = 0.42955437302589417
Iteration 4177: Loss = 0.42955419421195984
Iteration 4178: Loss = 0.4295540452003479
Iteration 4179: Loss = 0.4295538365840912
Iteration 4180: Loss = 0.42955365777015686
Iteration 4181: Loss = 0.42955347895622253
Iteration 4182: Loss = 0.4295532703399658
Iteration 4183: Loss = 0.4295530915260315
Iteration 4184: Loss = 0.42955291271209717
Iteration 4185: Loss = 0.4295527935028076
Iteration 4186: Loss = 0.4295525550842285
Iteration 4187: Loss = 0.42955243587493896
Iteration 4188: Loss = 0.42955219745635986
Iteration 4189: Loss = 0.42955198884010315
Iteration 4190: Loss = 0.4295518696308136
Iteration 4191: Loss = 0.4295516908168793
Iteration 4192: Loss = 0.42955145239830017
Iteration 4193: Loss = 0.42955130338668823
Iteration 4194: Loss = 0.4295511245727539
Iteration 4195: Loss = 0.4295509159564972
Iteration 4196: Loss = 0.42955073714256287
Iteration 4197: Loss = 0.42955052852630615
Iteration 4198: Loss = 0.4295503795146942
Iteration 4199: Loss = 0.4295501708984375
Iteration 4200: Loss = 0.42955002188682556
Iteration 4201: Loss = 0.42954984307289124
Iteration 4202: Loss = 0.4295496344566345
Iteration 4203: Loss = 0.4295493960380554
Iteration 4204: Loss = 0.42954927682876587
Iteration 4205: Loss = 0.42954906821250916
Iteration 4206: Loss = 0.42954885959625244
Iteration 4207: Loss = 0.4295487105846405
Iteration 4208: Loss = 0.4295485317707062
Iteration 4209: Loss = 0.42954838275909424
Iteration 4210: Loss = 0.42954814434051514
Iteration 4211: Loss = 0.4295479357242584
Iteration 4212: Loss = 0.4295477569103241
Iteration 4213: Loss = 0.4295475482940674
Iteration 4214: Loss = 0.4295474588871002
Iteration 4215: Loss = 0.4295472502708435
Iteration 4216: Loss = 0.4295470118522644
Iteration 4217: Loss = 0.4295468330383301
Iteration 4218: Loss = 0.42954662442207336
Iteration 4219: Loss = 0.4295464754104614
Iteration 4220: Loss = 0.4295462667942047
Iteration 4221: Loss = 0.4295460879802704
Iteration 4222: Loss = 0.42954590916633606
Iteration 4223: Loss = 0.42954570055007935
Iteration 4224: Loss = 0.4295455515384674
Iteration 4225: Loss = 0.4295453429222107
Iteration 4226: Loss = 0.42954516410827637
Iteration 4227: Loss = 0.42954498529434204
Iteration 4228: Loss = 0.4295447766780853
Iteration 4229: Loss = 0.4295446276664734
Iteration 4230: Loss = 0.4295444190502167
Iteration 4231: Loss = 0.4295441806316376
Iteration 4232: Loss = 0.42954403162002563
Iteration 4233: Loss = 0.4295438230037689
Iteration 4234: Loss = 0.4295436441898346
Iteration 4235: Loss = 0.42954349517822266
Iteration 4236: Loss = 0.42954331636428833
Iteration 4237: Loss = 0.4295431077480316
Iteration 4238: Loss = 0.4295429289340973
Iteration 4239: Loss = 0.4295427203178406
Iteration 4240: Loss = 0.42954254150390625
Iteration 4241: Loss = 0.4295423626899719
Iteration 4242: Loss = 0.4295421242713928
Iteration 4243: Loss = 0.4295419454574585
Iteration 4244: Loss = 0.42954176664352417
Iteration 4245: Loss = 0.42954158782958984
Iteration 4246: Loss = 0.42954137921333313
Iteration 4247: Loss = 0.4295411705970764
Iteration 4248: Loss = 0.4295410215854645
Iteration 4249: Loss = 0.42954081296920776
Iteration 4250: Loss = 0.42954060435295105
Iteration 4251: Loss = 0.4295404553413391
Iteration 4252: Loss = 0.4295402467250824
Iteration 4253: Loss = 0.42954006791114807
Iteration 4254: Loss = 0.42953985929489136
Iteration 4255: Loss = 0.42953965067863464
Iteration 4256: Loss = 0.4295395016670227
Iteration 4257: Loss = 0.429539293050766
Iteration 4258: Loss = 0.4295390844345093
Iteration 4259: Loss = 0.42953893542289734
Iteration 4260: Loss = 0.429538756608963
Iteration 4261: Loss = 0.4295385777950287
Iteration 4262: Loss = 0.429538369178772
Iteration 4263: Loss = 0.42953816056251526
Iteration 4264: Loss = 0.42953798174858093
Iteration 4265: Loss = 0.42953774333000183
Iteration 4266: Loss = 0.4295375645160675
Iteration 4267: Loss = 0.42953741550445557
Iteration 4268: Loss = 0.42953717708587646
Iteration 4269: Loss = 0.42953699827194214
Iteration 4270: Loss = 0.4295367896556854
Iteration 4271: Loss = 0.4295366108417511
Iteration 4272: Loss = 0.42953646183013916
Iteration 4273: Loss = 0.42953622341156006
Iteration 4274: Loss = 0.42953604459762573
Iteration 4275: Loss = 0.429535835981369
Iteration 4276: Loss = 0.4295356571674347
Iteration 4277: Loss = 0.429535448551178
Iteration 4278: Loss = 0.42953526973724365
Iteration 4279: Loss = 0.42953503131866455
Iteration 4280: Loss = 0.4295348525047302
Iteration 4281: Loss = 0.4295346736907959
Iteration 4282: Loss = 0.4295344948768616
Iteration 4283: Loss = 0.42953431606292725
Iteration 4284: Loss = 0.42953410744667053
Iteration 4285: Loss = 0.4295338988304138
Iteration 4286: Loss = 0.4295336902141571
Iteration 4287: Loss = 0.4295335114002228
Iteration 4288: Loss = 0.42953333258628845
Iteration 4289: Loss = 0.42953312397003174
Iteration 4290: Loss = 0.4295329451560974
Iteration 4291: Loss = 0.4295327365398407
Iteration 4292: Loss = 0.4295324981212616
Iteration 4293: Loss = 0.42953234910964966
Iteration 4294: Loss = 0.42953217029571533
Iteration 4295: Loss = 0.42953193187713623
Iteration 4296: Loss = 0.4295318126678467
Iteration 4297: Loss = 0.4295315742492676
Iteration 4298: Loss = 0.42953139543533325
Iteration 4299: Loss = 0.42953115701675415
Iteration 4300: Loss = 0.4295310080051422
Iteration 4301: Loss = 0.4295307993888855
Iteration 4302: Loss = 0.42953065037727356
Iteration 4303: Loss = 0.42953038215637207
Iteration 4304: Loss = 0.42953023314476013
Iteration 4305: Loss = 0.42952999472618103
Iteration 4306: Loss = 0.4295297861099243
Iteration 4307: Loss = 0.4295296370983124
Iteration 4308: Loss = 0.4295293986797333
Iteration 4309: Loss = 0.42952924966812134
Iteration 4310: Loss = 0.4295290410518646
Iteration 4311: Loss = 0.42952877283096313
Iteration 4312: Loss = 0.4295286238193512
Iteration 4313: Loss = 0.4295284152030945
Iteration 4314: Loss = 0.42952823638916016
Iteration 4315: Loss = 0.42952802777290344
Iteration 4316: Loss = 0.42952781915664673
Iteration 4317: Loss = 0.4295276403427124
Iteration 4318: Loss = 0.4295274615287781
Iteration 4319: Loss = 0.42952725291252136
Iteration 4320: Loss = 0.42952704429626465
Iteration 4321: Loss = 0.42952683568000793
Iteration 4322: Loss = 0.42952659726142883
Iteration 4323: Loss = 0.4295264184474945
Iteration 4324: Loss = 0.4295262396335602
Iteration 4325: Loss = 0.42952606081962585
Iteration 4326: Loss = 0.42952585220336914
Iteration 4327: Loss = 0.4295256435871124
Iteration 4328: Loss = 0.4295254647731781
Iteration 4329: Loss = 0.4295251965522766
Iteration 4330: Loss = 0.4295250475406647
Iteration 4331: Loss = 0.42952483892440796
Iteration 4332: Loss = 0.42952466011047363
Iteration 4333: Loss = 0.4295244514942169
Iteration 4334: Loss = 0.4295242130756378
Iteration 4335: Loss = 0.4295240342617035
Iteration 4336: Loss = 0.4295237958431244
Iteration 4337: Loss = 0.42952361702919006
Iteration 4338: Loss = 0.4295234680175781
Iteration 4339: Loss = 0.42952319979667664
Iteration 4340: Loss = 0.4295231103897095
Iteration 4341: Loss = 0.42952287197113037
Iteration 4342: Loss = 0.4295226037502289
Iteration 4343: Loss = 0.42952245473861694
Iteration 4344: Loss = 0.4295222759246826
Iteration 4345: Loss = 0.4295220375061035
Iteration 4346: Loss = 0.4295218288898468
Iteration 4347: Loss = 0.42952167987823486
Iteration 4348: Loss = 0.429521381855011
Iteration 4349: Loss = 0.42952120304107666
Iteration 4350: Loss = 0.42952102422714233
Iteration 4351: Loss = 0.42952078580856323
Iteration 4352: Loss = 0.4295206665992737
Iteration 4353: Loss = 0.4295203983783722
Iteration 4354: Loss = 0.4295201897621155
Iteration 4355: Loss = 0.42952001094818115
Iteration 4356: Loss = 0.4295198321342468
Iteration 4357: Loss = 0.4295195937156677
Iteration 4358: Loss = 0.429519385099411
Iteration 4359: Loss = 0.4295192360877991
Iteration 4360: Loss = 0.42951899766921997
Iteration 4361: Loss = 0.42951878905296326
Iteration 4362: Loss = 0.42951855063438416
Iteration 4363: Loss = 0.42951837182044983
Iteration 4364: Loss = 0.4295181930065155
Iteration 4365: Loss = 0.4295179545879364
Iteration 4366: Loss = 0.4295177757740021
Iteration 4367: Loss = 0.42951756715774536
Iteration 4368: Loss = 0.42951735854148865
Iteration 4369: Loss = 0.4295171797275543
Iteration 4370: Loss = 0.4295169413089752
Iteration 4371: Loss = 0.4295167326927185
Iteration 4372: Loss = 0.4295165538787842
Iteration 4373: Loss = 0.42951634526252747
Iteration 4374: Loss = 0.42951610684394836
Iteration 4375: Loss = 0.42951592803001404
Iteration 4376: Loss = 0.4295157194137573
Iteration 4377: Loss = 0.429515540599823
Iteration 4378: Loss = 0.4295152723789215
Iteration 4379: Loss = 0.4295150935649872
Iteration 4380: Loss = 0.4295148253440857
Iteration 4381: Loss = 0.42951470613479614
Iteration 4382: Loss = 0.42951449751853943
Iteration 4383: Loss = 0.4295142889022827
Iteration 4384: Loss = 0.4295140504837036
Iteration 4385: Loss = 0.4295138716697693
Iteration 4386: Loss = 0.4295136630535126
Iteration 4387: Loss = 0.42951345443725586
Iteration 4388: Loss = 0.42951321601867676
Iteration 4389: Loss = 0.42951303720474243
Iteration 4390: Loss = 0.4295128583908081
Iteration 4391: Loss = 0.429512619972229
Iteration 4392: Loss = 0.4295124113559723
Iteration 4393: Loss = 0.4295122027397156
Iteration 4394: Loss = 0.42951199412345886
Iteration 4395: Loss = 0.42951178550720215
Iteration 4396: Loss = 0.4295116066932678
Iteration 4397: Loss = 0.4295113682746887
Iteration 4398: Loss = 0.429511159658432
Iteration 4399: Loss = 0.4295109510421753
Iteration 4400: Loss = 0.4295107424259186
Iteration 4401: Loss = 0.42951056361198425
Iteration 4402: Loss = 0.42951032519340515
Iteration 4403: Loss = 0.42951008677482605
Iteration 4404: Loss = 0.4295099079608917
Iteration 4405: Loss = 0.4295096695423126
Iteration 4406: Loss = 0.4295094907283783
Iteration 4407: Loss = 0.4295092821121216
Iteration 4408: Loss = 0.42950910329818726
Iteration 4409: Loss = 0.42950889468193054
Iteration 4410: Loss = 0.42950859665870667
Iteration 4411: Loss = 0.4295084476470947
Iteration 4412: Loss = 0.4295082092285156
Iteration 4413: Loss = 0.4295080304145813
Iteration 4414: Loss = 0.4295078217983246
Iteration 4415: Loss = 0.4295075535774231
Iteration 4416: Loss = 0.4295073449611664
Iteration 4417: Loss = 0.42950716614723206
Iteration 4418: Loss = 0.42950692772865295
Iteration 4419: Loss = 0.42950671911239624
Iteration 4420: Loss = 0.4295065402984619
Iteration 4421: Loss = 0.4295063316822052
Iteration 4422: Loss = 0.4295060932636261
Iteration 4423: Loss = 0.4295058846473694
Iteration 4424: Loss = 0.4295056462287903
Iteration 4425: Loss = 0.42950543761253357
Iteration 4426: Loss = 0.429505318403244
Iteration 4427: Loss = 0.4295050799846649
Iteration 4428: Loss = 0.4295048415660858
Iteration 4429: Loss = 0.4295046031475067
Iteration 4430: Loss = 0.4295044541358948
Iteration 4431: Loss = 0.4295042157173157
Iteration 4432: Loss = 0.4295039772987366
Iteration 4433: Loss = 0.42950379848480225
Iteration 4434: Loss = 0.42950350046157837
Iteration 4435: Loss = 0.42950329184532166
Iteration 4436: Loss = 0.42950311303138733
Iteration 4437: Loss = 0.429502934217453
Iteration 4438: Loss = 0.4295026659965515
Iteration 4439: Loss = 0.4295025169849396
Iteration 4440: Loss = 0.4295022487640381
Iteration 4441: Loss = 0.42950206995010376
Iteration 4442: Loss = 0.42950180172920227
Iteration 4443: Loss = 0.42950159311294556
Iteration 4444: Loss = 0.42950138449668884
Iteration 4445: Loss = 0.42950117588043213
Iteration 4446: Loss = 0.4295009970664978
Iteration 4447: Loss = 0.4295007884502411
Iteration 4448: Loss = 0.4295005798339844
Iteration 4449: Loss = 0.4295003116130829
Iteration 4450: Loss = 0.42950010299682617
Iteration 4451: Loss = 0.42949992418289185
Iteration 4452: Loss = 0.42949971556663513
Iteration 4453: Loss = 0.42949947714805603
Iteration 4454: Loss = 0.4294992685317993
Iteration 4455: Loss = 0.4294991195201874
Iteration 4456: Loss = 0.42949891090393066
Iteration 4457: Loss = 0.4294986128807068
Iteration 4458: Loss = 0.4294984042644501
Iteration 4459: Loss = 0.42949822545051575
Iteration 4460: Loss = 0.42949798703193665
Iteration 4461: Loss = 0.42949774861335754
Iteration 4462: Loss = 0.42949753999710083
Iteration 4463: Loss = 0.4294973611831665
Iteration 4464: Loss = 0.4294971227645874
Iteration 4465: Loss = 0.4294968843460083
Iteration 4466: Loss = 0.4294966757297516
Iteration 4467: Loss = 0.42949649691581726
Iteration 4468: Loss = 0.42949622869491577
Iteration 4469: Loss = 0.42949607968330383
Iteration 4470: Loss = 0.42949584126472473
Iteration 4471: Loss = 0.42949560284614563
Iteration 4472: Loss = 0.4294953942298889
Iteration 4473: Loss = 0.4294952154159546
Iteration 4474: Loss = 0.4294950067996979
Iteration 4475: Loss = 0.4294947385787964
Iteration 4476: Loss = 0.4294945299625397
Iteration 4477: Loss = 0.42949429154396057
Iteration 4478: Loss = 0.42949411273002625
Iteration 4479: Loss = 0.42949387431144714
Iteration 4480: Loss = 0.4294936954975128
Iteration 4481: Loss = 0.42949342727661133
Iteration 4482: Loss = 0.4294932186603546
Iteration 4483: Loss = 0.4294930398464203
Iteration 4484: Loss = 0.4294928312301636
Iteration 4485: Loss = 0.4294925630092621
Iteration 4486: Loss = 0.42949241399765015
Iteration 4487: Loss = 0.42949217557907104
Iteration 4488: Loss = 0.42949190735816956
Iteration 4489: Loss = 0.42949166893959045
Iteration 4490: Loss = 0.4294915199279785
Iteration 4491: Loss = 0.429491251707077
Iteration 4492: Loss = 0.4294910132884979
Iteration 4493: Loss = 0.429490864276886
Iteration 4494: Loss = 0.4294906258583069
Iteration 4495: Loss = 0.42949041724205017
Iteration 4496: Loss = 0.42949020862579346
Iteration 4497: Loss = 0.42948997020721436
Iteration 4498: Loss = 0.42948979139328003
Iteration 4499: Loss = 0.4294895529747009
Iteration 4500: Loss = 0.4294893443584442
Iteration 4501: Loss = 0.4294891357421875
Iteration 4502: Loss = 0.4294889271259308
Iteration 4503: Loss = 0.4294887185096741
Iteration 4504: Loss = 0.4294884502887726
Iteration 4505: Loss = 0.42948824167251587
Iteration 4506: Loss = 0.42948803305625916
Iteration 4507: Loss = 0.42948785424232483
Iteration 4508: Loss = 0.42948758602142334
Iteration 4509: Loss = 0.4294873774051666
Iteration 4510: Loss = 0.4294871389865875
Iteration 4511: Loss = 0.4294869601726532
Iteration 4512: Loss = 0.4294867217540741
Iteration 4513: Loss = 0.4294865131378174
Iteration 4514: Loss = 0.42948630452156067
Iteration 4515: Loss = 0.42948615550994873
Iteration 4516: Loss = 0.42948588728904724
Iteration 4517: Loss = 0.42948561906814575
Iteration 4518: Loss = 0.4294854402542114
Iteration 4519: Loss = 0.4294852316379547
Iteration 4520: Loss = 0.429485023021698
Iteration 4521: Loss = 0.4294848144054413
Iteration 4522: Loss = 0.4294845461845398
Iteration 4523: Loss = 0.4294843375682831
Iteration 4524: Loss = 0.42948418855667114
Iteration 4525: Loss = 0.42948392033576965
Iteration 4526: Loss = 0.42948368191719055
Iteration 4527: Loss = 0.4294835329055786
Iteration 4528: Loss = 0.4294832646846771
Iteration 4529: Loss = 0.429483026266098
Iteration 4530: Loss = 0.4294828176498413
Iteration 4531: Loss = 0.4294826090335846
Iteration 4532: Loss = 0.4294824004173279
Iteration 4533: Loss = 0.4294821619987488
Iteration 4534: Loss = 0.4294819235801697
Iteration 4535: Loss = 0.42948174476623535
Iteration 4536: Loss = 0.42948153614997864
Iteration 4537: Loss = 0.42948129773139954
Iteration 4538: Loss = 0.42948105931282043
Iteration 4539: Loss = 0.42948082089424133
Iteration 4540: Loss = 0.429480642080307
Iteration 4541: Loss = 0.4294803738594055
Iteration 4542: Loss = 0.4294801652431488
Iteration 4543: Loss = 0.4294799268245697
Iteration 4544: Loss = 0.4294797480106354
Iteration 4545: Loss = 0.4294795095920563
Iteration 4546: Loss = 0.42947930097579956
Iteration 4547: Loss = 0.42947906255722046
Iteration 4548: Loss = 0.42947888374328613
Iteration 4549: Loss = 0.4294787049293518
Iteration 4550: Loss = 0.4294784367084503
Iteration 4551: Loss = 0.42947816848754883
Iteration 4552: Loss = 0.4294779896736145
Iteration 4553: Loss = 0.4294777810573578
Iteration 4554: Loss = 0.42947760224342346
Iteration 4555: Loss = 0.429477334022522
Iteration 4556: Loss = 0.42947712540626526
Iteration 4557: Loss = 0.42947691679000854
Iteration 4558: Loss = 0.42947664856910706
Iteration 4559: Loss = 0.42947643995285034
Iteration 4560: Loss = 0.429476261138916
Iteration 4561: Loss = 0.4294760823249817
Iteration 4562: Loss = 0.4294757544994354
Iteration 4563: Loss = 0.4294756054878235
Iteration 4564: Loss = 0.429475337266922
Iteration 4565: Loss = 0.4294750988483429
Iteration 4566: Loss = 0.42947492003440857
Iteration 4567: Loss = 0.4294746518135071
Iteration 4568: Loss = 0.429474413394928
Iteration 4569: Loss = 0.42947423458099365
Iteration 4570: Loss = 0.4294740557670593
Iteration 4571: Loss = 0.4294738173484802
Iteration 4572: Loss = 0.42947354912757874
Iteration 4573: Loss = 0.429473340511322
Iteration 4574: Loss = 0.4294731020927429
Iteration 4575: Loss = 0.429472953081131
Iteration 4576: Loss = 0.4294726848602295
Iteration 4577: Loss = 0.4294724762439728
Iteration 4578: Loss = 0.4294722378253937
Iteration 4579: Loss = 0.42947202920913696
Iteration 4580: Loss = 0.42947182059288025
Iteration 4581: Loss = 0.42947155237197876
Iteration 4582: Loss = 0.42947134375572205
Iteration 4583: Loss = 0.42947113513946533
Iteration 4584: Loss = 0.4294709265232086
Iteration 4585: Loss = 0.4294707179069519
Iteration 4586: Loss = 0.4294704496860504
Iteration 4587: Loss = 0.4294701814651489
Iteration 4588: Loss = 0.4294700026512146
Iteration 4589: Loss = 0.4294698238372803
Iteration 4590: Loss = 0.42946958541870117
Iteration 4591: Loss = 0.4294692873954773
Iteration 4592: Loss = 0.42946913838386536
Iteration 4593: Loss = 0.42946887016296387
Iteration 4594: Loss = 0.42946863174438477
Iteration 4595: Loss = 0.4294684827327728
Iteration 4596: Loss = 0.4294682443141937
Iteration 4597: Loss = 0.4294680058956146
Iteration 4598: Loss = 0.4294677674770355
Iteration 4599: Loss = 0.4294675290584564
Iteration 4600: Loss = 0.4294673204421997
Iteration 4601: Loss = 0.4294670820236206
Iteration 4602: Loss = 0.4294668436050415
Iteration 4603: Loss = 0.4294666647911072
Iteration 4604: Loss = 0.4294664263725281
Iteration 4605: Loss = 0.42946621775627136
Iteration 4606: Loss = 0.42946600914001465
Iteration 4607: Loss = 0.42946577072143555
Iteration 4608: Loss = 0.42946553230285645
Iteration 4609: Loss = 0.42946526408195496
Iteration 4610: Loss = 0.42946505546569824
Iteration 4611: Loss = 0.42946484684944153
Iteration 4612: Loss = 0.4294646382331848
Iteration 4613: Loss = 0.4294643998146057
Iteration 4614: Loss = 0.4294641613960266
Iteration 4615: Loss = 0.4294639229774475
Iteration 4616: Loss = 0.4294637441635132
Iteration 4617: Loss = 0.42946353554725647
Iteration 4618: Loss = 0.42946329712867737
Iteration 4619: Loss = 0.4294629991054535
Iteration 4620: Loss = 0.4294627904891968
Iteration 4621: Loss = 0.42946258187294006
Iteration 4622: Loss = 0.42946237325668335
Iteration 4623: Loss = 0.42946213483810425
Iteration 4624: Loss = 0.42946189641952515
Iteration 4625: Loss = 0.42946165800094604
Iteration 4626: Loss = 0.42946144938468933
Iteration 4627: Loss = 0.42946121096611023
Iteration 4628: Loss = 0.4294610023498535
Iteration 4629: Loss = 0.4294607639312744
Iteration 4630: Loss = 0.4294605553150177
Iteration 4631: Loss = 0.4294602870941162
Iteration 4632: Loss = 0.4294600784778595
Iteration 4633: Loss = 0.4294598698616028
Iteration 4634: Loss = 0.4294596314430237
Iteration 4635: Loss = 0.42945942282676697
Iteration 4636: Loss = 0.4294591248035431
Iteration 4637: Loss = 0.4294589161872864
Iteration 4638: Loss = 0.42945870757102966
Iteration 4639: Loss = 0.42945846915245056
Iteration 4640: Loss = 0.42945823073387146
Iteration 4641: Loss = 0.42945802211761475
Iteration 4642: Loss = 0.42945775389671326
Iteration 4643: Loss = 0.42945754528045654
Iteration 4644: Loss = 0.42945733666419983
Iteration 4645: Loss = 0.4294570982456207
Iteration 4646: Loss = 0.4294568598270416
Iteration 4647: Loss = 0.4294566512107849
Iteration 4648: Loss = 0.4294564425945282
Iteration 4649: Loss = 0.4294561743736267
Iteration 4650: Loss = 0.4294559359550476
Iteration 4651: Loss = 0.4294556975364685
Iteration 4652: Loss = 0.4294555187225342
Iteration 4653: Loss = 0.4294552803039551
Iteration 4654: Loss = 0.42945507168769836
Iteration 4655: Loss = 0.4294547736644745
Iteration 4656: Loss = 0.42945459485054016
Iteration 4657: Loss = 0.42945435643196106
Iteration 4658: Loss = 0.42945411801338196
Iteration 4659: Loss = 0.42945384979248047
Iteration 4660: Loss = 0.42945367097854614
Iteration 4661: Loss = 0.42945340275764465
Iteration 4662: Loss = 0.42945319414138794
Iteration 4663: Loss = 0.42945295572280884
Iteration 4664: Loss = 0.4294527471065521
Iteration 4665: Loss = 0.42945244908332825
Iteration 4666: Loss = 0.4294523000717163
Iteration 4667: Loss = 0.42945200204849243
Iteration 4668: Loss = 0.4294518232345581
Iteration 4669: Loss = 0.429451584815979
Iteration 4670: Loss = 0.4294513463973999
Iteration 4671: Loss = 0.4294511079788208
Iteration 4672: Loss = 0.4294508993625641
Iteration 4673: Loss = 0.4294506311416626
Iteration 4674: Loss = 0.4294503927230835
Iteration 4675: Loss = 0.42945021390914917
Iteration 4676: Loss = 0.42945000529289246
Iteration 4677: Loss = 0.4294497072696686
Iteration 4678: Loss = 0.42944952845573425
Iteration 4679: Loss = 0.4294492304325104
Iteration 4680: Loss = 0.4294489920139313
Iteration 4681: Loss = 0.42944878339767456
Iteration 4682: Loss = 0.42944860458374023
Iteration 4683: Loss = 0.42944833636283875
Iteration 4684: Loss = 0.42944812774658203
Iteration 4685: Loss = 0.42944788932800293
Iteration 4686: Loss = 0.42944759130477905
Iteration 4687: Loss = 0.42944738268852234
Iteration 4688: Loss = 0.4294471740722656
Iteration 4689: Loss = 0.42944690585136414
Iteration 4690: Loss = 0.42944666743278503
Iteration 4691: Loss = 0.4294464588165283
Iteration 4692: Loss = 0.4294462203979492
Iteration 4693: Loss = 0.4294459819793701
Iteration 4694: Loss = 0.4294457733631134
Iteration 4695: Loss = 0.4294455349445343
Iteration 4696: Loss = 0.4294453263282776
Iteration 4697: Loss = 0.4294450283050537
Iteration 4698: Loss = 0.429444819688797
Iteration 4699: Loss = 0.4294445812702179
Iteration 4700: Loss = 0.4294443428516388
Iteration 4701: Loss = 0.4294441044330597
Iteration 4702: Loss = 0.4294438362121582
Iteration 4703: Loss = 0.4294435977935791
Iteration 4704: Loss = 0.4294433891773224
Iteration 4705: Loss = 0.4294431805610657
Iteration 4706: Loss = 0.4294429421424866
Iteration 4707: Loss = 0.4294426739215851
Iteration 4708: Loss = 0.4294424057006836
Iteration 4709: Loss = 0.42944225668907166
Iteration 4710: Loss = 0.4294419586658478
Iteration 4711: Loss = 0.42944177985191345
Iteration 4712: Loss = 0.42944151163101196
Iteration 4713: Loss = 0.42944130301475525
Iteration 4714: Loss = 0.42944100499153137
Iteration 4715: Loss = 0.42944079637527466
Iteration 4716: Loss = 0.42944058775901794
Iteration 4717: Loss = 0.42944034934043884
Iteration 4718: Loss = 0.42944011092185974
Iteration 4719: Loss = 0.42943987250328064
Iteration 4720: Loss = 0.42943957448005676
Iteration 4721: Loss = 0.42943939566612244
Iteration 4722: Loss = 0.42943915724754333
Iteration 4723: Loss = 0.42943888902664185
Iteration 4724: Loss = 0.42943865060806274
Iteration 4725: Loss = 0.42943841218948364
Iteration 4726: Loss = 0.42943820357322693
Iteration 4727: Loss = 0.42943793535232544
Iteration 4728: Loss = 0.4294377565383911
Iteration 4729: Loss = 0.42943745851516724
Iteration 4730: Loss = 0.4294372498989105
Iteration 4731: Loss = 0.42943695187568665
Iteration 4732: Loss = 0.42943674325942993
Iteration 4733: Loss = 0.42943647503852844
Iteration 4734: Loss = 0.4294362962245941
Iteration 4735: Loss = 0.429436057806015
Iteration 4736: Loss = 0.4294358193874359
Iteration 4737: Loss = 0.4294355809688568
Iteration 4738: Loss = 0.4294353425502777
Iteration 4739: Loss = 0.42943504452705383
Iteration 4740: Loss = 0.42943480610847473
Iteration 4741: Loss = 0.4294346272945404
Iteration 4742: Loss = 0.4294343888759613
Iteration 4743: Loss = 0.4294341504573822
Iteration 4744: Loss = 0.4294339120388031
Iteration 4745: Loss = 0.4294336438179016
Iteration 4746: Loss = 0.4294334053993225
Iteration 4747: Loss = 0.4294331967830658
Iteration 4748: Loss = 0.4294329285621643
Iteration 4749: Loss = 0.4294326603412628
Iteration 4750: Loss = 0.4294324219226837
Iteration 4751: Loss = 0.4294321835041046
Iteration 4752: Loss = 0.4294319748878479
Iteration 4753: Loss = 0.4294317066669464
Iteration 4754: Loss = 0.4294314682483673
Iteration 4755: Loss = 0.42943117022514343
Iteration 4756: Loss = 0.42943093180656433
Iteration 4757: Loss = 0.42943069338798523
Iteration 4758: Loss = 0.4294304847717285
Iteration 4759: Loss = 0.4294302463531494
Iteration 4760: Loss = 0.4294299781322479
Iteration 4761: Loss = 0.4294297695159912
Iteration 4762: Loss = 0.4294295310974121
Iteration 4763: Loss = 0.429429292678833
Iteration 4764: Loss = 0.4294290840625763
Iteration 4765: Loss = 0.4294288158416748
Iteration 4766: Loss = 0.4294285774230957
Iteration 4767: Loss = 0.4294283092021942
Iteration 4768: Loss = 0.4294280409812927
Iteration 4769: Loss = 0.4294278621673584
Iteration 4770: Loss = 0.4294276237487793
Iteration 4771: Loss = 0.4294273853302002
Iteration 4772: Loss = 0.4294271171092987
Iteration 4773: Loss = 0.42942681908607483
Iteration 4774: Loss = 0.4294266402721405
Iteration 4775: Loss = 0.4294264018535614
Iteration 4776: Loss = 0.4294261038303375
Iteration 4777: Loss = 0.4294258952140808
Iteration 4778: Loss = 0.4294256567955017
Iteration 4779: Loss = 0.4294253885746002
Iteration 4780: Loss = 0.4294251799583435
Iteration 4781: Loss = 0.42942488193511963
Iteration 4782: Loss = 0.4294246435165405
Iteration 4783: Loss = 0.4294244349002838
Iteration 4784: Loss = 0.4294241666793823
Iteration 4785: Loss = 0.4294239282608032
Iteration 4786: Loss = 0.4294237196445465
Iteration 4787: Loss = 0.42942342162132263
Iteration 4788: Loss = 0.42942318320274353
Iteration 4789: Loss = 0.42942291498184204
Iteration 4790: Loss = 0.4294227361679077
Iteration 4791: Loss = 0.4294224679470062
Iteration 4792: Loss = 0.42942216992378235
Iteration 4793: Loss = 0.42942196130752563
Iteration 4794: Loss = 0.42942172288894653
Iteration 4795: Loss = 0.42942148447036743
Iteration 4796: Loss = 0.42942121624946594
Iteration 4797: Loss = 0.42942094802856445
Iteration 4798: Loss = 0.42942070960998535
Iteration 4799: Loss = 0.42942044138908386
Iteration 4800: Loss = 0.42942023277282715
Iteration 4801: Loss = 0.42941996455192566
Iteration 4802: Loss = 0.42941969633102417
Iteration 4803: Loss = 0.42941948771476746
Iteration 4804: Loss = 0.42941924929618835
Iteration 4805: Loss = 0.42941898107528687
Iteration 4806: Loss = 0.4294187128543854
Iteration 4807: Loss = 0.42941850423812866
Iteration 4808: Loss = 0.4294182062149048
Iteration 4809: Loss = 0.4294179677963257
Iteration 4810: Loss = 0.42941775918006897
Iteration 4811: Loss = 0.42941752076148987
Iteration 4812: Loss = 0.429417222738266
Iteration 4813: Loss = 0.4294169545173645
Iteration 4814: Loss = 0.4294167459011078
Iteration 4815: Loss = 0.4294164478778839
Iteration 4816: Loss = 0.4294162094593048
Iteration 4817: Loss = 0.4294160008430481
Iteration 4818: Loss = 0.4294157028198242
Iteration 4819: Loss = 0.4294154942035675
Iteration 4820: Loss = 0.429415225982666
Iteration 4821: Loss = 0.4294149875640869
Iteration 4822: Loss = 0.4294147193431854
Iteration 4823: Loss = 0.4294145107269287
Iteration 4824: Loss = 0.4294142425060272
Iteration 4825: Loss = 0.4294140040874481
Iteration 4826: Loss = 0.4294137954711914
Iteration 4827: Loss = 0.4294135272502899
Iteration 4828: Loss = 0.42941322922706604
Iteration 4829: Loss = 0.4294130206108093
Iteration 4830: Loss = 0.42941275238990784
Iteration 4831: Loss = 0.4294125437736511
Iteration 4832: Loss = 0.429412305355072
Iteration 4833: Loss = 0.42941200733184814
Iteration 4834: Loss = 0.4294118285179138
Iteration 4835: Loss = 0.42941156029701233
Iteration 4836: Loss = 0.42941129207611084
Iteration 4837: Loss = 0.42941105365753174
Iteration 4838: Loss = 0.42941081523895264
Iteration 4839: Loss = 0.42941054701805115
Iteration 4840: Loss = 0.42941027879714966
Iteration 4841: Loss = 0.42941007018089294
Iteration 4842: Loss = 0.42940983176231384
Iteration 4843: Loss = 0.42940956354141235
Iteration 4844: Loss = 0.42940935492515564
Iteration 4845: Loss = 0.42940908670425415
Iteration 4846: Loss = 0.42940881848335266
Iteration 4847: Loss = 0.42940860986709595
Iteration 4848: Loss = 0.42940834164619446
Iteration 4849: Loss = 0.42940807342529297
Iteration 4850: Loss = 0.42940786480903625
Iteration 4851: Loss = 0.42940759658813477
Iteration 4852: Loss = 0.42940735816955566
Iteration 4853: Loss = 0.4294070899486542
Iteration 4854: Loss = 0.42940688133239746
Iteration 4855: Loss = 0.4294065535068512
Iteration 4856: Loss = 0.4294063150882721
Iteration 4857: Loss = 0.42940613627433777
Iteration 4858: Loss = 0.4294058084487915
Iteration 4859: Loss = 0.4294055700302124
Iteration 4860: Loss = 0.4294053316116333
Iteration 4861: Loss = 0.4294050633907318
Iteration 4862: Loss = 0.4294048249721527
Iteration 4863: Loss = 0.4294045567512512
Iteration 4864: Loss = 0.4294043183326721
Iteration 4865: Loss = 0.429404079914093
Iteration 4866: Loss = 0.42940381169319153
Iteration 4867: Loss = 0.4294036030769348
Iteration 4868: Loss = 0.4294033348560333
Iteration 4869: Loss = 0.42940306663513184
Iteration 4870: Loss = 0.42940282821655273
Iteration 4871: Loss = 0.42940258979797363
Iteration 4872: Loss = 0.4294023811817169
Iteration 4873: Loss = 0.42940208315849304
Iteration 4874: Loss = 0.42940181493759155
Iteration 4875: Loss = 0.42940157651901245
Iteration 4876: Loss = 0.42940133810043335
Iteration 4877: Loss = 0.42940106987953186
Iteration 4878: Loss = 0.42940083146095276
Iteration 4879: Loss = 0.42940059304237366
Iteration 4880: Loss = 0.4294002950191498
Iteration 4881: Loss = 0.42940008640289307
Iteration 4882: Loss = 0.4293998181819916
Iteration 4883: Loss = 0.42939960956573486
Iteration 4884: Loss = 0.4293992519378662
Iteration 4885: Loss = 0.4293990731239319
Iteration 4886: Loss = 0.4293988049030304
Iteration 4887: Loss = 0.4293985664844513
Iteration 4888: Loss = 0.4293982684612274
Iteration 4889: Loss = 0.4293980598449707
Iteration 4890: Loss = 0.4293977916240692
Iteration 4891: Loss = 0.4293975234031677
Iteration 4892: Loss = 0.4293973445892334
Iteration 4893: Loss = 0.4293970763683319
Iteration 4894: Loss = 0.42939677834510803
Iteration 4895: Loss = 0.42939651012420654
Iteration 4896: Loss = 0.42939627170562744
Iteration 4897: Loss = 0.42939603328704834
Iteration 4898: Loss = 0.429395854473114
Iteration 4899: Loss = 0.42939549684524536
Iteration 4900: Loss = 0.42939528822898865
Iteration 4901: Loss = 0.42939504981040955
Iteration 4902: Loss = 0.4293947219848633
Iteration 4903: Loss = 0.42939454317092896
Iteration 4904: Loss = 0.4293942451477051
Iteration 4905: Loss = 0.4293939769268036
Iteration 4906: Loss = 0.4293937087059021
Iteration 4907: Loss = 0.4293935000896454
Iteration 4908: Loss = 0.42939329147338867
Iteration 4909: Loss = 0.4293929636478424
Iteration 4910: Loss = 0.4293927252292633
Iteration 4911: Loss = 0.4293924868106842
Iteration 4912: Loss = 0.4293922185897827
Iteration 4913: Loss = 0.42939192056655884
Iteration 4914: Loss = 0.4293917119503021
Iteration 4915: Loss = 0.42939144372940063
Iteration 4916: Loss = 0.4293912351131439
Iteration 4917: Loss = 0.42939093708992004
Iteration 4918: Loss = 0.42939066886901855
Iteration 4919: Loss = 0.42939040064811707
Iteration 4920: Loss = 0.42939016222953796
Iteration 4921: Loss = 0.4293898642063141
Iteration 4922: Loss = 0.4293896555900574
Iteration 4923: Loss = 0.4293893873691559
Iteration 4924: Loss = 0.429389089345932
Iteration 4925: Loss = 0.4293888807296753
Iteration 4926: Loss = 0.4293886125087738
Iteration 4927: Loss = 0.4293884038925171
Iteration 4928: Loss = 0.429388165473938
Iteration 4929: Loss = 0.4293879270553589
Iteration 4930: Loss = 0.42938756942749023
Iteration 4931: Loss = 0.4293873608112335
Iteration 4932: Loss = 0.42938703298568726
Iteration 4933: Loss = 0.42938682436943054
Iteration 4934: Loss = 0.42938655614852905
Iteration 4935: Loss = 0.42938628792762756
Iteration 4936: Loss = 0.42938604950904846
Iteration 4937: Loss = 0.4293857514858246
Iteration 4938: Loss = 0.42938554286956787
Iteration 4939: Loss = 0.429385244846344
Iteration 4940: Loss = 0.4293850064277649
Iteration 4941: Loss = 0.4293847680091858
Iteration 4942: Loss = 0.4293844699859619
Iteration 4943: Loss = 0.4293842017650604
Iteration 4944: Loss = 0.4293839633464813
Iteration 4945: Loss = 0.42938369512557983
Iteration 4946: Loss = 0.4293834865093231
Iteration 4947: Loss = 0.42938318848609924
Iteration 4948: Loss = 0.42938289046287537
Iteration 4949: Loss = 0.42938265204429626
Iteration 4950: Loss = 0.42938244342803955
Iteration 4951: Loss = 0.4293821454048157
Iteration 4952: Loss = 0.4293819069862366
Iteration 4953: Loss = 0.4293815493583679
Iteration 4954: Loss = 0.4293813109397888
Iteration 4955: Loss = 0.4293811023235321
Iteration 4956: Loss = 0.429380863904953
Iteration 4957: Loss = 0.4293805658817291
Iteration 4958: Loss = 0.4293803572654724
Iteration 4959: Loss = 0.42938005924224854
Iteration 4960: Loss = 0.42937979102134705
Iteration 4961: Loss = 0.42937958240509033
Iteration 4962: Loss = 0.42937925457954407
Iteration 4963: Loss = 0.4293789863586426
Iteration 4964: Loss = 0.4293787181377411
Iteration 4965: Loss = 0.4293785095214844
Iteration 4966: Loss = 0.4293782413005829
Iteration 4967: Loss = 0.4293779134750366
Iteration 4968: Loss = 0.4293777048587799
Iteration 4969: Loss = 0.42937740683555603
Iteration 4970: Loss = 0.42937716841697693
Iteration 4971: Loss = 0.42937690019607544
Iteration 4972: Loss = 0.42937666177749634
Iteration 4973: Loss = 0.4293763041496277
Iteration 4974: Loss = 0.42937609553337097
Iteration 4975: Loss = 0.42937588691711426
Iteration 4976: Loss = 0.4293755888938904
Iteration 4977: Loss = 0.4293752908706665
Iteration 4978: Loss = 0.4293750524520874
Iteration 4979: Loss = 0.4293747842311859
Iteration 4980: Loss = 0.4293745458126068
Iteration 4981: Loss = 0.4293742775917053
Iteration 4982: Loss = 0.42937400937080383
Iteration 4983: Loss = 0.42937371134757996
Iteration 4984: Loss = 0.42937347292900085
Iteration 4985: Loss = 0.429373174905777
Iteration 4986: Loss = 0.42937296628952026
Iteration 4987: Loss = 0.4293726980686188
Iteration 4988: Loss = 0.4293724000453949
Iteration 4989: Loss = 0.4293721318244934
Iteration 4990: Loss = 0.4293719530105591
Iteration 4991: Loss = 0.4293716847896576
Iteration 4992: Loss = 0.42937132716178894
Iteration 4993: Loss = 0.42937108874320984
Iteration 4994: Loss = 0.42937085032463074
Iteration 4995: Loss = 0.42937058210372925
Iteration 4996: Loss = 0.42937031388282776
Iteration 4997: Loss = 0.4293700158596039
Iteration 4998: Loss = 0.42936980724334717
Iteration 4999: Loss = 0.4293695390224457
Iteration 5000: Loss = 0.4293693006038666


Total training time (seconds): 45.43
