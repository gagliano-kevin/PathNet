Iteration 1: Loss = 0.8699366450309753
Iteration 2: Loss = 0.8595712184906006
Iteration 3: Loss = 0.8494940996170044
Iteration 4: Loss = 0.8397039771080017
Iteration 5: Loss = 0.8301900029182434
Iteration 6: Loss = 0.8209460973739624
Iteration 7: Loss = 0.8119709491729736
Iteration 8: Loss = 0.8032623529434204
Iteration 9: Loss = 0.7948160171508789
Iteration 10: Loss = 0.7866283059120178
Iteration 11: Loss = 0.7786955833435059
Iteration 12: Loss = 0.7710157036781311
Iteration 13: Loss = 0.7635834813117981
Iteration 14: Loss = 0.7563945055007935
Iteration 15: Loss = 0.7494444847106934
Iteration 16: Loss = 0.7427291870117188
Iteration 17: Loss = 0.7362443804740906
Iteration 18: Loss = 0.7299853563308716
Iteration 19: Loss = 0.7239457964897156
Iteration 20: Loss = 0.7181224226951599
Iteration 21: Loss = 0.7125088572502136
Iteration 22: Loss = 0.7070984840393066
Iteration 23: Loss = 0.7018856406211853
Iteration 24: Loss = 0.6968654990196228
Iteration 25: Loss = 0.6920320987701416
Iteration 26: Loss = 0.6873813271522522
Iteration 27: Loss = 0.682906985282898
Iteration 28: Loss = 0.6786041855812073
Iteration 29: Loss = 0.6744664311408997
Iteration 30: Loss = 0.6704906225204468
Iteration 31: Loss = 0.6666707992553711
Iteration 32: Loss = 0.6630012392997742
Iteration 33: Loss = 0.659477949142456
Iteration 34: Loss = 0.6560956835746765
Iteration 35: Loss = 0.6528468728065491
Iteration 36: Loss = 0.6497277617454529
Iteration 37: Loss = 0.6467334032058716
Iteration 38: Loss = 0.6438570618629456
Iteration 39: Loss = 0.6410939693450928
Iteration 40: Loss = 0.6384403109550476
Iteration 41: Loss = 0.6358888745307922
Iteration 42: Loss = 0.6334347128868103
Iteration 43: Loss = 0.6310724020004272
Iteration 44: Loss = 0.6287968754768372
Iteration 45: Loss = 0.6266025304794312
Iteration 46: Loss = 0.624485433101654
Iteration 47: Loss = 0.6224405169487
Iteration 48: Loss = 0.6204640865325928
Iteration 49: Loss = 0.618553876876831
Iteration 50: Loss = 0.6167075037956238
Iteration 51: Loss = 0.6149221658706665
Iteration 52: Loss = 0.6131975650787354
Iteration 53: Loss = 0.6115332245826721
Iteration 54: Loss = 0.6099318265914917
Iteration 55: Loss = 0.6083968281745911
Iteration 56: Loss = 0.6069313883781433
Iteration 57: Loss = 0.605541467666626
Iteration 58: Loss = 0.6042322516441345
Iteration 59: Loss = 0.6030059456825256
Iteration 60: Loss = 0.6018632650375366
Iteration 61: Loss = 0.600800633430481
Iteration 62: Loss = 0.5998140573501587
Iteration 63: Loss = 0.5988951921463013
Iteration 64: Loss = 0.5980348587036133
Iteration 65: Loss = 0.5972235202789307
Iteration 66: Loss = 0.5964497327804565
Iteration 67: Loss = 0.595704972743988
Iteration 68: Loss = 0.5949825644493103
Iteration 69: Loss = 0.59427809715271
Iteration 70: Loss = 0.5935899019241333
Iteration 71: Loss = 0.5929160118103027
Iteration 72: Loss = 0.5922541618347168
Iteration 73: Loss = 0.5916025042533875
Iteration 74: Loss = 0.5909594893455505
Iteration 75: Loss = 0.5903236269950867
Iteration 76: Loss = 0.5896936655044556
Iteration 77: Loss = 0.5890684127807617
Iteration 78: Loss = 0.5884471535682678
Iteration 79: Loss = 0.587829053401947
Iteration 80: Loss = 0.587213397026062
Iteration 81: Loss = 0.586599588394165
Iteration 82: Loss = 0.5859875679016113
Iteration 83: Loss = 0.585376501083374
Iteration 84: Loss = 0.5847663283348083
Iteration 85: Loss = 0.5841570496559143
Iteration 86: Loss = 0.5835481882095337
Iteration 87: Loss = 0.582939863204956
Iteration 88: Loss = 0.5823318362236023
Iteration 89: Loss = 0.5817243456840515
Iteration 90: Loss = 0.5811172723770142
Iteration 91: Loss = 0.580510675907135
Iteration 92: Loss = 0.5799045562744141
Iteration 93: Loss = 0.5792988538742065
Iteration 94: Loss = 0.5786937475204468
Iteration 95: Loss = 0.5780892968177795
Iteration 96: Loss = 0.5774852633476257
Iteration 97: Loss = 0.5768815279006958
Iteration 98: Loss = 0.5762783885002136
Iteration 99: Loss = 0.575675904750824
Iteration 100: Loss = 0.5750743746757507
Iteration 101: Loss = 0.5744746923446655
Iteration 102: Loss = 0.5738769769668579
Iteration 103: Loss = 0.5732818841934204
Iteration 104: Loss = 0.5726898908615112
Iteration 105: Loss = 0.572101354598999
Iteration 106: Loss = 0.5715165734291077
Iteration 107: Loss = 0.5709356069564819
Iteration 108: Loss = 0.5703582167625427
Iteration 109: Loss = 0.5697839856147766
Iteration 110: Loss = 0.5692127346992493
Iteration 111: Loss = 0.5686436295509338
Iteration 112: Loss = 0.5680765509605408
Iteration 113: Loss = 0.5675110220909119
Iteration 114: Loss = 0.5669466257095337
Iteration 115: Loss = 0.5663832426071167
Iteration 116: Loss = 0.5658203363418579
Iteration 117: Loss = 0.5652578473091125
Iteration 118: Loss = 0.5646956562995911
Iteration 119: Loss = 0.5641337633132935
Iteration 120: Loss = 0.5635722279548645
Iteration 121: Loss = 0.5630109310150146
Iteration 122: Loss = 0.562450110912323
Iteration 123: Loss = 0.5618898868560791
Iteration 124: Loss = 0.5613303184509277
Iteration 125: Loss = 0.5607714653015137
Iteration 126: Loss = 0.5602136254310608
Iteration 127: Loss = 0.5596566796302795
Iteration 128: Loss = 0.5591008067131042
Iteration 129: Loss = 0.5585458874702454
Iteration 130: Loss = 0.5579921007156372
Iteration 131: Loss = 0.557439386844635
Iteration 132: Loss = 0.5568877458572388
Iteration 133: Loss = 0.5563370585441589
Iteration 134: Loss = 0.5557872653007507
Iteration 135: Loss = 0.5552384853363037
Iteration 136: Loss = 0.5546905398368835
Iteration 137: Loss = 0.5541433691978455
Iteration 138: Loss = 0.553597092628479
Iteration 139: Loss = 0.5530516505241394
Iteration 140: Loss = 0.5525071024894714
Iteration 141: Loss = 0.5519630312919617
Iteration 142: Loss = 0.5514198541641235
Iteration 143: Loss = 0.5508773326873779
Iteration 144: Loss = 0.550335705280304
Iteration 145: Loss = 0.5497946739196777
Iteration 146: Loss = 0.5492545366287231
Iteration 147: Loss = 0.5487151741981506
Iteration 148: Loss = 0.5481765270233154
Iteration 149: Loss = 0.5476387143135071
Iteration 150: Loss = 0.5471016764640808
Iteration 151: Loss = 0.5465655326843262
Iteration 152: Loss = 0.5460302233695984
Iteration 153: Loss = 0.5454957485198975
Iteration 154: Loss = 0.5449619889259338
Iteration 155: Loss = 0.5444291830062866
Iteration 156: Loss = 0.5438970923423767
Iteration 157: Loss = 0.5433658957481384
Iteration 158: Loss = 0.5428354740142822
Iteration 159: Loss = 0.5423058867454529
Iteration 160: Loss = 0.5417770743370056
Iteration 161: Loss = 0.5412492156028748
Iteration 162: Loss = 0.5407220721244812
Iteration 163: Loss = 0.5401958227157593
Iteration 164: Loss = 0.5396702885627747
Iteration 165: Loss = 0.5391456484794617
Iteration 166: Loss = 0.538621723651886
Iteration 167: Loss = 0.5380986332893372
Iteration 168: Loss = 0.5375763177871704
Iteration 169: Loss = 0.5370548367500305
Iteration 170: Loss = 0.5365341901779175
Iteration 171: Loss = 0.5360143184661865
Iteration 172: Loss = 0.5354952216148376
Iteration 173: Loss = 0.5349770784378052
Iteration 174: Loss = 0.5344595909118652
Iteration 175: Loss = 0.5339428782463074
Iteration 176: Loss = 0.5334269404411316
Iteration 177: Loss = 0.5329118371009827
Iteration 178: Loss = 0.5323975086212158
Iteration 179: Loss = 0.531883955001831
Iteration 180: Loss = 0.5313711762428284
Iteration 181: Loss = 0.5308591723442078
Iteration 182: Loss = 0.530348002910614
Iteration 183: Loss = 0.5298375487327576
Iteration 184: Loss = 0.5293278098106384
Iteration 185: Loss = 0.5288189649581909
Iteration 186: Loss = 0.5283107757568359
Iteration 187: Loss = 0.5278034806251526
Iteration 188: Loss = 0.527296781539917
Iteration 189: Loss = 0.5267908573150635
Iteration 190: Loss = 0.526285707950592
Iteration 191: Loss = 0.5257813930511475
Iteration 192: Loss = 0.5252777338027954
Iteration 193: Loss = 0.5247747898101807
Iteration 194: Loss = 0.5242725610733032
Iteration 195: Loss = 0.5237711071968079
Iteration 196: Loss = 0.5232703685760498
Iteration 197: Loss = 0.5227704644203186
Iteration 198: Loss = 0.5222712159156799
Iteration 199: Loss = 0.5217726230621338
Iteration 200: Loss = 0.5212749242782593
Iteration 201: Loss = 0.5207777619361877
Iteration 202: Loss = 0.5202813148498535
Iteration 203: Loss = 0.5197857618331909
Iteration 204: Loss = 0.5192909836769104
Iteration 205: Loss = 0.5187969207763672
Iteration 206: Loss = 0.5183035731315613
Iteration 207: Loss = 0.5178109407424927
Iteration 208: Loss = 0.5173189640045166
Iteration 209: Loss = 0.5168279409408569
Iteration 210: Loss = 0.5163375735282898
Iteration 211: Loss = 0.5158479809761047
Iteration 212: Loss = 0.5153589844703674
Iteration 213: Loss = 0.5148707032203674
Iteration 214: Loss = 0.5143832564353943
Iteration 215: Loss = 0.5138964653015137
Iteration 216: Loss = 0.5134103894233704
Iteration 217: Loss = 0.5129250288009644
Iteration 218: Loss = 0.5124404430389404
Iteration 219: Loss = 0.5119568705558777
Iteration 220: Loss = 0.5114741325378418
Iteration 221: Loss = 0.5109923481941223
Iteration 222: Loss = 0.5105112791061401
Iteration 223: Loss = 0.5100311636924744
Iteration 224: Loss = 0.509552001953125
Iteration 225: Loss = 0.509073793888092
Iteration 226: Loss = 0.5085965991020203
Iteration 227: Loss = 0.5081202983856201
Iteration 228: Loss = 0.5076451897621155
Iteration 229: Loss = 0.5071709752082825
Iteration 230: Loss = 0.5066978335380554
Iteration 231: Loss = 0.5062257051467896
Iteration 232: Loss = 0.5057546496391296
Iteration 233: Loss = 0.5052846670150757
Iteration 234: Loss = 0.5048156380653381
Iteration 235: Loss = 0.5043476223945618
Iteration 236: Loss = 0.5038806796073914
Iteration 237: Loss = 0.5034149289131165
Iteration 238: Loss = 0.5029503107070923
Iteration 239: Loss = 0.5024867653846741
Iteration 240: Loss = 0.5020243525505066
Iteration 241: Loss = 0.5015632510185242
Iteration 242: Loss = 0.5011031627655029
Iteration 243: Loss = 0.5006442070007324
Iteration 244: Loss = 0.5001865029335022
Iteration 245: Loss = 0.49973011016845703
Iteration 246: Loss = 0.4992748498916626
Iteration 247: Loss = 0.4988207221031189
Iteration 248: Loss = 0.49836790561676025
Iteration 249: Loss = 0.49791643023490906
Iteration 250: Loss = 0.497466117143631
Iteration 251: Loss = 0.49701693654060364
Iteration 252: Loss = 0.4965691566467285
Iteration 253: Loss = 0.4961225986480713
Iteration 254: Loss = 0.4956771731376648
Iteration 255: Loss = 0.4952329695224762
Iteration 256: Loss = 0.49479031562805176
Iteration 257: Loss = 0.4943488538265228
Iteration 258: Loss = 0.4939086437225342
Iteration 259: Loss = 0.4934696555137634
Iteration 260: Loss = 0.4930320084095001
Iteration 261: Loss = 0.4925954341888428
Iteration 262: Loss = 0.49216005206108093
Iteration 263: Loss = 0.4917261600494385
Iteration 264: Loss = 0.49129340052604675
Iteration 265: Loss = 0.4908618628978729
Iteration 266: Loss = 0.4904317855834961
Iteration 267: Loss = 0.49000290036201477
Iteration 268: Loss = 0.4895751476287842
Iteration 269: Loss = 0.489148885011673
Iteration 270: Loss = 0.48872387409210205
Iteration 271: Loss = 0.4882999360561371
Iteration 272: Loss = 0.4878774881362915
Iteration 273: Loss = 0.4874561131000519
Iteration 274: Loss = 0.4870359003543854
Iteration 275: Loss = 0.4866170287132263
Iteration 276: Loss = 0.4861992597579956
Iteration 277: Loss = 0.48578253388404846
Iteration 278: Loss = 0.4853672981262207
Iteration 279: Loss = 0.4849531948566437
Iteration 280: Loss = 0.4845401644706726
Iteration 281: Loss = 0.48412859439849854
Iteration 282: Loss = 0.4837180972099304
Iteration 283: Loss = 0.48330870270729065
Iteration 284: Loss = 0.48290055990219116
Iteration 285: Loss = 0.48249351978302
Iteration 286: Loss = 0.48208755254745483
Iteration 287: Loss = 0.4816829264163971
Iteration 288: Loss = 0.4812794029712677
Iteration 289: Loss = 0.4808768332004547
Iteration 290: Loss = 0.4804755747318268
Iteration 291: Loss = 0.4800754487514496
Iteration 292: Loss = 0.47967642545700073
Iteration 293: Loss = 0.47927868366241455
Iteration 294: Loss = 0.47888198494911194
Iteration 295: Loss = 0.47848638892173767
Iteration 296: Loss = 0.47809210419654846
Iteration 297: Loss = 0.47769874334335327
Iteration 298: Loss = 0.47730645537376404
Iteration 299: Loss = 0.4769154191017151
Iteration 300: Loss = 0.47652533650398254
Iteration 301: Loss = 0.4761362671852112
Iteration 302: Loss = 0.47574833035469055
Iteration 303: Loss = 0.47536131739616394
Iteration 304: Loss = 0.4749753475189209
Iteration 305: Loss = 0.47459056973457336
Iteration 306: Loss = 0.4742067754268646
Iteration 307: Loss = 0.47382408380508423
Iteration 308: Loss = 0.4734424948692322
Iteration 309: Loss = 0.47306185960769653
Iteration 310: Loss = 0.472682386636734
Iteration 311: Loss = 0.4723040759563446
Iteration 312: Loss = 0.471926748752594
Iteration 313: Loss = 0.47155043482780457
Iteration 314: Loss = 0.47117528319358826
Iteration 315: Loss = 0.4708010256290436
Iteration 316: Loss = 0.4704277813434601
Iteration 317: Loss = 0.4700557291507721
Iteration 318: Loss = 0.4696846604347229
Iteration 319: Loss = 0.46931442618370056
Iteration 320: Loss = 0.4689455032348633
Iteration 321: Loss = 0.4685775339603424
Iteration 322: Loss = 0.46821048855781555
Iteration 323: Loss = 0.46784472465515137
Iteration 324: Loss = 0.4674798846244812
Iteration 325: Loss = 0.46711593866348267
Iteration 326: Loss = 0.4667533040046692
Iteration 327: Loss = 0.4663916528224945
Iteration 328: Loss = 0.46603086590766907
Iteration 329: Loss = 0.4656713604927063
Iteration 330: Loss = 0.46531280875205994
Iteration 331: Loss = 0.46495532989501953
Iteration 332: Loss = 0.4645988345146179
Iteration 333: Loss = 0.46424350142478943
Iteration 334: Loss = 0.46388906240463257
Iteration 335: Loss = 0.4635355770587921
Iteration 336: Loss = 0.46318337321281433
Iteration 337: Loss = 0.4628320634365082
Iteration 338: Loss = 0.46248167753219604
Iteration 339: Loss = 0.4621324837207794
Iteration 340: Loss = 0.4617844820022583
Iteration 341: Loss = 0.4614374339580536
Iteration 342: Loss = 0.4610913395881653
Iteration 343: Loss = 0.4607466161251068
Iteration 344: Loss = 0.4604029357433319
Iteration 345: Loss = 0.460060179233551
Iteration 346: Loss = 0.4597184956073761
Iteration 347: Loss = 0.4593782424926758
Iteration 348: Loss = 0.4590388834476471
Iteration 349: Loss = 0.4587005376815796
Iteration 350: Loss = 0.45836350321769714
Iteration 351: Loss = 0.4580276310443878
Iteration 352: Loss = 0.45769286155700684
Iteration 353: Loss = 0.4573590159416199
Iteration 354: Loss = 0.45702654123306274
Iteration 355: Loss = 0.4566952586174011
Iteration 356: Loss = 0.4563649892807007
Iteration 357: Loss = 0.45603594183921814
Iteration 358: Loss = 0.4557081162929535
Iteration 359: Loss = 0.45538148283958435
Iteration 360: Loss = 0.45505598187446594
Iteration 361: Loss = 0.45473143458366394
Iteration 362: Loss = 0.4544082581996918
Iteration 363: Loss = 0.45408639311790466
Iteration 364: Loss = 0.45376551151275635
Iteration 365: Loss = 0.45344579219818115
Iteration 366: Loss = 0.453127384185791
Iteration 367: Loss = 0.4528104066848755
Iteration 368: Loss = 0.45249441266059875
Iteration 369: Loss = 0.4521796703338623
Iteration 370: Loss = 0.451866090297699
Iteration 371: Loss = 0.45155394077301025
Iteration 372: Loss = 0.45124295353889465
Iteration 373: Loss = 0.4509330987930298
Iteration 374: Loss = 0.45062434673309326
Iteration 375: Loss = 0.4503169655799866
Iteration 376: Loss = 0.4500108063220978
Iteration 377: Loss = 0.44970569014549255
Iteration 378: Loss = 0.4494017958641052
Iteration 379: Loss = 0.44909921288490295
Iteration 380: Loss = 0.4487980604171753
Iteration 381: Loss = 0.4484979808330536
Iteration 382: Loss = 0.44819921255111694
Iteration 383: Loss = 0.44790154695510864
Iteration 384: Loss = 0.44760552048683167
Iteration 385: Loss = 0.44731056690216064
Iteration 386: Loss = 0.4470168352127075
Iteration 387: Loss = 0.44672420620918274
Iteration 388: Loss = 0.44643309712409973
Iteration 389: Loss = 0.4461432993412018
Iteration 390: Loss = 0.44585493206977844
Iteration 391: Loss = 0.44556766748428345
Iteration 392: Loss = 0.4452816843986511
Iteration 393: Loss = 0.44499701261520386
Iteration 394: Loss = 0.4447137713432312
Iteration 395: Loss = 0.44443169236183167
Iteration 396: Loss = 0.4441508948802948
Iteration 397: Loss = 0.4438713490962982
Iteration 398: Loss = 0.4435930848121643
Iteration 399: Loss = 0.4433162212371826
Iteration 400: Loss = 0.4430406391620636
Iteration 401: Loss = 0.4427662491798401
Iteration 402: Loss = 0.44249311089515686
Iteration 403: Loss = 0.44222116470336914
Iteration 404: Loss = 0.4419507682323456
Iteration 405: Loss = 0.44168174266815186
Iteration 406: Loss = 0.44141384959220886
Iteration 407: Loss = 0.4411473274230957
Iteration 408: Loss = 0.44088196754455566
Iteration 409: Loss = 0.44061821699142456
Iteration 410: Loss = 0.44035568833351135
Iteration 411: Loss = 0.4400945007801056
Iteration 412: Loss = 0.4398345947265625
Iteration 413: Loss = 0.4395759105682373
Iteration 414: Loss = 0.43931877613067627
Iteration 415: Loss = 0.4390629231929779
Iteration 416: Loss = 0.43880847096443176
Iteration 417: Loss = 0.4385550618171692
Iteration 418: Loss = 0.438303142786026
Iteration 419: Loss = 0.43805253505706787
Iteration 420: Loss = 0.4378034770488739
Iteration 421: Loss = 0.43755561113357544
Iteration 422: Loss = 0.43730905652046204
Iteration 423: Loss = 0.4370637536048889
Iteration 424: Loss = 0.4368197023868561
Iteration 425: Loss = 0.4365772008895874
Iteration 426: Loss = 0.436335951089859
Iteration 427: Loss = 0.43609604239463806
Iteration 428: Loss = 0.43585729598999023
Iteration 429: Loss = 0.4356198012828827
Iteration 430: Loss = 0.4353835880756378
Iteration 431: Loss = 0.43514877557754517
Iteration 432: Loss = 0.4349154233932495
Iteration 433: Loss = 0.434683233499527
Iteration 434: Loss = 0.43445226550102234
Iteration 435: Loss = 0.4342225193977356
Iteration 436: Loss = 0.43399402499198914
Iteration 437: Loss = 0.4337671399116516
Iteration 438: Loss = 0.43354135751724243
Iteration 439: Loss = 0.43331682682037354
Iteration 440: Loss = 0.43309351801872253
Iteration 441: Loss = 0.4328713119029999
Iteration 442: Loss = 0.43265047669410706
Iteration 443: Loss = 0.4324309825897217
Iteration 444: Loss = 0.432212769985199
Iteration 445: Loss = 0.43199583888053894
Iteration 446: Loss = 0.43177998065948486
Iteration 447: Loss = 0.431565523147583
Iteration 448: Loss = 0.4313521683216095
Iteration 449: Loss = 0.4311401844024658
Iteration 450: Loss = 0.43092969059944153
Iteration 451: Loss = 0.4307202398777008
Iteration 452: Loss = 0.43051213026046753
Iteration 453: Loss = 0.4303050935268402
Iteration 454: Loss = 0.43009912967681885
Iteration 455: Loss = 0.4298945665359497
Iteration 456: Loss = 0.42969122529029846
Iteration 457: Loss = 0.4294890761375427
Iteration 458: Loss = 0.4292881488800049
Iteration 459: Loss = 0.4290883243083954
Iteration 460: Loss = 0.4288897216320038
Iteration 461: Loss = 0.42869219183921814
Iteration 462: Loss = 0.428495854139328
Iteration 463: Loss = 0.4283009469509125
Iteration 464: Loss = 0.4281071126461029
Iteration 465: Loss = 0.4279143214225769
Iteration 466: Loss = 0.4277227818965912
Iteration 467: Loss = 0.42753228545188904
Iteration 468: Loss = 0.4273427724838257
Iteration 469: Loss = 0.4271545112133026
Iteration 470: Loss = 0.42696747183799744
Iteration 471: Loss = 0.4267815053462982
Iteration 472: Loss = 0.42659661173820496
Iteration 473: Loss = 0.4264127314090729
Iteration 474: Loss = 0.42622992396354675
Iteration 475: Loss = 0.426048219203949
Iteration 476: Loss = 0.4258674383163452
Iteration 477: Loss = 0.42568784952163696
Iteration 478: Loss = 0.42550957202911377
Iteration 479: Loss = 0.4253321588039398
Iteration 480: Loss = 0.4251559376716614
Iteration 481: Loss = 0.42498070001602173
Iteration 482: Loss = 0.4248063862323761
Iteration 483: Loss = 0.4246331751346588
Iteration 484: Loss = 0.4244609773159027
Iteration 485: Loss = 0.42428964376449585
Iteration 486: Loss = 0.42411959171295166
Iteration 487: Loss = 0.4239504933357239
Iteration 488: Loss = 0.42378225922584534
Iteration 489: Loss = 0.4236150085926056
Iteration 490: Loss = 0.423448771238327
Iteration 491: Loss = 0.4232832193374634
Iteration 492: Loss = 0.4231187105178833
Iteration 493: Loss = 0.42295506596565247
Iteration 494: Loss = 0.4227924048900604
Iteration 495: Loss = 0.4226307272911072
Iteration 496: Loss = 0.4224698841571808
Iteration 497: Loss = 0.4223098158836365
Iteration 498: Loss = 0.42215055227279663
Iteration 499: Loss = 0.42199215292930603
Iteration 500: Loss = 0.4218345880508423
Iteration 501: Loss = 0.42167767882347107
Iteration 502: Loss = 0.421521931886673
Iteration 503: Loss = 0.4213669002056122
Iteration 504: Loss = 0.4212126135826111
Iteration 505: Loss = 0.42105919122695923
Iteration 506: Loss = 0.4209064543247223
Iteration 507: Loss = 0.42075446248054504
Iteration 508: Loss = 0.4206032454967499
Iteration 509: Loss = 0.4204528033733368
Iteration 510: Loss = 0.4203030467033386
Iteration 511: Loss = 0.42015406489372253
Iteration 512: Loss = 0.42000603675842285
Iteration 513: Loss = 0.41985857486724854
Iteration 514: Loss = 0.4197116792201996
Iteration 515: Loss = 0.4195656180381775
Iteration 516: Loss = 0.41942012310028076
Iteration 517: Loss = 0.41927531361579895
Iteration 518: Loss = 0.4191311299800873
Iteration 519: Loss = 0.4189879298210144
Iteration 520: Loss = 0.4188452363014221
Iteration 521: Loss = 0.4187031388282776
Iteration 522: Loss = 0.41856178641319275
Iteration 523: Loss = 0.4184210002422333
Iteration 524: Loss = 0.418280690908432
Iteration 525: Loss = 0.41814112663269043
Iteration 526: Loss = 0.4180021286010742
Iteration 527: Loss = 0.4178636372089386
Iteration 528: Loss = 0.4177258014678955
Iteration 529: Loss = 0.4175887405872345
Iteration 530: Loss = 0.41745224595069885
Iteration 531: Loss = 0.4173160791397095
Iteration 532: Loss = 0.41718050837516785
Iteration 533: Loss = 0.41704562306404114
Iteration 534: Loss = 0.41691115498542786
Iteration 535: Loss = 0.416777104139328
Iteration 536: Loss = 0.4166436493396759
Iteration 537: Loss = 0.4165106415748596
Iteration 538: Loss = 0.4163782000541687
Iteration 539: Loss = 0.416246235370636
Iteration 540: Loss = 0.41611480712890625
Iteration 541: Loss = 0.41598376631736755
Iteration 542: Loss = 0.41585302352905273
Iteration 543: Loss = 0.4157227873802185
Iteration 544: Loss = 0.41559290885925293
Iteration 545: Loss = 0.4154634475708008
Iteration 546: Loss = 0.41533422470092773
Iteration 547: Loss = 0.41520553827285767
Iteration 548: Loss = 0.41507720947265625
Iteration 549: Loss = 0.4149491488933563
Iteration 550: Loss = 0.4148213565349579
Iteration 551: Loss = 0.41469430923461914
Iteration 552: Loss = 0.4145674407482147
Iteration 553: Loss = 0.41444092988967896
Iteration 554: Loss = 0.4143146276473999
Iteration 555: Loss = 0.41418880224227905
Iteration 556: Loss = 0.41406336426734924
Iteration 557: Loss = 0.41393807530403137
Iteration 558: Loss = 0.4138130247592926
Iteration 559: Loss = 0.41368839144706726
Iteration 560: Loss = 0.4135640263557434
Iteration 561: Loss = 0.4134398102760315
Iteration 562: Loss = 0.41331586241722107
Iteration 563: Loss = 0.4131922721862793
Iteration 564: Loss = 0.4130690097808838
Iteration 565: Loss = 0.4129459261894226
Iteration 566: Loss = 0.4128231108188629
Iteration 567: Loss = 0.4127006232738495
Iteration 568: Loss = 0.412578284740448
Iteration 569: Loss = 0.41245612502098083
Iteration 570: Loss = 0.41233405470848083
Iteration 571: Loss = 0.4122123122215271
Iteration 572: Loss = 0.41209062933921814
Iteration 573: Loss = 0.41196900606155396
Iteration 574: Loss = 0.41184747219085693
Iteration 575: Loss = 0.4117264151573181
Iteration 576: Loss = 0.4116053581237793
Iteration 577: Loss = 0.41148436069488525
Iteration 578: Loss = 0.411363422870636
Iteration 579: Loss = 0.41124290227890015
Iteration 580: Loss = 0.4111223816871643
Iteration 581: Loss = 0.41100195050239563
Iteration 582: Loss = 0.41088157892227173
Iteration 583: Loss = 0.4107615053653717
Iteration 584: Loss = 0.4106414020061493
Iteration 585: Loss = 0.4105212986469269
Iteration 586: Loss = 0.4104013442993164
Iteration 587: Loss = 0.4102816879749298
Iteration 588: Loss = 0.41016215085983276
Iteration 589: Loss = 0.41004255414009094
Iteration 590: Loss = 0.40992307662963867
Iteration 591: Loss = 0.40980368852615356
Iteration 592: Loss = 0.409684419631958
Iteration 593: Loss = 0.4095650315284729
Iteration 594: Loss = 0.4094456732273102
Iteration 595: Loss = 0.4093264639377594
Iteration 596: Loss = 0.409207284450531
Iteration 597: Loss = 0.40908798575401306
Iteration 598: Loss = 0.4089687168598175
Iteration 599: Loss = 0.4088497757911682
Iteration 600: Loss = 0.4087308943271637
Iteration 601: Loss = 0.40861204266548157
Iteration 602: Loss = 0.4084931015968323
Iteration 603: Loss = 0.40837419033050537
Iteration 604: Loss = 0.4082554578781128
Iteration 605: Loss = 0.4081367254257202
Iteration 606: Loss = 0.40801793336868286
Iteration 607: Loss = 0.40789899230003357
Iteration 608: Loss = 0.4077802896499634
Iteration 609: Loss = 0.4076615869998932
Iteration 610: Loss = 0.40754276514053345
Iteration 611: Loss = 0.40742382407188416
Iteration 612: Loss = 0.40730494260787964
Iteration 613: Loss = 0.40718621015548706
Iteration 614: Loss = 0.40706750750541687
Iteration 615: Loss = 0.40694865584373474
Iteration 616: Loss = 0.406829833984375
Iteration 617: Loss = 0.40671107172966003
Iteration 618: Loss = 0.4065922796726227
Iteration 619: Loss = 0.4064733386039734
Iteration 620: Loss = 0.4063543379306793
Iteration 621: Loss = 0.40623530745506287
Iteration 622: Loss = 0.4061163067817688
Iteration 623: Loss = 0.40599724650382996
Iteration 624: Loss = 0.4058780074119568
Iteration 625: Loss = 0.4057587683200836
Iteration 626: Loss = 0.4056394100189209
Iteration 627: Loss = 0.4055202305316925
Iteration 628: Loss = 0.40540099143981934
Iteration 629: Loss = 0.4052816331386566
Iteration 630: Loss = 0.4051620662212372
Iteration 631: Loss = 0.4050426185131073
Iteration 632: Loss = 0.40492314100265503
Iteration 633: Loss = 0.40480339527130127
Iteration 634: Loss = 0.4046836793422699
Iteration 635: Loss = 0.40456363558769226
Iteration 636: Loss = 0.404443621635437
Iteration 637: Loss = 0.404323548078537
Iteration 638: Loss = 0.40420323610305786
Iteration 639: Loss = 0.40408289432525635
Iteration 640: Loss = 0.40396222472190857
Iteration 641: Loss = 0.4038415551185608
Iteration 642: Loss = 0.4037207067012787
Iteration 643: Loss = 0.4035998582839966
Iteration 644: Loss = 0.4034788906574249
Iteration 645: Loss = 0.4033576548099518
Iteration 646: Loss = 0.4032363295555115
Iteration 647: Loss = 0.403114914894104
Iteration 648: Loss = 0.40299323201179504
Iteration 649: Loss = 0.402871310710907
Iteration 650: Loss = 0.40274932980537415
Iteration 651: Loss = 0.40262722969055176
Iteration 652: Loss = 0.40250495076179504
Iteration 653: Loss = 0.40238237380981445
Iteration 654: Loss = 0.40225961804389954
Iteration 655: Loss = 0.4021366238594055
Iteration 656: Loss = 0.4020135700702667
Iteration 657: Loss = 0.4018903076648712
Iteration 658: Loss = 0.40176695585250854
Iteration 659: Loss = 0.40164342522621155
Iteration 660: Loss = 0.4015195965766907
Iteration 661: Loss = 0.4013955891132355
Iteration 662: Loss = 0.4012715220451355
Iteration 663: Loss = 0.40114709734916687
Iteration 664: Loss = 0.4010225236415863
Iteration 665: Loss = 0.4008975923061371
Iteration 666: Loss = 0.40077242255210876
Iteration 667: Loss = 0.40064722299575806
Iteration 668: Loss = 0.40052175521850586
Iteration 669: Loss = 0.4003959894180298
Iteration 670: Loss = 0.400270015001297
Iteration 671: Loss = 0.40014374256134033
Iteration 672: Loss = 0.4000172019004822
Iteration 673: Loss = 0.3998905122280121
Iteration 674: Loss = 0.3997636139392853
Iteration 675: Loss = 0.3996363580226898
Iteration 676: Loss = 0.3995087146759033
Iteration 677: Loss = 0.3993808627128601
Iteration 678: Loss = 0.39925289154052734
Iteration 679: Loss = 0.3991245627403259
Iteration 680: Loss = 0.39899590611457825
Iteration 681: Loss = 0.3988669812679291
Iteration 682: Loss = 0.39873772859573364
Iteration 683: Loss = 0.39860835671424866
Iteration 684: Loss = 0.3984786868095398
Iteration 685: Loss = 0.39834871888160706
Iteration 686: Loss = 0.3982185125350952
Iteration 687: Loss = 0.39808782935142517
Iteration 688: Loss = 0.39795684814453125
Iteration 689: Loss = 0.397825688123703
Iteration 690: Loss = 0.3976943790912628
Iteration 691: Loss = 0.3975626528263092
Iteration 692: Loss = 0.39743050932884216
Iteration 693: Loss = 0.3972982168197632
Iteration 694: Loss = 0.3971654772758484
Iteration 695: Loss = 0.39703235030174255
Iteration 696: Loss = 0.39689892530441284
Iteration 697: Loss = 0.39676520228385925
Iteration 698: Loss = 0.396631121635437
Iteration 699: Loss = 0.3964966833591461
Iteration 700: Loss = 0.39636173844337463
Iteration 701: Loss = 0.3962264657020569
Iteration 702: Loss = 0.3960910439491272
Iteration 703: Loss = 0.3959552049636841
Iteration 704: Loss = 0.39581891894340515
Iteration 705: Loss = 0.3956821858882904
Iteration 706: Loss = 0.39554500579833984
Iteration 707: Loss = 0.39540746808052063
Iteration 708: Loss = 0.3952697515487671
Iteration 709: Loss = 0.39513152837753296
Iteration 710: Loss = 0.3949931561946869
Iteration 711: Loss = 0.39485424757003784
Iteration 712: Loss = 0.3947148025035858
Iteration 713: Loss = 0.39457494020462036
Iteration 714: Loss = 0.3944348096847534
Iteration 715: Loss = 0.3942943215370178
Iteration 716: Loss = 0.3941534459590912
Iteration 717: Loss = 0.39401206374168396
Iteration 718: Loss = 0.39387020468711853
Iteration 719: Loss = 0.3937280476093292
Iteration 720: Loss = 0.3935854732990265
Iteration 721: Loss = 0.3934424817562103
Iteration 722: Loss = 0.3932989835739136
Iteration 723: Loss = 0.3931550085544586
Iteration 724: Loss = 0.3930107355117798
Iteration 725: Loss = 0.39286601543426514
Iteration 726: Loss = 0.3927207291126251
Iteration 727: Loss = 0.39257514476776123
Iteration 728: Loss = 0.39242902398109436
Iteration 729: Loss = 0.3922824561595917
Iteration 730: Loss = 0.3921354413032532
Iteration 731: Loss = 0.391988068819046
Iteration 732: Loss = 0.3918401300907135
Iteration 733: Loss = 0.391691654920578
Iteration 734: Loss = 0.39154279232025146
Iteration 735: Loss = 0.39139339327812195
Iteration 736: Loss = 0.39124351739883423
Iteration 737: Loss = 0.3910931348800659
Iteration 738: Loss = 0.3909423053264618
Iteration 739: Loss = 0.39079102873802185
Iteration 740: Loss = 0.39063918590545654
Iteration 741: Loss = 0.39048686623573303
Iteration 742: Loss = 0.3903340697288513
Iteration 743: Loss = 0.390180766582489
Iteration 744: Loss = 0.39002689719200134
Iteration 745: Loss = 0.38987240195274353
Iteration 746: Loss = 0.3897174894809723
Iteration 747: Loss = 0.38956212997436523
Iteration 748: Loss = 0.3894061744213104
Iteration 749: Loss = 0.3892497718334198
Iteration 750: Loss = 0.38909274339675903
Iteration 751: Loss = 0.3889351785182953
Iteration 752: Loss = 0.3887770175933838
Iteration 753: Loss = 0.3886182904243469
Iteration 754: Loss = 0.3884589672088623
Iteration 755: Loss = 0.38829904794692993
Iteration 756: Loss = 0.38813868165016174
Iteration 757: Loss = 0.3879777789115906
Iteration 758: Loss = 0.38781630992889404
Iteration 759: Loss = 0.38765427470207214
Iteration 760: Loss = 0.3874916136264801
Iteration 761: Loss = 0.3873283565044403
Iteration 762: Loss = 0.38716450333595276
Iteration 763: Loss = 0.38700005412101746
Iteration 764: Loss = 0.38683515787124634
Iteration 765: Loss = 0.3866695463657379
Iteration 766: Loss = 0.3865034282207489
Iteration 767: Loss = 0.3863365352153778
Iteration 768: Loss = 0.38616910576820374
Iteration 769: Loss = 0.3860010504722595
Iteration 770: Loss = 0.3858323097229004
Iteration 771: Loss = 0.3856630325317383
Iteration 772: Loss = 0.3854931592941284
Iteration 773: Loss = 0.38532277941703796
Iteration 774: Loss = 0.385151743888855
Iteration 775: Loss = 0.38498005270957947
Iteration 776: Loss = 0.38480767607688904
Iteration 777: Loss = 0.3846346437931061
Iteration 778: Loss = 0.3844609558582306
Iteration 779: Loss = 0.38428670167922974
Iteration 780: Loss = 0.38411176204681396
Iteration 781: Loss = 0.3839362859725952
Iteration 782: Loss = 0.3837600648403168
Iteration 783: Loss = 0.3835831880569458
Iteration 784: Loss = 0.3834055960178375
Iteration 785: Loss = 0.38322728872299194
Iteration 786: Loss = 0.38304832577705383
Iteration 787: Loss = 0.3828687071800232
Iteration 788: Loss = 0.3826884925365448
Iteration 789: Loss = 0.38250768184661865
Iteration 790: Loss = 0.38232627511024475
Iteration 791: Loss = 0.38214409351348877
Iteration 792: Loss = 0.38196122646331787
Iteration 793: Loss = 0.38177764415740967
Iteration 794: Loss = 0.3815932869911194
Iteration 795: Loss = 0.3814082741737366
Iteration 796: Loss = 0.38122254610061646
Iteration 797: Loss = 0.3810361623764038
Iteration 798: Loss = 0.3808491826057434
Iteration 799: Loss = 0.3806614577770233
Iteration 800: Loss = 0.3804730176925659
Iteration 801: Loss = 0.3802838623523712
Iteration 802: Loss = 0.3800939619541168
Iteration 803: Loss = 0.3799034357070923
Iteration 804: Loss = 0.37971216440200806
Iteration 805: Loss = 0.37952014803886414
Iteration 806: Loss = 0.37932732701301575
Iteration 807: Loss = 0.379133939743042
Iteration 808: Loss = 0.37893980741500854
Iteration 809: Loss = 0.37874484062194824
Iteration 810: Loss = 0.378549188375473
Iteration 811: Loss = 0.3783527612686157
Iteration 812: Loss = 0.37815558910369873
Iteration 813: Loss = 0.3779575824737549
Iteration 814: Loss = 0.37775883078575134
Iteration 815: Loss = 0.37755927443504333
Iteration 816: Loss = 0.37735891342163086
Iteration 817: Loss = 0.37715786695480347
Iteration 818: Loss = 0.3769562244415283
Iteration 819: Loss = 0.37675368785858154
Iteration 820: Loss = 0.3765502870082855
Iteration 821: Loss = 0.37634602189064026
Iteration 822: Loss = 0.37614116072654724
Iteration 823: Loss = 0.37593555450439453
Iteration 824: Loss = 0.3757290840148926
Iteration 825: Loss = 0.37552177906036377
Iteration 826: Loss = 0.3753136694431305
Iteration 827: Loss = 0.37510478496551514
Iteration 828: Loss = 0.37489527463912964
Iteration 829: Loss = 0.3746849596500397
Iteration 830: Loss = 0.37447378039360046
Iteration 831: Loss = 0.37426188588142395
Iteration 832: Loss = 0.3740490972995758
Iteration 833: Loss = 0.3738355338573456
Iteration 834: Loss = 0.3736211657524109
Iteration 835: Loss = 0.37340599298477173
Iteration 836: Loss = 0.3731900155544281
Iteration 837: Loss = 0.37297311425209045
Iteration 838: Loss = 0.3727554976940155
Iteration 839: Loss = 0.37253713607788086
Iteration 840: Loss = 0.37231793999671936
Iteration 841: Loss = 0.3720978796482086
Iteration 842: Loss = 0.37187695503234863
Iteration 843: Loss = 0.37165531516075134
Iteration 844: Loss = 0.37143275141716003
Iteration 845: Loss = 0.37120938301086426
Iteration 846: Loss = 0.37098515033721924
Iteration 847: Loss = 0.37076014280319214
Iteration 848: Loss = 0.37053415179252625
Iteration 849: Loss = 0.37030738592147827
Iteration 850: Loss = 0.3700798749923706
Iteration 851: Loss = 0.3698514401912689
Iteration 852: Loss = 0.36962223052978516
Iteration 853: Loss = 0.36939218640327454
Iteration 854: Loss = 0.3691612184047699
Iteration 855: Loss = 0.3689294457435608
Iteration 856: Loss = 0.36869677901268005
Iteration 857: Loss = 0.3684631884098053
Iteration 858: Loss = 0.3682287931442261
Iteration 859: Loss = 0.36799347400665283
Iteration 860: Loss = 0.36775726079940796
Iteration 861: Loss = 0.36752021312713623
Iteration 862: Loss = 0.3672822117805481
Iteration 863: Loss = 0.36704346537590027
Iteration 864: Loss = 0.36680373549461365
Iteration 865: Loss = 0.3665631115436554
Iteration 866: Loss = 0.3663216233253479
Iteration 867: Loss = 0.3660791516304016
Iteration 868: Loss = 0.3658358156681061
Iteration 869: Loss = 0.36559152603149414
Iteration 870: Loss = 0.36534643173217773
Iteration 871: Loss = 0.3651004731655121
Iteration 872: Loss = 0.3648536801338196
Iteration 873: Loss = 0.364606112241745
Iteration 874: Loss = 0.36435750126838684
Iteration 875: Loss = 0.36410796642303467
Iteration 876: Loss = 0.36385753750801086
Iteration 877: Loss = 0.3636062741279602
Iteration 878: Loss = 0.3633541464805603
Iteration 879: Loss = 0.36310115456581116
Iteration 880: Loss = 0.3628471791744232
Iteration 881: Loss = 0.3625921905040741
Iteration 882: Loss = 0.36233648657798767
Iteration 883: Loss = 0.36207976937294006
Iteration 884: Loss = 0.3618222177028656
Iteration 885: Loss = 0.36156371235847473
Iteration 886: Loss = 0.36130428314208984
Iteration 887: Loss = 0.3610439598560333
Iteration 888: Loss = 0.3607827126979828
Iteration 889: Loss = 0.3605205714702606
Iteration 890: Loss = 0.3602575361728668
Iteration 891: Loss = 0.35999372601509094
Iteration 892: Loss = 0.35972893238067627
Iteration 893: Loss = 0.35946324467658997
Iteration 894: Loss = 0.35919663310050964
Iteration 895: Loss = 0.3589290380477905
Iteration 896: Loss = 0.3586605191230774
Iteration 897: Loss = 0.35839107632637024
Iteration 898: Loss = 0.35812070965766907
Iteration 899: Loss = 0.3578492999076843
Iteration 900: Loss = 0.3575769364833832
Iteration 901: Loss = 0.3573036193847656
Iteration 902: Loss = 0.3570293188095093
Iteration 903: Loss = 0.3567540943622589
Iteration 904: Loss = 0.3564777970314026
Iteration 905: Loss = 0.3562004864215851
Iteration 906: Loss = 0.35592272877693176
Iteration 907: Loss = 0.35564398765563965
Iteration 908: Loss = 0.3553643524646759
Iteration 909: Loss = 0.3550836443901062
Iteration 910: Loss = 0.3548020124435425
Iteration 911: Loss = 0.35451945662498474
Iteration 912: Loss = 0.3542359471321106
Iteration 913: Loss = 0.35395148396492004
Iteration 914: Loss = 0.3536660671234131
Iteration 915: Loss = 0.3533797264099121
Iteration 916: Loss = 0.35309237241744995
Iteration 917: Loss = 0.3528040945529938
Iteration 918: Loss = 0.3525148928165436
Iteration 919: Loss = 0.3522246778011322
Iteration 920: Loss = 0.3519335985183716
Iteration 921: Loss = 0.3516415059566498
Iteration 922: Loss = 0.3513484597206116
Iteration 923: Loss = 0.35105443000793457
Iteration 924: Loss = 0.3507593870162964
Iteration 925: Loss = 0.3504634499549866
Iteration 926: Loss = 0.3501664996147156
Iteration 927: Loss = 0.34986862540245056
Iteration 928: Loss = 0.34956982731819153
Iteration 929: Loss = 0.3492702841758728
Iteration 930: Loss = 0.34896978735923767
Iteration 931: Loss = 0.34866827726364136
Iteration 932: Loss = 0.34836578369140625
Iteration 933: Loss = 0.34806233644485474
Iteration 934: Loss = 0.3477579653263092
Iteration 935: Loss = 0.3474526107311249
Iteration 936: Loss = 0.3471463620662689
Iteration 937: Loss = 0.34683912992477417
Iteration 938: Loss = 0.3465310037136078
Iteration 939: Loss = 0.3462218940258026
Iteration 940: Loss = 0.34591177105903625
Iteration 941: Loss = 0.3456006944179535
Iteration 942: Loss = 0.3452886641025543
Iteration 943: Loss = 0.34497570991516113
Iteration 944: Loss = 0.34466174244880676
Iteration 945: Loss = 0.3443467915058136
Iteration 946: Loss = 0.3440309166908264
Iteration 947: Loss = 0.34371402859687805
Iteration 948: Loss = 0.3433961868286133
Iteration 949: Loss = 0.34307727217674255
Iteration 950: Loss = 0.3427577316761017
Iteration 951: Loss = 0.3424372673034668
Iteration 952: Loss = 0.3421157896518707
Iteration 953: Loss = 0.34179332852363586
Iteration 954: Loss = 0.34146997332572937
Iteration 955: Loss = 0.34114566445350647
Iteration 956: Loss = 0.34082043170928955
Iteration 957: Loss = 0.3404942750930786
Iteration 958: Loss = 0.3401671350002289
Iteration 959: Loss = 0.3398391604423523
Iteration 960: Loss = 0.3395101726055145
Iteration 961: Loss = 0.33918023109436035
Iteration 962: Loss = 0.33884933590888977
Iteration 963: Loss = 0.33851751685142517
Iteration 964: Loss = 0.3381846845149994
Iteration 965: Loss = 0.33785098791122437
Iteration 966: Loss = 0.33751627802848816
Iteration 967: Loss = 0.33718061447143555
Iteration 968: Loss = 0.33684393763542175
Iteration 969: Loss = 0.33650630712509155
Iteration 970: Loss = 0.33616793155670166
Iteration 971: Loss = 0.3358287513256073
Iteration 972: Loss = 0.33548858761787415
Iteration 973: Loss = 0.335147500038147
Iteration 974: Loss = 0.334805428981781
Iteration 975: Loss = 0.334462434053421
Iteration 976: Loss = 0.3341186046600342
Iteration 977: Loss = 0.33377379179000854
Iteration 978: Loss = 0.33342814445495605
Iteration 979: Loss = 0.3330814838409424
Iteration 980: Loss = 0.33273398876190186
Iteration 981: Loss = 0.33238551020622253
Iteration 982: Loss = 0.3320360779762268
Iteration 983: Loss = 0.33168578147888184
Iteration 984: Loss = 0.33133453130722046
Iteration 985: Loss = 0.33098235726356506
Iteration 986: Loss = 0.33062922954559326
Iteration 987: Loss = 0.33027517795562744
Iteration 988: Loss = 0.3299201726913452
Iteration 989: Loss = 0.32956433296203613
Iteration 990: Loss = 0.3292078673839569
Iteration 991: Loss = 0.3288504481315613
Iteration 992: Loss = 0.32849207520484924
Iteration 993: Loss = 0.32813283801078796
Iteration 994: Loss = 0.32777273654937744
Iteration 995: Loss = 0.3274117708206177
Iteration 996: Loss = 0.32704997062683105
Iteration 997: Loss = 0.3266872465610504
Iteration 998: Loss = 0.32632365822792053
Iteration 999: Loss = 0.3259592652320862
Iteration 1000: Loss = 0.3255939185619354
Iteration 1001: Loss = 0.3252277970314026
Iteration 1002: Loss = 0.32486069202423096
Iteration 1003: Loss = 0.32449275255203247
Iteration 1004: Loss = 0.32412391901016235
Iteration 1005: Loss = 0.323754221200943
Iteration 1006: Loss = 0.3233835697174072
Iteration 1007: Loss = 0.3230120837688446
Iteration 1008: Loss = 0.3226396441459656
Iteration 1009: Loss = 0.3222663104534149
Iteration 1010: Loss = 0.32189202308654785
Iteration 1011: Loss = 0.32151734828948975
Iteration 1012: Loss = 0.32114171981811523
Iteration 1013: Loss = 0.32076528668403625
Iteration 1014: Loss = 0.32038798928260803
Iteration 1015: Loss = 0.32000985741615295
Iteration 1016: Loss = 0.3196309208869934
Iteration 1017: Loss = 0.31925109028816223
Iteration 1018: Loss = 0.3188703954219818
Iteration 1019: Loss = 0.3184888958930969
Iteration 1020: Loss = 0.3181065320968628
Iteration 1021: Loss = 0.3177233040332794
Iteration 1022: Loss = 0.31733930110931396
Iteration 1023: Loss = 0.3169544041156769
Iteration 1024: Loss = 0.31656867265701294
Iteration 1025: Loss = 0.3161821961402893
Iteration 1026: Loss = 0.3157951235771179
Iteration 1027: Loss = 0.3154072165489197
Iteration 1028: Loss = 0.3150184452533722
Iteration 1029: Loss = 0.314628928899765
Iteration 1030: Loss = 0.31423863768577576
Iteration 1031: Loss = 0.3138476014137268
Iteration 1032: Loss = 0.31345582008361816
Iteration 1033: Loss = 0.31306323409080505
Iteration 1034: Loss = 0.31266990303993225
Iteration 1035: Loss = 0.31227585673332214
Iteration 1036: Loss = 0.3118809759616852
Iteration 1037: Loss = 0.3114854097366333
Iteration 1038: Loss = 0.3110889792442322
Iteration 1039: Loss = 0.310691773891449
Iteration 1040: Loss = 0.3102938234806061
Iteration 1041: Loss = 0.30989500880241394
Iteration 1042: Loss = 0.3094954490661621
Iteration 1043: Loss = 0.3090950548648834
Iteration 1044: Loss = 0.30869385600090027
Iteration 1045: Loss = 0.30829182267189026
Iteration 1046: Loss = 0.307889461517334
Iteration 1047: Loss = 0.30748647451400757
Iteration 1048: Loss = 0.30708274245262146
Iteration 1049: Loss = 0.30667826533317566
Iteration 1050: Loss = 0.30627307295799255
Iteration 1051: Loss = 0.30586713552474976
Iteration 1052: Loss = 0.30546048283576965
Iteration 1053: Loss = 0.30505311489105225
Iteration 1054: Loss = 0.30464500188827515
Iteration 1055: Loss = 0.30423620343208313
Iteration 1056: Loss = 0.3038266897201538
Iteration 1057: Loss = 0.30341655015945435
Iteration 1058: Loss = 0.3030056953430176
Iteration 1059: Loss = 0.3025941848754883
Iteration 1060: Loss = 0.3021819591522217
Iteration 1061: Loss = 0.301768958568573
Iteration 1062: Loss = 0.3013555407524109
Iteration 1063: Loss = 0.3009415566921234
Iteration 1064: Loss = 0.30052685737609863
Iteration 1065: Loss = 0.30011171102523804
Iteration 1066: Loss = 0.2996959388256073
Iteration 1067: Loss = 0.2992796003818512
Iteration 1068: Loss = 0.2988625764846802
Iteration 1069: Loss = 0.2984449565410614
Iteration 1070: Loss = 0.2980266511440277
Iteration 1071: Loss = 0.2976077198982239
Iteration 1072: Loss = 0.29718807339668274
Iteration 1073: Loss = 0.29676786065101624
Iteration 1074: Loss = 0.2963469922542572
Iteration 1075: Loss = 0.29592546820640564
Iteration 1076: Loss = 0.29550331830978394
Iteration 1077: Loss = 0.2950805425643921
Iteration 1078: Loss = 0.2946571707725525
Iteration 1079: Loss = 0.2942337989807129
Iteration 1080: Loss = 0.2938097417354584
Iteration 1081: Loss = 0.29338499903678894
Iteration 1082: Loss = 0.29295966029167175
Iteration 1083: Loss = 0.2925337553024292
Iteration 1084: Loss = 0.29210734367370605
Iteration 1085: Loss = 0.29168036580085754
Iteration 1086: Loss = 0.29125288128852844
Iteration 1087: Loss = 0.29082486033439636
Iteration 1088: Loss = 0.2903963625431061
Iteration 1089: Loss = 0.2899673581123352
Iteration 1090: Loss = 0.28953781723976135
Iteration 1091: Loss = 0.2891077697277069
Iteration 1092: Loss = 0.2886771559715271
Iteration 1093: Loss = 0.2882460653781891
Iteration 1094: Loss = 0.2878144085407257
Iteration 1095: Loss = 0.2873822748661041
Iteration 1096: Loss = 0.2869495153427124
Iteration 1097: Loss = 0.2865161597728729
Iteration 1098: Loss = 0.2860822379589081
Iteration 1099: Loss = 0.28564777970314026
Iteration 1100: Loss = 0.2852129638195038
Iteration 1101: Loss = 0.2847781479358673
Iteration 1102: Loss = 0.2843427062034607
Iteration 1103: Loss = 0.2839067280292511
Iteration 1104: Loss = 0.2834703326225281
Iteration 1105: Loss = 0.28303343057632446
Iteration 1106: Loss = 0.28259605169296265
Iteration 1107: Loss = 0.28215813636779785
Iteration 1108: Loss = 0.28171980381011963
Iteration 1109: Loss = 0.2812812328338623
Iteration 1110: Loss = 0.2808421552181244
Iteration 1111: Loss = 0.280402809381485
Iteration 1112: Loss = 0.2799629867076874
Iteration 1113: Loss = 0.27952274680137634
Iteration 1114: Loss = 0.2790820002555847
Iteration 1115: Loss = 0.27864086627960205
Iteration 1116: Loss = 0.27819928526878357
Iteration 1117: Loss = 0.2777572572231293
Iteration 1118: Loss = 0.2773147225379944
Iteration 1119: Loss = 0.2768717408180237
Iteration 1120: Loss = 0.27642887830734253
Iteration 1121: Loss = 0.27598559856414795
Iteration 1122: Loss = 0.2755415737628937
Iteration 1123: Loss = 0.2750972509384155
Iteration 1124: Loss = 0.2746526896953583
Iteration 1125: Loss = 0.2742077112197876
Iteration 1126: Loss = 0.2737622857093811
Iteration 1127: Loss = 0.27331656217575073
Iteration 1128: Loss = 0.27287033200263977
Iteration 1129: Loss = 0.27242371439933777
Iteration 1130: Loss = 0.27197664976119995
Iteration 1131: Loss = 0.27152925729751587
Iteration 1132: Loss = 0.27108147740364075
Iteration 1133: Loss = 0.2706332802772522
Iteration 1134: Loss = 0.270184725522995
Iteration 1135: Loss = 0.269735723733902
Iteration 1136: Loss = 0.2692863643169403
Iteration 1137: Loss = 0.2688366770744324
Iteration 1138: Loss = 0.2683870494365692
Iteration 1139: Loss = 0.2679370641708374
Iteration 1140: Loss = 0.2674867808818817
Iteration 1141: Loss = 0.26703619956970215
Iteration 1142: Loss = 0.26658520102500916
Iteration 1143: Loss = 0.26613399386405945
Iteration 1144: Loss = 0.2656824290752411
Iteration 1145: Loss = 0.26523059606552124
Iteration 1146: Loss = 0.2647784352302551
Iteration 1147: Loss = 0.2643260657787323
Iteration 1148: Loss = 0.26387354731559753
Iteration 1149: Loss = 0.26342079043388367
Iteration 1150: Loss = 0.2629677653312683
Iteration 1151: Loss = 0.26251453161239624
Iteration 1152: Loss = 0.2620609402656555
Iteration 1153: Loss = 0.26160717010498047
Iteration 1154: Loss = 0.26115307211875916
Iteration 1155: Loss = 0.26069867610931396
Iteration 1156: Loss = 0.260244220495224
Iteration 1157: Loss = 0.25978967547416687
Iteration 1158: Loss = 0.2593352496623993
Iteration 1159: Loss = 0.25888052582740784
Iteration 1160: Loss = 0.2584255337715149
Iteration 1161: Loss = 0.25797033309936523
Iteration 1162: Loss = 0.25751498341560364
Iteration 1163: Loss = 0.2570595443248749
Iteration 1164: Loss = 0.2566039264202118
Iteration 1165: Loss = 0.2561483681201935
Iteration 1166: Loss = 0.2556929290294647
Iteration 1167: Loss = 0.25523707270622253
Iteration 1168: Loss = 0.25478094816207886
Iteration 1169: Loss = 0.25432467460632324
Iteration 1170: Loss = 0.25386834144592285
Iteration 1171: Loss = 0.2534118592739105
Iteration 1172: Loss = 0.2529551684856415
Iteration 1173: Loss = 0.2524982690811157
Iteration 1174: Loss = 0.2520413100719452
Iteration 1175: Loss = 0.2515842318534851
Iteration 1176: Loss = 0.2511277198791504
Iteration 1177: Loss = 0.25067105889320374
Iteration 1178: Loss = 0.25021421909332275
Iteration 1179: Loss = 0.24975727498531342
Iteration 1180: Loss = 0.2493002712726593
Iteration 1181: Loss = 0.24884316325187683
Iteration 1182: Loss = 0.24838605523109436
Iteration 1183: Loss = 0.24792896211147308
Iteration 1184: Loss = 0.24747195839881897
Iteration 1185: Loss = 0.24701490998268127
Iteration 1186: Loss = 0.24655786156654358
Iteration 1187: Loss = 0.24610081315040588
Iteration 1188: Loss = 0.24564366042613983
Iteration 1189: Loss = 0.2451864331960678
Iteration 1190: Loss = 0.2447292059659958
Iteration 1191: Loss = 0.24427205324172974
Iteration 1192: Loss = 0.24381479620933533
Iteration 1193: Loss = 0.24335747957229614
Iteration 1194: Loss = 0.24290011823177338
Iteration 1195: Loss = 0.24244269728660583
Iteration 1196: Loss = 0.2419852316379547
Iteration 1197: Loss = 0.24152863025665283
Iteration 1198: Loss = 0.24107185006141663
Iteration 1199: Loss = 0.24061496555805206
Iteration 1200: Loss = 0.24015796184539795
Iteration 1201: Loss = 0.23970118165016174
Iteration 1202: Loss = 0.23924481868743896
Iteration 1203: Loss = 0.23878854513168335
Iteration 1204: Loss = 0.23833218216896057
Iteration 1205: Loss = 0.23787608742713928
Iteration 1206: Loss = 0.23742009699344635
Iteration 1207: Loss = 0.2369641214609146
Iteration 1208: Loss = 0.23650820553302765
Iteration 1209: Loss = 0.2360524833202362
Iteration 1210: Loss = 0.23559728264808655
Iteration 1211: Loss = 0.23514218628406525
Iteration 1212: Loss = 0.23468710482120514
Iteration 1213: Loss = 0.234232097864151
Iteration 1214: Loss = 0.23377718031406403
Iteration 1215: Loss = 0.2333223670721054
Iteration 1216: Loss = 0.23286773264408112
Iteration 1217: Loss = 0.2324131727218628
Iteration 1218: Loss = 0.23195965588092804
Iteration 1219: Loss = 0.23150615394115448
Iteration 1220: Loss = 0.23105254769325256
Iteration 1221: Loss = 0.23059895634651184
Iteration 1222: Loss = 0.2301454395055771
Iteration 1223: Loss = 0.22969220578670502
Iteration 1224: Loss = 0.2292392998933792
Iteration 1225: Loss = 0.22878703474998474
Iteration 1226: Loss = 0.22833508253097534
Iteration 1227: Loss = 0.22788293659687042
Iteration 1228: Loss = 0.22743076086044312
Iteration 1229: Loss = 0.2269793003797531
Iteration 1230: Loss = 0.226528137922287
Iteration 1231: Loss = 0.22607727348804474
Iteration 1232: Loss = 0.2256266176700592
Iteration 1233: Loss = 0.2251761108636856
Iteration 1234: Loss = 0.22472582757472992
Iteration 1235: Loss = 0.22427600622177124
Iteration 1236: Loss = 0.22382646799087524
Iteration 1237: Loss = 0.22337712347507477
Iteration 1238: Loss = 0.22292792797088623
Iteration 1239: Loss = 0.22247907519340515
Iteration 1240: Loss = 0.22203050553798676
Iteration 1241: Loss = 0.22158239781856537
Iteration 1242: Loss = 0.2211345136165619
Iteration 1243: Loss = 0.2206868678331375
Iteration 1244: Loss = 0.22023950517177582
Iteration 1245: Loss = 0.21979257464408875
Iteration 1246: Loss = 0.21934595704078674
Iteration 1247: Loss = 0.21889983117580414
Iteration 1248: Loss = 0.21845416724681854
Iteration 1249: Loss = 0.21800920367240906
Iteration 1250: Loss = 0.21756435930728912
Iteration 1251: Loss = 0.2171197533607483
Iteration 1252: Loss = 0.21667571365833282
Iteration 1253: Loss = 0.21623218059539795
Iteration 1254: Loss = 0.21578893065452576
Iteration 1255: Loss = 0.2153460681438446
Iteration 1256: Loss = 0.2149035483598709
Iteration 1257: Loss = 0.21446146070957184
Iteration 1258: Loss = 0.21401971578598022
Iteration 1259: Loss = 0.21357855200767517
Iteration 1260: Loss = 0.21313776075839996
Iteration 1261: Loss = 0.21269731223583221
Iteration 1262: Loss = 0.21225717663764954
Iteration 1263: Loss = 0.21181736886501312
Iteration 1264: Loss = 0.21137791872024536
Iteration 1265: Loss = 0.2109389454126358
Iteration 1266: Loss = 0.21050044894218445
Iteration 1267: Loss = 0.21006232500076294
Iteration 1268: Loss = 0.20962458848953247
Iteration 1269: Loss = 0.20918726921081543
Iteration 1270: Loss = 0.20875060558319092
Iteration 1271: Loss = 0.20831461250782013
Iteration 1272: Loss = 0.2078787237405777
Iteration 1273: Loss = 0.20744368433952332
Iteration 1274: Loss = 0.20700934529304504
Iteration 1275: Loss = 0.20657525956630707
Iteration 1276: Loss = 0.20614200830459595
Iteration 1277: Loss = 0.20570935308933258
Iteration 1278: Loss = 0.2052771896123886
Iteration 1279: Loss = 0.20484548807144165
Iteration 1280: Loss = 0.2044142782688141
Iteration 1281: Loss = 0.20398356020450592
Iteration 1282: Loss = 0.20355340838432312
Iteration 1283: Loss = 0.20312389731407166
Iteration 1284: Loss = 0.20269504189491272
Iteration 1285: Loss = 0.20226669311523438
Iteration 1286: Loss = 0.20183882117271423
Iteration 1287: Loss = 0.2014113813638687
Iteration 1288: Loss = 0.20098444819450378
Iteration 1289: Loss = 0.20055817067623138
Iteration 1290: Loss = 0.20013241469860077
Iteration 1291: Loss = 0.19970707595348358
Iteration 1292: Loss = 0.19928228855133057
Iteration 1293: Loss = 0.19885815680027008
Iteration 1294: Loss = 0.19843463599681854
Iteration 1295: Loss = 0.19801178574562073
Iteration 1296: Loss = 0.197589710354805
Iteration 1297: Loss = 0.19716806709766388
Iteration 1298: Loss = 0.19674676656723022
Iteration 1299: Loss = 0.1963266283273697
Iteration 1300: Loss = 0.19590750336647034
Iteration 1301: Loss = 0.1954888254404068
Iteration 1302: Loss = 0.19507071375846863
Iteration 1303: Loss = 0.19465334713459015
Iteration 1304: Loss = 0.19423654675483704
Iteration 1305: Loss = 0.19382034242153168
Iteration 1306: Loss = 0.19340477883815765
Iteration 1307: Loss = 0.19299010932445526
Iteration 1308: Loss = 0.19257600605487823
Iteration 1309: Loss = 0.19216249883174896
Iteration 1310: Loss = 0.1917496770620346
Iteration 1311: Loss = 0.19133754074573517
Iteration 1312: Loss = 0.19092608988285065
Iteration 1313: Loss = 0.1905154138803482
Iteration 1314: Loss = 0.19010531902313232
Iteration 1315: Loss = 0.1896958351135254
Iteration 1316: Loss = 0.1892869919538498
Iteration 1317: Loss = 0.18887871503829956
Iteration 1318: Loss = 0.1884710192680359
Iteration 1319: Loss = 0.18806445598602295
Iteration 1320: Loss = 0.187658429145813
Iteration 1321: Loss = 0.18725289404392242
Iteration 1322: Loss = 0.18684826791286469
Iteration 1323: Loss = 0.1864442229270935
Iteration 1324: Loss = 0.18604078888893127
Iteration 1325: Loss = 0.18563850224018097
Iteration 1326: Loss = 0.18523724377155304
Iteration 1327: Loss = 0.18483664095401764
Iteration 1328: Loss = 0.18443678319454193
Iteration 1329: Loss = 0.1840376853942871
Iteration 1330: Loss = 0.18363916873931885
Iteration 1331: Loss = 0.1832415610551834
Iteration 1332: Loss = 0.18284469842910767
Iteration 1333: Loss = 0.18244846165180206
Iteration 1334: Loss = 0.182052880525589
Iteration 1335: Loss = 0.18165798485279083
Iteration 1336: Loss = 0.18126383423805237
Iteration 1337: Loss = 0.18087084591388702
Iteration 1338: Loss = 0.18047860264778137
Iteration 1339: Loss = 0.18008704483509064
Iteration 1340: Loss = 0.1796962022781372
Iteration 1341: Loss = 0.1793060302734375
Iteration 1342: Loss = 0.17891672253608704
Iteration 1343: Loss = 0.1785283088684082
Iteration 1344: Loss = 0.17814064025878906
Iteration 1345: Loss = 0.17775380611419678
Iteration 1346: Loss = 0.17736773192882538
Iteration 1347: Loss = 0.1769825965166092
Iteration 1348: Loss = 0.17659813165664673
Iteration 1349: Loss = 0.17621470987796783
Iteration 1350: Loss = 0.1758321076631546
Iteration 1351: Loss = 0.1754501909017563
Iteration 1352: Loss = 0.1750689148902893
Iteration 1353: Loss = 0.17468854784965515
Iteration 1354: Loss = 0.17430970072746277
Iteration 1355: Loss = 0.17393182218074799
Iteration 1356: Loss = 0.17355477809906006
Iteration 1357: Loss = 0.1731785535812378
Iteration 1358: Loss = 0.17280307412147522
Iteration 1359: Loss = 0.17242836952209473
Iteration 1360: Loss = 0.17205478250980377
Iteration 1361: Loss = 0.17168207466602325
Iteration 1362: Loss = 0.1713101863861084
Iteration 1363: Loss = 0.17093922197818756
Iteration 1364: Loss = 0.17056904733181
Iteration 1365: Loss = 0.17019961774349213
Iteration 1366: Loss = 0.16983123123645782
Iteration 1367: Loss = 0.16946375370025635
Iteration 1368: Loss = 0.16909706592559814
Iteration 1369: Loss = 0.1687311828136444
Iteration 1370: Loss = 0.16836607456207275
Iteration 1371: Loss = 0.1680019199848175
Iteration 1372: Loss = 0.167638897895813
Iteration 1373: Loss = 0.1672767847776413
Iteration 1374: Loss = 0.16691544651985168
Iteration 1375: Loss = 0.16655495762825012
Iteration 1376: Loss = 0.16619527339935303
Iteration 1377: Loss = 0.16583633422851562
Iteration 1378: Loss = 0.16547834873199463
Iteration 1379: Loss = 0.16512137651443481
Iteration 1380: Loss = 0.16476550698280334
Iteration 1381: Loss = 0.164410799741745
Iteration 1382: Loss = 0.1640569567680359
Iteration 1383: Loss = 0.1637040078639984
Iteration 1384: Loss = 0.16335198283195496
Iteration 1385: Loss = 0.1630008965730667
Iteration 1386: Loss = 0.16265062987804413
Iteration 1387: Loss = 0.1623012274503708
Iteration 1388: Loss = 0.1619526892900467
Iteration 1389: Loss = 0.1616053283214569
Iteration 1390: Loss = 0.1612587422132492
Iteration 1391: Loss = 0.1609131395816803
Iteration 1392: Loss = 0.16056835651397705
Iteration 1393: Loss = 0.16022439301013947
Iteration 1394: Loss = 0.15988129377365112
Iteration 1395: Loss = 0.15953896939754486
Iteration 1396: Loss = 0.15919749438762665
Iteration 1397: Loss = 0.15885712206363678
Iteration 1398: Loss = 0.15851770341396332
Iteration 1399: Loss = 0.15817907452583313
Iteration 1400: Loss = 0.1578412801027298
Iteration 1401: Loss = 0.15750432014465332
Iteration 1402: Loss = 0.1571681946516037
Iteration 1403: Loss = 0.15683303773403168
Iteration 1404: Loss = 0.15649878978729248
Iteration 1405: Loss = 0.15616534650325775
Iteration 1406: Loss = 0.15583306550979614
Iteration 1407: Loss = 0.15550173819065094
Iteration 1408: Loss = 0.15517142415046692
Iteration 1409: Loss = 0.15484212338924408
Iteration 1410: Loss = 0.15451377630233765
Iteration 1411: Loss = 0.15418651700019836
Iteration 1412: Loss = 0.15386006236076355
Iteration 1413: Loss = 0.1535344123840332
Iteration 1414: Loss = 0.15320974588394165
Iteration 1415: Loss = 0.15288610756397247
Iteration 1416: Loss = 0.15256333351135254
Iteration 1417: Loss = 0.15224142372608185
Iteration 1418: Loss = 0.15192031860351562
Iteration 1419: Loss = 0.15160007774829865
Iteration 1420: Loss = 0.15128067135810852
Iteration 1421: Loss = 0.15096206963062286
Iteration 1422: Loss = 0.15064437687397003
Iteration 1423: Loss = 0.1503276228904724
Iteration 1424: Loss = 0.15001170337200165
Iteration 1425: Loss = 0.14969661831855774
Iteration 1426: Loss = 0.1493823528289795
Iteration 1427: Loss = 0.14906911551952362
Iteration 1428: Loss = 0.14875710010528564
Iteration 1429: Loss = 0.14844590425491333
Iteration 1430: Loss = 0.14813560247421265
Iteration 1431: Loss = 0.14782625436782837
Iteration 1432: Loss = 0.14751790463924408
Iteration 1433: Loss = 0.147210493683815
Iteration 1434: Loss = 0.14690420031547546
Iteration 1435: Loss = 0.14659874141216278
Iteration 1436: Loss = 0.1462939828634262
Iteration 1437: Loss = 0.14598998427391052
Iteration 1438: Loss = 0.14568696916103363
Iteration 1439: Loss = 0.1453850120306015
Iteration 1440: Loss = 0.14508448541164398
Iteration 1441: Loss = 0.14478595554828644
Iteration 1442: Loss = 0.14448858797550201
Iteration 1443: Loss = 0.1441924124956131
Iteration 1444: Loss = 0.14389702677726746
Iteration 1445: Loss = 0.14360257983207703
Iteration 1446: Loss = 0.14330992102622986
Iteration 1447: Loss = 0.1430184692144394
Iteration 1448: Loss = 0.1427280604839325
Iteration 1449: Loss = 0.14243893325328827
Iteration 1450: Loss = 0.1421511173248291
Iteration 1451: Loss = 0.14186425507068634
Iteration 1452: Loss = 0.14157849550247192
Iteration 1453: Loss = 0.14129424095153809
Iteration 1454: Loss = 0.14101094007492065
Iteration 1455: Loss = 0.14072875678539276
Iteration 1456: Loss = 0.14044781029224396
Iteration 1457: Loss = 0.1401679962873459
Iteration 1458: Loss = 0.13988934457302094
Iteration 1459: Loss = 0.13961230218410492
Iteration 1460: Loss = 0.1393362432718277
Iteration 1461: Loss = 0.13906116783618927
Iteration 1462: Loss = 0.13878704607486725
Iteration 1463: Loss = 0.13851425051689148
Iteration 1464: Loss = 0.13824281096458435
Iteration 1465: Loss = 0.13797298073768616
Iteration 1466: Loss = 0.13770435750484467
Iteration 1467: Loss = 0.1374366730451584
Iteration 1468: Loss = 0.13716991245746613
Iteration 1469: Loss = 0.13690397143363953
Iteration 1470: Loss = 0.13663898408412933
Iteration 1471: Loss = 0.1363750845193863
Iteration 1472: Loss = 0.13611236214637756
Iteration 1473: Loss = 0.135850727558136
Iteration 1474: Loss = 0.13559015095233917
Iteration 1475: Loss = 0.13533060252666473
Iteration 1476: Loss = 0.13507187366485596
Iteration 1477: Loss = 0.13481397926807404
Iteration 1478: Loss = 0.13455691933631897
Iteration 1479: Loss = 0.1343008428812027
Iteration 1480: Loss = 0.13404616713523865
Iteration 1481: Loss = 0.13379234075546265
Iteration 1482: Loss = 0.13353930413722992
Iteration 1483: Loss = 0.13328713178634644
Iteration 1484: Loss = 0.13303609192371368
Iteration 1485: Loss = 0.1327858418226242
Iteration 1486: Loss = 0.13253642618656158
Iteration 1487: Loss = 0.13228771090507507
Iteration 1488: Loss = 0.13204020261764526
Iteration 1489: Loss = 0.13179369270801544
Iteration 1490: Loss = 0.13154825568199158
Iteration 1491: Loss = 0.13130345940589905
Iteration 1492: Loss = 0.13105936348438263
Iteration 1493: Loss = 0.1308159977197647
Iteration 1494: Loss = 0.1305736005306244
Iteration 1495: Loss = 0.13033226132392883
Iteration 1496: Loss = 0.1300920695066452
Iteration 1497: Loss = 0.1298525035381317
Iteration 1498: Loss = 0.1296139508485794
Iteration 1499: Loss = 0.12937615811824799
Iteration 1500: Loss = 0.1291390359401703
Iteration 1501: Loss = 0.12890271842479706
Iteration 1502: Loss = 0.12866730988025665
Iteration 1503: Loss = 0.1284325271844864
Iteration 1504: Loss = 0.1281985640525818
Iteration 1505: Loss = 0.12796524167060852
Iteration 1506: Loss = 0.1277325451374054
Iteration 1507: Loss = 0.12750057876110077
Iteration 1508: Loss = 0.12726964056491852
Iteration 1509: Loss = 0.12703943252563477
Iteration 1510: Loss = 0.126810222864151
Iteration 1511: Loss = 0.1265815794467926
Iteration 1512: Loss = 0.12635350227355957
Iteration 1513: Loss = 0.12612630426883698
Iteration 1514: Loss = 0.1258997619152069
Iteration 1515: Loss = 0.12567384541034698
Iteration 1516: Loss = 0.1254490166902542
Iteration 1517: Loss = 0.12522464990615845
Iteration 1518: Loss = 0.12500081956386566
Iteration 1519: Loss = 0.12477795779705048
Iteration 1520: Loss = 0.12455609440803528
Iteration 1521: Loss = 0.12433482706546783
Iteration 1522: Loss = 0.12411433458328247
Iteration 1523: Loss = 0.12389443814754486
Iteration 1524: Loss = 0.12367521971464157
Iteration 1525: Loss = 0.12345661967992783
Iteration 1526: Loss = 0.12323866039514542
Iteration 1527: Loss = 0.12302129715681076
Iteration 1528: Loss = 0.12280464917421341
Iteration 1529: Loss = 0.12258866429328918
Iteration 1530: Loss = 0.12237339466810226
Iteration 1531: Loss = 0.12215890735387802
Iteration 1532: Loss = 0.12194504588842392
Iteration 1533: Loss = 0.12173185497522354
Iteration 1534: Loss = 0.12151923030614853
Iteration 1535: Loss = 0.12130717933177948
Iteration 1536: Loss = 0.12109580636024475
Iteration 1537: Loss = 0.12088493257761002
Iteration 1538: Loss = 0.12067467719316483
Iteration 1539: Loss = 0.12046508491039276
Iteration 1540: Loss = 0.12025608867406845
Iteration 1541: Loss = 0.12004779279232025
Iteration 1542: Loss = 0.11984024196863174
Iteration 1543: Loss = 0.11963316053152084
Iteration 1544: Loss = 0.1194266825914383
Iteration 1545: Loss = 0.11922094225883484
Iteration 1546: Loss = 0.1190159022808075
Iteration 1547: Loss = 0.11881144344806671
Iteration 1548: Loss = 0.11860762536525726
Iteration 1549: Loss = 0.11840444058179855
Iteration 1550: Loss = 0.11820220202207565
Iteration 1551: Loss = 0.11800044029951096
Iteration 1552: Loss = 0.1177992969751358
Iteration 1553: Loss = 0.11759888380765915
Iteration 1554: Loss = 0.11739902198314667
Iteration 1555: Loss = 0.11719981580972672
Iteration 1556: Loss = 0.11700107157230377
Iteration 1557: Loss = 0.11680295318365097
Iteration 1558: Loss = 0.11660533398389816
Iteration 1559: Loss = 0.11640820652246475
Iteration 1560: Loss = 0.1162116527557373
Iteration 1561: Loss = 0.11601558327674866
Iteration 1562: Loss = 0.1158200278878212
Iteration 1563: Loss = 0.11562496423721313
Iteration 1564: Loss = 0.11543054133653641
Iteration 1565: Loss = 0.11523663252592087
Iteration 1566: Loss = 0.11504329741001129
Iteration 1567: Loss = 0.11485040187835693
Iteration 1568: Loss = 0.11465796828269958
Iteration 1569: Loss = 0.11446603387594223
Iteration 1570: Loss = 0.11427454650402069
Iteration 1571: Loss = 0.11408355832099915
Iteration 1572: Loss = 0.1138930395245552
Iteration 1573: Loss = 0.11370297521352768
Iteration 1574: Loss = 0.11351356655359268
Iteration 1575: Loss = 0.1133246049284935
Iteration 1576: Loss = 0.11313652247190475
Iteration 1577: Loss = 0.1129489466547966
Iteration 1578: Loss = 0.11276181042194366
Iteration 1579: Loss = 0.11257528513669968
Iteration 1580: Loss = 0.11238912492990494
Iteration 1581: Loss = 0.11220339685678482
Iteration 1582: Loss = 0.1120181456208229
Iteration 1583: Loss = 0.11183357983827591
Iteration 1584: Loss = 0.11164955049753189
Iteration 1585: Loss = 0.11146590113639832
Iteration 1586: Loss = 0.11128277331590652
Iteration 1587: Loss = 0.11110011488199234
Iteration 1588: Loss = 0.11091789603233337
Iteration 1589: Loss = 0.11073608696460724
Iteration 1590: Loss = 0.11055472493171692
Iteration 1591: Loss = 0.11037378758192062
Iteration 1592: Loss = 0.11019319295883179
Iteration 1593: Loss = 0.11001309007406235
Iteration 1594: Loss = 0.10983341932296753
Iteration 1595: Loss = 0.10965431481599808
Iteration 1596: Loss = 0.1094755232334137
Iteration 1597: Loss = 0.10929707437753677
Iteration 1598: Loss = 0.10911912471055984
Iteration 1599: Loss = 0.10894171893596649
Iteration 1600: Loss = 0.1087646633386612
Iteration 1601: Loss = 0.10858799517154694
Iteration 1602: Loss = 0.10841172933578491
Iteration 1603: Loss = 0.1082359254360199
Iteration 1604: Loss = 0.10806071758270264
Iteration 1605: Loss = 0.10788594186306
Iteration 1606: Loss = 0.10771151632070541
Iteration 1607: Loss = 0.10753752291202545
Iteration 1608: Loss = 0.10736379772424698
Iteration 1609: Loss = 0.10719051212072372
Iteration 1610: Loss = 0.10701766610145569
Iteration 1611: Loss = 0.10684520751237869
Iteration 1612: Loss = 0.10667329281568527
Iteration 1613: Loss = 0.10650178790092468
Iteration 1614: Loss = 0.1063305214047432
Iteration 1615: Loss = 0.10615961998701096
Iteration 1616: Loss = 0.1059892326593399
Iteration 1617: Loss = 0.10581917315721512
Iteration 1618: Loss = 0.10564949363470078
Iteration 1619: Loss = 0.10548018664121628
Iteration 1620: Loss = 0.10531128197908401
Iteration 1621: Loss = 0.10514267534017563
Iteration 1622: Loss = 0.10497450828552246
Iteration 1623: Loss = 0.10480669140815735
Iteration 1624: Loss = 0.10463912039995193
Iteration 1625: Loss = 0.10447186976671219
Iteration 1626: Loss = 0.10430488735437393
Iteration 1627: Loss = 0.10413867235183716
Iteration 1628: Loss = 0.1039726734161377
Iteration 1629: Loss = 0.10380667448043823
Iteration 1630: Loss = 0.10364170372486115
Iteration 1631: Loss = 0.1034770980477333
Iteration 1632: Loss = 0.10331248492002487
Iteration 1633: Loss = 0.1031484454870224
Iteration 1634: Loss = 0.1029847264289856
Iteration 1635: Loss = 0.1028212308883667
Iteration 1636: Loss = 0.10265812277793884
Iteration 1637: Loss = 0.10249541699886322
Iteration 1638: Loss = 0.10233297199010849
Iteration 1639: Loss = 0.10217094421386719
Iteration 1640: Loss = 0.10200914740562439
Iteration 1641: Loss = 0.10184775292873383
Iteration 1642: Loss = 0.10168658196926117
Iteration 1643: Loss = 0.10152570903301239
Iteration 1644: Loss = 0.10136516392230988
Iteration 1645: Loss = 0.10120493173599243
Iteration 1646: Loss = 0.10104496777057648
Iteration 1647: Loss = 0.10088527947664261
Iteration 1648: Loss = 0.10072582215070724
Iteration 1649: Loss = 0.10056666284799576
Iteration 1650: Loss = 0.10040774941444397
Iteration 1651: Loss = 0.10024912655353546
Iteration 1652: Loss = 0.10009074211120605
Iteration 1653: Loss = 0.09993257373571396
Iteration 1654: Loss = 0.09977468103170395
Iteration 1655: Loss = 0.09961709380149841
Iteration 1656: Loss = 0.09945973753929138
Iteration 1657: Loss = 0.09930268675088882
Iteration 1658: Loss = 0.09914588183164597
Iteration 1659: Loss = 0.098989337682724
Iteration 1660: Loss = 0.09883301705121994
Iteration 1661: Loss = 0.09867698699235916
Iteration 1662: Loss = 0.0985211580991745
Iteration 1663: Loss = 0.09836553782224655
Iteration 1664: Loss = 0.09821008145809174
Iteration 1665: Loss = 0.09805501997470856
Iteration 1666: Loss = 0.09790010005235672
Iteration 1667: Loss = 0.09774533659219742
Iteration 1668: Loss = 0.09759081900119781
Iteration 1669: Loss = 0.09743660688400269
Iteration 1670: Loss = 0.09728271514177322
Iteration 1671: Loss = 0.09712899476289749
Iteration 1672: Loss = 0.09697549045085907
Iteration 1673: Loss = 0.09682217985391617
Iteration 1674: Loss = 0.09666906297206879
Iteration 1675: Loss = 0.09651630371809006
Iteration 1676: Loss = 0.09636378288269043
Iteration 1677: Loss = 0.09621139615774155
Iteration 1678: Loss = 0.09605921804904938
Iteration 1679: Loss = 0.0959072932600975
Iteration 1680: Loss = 0.09575554728507996
Iteration 1681: Loss = 0.0956040620803833
Iteration 1682: Loss = 0.09545295685529709
Iteration 1683: Loss = 0.09530197829008102
Iteration 1684: Loss = 0.09515123814344406
Iteration 1685: Loss = 0.09500070661306381
Iteration 1686: Loss = 0.09485024958848953
Iteration 1687: Loss = 0.0947001501917839
Iteration 1688: Loss = 0.09455032646656036
Iteration 1689: Loss = 0.09440070390701294
Iteration 1690: Loss = 0.09425124526023865
Iteration 1691: Loss = 0.0941019281744957
Iteration 1692: Loss = 0.09395282715559006
Iteration 1693: Loss = 0.09380387514829636
Iteration 1694: Loss = 0.09365510195493698
Iteration 1695: Loss = 0.09350660443305969
Iteration 1696: Loss = 0.09335827827453613
Iteration 1697: Loss = 0.09321009367704391
Iteration 1698: Loss = 0.09306210279464722
Iteration 1699: Loss = 0.09291423857212067
Iteration 1700: Loss = 0.09276652336120605
Iteration 1701: Loss = 0.09261901676654816
Iteration 1702: Loss = 0.09247183799743652
Iteration 1703: Loss = 0.0923248827457428
Iteration 1704: Loss = 0.09217794984579086
Iteration 1705: Loss = 0.09203115850687027
Iteration 1706: Loss = 0.09188461303710938
Iteration 1707: Loss = 0.09173817187547684
Iteration 1708: Loss = 0.09159187972545624
Iteration 1709: Loss = 0.09144569933414459
Iteration 1710: Loss = 0.09129971265792847
Iteration 1711: Loss = 0.0911538302898407
Iteration 1712: Loss = 0.09100814163684845
Iteration 1713: Loss = 0.09086254984140396
Iteration 1714: Loss = 0.09071706980466843
Iteration 1715: Loss = 0.09057167172431946
Iteration 1716: Loss = 0.09042657166719437
Iteration 1717: Loss = 0.0902816653251648
Iteration 1718: Loss = 0.09013692289590836
Iteration 1719: Loss = 0.08999220281839371
Iteration 1720: Loss = 0.0898476094007492
Iteration 1721: Loss = 0.08970311284065247
Iteration 1722: Loss = 0.08955874294042587
Iteration 1723: Loss = 0.08941444754600525
Iteration 1724: Loss = 0.08927028626203537
Iteration 1725: Loss = 0.08912624418735504
Iteration 1726: Loss = 0.08898226171731949
Iteration 1727: Loss = 0.08883856981992722
Iteration 1728: Loss = 0.08869469910860062
Iteration 1729: Loss = 0.08855099231004715
Iteration 1730: Loss = 0.0884074866771698
Iteration 1731: Loss = 0.088264100253582
Iteration 1732: Loss = 0.08812078833580017
Iteration 1733: Loss = 0.08797742426395416
Iteration 1734: Loss = 0.08783464133739471
Iteration 1735: Loss = 0.08769167959690094
Iteration 1736: Loss = 0.08754858374595642
Iteration 1737: Loss = 0.08740556240081787
Iteration 1738: Loss = 0.08726287633180618
Iteration 1739: Loss = 0.08712024241685867
Iteration 1740: Loss = 0.08697758615016937
Iteration 1741: Loss = 0.08683519810438156
Iteration 1742: Loss = 0.08669283986091614
Iteration 1743: Loss = 0.08655042201280594
Iteration 1744: Loss = 0.08640818297863007
Iteration 1745: Loss = 0.08626608550548553
Iteration 1746: Loss = 0.08612388372421265
Iteration 1747: Loss = 0.08598174899816513
Iteration 1748: Loss = 0.08583985269069672
Iteration 1749: Loss = 0.08569792658090591
Iteration 1750: Loss = 0.08555611222982407
Iteration 1751: Loss = 0.08541439473628998
Iteration 1752: Loss = 0.0852726399898529
Iteration 1753: Loss = 0.08513108640909195
Iteration 1754: Loss = 0.08498960733413696
Iteration 1755: Loss = 0.08484809845685959
Iteration 1756: Loss = 0.08470693975687027
Iteration 1757: Loss = 0.08456574380397797
Iteration 1758: Loss = 0.08442452549934387
Iteration 1759: Loss = 0.08428338915109634
Iteration 1760: Loss = 0.08414240926504135
Iteration 1761: Loss = 0.08400130271911621
Iteration 1762: Loss = 0.0838603526353836
Iteration 1763: Loss = 0.08371952921152115
Iteration 1764: Loss = 0.0835786685347557
Iteration 1765: Loss = 0.08343811333179474
Iteration 1766: Loss = 0.083297498524189
Iteration 1767: Loss = 0.08315680176019669
Iteration 1768: Loss = 0.0830162838101387
Iteration 1769: Loss = 0.08287594467401505
Iteration 1770: Loss = 0.08273554593324661
Iteration 1771: Loss = 0.08259530365467072
Iteration 1772: Loss = 0.08245515078306198
Iteration 1773: Loss = 0.08231492340564728
Iteration 1774: Loss = 0.0821748673915863
Iteration 1775: Loss = 0.08203485608100891
Iteration 1776: Loss = 0.08189475536346436
Iteration 1777: Loss = 0.08175478130578995
Iteration 1778: Loss = 0.0816149115562439
Iteration 1779: Loss = 0.08147489279508591
Iteration 1780: Loss = 0.0813351720571518
Iteration 1781: Loss = 0.08119543641805649
Iteration 1782: Loss = 0.0810556411743164
Iteration 1783: Loss = 0.08091582357883453
Iteration 1784: Loss = 0.08077654242515564
Iteration 1785: Loss = 0.0806371197104454
Iteration 1786: Loss = 0.08049757778644562
Iteration 1787: Loss = 0.08035790920257568
Iteration 1788: Loss = 0.08021873980760574
Iteration 1789: Loss = 0.08007945120334625
Iteration 1790: Loss = 0.07994011789560318
Iteration 1791: Loss = 0.07980110496282578
Iteration 1792: Loss = 0.07966196537017822
Iteration 1793: Loss = 0.07952259480953217
Iteration 1794: Loss = 0.07938356697559357
Iteration 1795: Loss = 0.07924448698759079
Iteration 1796: Loss = 0.07910548150539398
Iteration 1797: Loss = 0.07896643131971359
Iteration 1798: Loss = 0.07882748544216156
Iteration 1799: Loss = 0.0786885917186737
Iteration 1800: Loss = 0.07854966074228287
Iteration 1801: Loss = 0.07841078191995621
Iteration 1802: Loss = 0.07827191799879074
Iteration 1803: Loss = 0.07813317328691483
Iteration 1804: Loss = 0.07799447327852249
Iteration 1805: Loss = 0.07785581797361374
Iteration 1806: Loss = 0.07771717011928558
Iteration 1807: Loss = 0.07757853716611862
Iteration 1808: Loss = 0.07744014263153076
Iteration 1809: Loss = 0.07730139046907425
Iteration 1810: Loss = 0.07716290652751923
Iteration 1811: Loss = 0.0770244151353836
Iteration 1812: Loss = 0.07688593864440918
Iteration 1813: Loss = 0.07674747705459595
Iteration 1814: Loss = 0.07660903036594391
Iteration 1815: Loss = 0.07647082954645157
Iteration 1816: Loss = 0.07633232325315475
Iteration 1817: Loss = 0.07619399577379227
Iteration 1818: Loss = 0.07605573534965515
Iteration 1819: Loss = 0.07591751962900162
Iteration 1820: Loss = 0.07577930390834808
Iteration 1821: Loss = 0.07564113289117813
Iteration 1822: Loss = 0.07550296187400818
Iteration 1823: Loss = 0.07536490261554718
Iteration 1824: Loss = 0.07522693276405334
Iteration 1825: Loss = 0.0750889703631401
Iteration 1826: Loss = 0.07495107501745224
Iteration 1827: Loss = 0.07481321692466736
Iteration 1828: Loss = 0.07467538118362427
Iteration 1829: Loss = 0.07453755289316177
Iteration 1830: Loss = 0.07439975440502167
Iteration 1831: Loss = 0.07426199316978455
Iteration 1832: Loss = 0.07412425428628922
Iteration 1833: Loss = 0.07398657500743866
Iteration 1834: Loss = 0.07384894788265228
Iteration 1835: Loss = 0.07371148467063904
Iteration 1836: Loss = 0.07357405126094818
Iteration 1837: Loss = 0.0734366700053215
Iteration 1838: Loss = 0.07329929620027542
Iteration 1839: Loss = 0.07316197454929352
Iteration 1840: Loss = 0.0730246901512146
Iteration 1841: Loss = 0.07288747280836105
Iteration 1842: Loss = 0.07275033742189407
Iteration 1843: Loss = 0.0726131722331047
Iteration 1844: Loss = 0.07247602939605713
Iteration 1845: Loss = 0.07233892381191254
Iteration 1846: Loss = 0.07220201194286346
Iteration 1847: Loss = 0.07206506282091141
Iteration 1848: Loss = 0.07192807644605637
Iteration 1849: Loss = 0.07179108262062073
Iteration 1850: Loss = 0.07165434956550598
Iteration 1851: Loss = 0.07151760160923004
Iteration 1852: Loss = 0.07138080149888992
Iteration 1853: Loss = 0.07124412059783936
Iteration 1854: Loss = 0.07110761851072311
Iteration 1855: Loss = 0.07097114622592926
Iteration 1856: Loss = 0.0708346888422966
Iteration 1857: Loss = 0.07069823145866394
Iteration 1858: Loss = 0.07056184858083725
Iteration 1859: Loss = 0.07042557746171951
Iteration 1860: Loss = 0.07028932124376297
Iteration 1861: Loss = 0.0701531395316124
Iteration 1862: Loss = 0.0700170025229454
Iteration 1863: Loss = 0.0698808878660202
Iteration 1864: Loss = 0.06974482536315918
Iteration 1865: Loss = 0.06960883736610413
Iteration 1866: Loss = 0.06947288662195206
Iteration 1867: Loss = 0.06933698803186417
Iteration 1868: Loss = 0.06920119374990463
Iteration 1869: Loss = 0.06906543672084808
Iteration 1870: Loss = 0.06892980635166168
Iteration 1871: Loss = 0.06879433244466782
Iteration 1872: Loss = 0.06865878403186798
Iteration 1873: Loss = 0.06852340698242188
Iteration 1874: Loss = 0.06838813424110413
Iteration 1875: Loss = 0.06825293600559235
Iteration 1876: Loss = 0.06811775267124176
Iteration 1877: Loss = 0.06798257678747177
Iteration 1878: Loss = 0.06784739345312119
Iteration 1879: Loss = 0.06771255284547806
Iteration 1880: Loss = 0.06757761538028717
Iteration 1881: Loss = 0.06744252145290375
Iteration 1882: Loss = 0.06730791926383972
Iteration 1883: Loss = 0.06717333197593689
Iteration 1884: Loss = 0.06703860312700272
Iteration 1885: Loss = 0.06690375506877899
Iteration 1886: Loss = 0.06676937639713287
Iteration 1887: Loss = 0.06663510203361511
Iteration 1888: Loss = 0.066500723361969
Iteration 1889: Loss = 0.0663662999868393
Iteration 1890: Loss = 0.06623192131519318
Iteration 1891: Loss = 0.066097691655159
Iteration 1892: Loss = 0.06596381962299347
Iteration 1893: Loss = 0.06582970172166824
Iteration 1894: Loss = 0.06569568067789078
Iteration 1895: Loss = 0.06556182354688644
Iteration 1896: Loss = 0.06542808562517166
Iteration 1897: Loss = 0.06529440730810165
Iteration 1898: Loss = 0.06516075134277344
Iteration 1899: Loss = 0.0650271400809288
Iteration 1900: Loss = 0.06489358097314835
Iteration 1901: Loss = 0.06476014852523804
Iteration 1902: Loss = 0.0646267756819725
Iteration 1903: Loss = 0.06449348479509354
Iteration 1904: Loss = 0.06436027586460114
Iteration 1905: Loss = 0.06422711163759232
Iteration 1906: Loss = 0.06409396976232529
Iteration 1907: Loss = 0.0639609545469284
Iteration 1908: Loss = 0.06382805854082108
Iteration 1909: Loss = 0.06369522213935852
Iteration 1910: Loss = 0.06356258690357208
Iteration 1911: Loss = 0.06342993676662445
Iteration 1912: Loss = 0.06329730898141861
Iteration 1913: Loss = 0.06316492706537247
Iteration 1914: Loss = 0.06303241848945618
Iteration 1915: Loss = 0.06290020048618317
Iteration 1916: Loss = 0.06276822090148926
Iteration 1917: Loss = 0.06263621151447296
Iteration 1918: Loss = 0.0625041052699089
Iteration 1919: Loss = 0.062372688204050064
Iteration 1920: Loss = 0.062241051346063614
Iteration 1921: Loss = 0.06210916116833687
Iteration 1922: Loss = 0.06197763606905937
Iteration 1923: Loss = 0.061846375465393066
Iteration 1924: Loss = 0.061714813113212585
Iteration 1925: Loss = 0.06158372759819031
Iteration 1926: Loss = 0.06145264580845833
Iteration 1927: Loss = 0.06132166087627411
Iteration 1928: Loss = 0.0611911304295063
Iteration 1929: Loss = 0.06106022745370865
Iteration 1930: Loss = 0.06092977523803711
Iteration 1931: Loss = 0.06079939007759094
Iteration 1932: Loss = 0.060669105499982834
Iteration 1933: Loss = 0.06053895130753517
Iteration 1934: Loss = 0.06040896102786064
Iteration 1935: Loss = 0.060279104858636856
Iteration 1936: Loss = 0.06014937907457352
Iteration 1937: Loss = 0.06001976504921913
Iteration 1938: Loss = 0.0598902702331543
Iteration 1939: Loss = 0.05976085737347603
Iteration 1940: Loss = 0.05963156372308731
Iteration 1941: Loss = 0.05950242653489113
Iteration 1942: Loss = 0.059373367577791214
Iteration 1943: Loss = 0.05924444645643234
Iteration 1944: Loss = 0.05911557376384735
Iteration 1945: Loss = 0.058986883610486984
Iteration 1946: Loss = 0.058858320116996765
Iteration 1947: Loss = 0.058729831129312515
Iteration 1948: Loss = 0.058601509779691696
Iteration 1949: Loss = 0.058473266661167145
Iteration 1950: Loss = 0.05834519490599632
Iteration 1951: Loss = 0.05821738392114639
Iteration 1952: Loss = 0.0580894835293293
Iteration 1953: Loss = 0.057961851358413696
Iteration 1954: Loss = 0.057834550738334656
Iteration 1955: Loss = 0.05770726129412651
Iteration 1956: Loss = 0.05758009850978851
Iteration 1957: Loss = 0.05745318904519081
Iteration 1958: Loss = 0.057326383888721466
Iteration 1959: Loss = 0.05719972401857376
Iteration 1960: Loss = 0.0570732057094574
Iteration 1961: Loss = 0.05694690719246864
Iteration 1962: Loss = 0.05682068690657616
Iteration 1963: Loss = 0.05669471248984337
Iteration 1964: Loss = 0.05656890198588371
Iteration 1965: Loss = 0.05644318461418152
Iteration 1966: Loss = 0.056317634880542755
Iteration 1967: Loss = 0.056192245334386826
Iteration 1968: Loss = 0.05606701970100403
Iteration 1969: Loss = 0.05594199523329735
Iteration 1970: Loss = 0.05581706762313843
Iteration 1971: Loss = 0.055692318826913834
Iteration 1972: Loss = 0.055567674338817596
Iteration 1973: Loss = 0.05544324219226837
Iteration 1974: Loss = 0.055318962782621384
Iteration 1975: Loss = 0.055194880813360214
Iteration 1976: Loss = 0.05507093667984009
Iteration 1977: Loss = 0.054947078227996826
Iteration 1978: Loss = 0.05482347309589386
Iteration 1979: Loss = 0.05470000579953194
Iteration 1980: Loss = 0.05457690358161926
Iteration 1981: Loss = 0.054453860968351364
Iteration 1982: Loss = 0.05433071404695511
Iteration 1983: Loss = 0.054207853972911835
Iteration 1984: Loss = 0.0540853776037693
Iteration 1985: Loss = 0.05396280065178871
Iteration 1986: Loss = 0.053840599954128265
Iteration 1987: Loss = 0.05371862277388573
Iteration 1988: Loss = 0.05359673127532005
Iteration 1989: Loss = 0.053475044667720795
Iteration 1990: Loss = 0.05335349217057228
Iteration 1991: Loss = 0.05323219671845436
Iteration 1992: Loss = 0.053111083805561066
Iteration 1993: Loss = 0.05299011245369911
Iteration 1994: Loss = 0.05286932364106178
Iteration 1995: Loss = 0.05274868384003639
Iteration 1996: Loss = 0.052628207951784134
Iteration 1997: Loss = 0.05250795930624008
Iteration 1998: Loss = 0.05238795652985573
Iteration 1999: Loss = 0.052268143743276596
Iteration 2000: Loss = 0.05214845389127731
Iteration 2001: Loss = 0.052028968930244446
Iteration 2002: Loss = 0.051909640431404114
Iteration 2003: Loss = 0.05179053172469139
Iteration 2004: Loss = 0.05167163163423538
Iteration 2005: Loss = 0.051552873104810715
Iteration 2006: Loss = 0.05143433064222336
Iteration 2007: Loss = 0.05131591856479645
Iteration 2008: Loss = 0.05119772255420685
Iteration 2009: Loss = 0.051079679280519485
Iteration 2010: Loss = 0.05096186324954033
Iteration 2011: Loss = 0.050844401121139526
Iteration 2012: Loss = 0.05072706565260887
Iteration 2013: Loss = 0.05061003193259239
Iteration 2014: Loss = 0.05049294978380203
Iteration 2015: Loss = 0.05037643760442734
Iteration 2016: Loss = 0.05025992542505264
Iteration 2017: Loss = 0.05014336481690407
Iteration 2018: Loss = 0.05002788081765175
Iteration 2019: Loss = 0.04991193115711212
Iteration 2020: Loss = 0.04979593679308891
Iteration 2021: Loss = 0.04968070238828659
Iteration 2022: Loss = 0.049565497785806656
Iteration 2023: Loss = 0.04945042356848717
Iteration 2024: Loss = 0.04933549091219902
Iteration 2025: Loss = 0.04922092705965042
Iteration 2026: Loss = 0.04910673946142197
Iteration 2027: Loss = 0.048992451280355453
Iteration 2028: Loss = 0.048878561705350876
Iteration 2029: Loss = 0.048764899373054504
Iteration 2030: Loss = 0.04865148290991783
Iteration 2031: Loss = 0.04853802174329758
Iteration 2032: Loss = 0.04842480644583702
Iteration 2033: Loss = 0.048311930149793625
Iteration 2034: Loss = 0.04819927364587784
Iteration 2035: Loss = 0.048086825758218765
Iteration 2036: Loss = 0.04797446355223656
Iteration 2037: Loss = 0.04786226525902748
Iteration 2038: Loss = 0.04775034263730049
Iteration 2039: Loss = 0.04763861000537872
Iteration 2040: Loss = 0.04752719774842262
Iteration 2041: Loss = 0.04741554334759712
Iteration 2042: Loss = 0.047304410487413406
Iteration 2043: Loss = 0.047193493694067
Iteration 2044: Loss = 0.047082770615816116
Iteration 2045: Loss = 0.04697243869304657
Iteration 2046: Loss = 0.046862054616212845
Iteration 2047: Loss = 0.046752188354730606
Iteration 2048: Loss = 0.0466424822807312
Iteration 2049: Loss = 0.04653292894363403
Iteration 2050: Loss = 0.046423859894275665
Iteration 2051: Loss = 0.04631488770246506
Iteration 2052: Loss = 0.04620615020394325
Iteration 2053: Loss = 0.04609771817922592
Iteration 2054: Loss = 0.04598962143063545
Iteration 2055: Loss = 0.04588169977068901
Iteration 2056: Loss = 0.0457739531993866
Iteration 2057: Loss = 0.04566638916730881
Iteration 2058: Loss = 0.045559111982584
Iteration 2059: Loss = 0.04545212537050247
Iteration 2060: Loss = 0.04534535109996796
Iteration 2061: Loss = 0.045238789170980453
Iteration 2062: Loss = 0.045132435858249664
Iteration 2063: Loss = 0.04502632096409798
Iteration 2064: Loss = 0.0449204221367836
Iteration 2065: Loss = 0.0448148138821125
Iteration 2066: Loss = 0.04470940679311752
Iteration 2067: Loss = 0.04460424929857254
Iteration 2068: Loss = 0.04449930414557457
Iteration 2069: Loss = 0.0443945974111557
Iteration 2070: Loss = 0.044290363788604736
Iteration 2071: Loss = 0.04418601095676422
Iteration 2072: Loss = 0.044082269072532654
Iteration 2073: Loss = 0.043978605419397354
Iteration 2074: Loss = 0.04387533292174339
Iteration 2075: Loss = 0.04377232491970062
Iteration 2076: Loss = 0.04366941750049591
Iteration 2077: Loss = 0.04356718435883522
Iteration 2078: Loss = 0.04346467927098274
Iteration 2079: Loss = 0.04336271435022354
Iteration 2080: Loss = 0.043261054903268814
Iteration 2081: Loss = 0.04315958172082901
Iteration 2082: Loss = 0.0430583581328392
Iteration 2083: Loss = 0.042957380414009094
Iteration 2084: Loss = 0.04285670444369316
Iteration 2085: Loss = 0.042756207287311554
Iteration 2086: Loss = 0.04265595227479935
Iteration 2087: Loss = 0.04255586490035057
Iteration 2088: Loss = 0.042455997318029404
Iteration 2089: Loss = 0.04235642030835152
Iteration 2090: Loss = 0.04225709289312363
Iteration 2091: Loss = 0.04215795546770096
Iteration 2092: Loss = 0.04205908253788948
Iteration 2093: Loss = 0.041960425674915314
Iteration 2094: Loss = 0.04186205565929413
Iteration 2095: Loss = 0.041763924062252045
Iteration 2096: Loss = 0.04166601225733757
Iteration 2097: Loss = 0.04156847670674324
Iteration 2098: Loss = 0.04147110506892204
Iteration 2099: Loss = 0.04137413576245308
Iteration 2100: Loss = 0.04127734526991844
Iteration 2101: Loss = 0.04118074104189873
Iteration 2102: Loss = 0.04108447954058647
Iteration 2103: Loss = 0.0409885011613369
Iteration 2104: Loss = 0.04089267551898956
Iteration 2105: Loss = 0.04079718887805939
Iteration 2106: Loss = 0.0407019779086113
Iteration 2107: Loss = 0.04060695320367813
Iteration 2108: Loss = 0.04051220417022705
Iteration 2109: Loss = 0.040417712181806564
Iteration 2110: Loss = 0.04032345116138458
Iteration 2111: Loss = 0.04022945463657379
Iteration 2112: Loss = 0.040135707706213
Iteration 2113: Loss = 0.040042199194431305
Iteration 2114: Loss = 0.03994894027709961
Iteration 2115: Loss = 0.0398559644818306
Iteration 2116: Loss = 0.0397631861269474
Iteration 2117: Loss = 0.03967069089412689
Iteration 2118: Loss = 0.03957848250865936
Iteration 2119: Loss = 0.03948654234409332
Iteration 2120: Loss = 0.039394818246364594
Iteration 2121: Loss = 0.039303235709667206
Iteration 2122: Loss = 0.039211928844451904
Iteration 2123: Loss = 0.03912097588181496
Iteration 2124: Loss = 0.039030320942401886
Iteration 2125: Loss = 0.03893980756402016
Iteration 2126: Loss = 0.03884989395737648
Iteration 2127: Loss = 0.03875965252518654
Iteration 2128: Loss = 0.03867004066705704
Iteration 2129: Loss = 0.038580719381570816
Iteration 2130: Loss = 0.038491591811180115
Iteration 2131: Loss = 0.038402702659368515
Iteration 2132: Loss = 0.0383140854537487
Iteration 2133: Loss = 0.03822575509548187
Iteration 2134: Loss = 0.038137707859277725
Iteration 2135: Loss = 0.03804986551403999
Iteration 2136: Loss = 0.03796229138970375
Iteration 2137: Loss = 0.037874992936849594
Iteration 2138: Loss = 0.03778792545199394
Iteration 2139: Loss = 0.03770112246274948
Iteration 2140: Loss = 0.037614572793245316
Iteration 2141: Loss = 0.03752829506993294
Iteration 2142: Loss = 0.037442248314619064
Iteration 2143: Loss = 0.037356458604335785
Iteration 2144: Loss = 0.03727090358734131
Iteration 2145: Loss = 0.037185586988925934
Iteration 2146: Loss = 0.03710052743554115
Iteration 2147: Loss = 0.03701573237776756
Iteration 2148: Loss = 0.03693113476037979
Iteration 2149: Loss = 0.03684687241911888
Iteration 2150: Loss = 0.03676286339759827
Iteration 2151: Loss = 0.03667914867401123
Iteration 2152: Loss = 0.03659569099545479
Iteration 2153: Loss = 0.03651253134012222
Iteration 2154: Loss = 0.036429524421691895
Iteration 2155: Loss = 0.03634671866893768
Iteration 2156: Loss = 0.03626418486237526
Iteration 2157: Loss = 0.03618187829852104
Iteration 2158: Loss = 0.036099791526794434
Iteration 2159: Loss = 0.03601792827248573
Iteration 2160: Loss = 0.035936325788497925
Iteration 2161: Loss = 0.035854946821928024
Iteration 2162: Loss = 0.035773757845163345
Iteration 2163: Loss = 0.03569287434220314
Iteration 2164: Loss = 0.03561227023601532
Iteration 2165: Loss = 0.03553188219666481
Iteration 2166: Loss = 0.035451702773571014
Iteration 2167: Loss = 0.035371728241443634
Iteration 2168: Loss = 0.035291947424411774
Iteration 2169: Loss = 0.03521248698234558
Iteration 2170: Loss = 0.03513326495885849
Iteration 2171: Loss = 0.03505422919988632
Iteration 2172: Loss = 0.03497546166181564
Iteration 2173: Loss = 0.034896962344646454
Iteration 2174: Loss = 0.034818802028894424
Iteration 2175: Loss = 0.034740839153528214
Iteration 2176: Loss = 0.034663207828998566
Iteration 2177: Loss = 0.03458576276898384
Iteration 2178: Loss = 0.0345085933804512
Iteration 2179: Loss = 0.03443168103694916
Iteration 2180: Loss = 0.034355033189058304
Iteration 2181: Loss = 0.03427863493561745
Iteration 2182: Loss = 0.0342024564743042
Iteration 2183: Loss = 0.03412657603621483
Iteration 2184: Loss = 0.034050919115543365
Iteration 2185: Loss = 0.0339755155146122
Iteration 2186: Loss = 0.03390032425522804
Iteration 2187: Loss = 0.03382528945803642
Iteration 2188: Loss = 0.033750440925359726
Iteration 2189: Loss = 0.033675841987133026
Iteration 2190: Loss = 0.03360147029161453
Iteration 2191: Loss = 0.03352741897106171
Iteration 2192: Loss = 0.03345353528857231
Iteration 2193: Loss = 0.03337984159588814
Iteration 2194: Loss = 0.033306434750556946
Iteration 2195: Loss = 0.033233266323804855
Iteration 2196: Loss = 0.033160410821437836
Iteration 2197: Loss = 0.03308789059519768
Iteration 2198: Loss = 0.03301560878753662
Iteration 2199: Loss = 0.032943498343229294
Iteration 2200: Loss = 0.03287167474627495
Iteration 2201: Loss = 0.032800182700157166
Iteration 2202: Loss = 0.03272892162203789
Iteration 2203: Loss = 0.032657794654369354
Iteration 2204: Loss = 0.032586924731731415
Iteration 2205: Loss = 0.032516349107027054
Iteration 2206: Loss = 0.03244598209857941
Iteration 2207: Loss = 0.03237586095929146
Iteration 2208: Loss = 0.0323060005903244
Iteration 2209: Loss = 0.032236382365226746
Iteration 2210: Loss = 0.0321669727563858
Iteration 2211: Loss = 0.03209781274199486
Iteration 2212: Loss = 0.032028935849666595
Iteration 2213: Loss = 0.03196028992533684
Iteration 2214: Loss = 0.03189189359545708
Iteration 2215: Loss = 0.03182373568415642
Iteration 2216: Loss = 0.031755831092596054
Iteration 2217: Loss = 0.03168817237019539
Iteration 2218: Loss = 0.03162074834108353
Iteration 2219: Loss = 0.03155353292822838
Iteration 2220: Loss = 0.03148641809821129
Iteration 2221: Loss = 0.031419482082128525
Iteration 2222: Loss = 0.03135265037417412
Iteration 2223: Loss = 0.031285952776670456
Iteration 2224: Loss = 0.03121952898800373
Iteration 2225: Loss = 0.031153369694948196
Iteration 2226: Loss = 0.031087465584278107
Iteration 2227: Loss = 0.031021686270833015
Iteration 2228: Loss = 0.03095605969429016
Iteration 2229: Loss = 0.03089071623980999
Iteration 2230: Loss = 0.030825665220618248
Iteration 2231: Loss = 0.030760880559682846
Iteration 2232: Loss = 0.030696235597133636
Iteration 2233: Loss = 0.030631789937615395
Iteration 2234: Loss = 0.030567653477191925
Iteration 2235: Loss = 0.0305037721991539
Iteration 2236: Loss = 0.030440108850598335
Iteration 2237: Loss = 0.030376745387911797
Iteration 2238: Loss = 0.03031349554657936
Iteration 2239: Loss = 0.03025052696466446
Iteration 2240: Loss = 0.030187934637069702
Iteration 2241: Loss = 0.030125491321086884
Iteration 2242: Loss = 0.030063221231102943
Iteration 2243: Loss = 0.030001256614923477
Iteration 2244: Loss = 0.029939547181129456
Iteration 2245: Loss = 0.029877999797463417
Iteration 2246: Loss = 0.029816703870892525
Iteration 2247: Loss = 0.029755692929029465
Iteration 2248: Loss = 0.029694875702261925
Iteration 2249: Loss = 0.02963428758084774
Iteration 2250: Loss = 0.029573954641819
Iteration 2251: Loss = 0.029513860121369362
Iteration 2252: Loss = 0.029453923925757408
Iteration 2253: Loss = 0.029394229874014854
Iteration 2254: Loss = 0.02933475933969021
Iteration 2255: Loss = 0.029275499284267426
Iteration 2256: Loss = 0.029216475784778595
Iteration 2257: Loss = 0.029157670214772224
Iteration 2258: Loss = 0.02909911423921585
Iteration 2259: Loss = 0.029040785506367683
Iteration 2260: Loss = 0.028982672840356827
Iteration 2261: Loss = 0.028924839571118355
Iteration 2262: Loss = 0.028867196291685104
Iteration 2263: Loss = 0.028809679672122
Iteration 2264: Loss = 0.028752481564879417
Iteration 2265: Loss = 0.028695520013570786
Iteration 2266: Loss = 0.02863873541355133
Iteration 2267: Loss = 0.028582176193594933
Iteration 2268: Loss = 0.02852587401866913
Iteration 2269: Loss = 0.028469759970903397
Iteration 2270: Loss = 0.028413884341716766
Iteration 2271: Loss = 0.028358230367302895
Iteration 2272: Loss = 0.028302839025855064
Iteration 2273: Loss = 0.028247658163309097
Iteration 2274: Loss = 0.028192680329084396
Iteration 2275: Loss = 0.02813795953989029
Iteration 2276: Loss = 0.02808346599340439
Iteration 2277: Loss = 0.02802915684878826
Iteration 2278: Loss = 0.02797522023320198
Iteration 2279: Loss = 0.027921363711357117
Iteration 2280: Loss = 0.027867920696735382
Iteration 2281: Loss = 0.027814820408821106
Iteration 2282: Loss = 0.027762023732066154
Iteration 2283: Loss = 0.02770923636853695
Iteration 2284: Loss = 0.027656229212880135
Iteration 2285: Loss = 0.02760360576212406
Iteration 2286: Loss = 0.02755158767104149
Iteration 2287: Loss = 0.027499787509441376
Iteration 2288: Loss = 0.02744797058403492
Iteration 2289: Loss = 0.027396224439144135
Iteration 2290: Loss = 0.027344612404704094
Iteration 2291: Loss = 0.027293330058455467
Iteration 2292: Loss = 0.027242513373494148
Iteration 2293: Loss = 0.027192028239369392
Iteration 2294: Loss = 0.02714158594608307
Iteration 2295: Loss = 0.027091244235634804
Iteration 2296: Loss = 0.027041049674153328
Iteration 2297: Loss = 0.026991158723831177
Iteration 2298: Loss = 0.026941582560539246
Iteration 2299: Loss = 0.026892302557826042
Iteration 2300: Loss = 0.026843182742595673
Iteration 2301: Loss = 0.026794185861945152
Iteration 2302: Loss = 0.026745490729808807
Iteration 2303: Loss = 0.02669684588909149
Iteration 2304: Loss = 0.026648741215467453
Iteration 2305: Loss = 0.02660122886300087
Iteration 2306: Loss = 0.0265540461987257
Iteration 2307: Loss = 0.02650684304535389
Iteration 2308: Loss = 0.026459243148565292
Iteration 2309: Loss = 0.026411613449454308
Iteration 2310: Loss = 0.026364296674728394
Iteration 2311: Loss = 0.02631743997335434
Iteration 2312: Loss = 0.02627110667526722
Iteration 2313: Loss = 0.0262250155210495
Iteration 2314: Loss = 0.026178523898124695
Iteration 2315: Loss = 0.026132037863135338
Iteration 2316: Loss = 0.026085803285241127
Iteration 2317: Loss = 0.02604011818766594
Iteration 2318: Loss = 0.02599463425576687
Iteration 2319: Loss = 0.02594902366399765
Iteration 2320: Loss = 0.02590370923280716
Iteration 2321: Loss = 0.02585887536406517
Iteration 2322: Loss = 0.025814330205321312
Iteration 2323: Loss = 0.025769740343093872
Iteration 2324: Loss = 0.025725174695253372
Iteration 2325: Loss = 0.025680838152766228
Iteration 2326: Loss = 0.025636840611696243
Iteration 2327: Loss = 0.025593189522624016
Iteration 2328: Loss = 0.025549637153744698
Iteration 2329: Loss = 0.02550618350505829
Iteration 2330: Loss = 0.025463024154305458
Iteration 2331: Loss = 0.02542008087038994
Iteration 2332: Loss = 0.025377361103892326
Iteration 2333: Loss = 0.02533472515642643
Iteration 2334: Loss = 0.02529224567115307
Iteration 2335: Loss = 0.025249961763620377
Iteration 2336: Loss = 0.025207914412021637
Iteration 2337: Loss = 0.025166083127260208
Iteration 2338: Loss = 0.025124408304691315
Iteration 2339: Loss = 0.02508288063108921
Iteration 2340: Loss = 0.02504158951342106
Iteration 2341: Loss = 0.02500053495168686
Iteration 2342: Loss = 0.024959642440080643
Iteration 2343: Loss = 0.024918919429183006
Iteration 2344: Loss = 0.024878351017832756
Iteration 2345: Loss = 0.02483799122273922
Iteration 2346: Loss = 0.024797828868031502
Iteration 2347: Loss = 0.0247578714042902
Iteration 2348: Loss = 0.024717997759580612
Iteration 2349: Loss = 0.02467832900583744
Iteration 2350: Loss = 0.02463884837925434
Iteration 2351: Loss = 0.024599555879831314
Iteration 2352: Loss = 0.024560462683439255
Iteration 2353: Loss = 0.024521565064787865
Iteration 2354: Loss = 0.02448294125497341
Iteration 2355: Loss = 0.02444450370967388
Iteration 2356: Loss = 0.024406198412179947
Iteration 2357: Loss = 0.024368157610297203
Iteration 2358: Loss = 0.024329926818609238
Iteration 2359: Loss = 0.024292171001434326
Iteration 2360: Loss = 0.024254612624645233
Iteration 2361: Loss = 0.024216972291469574
Iteration 2362: Loss = 0.024179713800549507
Iteration 2363: Loss = 0.024142839014530182
Iteration 2364: Loss = 0.02410603128373623
Iteration 2365: Loss = 0.024069620296359062
Iteration 2366: Loss = 0.024033626541495323
Iteration 2367: Loss = 0.02399802953004837
Iteration 2368: Loss = 0.023963170126080513
Iteration 2369: Loss = 0.023929404094815254
Iteration 2370: Loss = 0.023896874859929085
Iteration 2371: Loss = 0.0238661952316761
Iteration 2372: Loss = 0.023838026449084282
Iteration 2373: Loss = 0.023812310770154
Iteration 2374: Loss = 0.023788459599018097
Iteration 2375: Loss = 0.023764559999108315
Iteration 2376: Loss = 0.02374064177274704
Iteration 2377: Loss = 0.023706667125225067
Iteration 2378: Loss = 0.023658834397792816
Iteration 2379: Loss = 0.02360250987112522
Iteration 2380: Loss = 0.02354971505701542
Iteration 2381: Loss = 0.02350841835141182
Iteration 2382: Loss = 0.023479538038372993
Iteration 2383: Loss = 0.02345709688961506
Iteration 2384: Loss = 0.023433025926351547
Iteration 2385: Loss = 0.02340090461075306
Iteration 2386: Loss = 0.023361630737781525
Iteration 2387: Loss = 0.02332051657140255
Iteration 2388: Loss = 0.023282723501324654
Iteration 2389: Loss = 0.02325124852359295
Iteration 2390: Loss = 0.023223787546157837
Iteration 2391: Loss = 0.023196397349238396
Iteration 2392: Loss = 0.02316601574420929
Iteration 2393: Loss = 0.023133164271712303
Iteration 2394: Loss = 0.023098843172192574
Iteration 2395: Loss = 0.02306526154279709
Iteration 2396: Loss = 0.023034648969769478
Iteration 2397: Loss = 0.023006420582532883
Iteration 2398: Loss = 0.022978175431489944
Iteration 2399: Loss = 0.022948667407035828
Iteration 2400: Loss = 0.02291775681078434
Iteration 2401: Loss = 0.02288614585995674
Iteration 2402: Loss = 0.022855333983898163
Iteration 2403: Loss = 0.022826099768280983
Iteration 2404: Loss = 0.022797774523496628
Iteration 2405: Loss = 0.022769620642066002
Iteration 2406: Loss = 0.02274085208773613
Iteration 2407: Loss = 0.022711338475346565
Iteration 2408: Loss = 0.022681528702378273
Iteration 2409: Loss = 0.022652167826890945
Iteration 2410: Loss = 0.022623570635914803
Iteration 2411: Loss = 0.022595470771193504
Iteration 2412: Loss = 0.022567586973309517
Iteration 2413: Loss = 0.022539731115102768
Iteration 2414: Loss = 0.022511731833219528
Iteration 2415: Loss = 0.022483574226498604
Iteration 2416: Loss = 0.02245541848242283
Iteration 2417: Loss = 0.022427447140216827
Iteration 2418: Loss = 0.022399848327040672
Iteration 2419: Loss = 0.02237263135612011
Iteration 2420: Loss = 0.02234566956758499
Iteration 2421: Loss = 0.0223187617957592
Iteration 2422: Loss = 0.022291863337159157
Iteration 2423: Loss = 0.022265000268816948
Iteration 2424: Loss = 0.022238194942474365
Iteration 2425: Loss = 0.022211499512195587
Iteration 2426: Loss = 0.022184886038303375
Iteration 2427: Loss = 0.022158445790410042
Iteration 2428: Loss = 0.02213216945528984
Iteration 2429: Loss = 0.022106099873781204
Iteration 2430: Loss = 0.02208014205098152
Iteration 2431: Loss = 0.02205430343747139
Iteration 2432: Loss = 0.022028597071766853
Iteration 2433: Loss = 0.022002989426255226
Iteration 2434: Loss = 0.021977506577968597
Iteration 2435: Loss = 0.021952128037810326
Iteration 2436: Loss = 0.021926846355199814
Iteration 2437: Loss = 0.021901698783040047
Iteration 2438: Loss = 0.021876659244298935
Iteration 2439: Loss = 0.021851764991879463
Iteration 2440: Loss = 0.02182699181139469
Iteration 2441: Loss = 0.021802347153425217
Iteration 2442: Loss = 0.0217778030782938
Iteration 2443: Loss = 0.02175341360270977
Iteration 2444: Loss = 0.021729126572608948
Iteration 2445: Loss = 0.021704934537410736
Iteration 2446: Loss = 0.021680889651179314
Iteration 2447: Loss = 0.021656936034560204
Iteration 2448: Loss = 0.021633097901940346
Iteration 2449: Loss = 0.021609364077448845
Iteration 2450: Loss = 0.02158575877547264
Iteration 2451: Loss = 0.021562272682785988
Iteration 2452: Loss = 0.02153889834880829
Iteration 2453: Loss = 0.021515611559152603
Iteration 2454: Loss = 0.02149246260523796
Iteration 2455: Loss = 0.021469412371516228
Iteration 2456: Loss = 0.02144642174243927
Iteration 2457: Loss = 0.021423568949103355
Iteration 2458: Loss = 0.021400824189186096
Iteration 2459: Loss = 0.021378181874752045
Iteration 2460: Loss = 0.021355653181672096
Iteration 2461: Loss = 0.021333156153559685
Iteration 2462: Loss = 0.021310782060027122
Iteration 2463: Loss = 0.021288538351655006
Iteration 2464: Loss = 0.021266333758831024
Iteration 2465: Loss = 0.021244283765554428
Iteration 2466: Loss = 0.02122231014072895
Iteration 2467: Loss = 0.021200424060225487
Iteration 2468: Loss = 0.02117869071662426
Iteration 2469: Loss = 0.021157028153538704
Iteration 2470: Loss = 0.021135492250323296
Iteration 2471: Loss = 0.021114077419042587
Iteration 2472: Loss = 0.02109277807176113
Iteration 2473: Loss = 0.021071650087833405
Iteration 2474: Loss = 0.021050674840807915
Iteration 2475: Loss = 0.0210297591984272
Iteration 2476: Loss = 0.021008914336562157
Iteration 2477: Loss = 0.020988332107663155
Iteration 2478: Loss = 0.02096811681985855
Iteration 2479: Loss = 0.02094842679798603
Iteration 2480: Loss = 0.020929571241140366
Iteration 2481: Loss = 0.02091197296977043
Iteration 2482: Loss = 0.02089652419090271
Iteration 2483: Loss = 0.020884357392787933
Iteration 2484: Loss = 0.020877353847026825
Iteration 2485: Loss = 0.020877962931990623
Iteration 2486: Loss = 0.02088584378361702
Iteration 2487: Loss = 0.020896272733807564
Iteration 2488: Loss = 0.02089230902493
Iteration 2489: Loss = 0.020855186507105827
Iteration 2490: Loss = 0.020786704495549202
Iteration 2491: Loss = 0.020720403641462326
Iteration 2492: Loss = 0.02069029025733471
Iteration 2493: Loss = 0.02069465070962906
Iteration 2494: Loss = 0.02070373296737671
Iteration 2495: Loss = 0.0206881333142519
Iteration 2496: Loss = 0.020644985139369965
Iteration 2497: Loss = 0.020601538941264153
Iteration 2498: Loss = 0.020582962781190872
Iteration 2499: Loss = 0.02058282494544983
Iteration 2500: Loss = 0.020575862377882004
Iteration 2501: Loss = 0.020549502223730087
Iteration 2502: Loss = 0.02051485888659954
Iteration 2503: Loss = 0.020491668954491615
Iteration 2504: Loss = 0.02048247493803501
Iteration 2505: Loss = 0.020473714917898178
Iteration 2506: Loss = 0.02045435830950737
Iteration 2507: Loss = 0.020427824929356575
Iteration 2508: Loss = 0.020405437797307968
Iteration 2509: Loss = 0.020391536876559258
Iteration 2510: Loss = 0.02038033865392208
Iteration 2511: Loss = 0.0203641876578331
Iteration 2512: Loss = 0.020342815667390823
Iteration 2513: Loss = 0.020321883261203766
Iteration 2514: Loss = 0.02030581794679165
Iteration 2515: Loss = 0.020292699337005615
Iteration 2516: Loss = 0.02027774043381214
Iteration 2517: Loss = 0.020259590819478035
Iteration 2518: Loss = 0.02024037018418312
Iteration 2519: Loss = 0.02022341638803482
Iteration 2520: Loss = 0.020208945497870445
Iteration 2521: Loss = 0.020194483920931816
Iteration 2522: Loss = 0.020178133621811867
Iteration 2523: Loss = 0.02016051486134529
Iteration 2524: Loss = 0.020143674686551094
Iteration 2525: Loss = 0.02012847550213337
Iteration 2526: Loss = 0.02011394128203392
Iteration 2527: Loss = 0.020098526030778885
Iteration 2528: Loss = 0.0200820229947567
Iteration 2529: Loss = 0.020065752789378166
Iteration 2530: Loss = 0.020050354301929474
Iteration 2531: Loss = 0.02003556117415428
Iteration 2532: Loss = 0.020020658150315285
Iteration 2533: Loss = 0.02000517025589943
Iteration 2534: Loss = 0.01998942904174328
Iteration 2535: Loss = 0.01997404545545578
Iteration 2536: Loss = 0.019959183409810066
Iteration 2537: Loss = 0.019944539293646812
Iteration 2538: Loss = 0.019929757341742516
Iteration 2539: Loss = 0.019914697855710983
Iteration 2540: Loss = 0.019899602979421616
Iteration 2541: Loss = 0.019884800538420677
Iteration 2542: Loss = 0.019870275631546974
Iteration 2543: Loss = 0.019855860620737076
Iteration 2544: Loss = 0.019841376692056656
Iteration 2545: Loss = 0.019826773554086685
Iteration 2546: Loss = 0.01981223002076149
Iteration 2547: Loss = 0.019797828048467636
Iteration 2548: Loss = 0.0197836272418499
Iteration 2549: Loss = 0.01976950839161873
Iteration 2550: Loss = 0.0197554063051939
Iteration 2551: Loss = 0.019741253927350044
Iteration 2552: Loss = 0.01972714439034462
Iteration 2553: Loss = 0.019713113084435463
Iteration 2554: Loss = 0.01969914324581623
Iteration 2555: Loss = 0.0196852870285511
Iteration 2556: Loss = 0.019671520218253136
Iteration 2557: Loss = 0.019657762721180916
Iteration 2558: Loss = 0.019644033163785934
Iteration 2559: Loss = 0.0196303091943264
Iteration 2560: Loss = 0.019616683945059776
Iteration 2561: Loss = 0.019603189080953598
Iteration 2562: Loss = 0.019589759409427643
Iteration 2563: Loss = 0.019576339051127434
Iteration 2564: Loss = 0.019562914967536926
Iteration 2565: Loss = 0.01954956166446209
Iteration 2566: Loss = 0.019536279141902924
Iteration 2567: Loss = 0.019523048773407936
Iteration 2568: Loss = 0.019509922713041306
Iteration 2569: Loss = 0.019496824592351913
Iteration 2570: Loss = 0.019483748823404312
Iteration 2571: Loss = 0.019470753148198128
Iteration 2572: Loss = 0.019457805901765823
Iteration 2573: Loss = 0.0194449070841074
Iteration 2574: Loss = 0.019432075321674347
Iteration 2575: Loss = 0.01941927894949913
Iteration 2576: Loss = 0.01940656639635563
Iteration 2577: Loss = 0.01939390040934086
Iteration 2578: Loss = 0.01938127540051937
Iteration 2579: Loss = 0.01936870627105236
Iteration 2580: Loss = 0.019356196746230125
Iteration 2581: Loss = 0.01934371516108513
Iteration 2582: Loss = 0.019331317394971848
Iteration 2583: Loss = 0.019318977370858192
Iteration 2584: Loss = 0.019306683912873268
Iteration 2585: Loss = 0.019294429570436478
Iteration 2586: Loss = 0.019282234832644463
Iteration 2587: Loss = 0.01927008666098118
Iteration 2588: Loss = 0.01925799809396267
Iteration 2589: Loss = 0.019245946779847145
Iteration 2590: Loss = 0.019233953207731247
Iteration 2591: Loss = 0.01922202855348587
Iteration 2592: Loss = 0.019210148602724075
Iteration 2593: Loss = 0.019198305904865265
Iteration 2594: Loss = 0.019186511635780334
Iteration 2595: Loss = 0.019174771383404732
Iteration 2596: Loss = 0.0191631019115448
Iteration 2597: Loss = 0.019151462242007256
Iteration 2598: Loss = 0.019139865413308144
Iteration 2599: Loss = 0.01912831701338291
Iteration 2600: Loss = 0.019116807729005814
Iteration 2601: Loss = 0.019105345010757446
Iteration 2602: Loss = 0.019093932583928108
Iteration 2603: Loss = 0.019082549959421158
Iteration 2604: Loss = 0.019071226939558983
Iteration 2605: Loss = 0.0190599262714386
Iteration 2606: Loss = 0.01904868334531784
Iteration 2607: Loss = 0.019037459045648575
Iteration 2608: Loss = 0.019026288762688637
Iteration 2609: Loss = 0.019015157595276833
Iteration 2610: Loss = 0.0190040934830904
Iteration 2611: Loss = 0.01899305172264576
Iteration 2612: Loss = 0.018981987610459328
Iteration 2613: Loss = 0.018970971927046776
Iteration 2614: Loss = 0.018959982320666313
Iteration 2615: Loss = 0.018949048593640327
Iteration 2616: Loss = 0.018938137218356133
Iteration 2617: Loss = 0.018927285447716713
Iteration 2618: Loss = 0.018916459754109383
Iteration 2619: Loss = 0.018905656412243843
Iteration 2620: Loss = 0.018894920125603676
Iteration 2621: Loss = 0.018884222954511642
Iteration 2622: Loss = 0.018873559311032295
Iteration 2623: Loss = 0.018862921744585037
Iteration 2624: Loss = 0.01885235868394375
Iteration 2625: Loss = 0.01884181797504425
Iteration 2626: Loss = 0.018831325694918633
Iteration 2627: Loss = 0.018820859491825104
Iteration 2628: Loss = 0.018810436129570007
Iteration 2629: Loss = 0.018800068646669388
Iteration 2630: Loss = 0.018789738416671753
Iteration 2631: Loss = 0.018779443576931953
Iteration 2632: Loss = 0.018769187852740288
Iteration 2633: Loss = 0.01875898241996765
Iteration 2634: Loss = 0.018748806789517403
Iteration 2635: Loss = 0.01873868703842163
Iteration 2636: Loss = 0.018728598952293396
Iteration 2637: Loss = 0.018718598410487175
Iteration 2638: Loss = 0.018708650022745132
Iteration 2639: Loss = 0.018698800355196
Iteration 2640: Loss = 0.01868904009461403
Iteration 2641: Loss = 0.018679434433579445
Iteration 2642: Loss = 0.018670063465833664
Iteration 2643: Loss = 0.018661055713891983
Iteration 2644: Loss = 0.018652603030204773
Iteration 2645: Loss = 0.018645035102963448
Iteration 2646: Loss = 0.01863887906074524
Iteration 2647: Loss = 0.018634440377354622
Iteration 2648: Loss = 0.018631046637892723
Iteration 2649: Loss = 0.01863081008195877
Iteration 2650: Loss = 0.018633568659424782
Iteration 2651: Loss = 0.018638530746102333
Iteration 2652: Loss = 0.018644927069544792
Iteration 2653: Loss = 0.01864115707576275
Iteration 2654: Loss = 0.018625712022185326
Iteration 2655: Loss = 0.01859196461737156
Iteration 2656: Loss = 0.01855655200779438
Iteration 2657: Loss = 0.018528880551457405
Iteration 2658: Loss = 0.01851527765393257
Iteration 2659: Loss = 0.018514050170779228
Iteration 2660: Loss = 0.01851770095527172
Iteration 2661: Loss = 0.01851806417107582
Iteration 2662: Loss = 0.01850937120616436
Iteration 2663: Loss = 0.018491733819246292
Iteration 2664: Loss = 0.018470613285899162
Iteration 2665: Loss = 0.018452981486916542
Iteration 2666: Loss = 0.018442731350660324
Iteration 2667: Loss = 0.018438352271914482
Iteration 2668: Loss = 0.018435396254062653
Iteration 2669: Loss = 0.018429704010486603
Iteration 2670: Loss = 0.01841927319765091
Iteration 2671: Loss = 0.018405631184577942
Iteration 2672: Loss = 0.018391702324151993
Iteration 2673: Loss = 0.01838044635951519
Iteration 2674: Loss = 0.018372606486082077
Iteration 2675: Loss = 0.018366722390055656
Iteration 2676: Loss = 0.018360450863838196
Iteration 2677: Loss = 0.01835215836763382
Iteration 2678: Loss = 0.018342150375247
Iteration 2679: Loss = 0.018331123515963554
Iteration 2680: Loss = 0.018320582807064056
Iteration 2681: Loss = 0.01831149496138096
Iteration 2682: Loss = 0.018303800374269485
Iteration 2683: Loss = 0.01829662173986435
Iteration 2684: Loss = 0.018288783729076385
Iteration 2685: Loss = 0.018280237913131714
Iteration 2686: Loss = 0.018270932137966156
Iteration 2687: Loss = 0.01826157234609127
Iteration 2688: Loss = 0.018252624198794365
Iteration 2689: Loss = 0.018244249746203423
Iteration 2690: Loss = 0.018236374482512474
Iteration 2691: Loss = 0.018228594213724136
Iteration 2692: Loss = 0.018220599740743637
Iteration 2693: Loss = 0.018212340772151947
Iteration 2694: Loss = 0.01820378191769123
Iteration 2695: Loss = 0.01819518394768238
Iteration 2696: Loss = 0.018186740577220917
Iteration 2697: Loss = 0.01817852072417736
Iteration 2698: Loss = 0.018170533701777458
Iteration 2699: Loss = 0.018162691965699196
Iteration 2700: Loss = 0.018154824152588844
Iteration 2701: Loss = 0.01814691536128521
Iteration 2702: Loss = 0.018138883635401726
Iteration 2703: Loss = 0.018130799755454063
Iteration 2704: Loss = 0.018122732639312744
Iteration 2705: Loss = 0.01811467483639717
Iteration 2706: Loss = 0.01810675486922264
Iteration 2707: Loss = 0.01809891313314438
Iteration 2708: Loss = 0.018091149628162384
Iteration 2709: Loss = 0.01808345690369606
Iteration 2710: Loss = 0.018075749278068542
Iteration 2711: Loss = 0.018068043515086174
Iteration 2712: Loss = 0.018060337752103806
Iteration 2713: Loss = 0.018052615225315094
Iteration 2714: Loss = 0.01804491877555847
Iteration 2715: Loss = 0.018037224188447
Iteration 2716: Loss = 0.018029583618044853
Iteration 2717: Loss = 0.01802198588848114
Iteration 2718: Loss = 0.018014393746852875
Iteration 2719: Loss = 0.018006816506385803
Iteration 2720: Loss = 0.017999250441789627
Iteration 2721: Loss = 0.017991717904806137
Iteration 2722: Loss = 0.017984215170145035
Iteration 2723: Loss = 0.017976704984903336
Iteration 2724: Loss = 0.017969222739338875
Iteration 2725: Loss = 0.01796175166964531
Iteration 2726: Loss = 0.01795429177582264
Iteration 2727: Loss = 0.017946850508451462
Iteration 2728: Loss = 0.017939424142241478
Iteration 2729: Loss = 0.017932003363966942
Iteration 2730: Loss = 0.01792389154434204
Iteration 2731: Loss = 0.01791691593825817
Iteration 2732: Loss = 0.017909204587340355
Iteration 2733: Loss = 0.01790141873061657
Iteration 2734: Loss = 0.017894411459565163
Iteration 2735: Loss = 0.017887111753225327
Iteration 2736: Loss = 0.01787978783249855
Iteration 2737: Loss = 0.01787242665886879
Iteration 2738: Loss = 0.017864834517240524
Iteration 2739: Loss = 0.017857709899544716
Iteration 2740: Loss = 0.017850574105978012
Iteration 2741: Loss = 0.017843326553702354
Iteration 2742: Loss = 0.017836203798651695
Iteration 2743: Loss = 0.017828958109021187
Iteration 2744: Loss = 0.01782202534377575
Iteration 2745: Loss = 0.017815276980400085
Iteration 2746: Loss = 0.01780852861702442
Iteration 2747: Loss = 0.017802046611905098
Iteration 2748: Loss = 0.017795704305171967
Iteration 2749: Loss = 0.017789751291275024
Iteration 2750: Loss = 0.01778426580131054
Iteration 2751: Loss = 0.017779160290956497
Iteration 2752: Loss = 0.017774607986211777
Iteration 2753: Loss = 0.017770614475011826
Iteration 2754: Loss = 0.017766984179615974
Iteration 2755: Loss = 0.017761467024683952
Iteration 2756: Loss = 0.0177554152905941
Iteration 2757: Loss = 0.017747003585100174
Iteration 2758: Loss = 0.017737623304128647
Iteration 2759: Loss = 0.017726197838783264
Iteration 2760: Loss = 0.01771494932472706
Iteration 2761: Loss = 0.01770314946770668
Iteration 2762: Loss = 0.01769309490919113
Iteration 2763: Loss = 0.017684707418084145
Iteration 2764: Loss = 0.017677700147032738
Iteration 2765: Loss = 0.017671722918748856
Iteration 2766: Loss = 0.017666444182395935
Iteration 2767: Loss = 0.01766154356300831
Iteration 2768: Loss = 0.017656788229942322
Iteration 2769: Loss = 0.017651833593845367
Iteration 2770: Loss = 0.01764526031911373
Iteration 2771: Loss = 0.017638182267546654
Iteration 2772: Loss = 0.017629753798246384
Iteration 2773: Loss = 0.017621280625462532
Iteration 2774: Loss = 0.017612125724554062
Iteration 2775: Loss = 0.017604166641831398
Iteration 2776: Loss = 0.017596961930394173
Iteration 2777: Loss = 0.01759064570069313
Iteration 2778: Loss = 0.01758483611047268
Iteration 2779: Loss = 0.01757928729057312
Iteration 2780: Loss = 0.017574060708284378
Iteration 2781: Loss = 0.017567716538906097
Iteration 2782: Loss = 0.017561282962560654
Iteration 2783: Loss = 0.01755407638847828
Iteration 2784: Loss = 0.017546705901622772
Iteration 2785: Loss = 0.01753913424909115
Iteration 2786: Loss = 0.017531856894493103
Iteration 2787: Loss = 0.0175249595195055
Iteration 2788: Loss = 0.017518408596515656
Iteration 2789: Loss = 0.017512015998363495
Iteration 2790: Loss = 0.01750580593943596
Iteration 2791: Loss = 0.017499694600701332
Iteration 2792: Loss = 0.017493680119514465
Iteration 2793: Loss = 0.017487820237874985
Iteration 2794: Loss = 0.017481474205851555
Iteration 2795: Loss = 0.017475076019763947
Iteration 2796: Loss = 0.017468424513936043
Iteration 2797: Loss = 0.017461713403463364
Iteration 2798: Loss = 0.01745499297976494
Iteration 2799: Loss = 0.01744854263961315
Iteration 2800: Loss = 0.017442358657717705
Iteration 2801: Loss = 0.017436375841498375
Iteration 2802: Loss = 0.017430534586310387
Iteration 2803: Loss = 0.01742491126060486
Iteration 2804: Loss = 0.01741948164999485
Iteration 2805: Loss = 0.017413755878806114
Iteration 2806: Loss = 0.017408035695552826
Iteration 2807: Loss = 0.01740223541855812
Iteration 2808: Loss = 0.017396243289113045
Iteration 2809: Loss = 0.017390277236700058
Iteration 2810: Loss = 0.017384221777319908
Iteration 2811: Loss = 0.017378143966197968
Iteration 2812: Loss = 0.01737217605113983
Iteration 2813: Loss = 0.0173660796135664
Iteration 2814: Loss = 0.01736009679734707
Iteration 2815: Loss = 0.01735408417880535
Iteration 2816: Loss = 0.01734810695052147
Iteration 2817: Loss = 0.017342286184430122
Iteration 2818: Loss = 0.017336320132017136
Iteration 2819: Loss = 0.017330612987279892
Iteration 2820: Loss = 0.017324764281511307
Iteration 2821: Loss = 0.01731923781335354
Iteration 2822: Loss = 0.017313668504357338
Iteration 2823: Loss = 0.017308467999100685
Iteration 2824: Loss = 0.017303327098488808
Iteration 2825: Loss = 0.017298806458711624
Iteration 2826: Loss = 0.017294548451900482
Iteration 2827: Loss = 0.017291449010372162
Iteration 2828: Loss = 0.017289089038968086
Iteration 2829: Loss = 0.017288807779550552
Iteration 2830: Loss = 0.017290297895669937
Iteration 2831: Loss = 0.01729474775493145
Iteration 2832: Loss = 0.01730155013501644
Iteration 2833: Loss = 0.017310071736574173
Iteration 2834: Loss = 0.017316661775112152
Iteration 2835: Loss = 0.017316386103630066
Iteration 2836: Loss = 0.017303260043263435
Iteration 2837: Loss = 0.017277048900723457
Iteration 2838: Loss = 0.01724434643983841
Iteration 2839: Loss = 0.017218448221683502
Iteration 2840: Loss = 0.017207564786076546
Iteration 2841: Loss = 0.01721232570707798
Iteration 2842: Loss = 0.017222855240106583
Iteration 2843: Loss = 0.017226334661245346
Iteration 2844: Loss = 0.017217904329299927
Iteration 2845: Loss = 0.017199192196130753
Iteration 2846: Loss = 0.01718057133257389
Iteration 2847: Loss = 0.017169620841741562
Iteration 2848: Loss = 0.01716945692896843
Iteration 2849: Loss = 0.017173735424876213
Iteration 2850: Loss = 0.017172900959849358
Iteration 2851: Loss = 0.01716495305299759
Iteration 2852: Loss = 0.01715126819908619
Iteration 2853: Loss = 0.017139453440904617
Iteration 2854: Loss = 0.01713305152952671
Iteration 2855: Loss = 0.017131300643086433
Iteration 2856: Loss = 0.017130697146058083
Iteration 2857: Loss = 0.017127694562077522
Iteration 2858: Loss = 0.01712101697921753
Iteration 2859: Loss = 0.01711195707321167
Iteration 2860: Loss = 0.017103178426623344
Iteration 2861: Loss = 0.017096664756536484
Iteration 2862: Loss = 0.017092622816562653
Iteration 2863: Loss = 0.017089715227484703
Iteration 2864: Loss = 0.017086200416088104
Iteration 2865: Loss = 0.01708107627928257
Iteration 2866: Loss = 0.017074527218937874
Iteration 2867: Loss = 0.017067572101950645
Iteration 2868: Loss = 0.01706129126250744
Iteration 2869: Loss = 0.017056195065379143
Iteration 2870: Loss = 0.017051972448825836
Iteration 2871: Loss = 0.017047947272658348
Iteration 2872: Loss = 0.017043448984622955
Iteration 2873: Loss = 0.017038241028785706
Iteration 2874: Loss = 0.01703251712024212
Iteration 2875: Loss = 0.017026737332344055
Iteration 2876: Loss = 0.017021283507347107
Iteration 2877: Loss = 0.017016340047121048
Iteration 2878: Loss = 0.01701175980269909
Iteration 2879: Loss = 0.017007282003760338
Iteration 2880: Loss = 0.017002642154693604
Iteration 2881: Loss = 0.01699773408472538
Iteration 2882: Loss = 0.016992589458823204
Iteration 2883: Loss = 0.01698736660182476
Iteration 2884: Loss = 0.016982218250632286
Iteration 2885: Loss = 0.016977235674858093
Iteration 2886: Loss = 0.016972467303276062
Iteration 2887: Loss = 0.016967788338661194
Iteration 2888: Loss = 0.016963141039013863
Iteration 2889: Loss = 0.016958434134721756
Iteration 2890: Loss = 0.01695364899933338
Iteration 2891: Loss = 0.016948776319622993
Iteration 2892: Loss = 0.016943858936429024
Iteration 2893: Loss = 0.01693897321820259
Iteration 2894: Loss = 0.016934122890233994
Iteration 2895: Loss = 0.01692936196923256
Iteration 2896: Loss = 0.016924666240811348
Iteration 2897: Loss = 0.016919998452067375
Iteration 2898: Loss = 0.0169153343886137
Iteration 2899: Loss = 0.016910681501030922
Iteration 2900: Loss = 0.01690598949790001
Iteration 2901: Loss = 0.016901297494769096
Iteration 2902: Loss = 0.016896599903702736
Iteration 2903: Loss = 0.016891879960894585
Iteration 2904: Loss = 0.016887178644537926
Iteration 2905: Loss = 0.016882503405213356
Iteration 2906: Loss = 0.016877848654985428
Iteration 2907: Loss = 0.01687321439385414
Iteration 2908: Loss = 0.016868604347109795
Iteration 2909: Loss = 0.016864007338881493
Iteration 2910: Loss = 0.016859428957104683
Iteration 2911: Loss = 0.01685485802590847
Iteration 2912: Loss = 0.016850285232067108
Iteration 2913: Loss = 0.016845721751451492
Iteration 2914: Loss = 0.016841156408190727
Iteration 2915: Loss = 0.016836611554026604
Iteration 2916: Loss = 0.016832055523991585
Iteration 2917: Loss = 0.016827499493956566
Iteration 2918: Loss = 0.016822954639792442
Iteration 2919: Loss = 0.016818413510918617
Iteration 2920: Loss = 0.01681390590965748
Iteration 2921: Loss = 0.016809387132525444
Iteration 2922: Loss = 0.01680488884449005
Iteration 2923: Loss = 0.016800418496131897
Iteration 2924: Loss = 0.016795940697193146
Iteration 2925: Loss = 0.016791464760899544
Iteration 2926: Loss = 0.016787022352218628
Iteration 2927: Loss = 0.016782568767666817
Iteration 2928: Loss = 0.01677812822163105
Iteration 2929: Loss = 0.01677369885146618
Iteration 2930: Loss = 0.016769275069236755
Iteration 2931: Loss = 0.016764873638749123
Iteration 2932: Loss = 0.016760483384132385
Iteration 2933: Loss = 0.01675611175596714
Iteration 2934: Loss = 0.01675175502896309
Iteration 2935: Loss = 0.016747424378991127
Iteration 2936: Loss = 0.01674310863018036
Iteration 2937: Loss = 0.01673777587711811
Iteration 2938: Loss = 0.01673409901559353
Iteration 2939: Loss = 0.016728729009628296
Iteration 2940: Loss = 0.016724564135074615
Iteration 2941: Loss = 0.016720103099942207
Iteration 2942: Loss = 0.016715139150619507
Iteration 2943: Loss = 0.016711177304387093
Iteration 2944: Loss = 0.016706205904483795
Iteration 2945: Loss = 0.01670190691947937
Iteration 2946: Loss = 0.016697479411959648
Iteration 2947: Loss = 0.01669273152947426
Iteration 2948: Loss = 0.01668858900666237
Iteration 2949: Loss = 0.01668385975062847
Iteration 2950: Loss = 0.016679521650075912
Iteration 2951: Loss = 0.01667511649429798
Iteration 2952: Loss = 0.01667051389813423
Iteration 2953: Loss = 0.01666627824306488
Iteration 2954: Loss = 0.016661707311868668
Iteration 2955: Loss = 0.01665736362338066
Iteration 2956: Loss = 0.016652997583150864
Iteration 2957: Loss = 0.016648510470986366
Iteration 2958: Loss = 0.016644267365336418
Iteration 2959: Loss = 0.0166398324072361
Iteration 2960: Loss = 0.016635585576295853
Iteration 2961: Loss = 0.01663137786090374
Iteration 2962: Loss = 0.016627220436930656
Iteration 2963: Loss = 0.01662336476147175
Iteration 2964: Loss = 0.016619767993688583
Iteration 2965: Loss = 0.016616910696029663
Iteration 2966: Loss = 0.01661524921655655
Iteration 2967: Loss = 0.016615794971585274
Iteration 2968: Loss = 0.01662047579884529
Iteration 2969: Loss = 0.016632303595542908
Iteration 2970: Loss = 0.016656138002872467
Iteration 2971: Loss = 0.01669715903699398
Iteration 2972: Loss = 0.01675489917397499
Iteration 2973: Loss = 0.016811275854706764
Iteration 2974: Loss = 0.016810951754450798
Iteration 2975: Loss = 0.01672157272696495
Iteration 2976: Loss = 0.016605250537395477
Iteration 2977: Loss = 0.016565104946494102
Iteration 2978: Loss = 0.016613338142633438
Iteration 2979: Loss = 0.01667015627026558
Iteration 2980: Loss = 0.01665821112692356
Iteration 2981: Loss = 0.01658806763589382
Iteration 2982: Loss = 0.016544360667467117
Iteration 2983: Loss = 0.01656675897538662
Iteration 2984: Loss = 0.016602279618382454
Iteration 2985: Loss = 0.016590766608715057
Iteration 2986: Loss = 0.016545522958040237
Iteration 2987: Loss = 0.01652550883591175
Iteration 2988: Loss = 0.01654481329023838
Iteration 2989: Loss = 0.016559384763240814
Iteration 2990: Loss = 0.016540363430976868
Iteration 2991: Loss = 0.016512833535671234
Iteration 2992: Loss = 0.01651001162827015
Iteration 2993: Loss = 0.016523446887731552
Iteration 2994: Loss = 0.016522571444511414
Iteration 2995: Loss = 0.016503650695085526
Iteration 2996: Loss = 0.016490649431943893
Iteration 2997: Loss = 0.01649431511759758
Iteration 2998: Loss = 0.01649784855544567
Iteration 2999: Loss = 0.016488566994667053
Iteration 3000: Loss = 0.016476424410939217
Iteration 3001: Loss = 0.016474058851599693
Iteration 3002: Loss = 0.016477065160870552
Iteration 3003: Loss = 0.016473514959216118
Iteration 3004: Loss = 0.01646343246102333
Iteration 3005: Loss = 0.016456883400678635
Iteration 3006: Loss = 0.01645718328654766
Iteration 3007: Loss = 0.016455912962555885
Iteration 3008: Loss = 0.016449719667434692
Iteration 3009: Loss = 0.01644263230264187
Iteration 3010: Loss = 0.016439571976661682
Iteration 3011: Loss = 0.016438381746411324
Iteration 3012: Loss = 0.016435343772172928
Iteration 3013: Loss = 0.016429003328084946
Iteration 3014: Loss = 0.01642286591231823
Iteration 3015: Loss = 0.016420988366007805
Iteration 3016: Loss = 0.016418680548667908
Iteration 3017: Loss = 0.016414135694503784
Iteration 3018: Loss = 0.016408955678343773
Iteration 3019: Loss = 0.01640443131327629
Iteration 3020: Loss = 0.01640201546251774
Iteration 3021: Loss = 0.016399042680859566
Iteration 3022: Loss = 0.016394322738051414
Iteration 3023: Loss = 0.016389867290854454
Iteration 3024: Loss = 0.016386106610298157
Iteration 3025: Loss = 0.01638314127922058
Iteration 3026: Loss = 0.016379814594984055
Iteration 3027: Loss = 0.016375377774238586
Iteration 3028: Loss = 0.016371283680200577
Iteration 3029: Loss = 0.016367817297577858
Iteration 3030: Loss = 0.01636452041566372
Iteration 3031: Loss = 0.01636100746691227
Iteration 3032: Loss = 0.01635691523551941
Iteration 3033: Loss = 0.016353024169802666
Iteration 3034: Loss = 0.016349591314792633
Iteration 3035: Loss = 0.016346145421266556
Iteration 3036: Loss = 0.016342582181096077
Iteration 3037: Loss = 0.016338732093572617
Iteration 3038: Loss = 0.016334954649209976
Iteration 3039: Loss = 0.016331497579813004
Iteration 3040: Loss = 0.01632804609835148
Iteration 3041: Loss = 0.016324488446116447
Iteration 3042: Loss = 0.016320807859301567
Iteration 3043: Loss = 0.016317127272486687
Iteration 3044: Loss = 0.016313647851347923
Iteration 3045: Loss = 0.0163101889193058
Iteration 3046: Loss = 0.016306670382618904
Iteration 3047: Loss = 0.01630307547748089
Iteration 3048: Loss = 0.016299482434988022
Iteration 3049: Loss = 0.016295991837978363
Iteration 3050: Loss = 0.01629253476858139
Iteration 3051: Loss = 0.01628904603421688
Iteration 3052: Loss = 0.016285527497529984
Iteration 3053: Loss = 0.016281982883810997
Iteration 3054: Loss = 0.016278499737381935
Iteration 3055: Loss = 0.016275063157081604
Iteration 3056: Loss = 0.01627158746123314
Iteration 3057: Loss = 0.01626812107861042
Iteration 3058: Loss = 0.016264623031020164
Iteration 3059: Loss = 0.01626116782426834
Iteration 3060: Loss = 0.01625773310661316
Iteration 3061: Loss = 0.01625431329011917
Iteration 3062: Loss = 0.01625087484717369
Iteration 3063: Loss = 0.016247425228357315
Iteration 3064: Loss = 0.016243992373347282
Iteration 3065: Loss = 0.016240578144788742
Iteration 3066: Loss = 0.016237160190939903
Iteration 3067: Loss = 0.016233766451478004
Iteration 3068: Loss = 0.016230368986725807
Iteration 3069: Loss = 0.016226960346102715
Iteration 3070: Loss = 0.016223562881350517
Iteration 3071: Loss = 0.016220174729824066
Iteration 3072: Loss = 0.01621679775416851
Iteration 3073: Loss = 0.016213433817029
Iteration 3074: Loss = 0.016210045665502548
Iteration 3075: Loss = 0.016206689178943634
Iteration 3076: Loss = 0.016203321516513824
Iteration 3077: Loss = 0.016199959442019463
Iteration 3078: Loss = 0.01619662158191204
Iteration 3079: Loss = 0.01619328185915947
Iteration 3080: Loss = 0.0161899346858263
Iteration 3081: Loss = 0.01618659682571888
Iteration 3082: Loss = 0.01618327759206295
Iteration 3083: Loss = 0.016179954633116722
Iteration 3084: Loss = 0.016176635399460793
Iteration 3085: Loss = 0.01617332547903061
Iteration 3086: Loss = 0.016170019283890724
Iteration 3087: Loss = 0.01616671495139599
Iteration 3088: Loss = 0.016163412481546402
Iteration 3089: Loss = 0.016160128638148308
Iteration 3090: Loss = 0.01615682803094387
Iteration 3091: Loss = 0.016153555363416672
Iteration 3092: Loss = 0.016150273382663727
Iteration 3093: Loss = 0.01614699512720108
Iteration 3094: Loss = 0.016143741086125374
Iteration 3095: Loss = 0.016140468418598175
Iteration 3096: Loss = 0.016137205064296722
Iteration 3097: Loss = 0.016133954748511314
Iteration 3098: Loss = 0.01613071747124195
Iteration 3099: Loss = 0.016127480193972588
Iteration 3100: Loss = 0.016124244779348373
Iteration 3101: Loss = 0.016121001914143562
Iteration 3102: Loss = 0.016117796301841736
Iteration 3103: Loss = 0.01611459068953991
Iteration 3104: Loss = 0.016111381351947784
Iteration 3105: Loss = 0.016108188778162003
Iteration 3106: Loss = 0.01610499992966652
Iteration 3107: Loss = 0.016101807355880737
Iteration 3108: Loss = 0.0160986240953207
Iteration 3109: Loss = 0.016095448285341263
Iteration 3110: Loss = 0.016092266887426376
Iteration 3111: Loss = 0.016089104115962982
Iteration 3112: Loss = 0.016085950657725334
Iteration 3113: Loss = 0.01608278602361679
Iteration 3114: Loss = 0.01607964187860489
Iteration 3115: Loss = 0.016076505184173584
Iteration 3116: Loss = 0.016073355451226234
Iteration 3117: Loss = 0.01607021875679493
Iteration 3118: Loss = 0.016067085787653923
Iteration 3119: Loss = 0.01606396958231926
Iteration 3120: Loss = 0.016060836613178253
Iteration 3121: Loss = 0.01605772227048874
Iteration 3122: Loss = 0.016054615378379822
Iteration 3123: Loss = 0.016051504760980606
Iteration 3124: Loss = 0.016048412770032883
Iteration 3125: Loss = 0.01604527421295643
Iteration 3126: Loss = 0.016041962429881096
Iteration 3127: Loss = 0.01603912003338337
Iteration 3128: Loss = 0.0160357728600502
Iteration 3129: Loss = 0.016032742336392403
Iteration 3130: Loss = 0.016029613092541695
Iteration 3131: Loss = 0.016026347875595093
Iteration 3132: Loss = 0.016023382544517517
Iteration 3133: Loss = 0.016020115464925766
Iteration 3134: Loss = 0.01601705327630043
Iteration 3135: Loss = 0.016013985499739647
Iteration 3136: Loss = 0.016010809689760208
Iteration 3137: Loss = 0.016007820144295692
Iteration 3138: Loss = 0.01600465178489685
Iteration 3139: Loss = 0.016001567244529724
Iteration 3140: Loss = 0.015998510643839836
Iteration 3141: Loss = 0.015995360910892487
Iteration 3142: Loss = 0.01599235087633133
Iteration 3143: Loss = 0.01598922535777092
Iteration 3144: Loss = 0.015986179932951927
Iteration 3145: Loss = 0.015983128920197487
Iteration 3146: Loss = 0.015980055555701256
Iteration 3147: Loss = 0.0159770417958498
Iteration 3148: Loss = 0.015973959118127823
Iteration 3149: Loss = 0.015970934182405472
Iteration 3150: Loss = 0.01596790924668312
Iteration 3151: Loss = 0.015964852645993233
Iteration 3152: Loss = 0.015961842611432076
Iteration 3153: Loss = 0.01595880649983883
Iteration 3154: Loss = 0.015955796465277672
Iteration 3155: Loss = 0.015952790156006813
Iteration 3156: Loss = 0.01594976894557476
Iteration 3157: Loss = 0.015946781262755394
Iteration 3158: Loss = 0.01594378799200058
Iteration 3159: Loss = 0.015940804034471512
Iteration 3160: Loss = 0.01593780890107155
Iteration 3161: Loss = 0.015934832394123077
Iteration 3162: Loss = 0.015931861475110054
Iteration 3163: Loss = 0.015928879380226135
Iteration 3164: Loss = 0.01592591218650341
Iteration 3165: Loss = 0.01592295430600643
Iteration 3166: Loss = 0.015919992700219154
Iteration 3167: Loss = 0.01591702550649643
Iteration 3168: Loss = 0.01591407135128975
Iteration 3169: Loss = 0.015911119058728218
Iteration 3170: Loss = 0.015908176079392433
Iteration 3171: Loss = 0.015905236825346947
Iteration 3172: Loss = 0.015902293846011162
Iteration 3173: Loss = 0.01589934527873993
Iteration 3174: Loss = 0.01589641533792019
Iteration 3175: Loss = 0.015893494710326195
Iteration 3176: Loss = 0.015890564769506454
Iteration 3177: Loss = 0.015887659043073654
Iteration 3178: Loss = 0.01588473655283451
Iteration 3179: Loss = 0.015881827101111412
Iteration 3180: Loss = 0.015878921374678612
Iteration 3181: Loss = 0.01587601937353611
Iteration 3182: Loss = 0.015873124822974205
Iteration 3183: Loss = 0.015870235860347748
Iteration 3184: Loss = 0.015867331996560097
Iteration 3185: Loss = 0.015864456072449684
Iteration 3186: Loss = 0.015861576423048973
Iteration 3187: Loss = 0.015858711674809456
Iteration 3188: Loss = 0.01585584692656994
Iteration 3189: Loss = 0.015852995216846466
Iteration 3190: Loss = 0.015850134193897247
Iteration 3191: Loss = 0.015847312286496162
Iteration 3192: Loss = 0.01584448479115963
Iteration 3193: Loss = 0.015841694548726082
Iteration 3194: Loss = 0.01583891734480858
Iteration 3195: Loss = 0.015836182981729507
Iteration 3196: Loss = 0.015833519399166107
Iteration 3197: Loss = 0.015830976888537407
Iteration 3198: Loss = 0.015828577801585197
Iteration 3199: Loss = 0.01582644321024418
Iteration 3200: Loss = 0.01582474634051323
Iteration 3201: Loss = 0.015823738649487495
Iteration 3202: Loss = 0.015823854133486748
Iteration 3203: Loss = 0.015825806185603142
Iteration 3204: Loss = 0.015830637887120247
Iteration 3205: Loss = 0.015839919447898865
Iteration 3206: Loss = 0.015855496749281883
Iteration 3207: Loss = 0.01587885618209839
Iteration 3208: Loss = 0.01590893045067787
Iteration 3209: Loss = 0.015938319265842438
Iteration 3210: Loss = 0.01595105417072773
Iteration 3211: Loss = 0.015929801389575005
Iteration 3212: Loss = 0.01587427221238613
Iteration 3213: Loss = 0.015813445672392845
Iteration 3214: Loss = 0.01578374020755291
Iteration 3215: Loss = 0.01579536311328411
Iteration 3216: Loss = 0.01582610048353672
Iteration 3217: Loss = 0.015842970460653305
Iteration 3218: Loss = 0.01582847721874714
Iteration 3219: Loss = 0.01579449698328972
Iteration 3220: Loss = 0.01576971635222435
Iteration 3221: Loss = 0.01577027328312397
Iteration 3222: Loss = 0.01578625664114952
Iteration 3223: Loss = 0.01579546555876732
Iteration 3224: Loss = 0.01578601263463497
Iteration 3225: Loss = 0.015766065567731857
Iteration 3226: Loss = 0.015752945095300674
Iteration 3227: Loss = 0.015754394233226776
Iteration 3228: Loss = 0.015762493014335632
Iteration 3229: Loss = 0.015764432027935982
Iteration 3230: Loss = 0.01575590670108795
Iteration 3231: Loss = 0.015743855386972427
Iteration 3232: Loss = 0.015737567096948624
Iteration 3233: Loss = 0.015738947317004204
Iteration 3234: Loss = 0.015742113813757896
Iteration 3235: Loss = 0.015740539878606796
Iteration 3236: Loss = 0.015733694657683372
Iteration 3237: Loss = 0.015726353973150253
Iteration 3238: Loss = 0.01572299189865589
Iteration 3239: Loss = 0.015723301097750664
Iteration 3240: Loss = 0.0157235749065876
Iteration 3241: Loss = 0.0157209113240242
Iteration 3242: Loss = 0.01571577787399292
Iteration 3243: Loss = 0.015710977837443352
Iteration 3244: Loss = 0.015708470717072487
Iteration 3245: Loss = 0.015707695856690407
Iteration 3246: Loss = 0.01570662297308445
Iteration 3247: Loss = 0.015703894197940826
Iteration 3248: Loss = 0.01569999009370804
Iteration 3249: Loss = 0.01569635421037674
Iteration 3250: Loss = 0.01569395698606968
Iteration 3251: Loss = 0.015692468732595444
Iteration 3252: Loss = 0.015690801665186882
Iteration 3253: Loss = 0.015688281506299973
Iteration 3254: Loss = 0.01568511128425598
Iteration 3255: Loss = 0.01568203791975975
Iteration 3256: Loss = 0.01567959599196911
Iteration 3257: Loss = 0.015677670016884804
Iteration 3258: Loss = 0.015675723552703857
Iteration 3259: Loss = 0.01567338965833187
Iteration 3260: Loss = 0.015670672059059143
Iteration 3261: Loss = 0.015667898580431938
Iteration 3262: Loss = 0.01566542126238346
Iteration 3263: Loss = 0.01566324196755886
Iteration 3264: Loss = 0.015661148354411125
Iteration 3265: Loss = 0.015658913180232048
Iteration 3266: Loss = 0.015656469389796257
Iteration 3267: Loss = 0.01565392315387726
Iteration 3268: Loss = 0.015651438385248184
Iteration 3269: Loss = 0.01564912684261799
Iteration 3270: Loss = 0.01564691960811615
Iteration 3271: Loss = 0.01564471609890461
Iteration 3272: Loss = 0.015642421320080757
Iteration 3273: Loss = 0.01564003713428974
Iteration 3274: Loss = 0.01563761942088604
Iteration 3275: Loss = 0.01563524641096592
Iteration 3276: Loss = 0.015632962808012962
Iteration 3277: Loss = 0.015630710870027542
Iteration 3278: Loss = 0.015628475695848465
Iteration 3279: Loss = 0.01562621258199215
Iteration 3280: Loss = 0.01562389824539423
Iteration 3281: Loss = 0.015621574595570564
Iteration 3282: Loss = 0.015619254671037197
Iteration 3283: Loss = 0.01561695896089077
Iteration 3284: Loss = 0.015614703297615051
Iteration 3285: Loss = 0.015612460672855377
Iteration 3286: Loss = 0.015610219910740852
Iteration 3287: Loss = 0.01560795959085226
Iteration 3288: Loss = 0.015605677850544453
Iteration 3289: Loss = 0.015603410080075264
Iteration 3290: Loss = 0.015601139515638351
Iteration 3291: Loss = 0.015598880127072334
Iteration 3292: Loss = 0.015596644021570683
Iteration 3293: Loss = 0.015594408847391605
Iteration 3294: Loss = 0.015592172741889954
Iteration 3295: Loss = 0.015589953400194645
Iteration 3296: Loss = 0.01558772474527359
Iteration 3297: Loss = 0.015585477463901043
Iteration 3298: Loss = 0.01558324322104454
Iteration 3299: Loss = 0.015581021085381508
Iteration 3300: Loss = 0.015578792430460453
Iteration 3301: Loss = 0.015576590783894062
Iteration 3302: Loss = 0.015574371442198753
Iteration 3303: Loss = 0.015572167001664639
Iteration 3304: Loss = 0.015569964423775673
Iteration 3305: Loss = 0.015567762777209282
Iteration 3306: Loss = 0.015565555542707443
Iteration 3307: Loss = 0.015563360415399075
Iteration 3308: Loss = 0.015561167150735855
Iteration 3309: Loss = 0.015558973886072636
Iteration 3310: Loss = 0.01555678527802229
Iteration 3311: Loss = 0.015554595738649368
Iteration 3312: Loss = 0.015552413649857044
Iteration 3313: Loss = 0.015550251118838787
Iteration 3314: Loss = 0.015548072755336761
Iteration 3315: Loss = 0.015545898117125034
Iteration 3316: Loss = 0.015543731860816479
Iteration 3317: Loss = 0.015541558153927326
Iteration 3318: Loss = 0.015539389103651047
Iteration 3319: Loss = 0.015537232160568237
Iteration 3320: Loss = 0.015535074286162853
Iteration 3321: Loss = 0.015532913617789745
Iteration 3322: Loss = 0.015530772507190704
Iteration 3323: Loss = 0.015528617426753044
Iteration 3324: Loss = 0.01552647165954113
Iteration 3325: Loss = 0.01552432682365179
Iteration 3326: Loss = 0.0155221838504076
Iteration 3327: Loss = 0.015520061366260052
Iteration 3328: Loss = 0.015517914667725563
Iteration 3329: Loss = 0.015515780076384544
Iteration 3330: Loss = 0.01551366038620472
Iteration 3331: Loss = 0.015511533245444298
Iteration 3332: Loss = 0.01550940703600645
Iteration 3333: Loss = 0.015507297590374947
Iteration 3334: Loss = 0.015505166724324226
Iteration 3335: Loss = 0.01550286915153265
Iteration 3336: Loss = 0.015500979498028755
Iteration 3337: Loss = 0.015498633496463299
Iteration 3338: Loss = 0.015496654435992241
Iteration 3339: Loss = 0.015494508668780327
Iteration 3340: Loss = 0.015492326579988003
Iteration 3341: Loss = 0.015490316785871983
Iteration 3342: Loss = 0.015488057397305965
Iteration 3343: Loss = 0.015486045740544796
Iteration 3344: Loss = 0.015483880415558815
Iteration 3345: Loss = 0.01548172626644373
Iteration 3346: Loss = 0.015479669906198978
Iteration 3347: Loss = 0.015477476641535759
Iteration 3348: Loss = 0.015475435182452202
Iteration 3349: Loss = 0.01547328568994999
Iteration 3350: Loss = 0.015471170656383038
Iteration 3351: Loss = 0.01546910498291254
Iteration 3352: Loss = 0.015466966666281223
Iteration 3353: Loss = 0.015464931726455688
Iteration 3354: Loss = 0.015462810173630714
Iteration 3355: Loss = 0.015460732392966747
Iteration 3356: Loss = 0.015458669513463974
Iteration 3357: Loss = 0.015456573106348515
Iteration 3358: Loss = 0.015454540960490704
Iteration 3359: Loss = 0.015452451072633266
Iteration 3360: Loss = 0.015450411476194859
Iteration 3361: Loss = 0.015448368154466152
Iteration 3362: Loss = 0.015446321107447147
Iteration 3363: Loss = 0.015444314107298851
Iteration 3364: Loss = 0.01544229220598936
Iteration 3365: Loss = 0.015440314076840878
Iteration 3366: Loss = 0.015438348054885864
Iteration 3367: Loss = 0.015436427667737007
Iteration 3368: Loss = 0.015434560365974903
Iteration 3369: Loss = 0.015432785265147686
Iteration 3370: Loss = 0.015431126579642296
Iteration 3371: Loss = 0.015429661609232426
Iteration 3372: Loss = 0.01542846392840147
Iteration 3373: Loss = 0.01542770117521286
Iteration 3374: Loss = 0.015427579171955585
Iteration 3375: Loss = 0.015428478829562664
Iteration 3376: Loss = 0.015430948697030544
Iteration 3377: Loss = 0.015435689128935337
Iteration 3378: Loss = 0.015443719923496246
Iteration 3379: Loss = 0.015456096269190311
Iteration 3380: Loss = 0.015473481267690659
Iteration 3381: Loss = 0.015494825318455696
Iteration 3382: Loss = 0.015515916049480438
Iteration 3383: Loss = 0.015529436059296131
Iteration 3384: Loss = 0.01552257128059864
Iteration 3385: Loss = 0.015491863712668419
Iteration 3386: Loss = 0.015445969067513943
Iteration 3387: Loss = 0.015407642349600792
Iteration 3388: Loss = 0.015394804067909718
Iteration 3389: Loss = 0.015407043509185314
Iteration 3390: Loss = 0.01542834285646677
Iteration 3391: Loss = 0.015439790673553944
Iteration 3392: Loss = 0.01543150283396244
Iteration 3393: Loss = 0.015409235842525959
Iteration 3394: Loss = 0.015388580039143562
Iteration 3395: Loss = 0.015381978824734688
Iteration 3396: Loss = 0.015389087609946728
Iteration 3397: Loss = 0.015399160794913769
Iteration 3398: Loss = 0.015401187352836132
Iteration 3399: Loss = 0.015392393805086613
Iteration 3400: Loss = 0.015379113145172596
Iteration 3401: Loss = 0.015370293520390987
Iteration 3402: Loss = 0.015369784086942673
Iteration 3403: Loss = 0.015374140813946724
Iteration 3404: Loss = 0.015376807190477848
Iteration 3405: Loss = 0.015373928472399712
Iteration 3406: Loss = 0.015366668812930584
Iteration 3407: Loss = 0.015359600074589252
Iteration 3408: Loss = 0.015356228686869144
Iteration 3409: Loss = 0.015356580726802349
Iteration 3410: Loss = 0.01535786408931017
Iteration 3411: Loss = 0.01535709947347641
Iteration 3412: Loss = 0.015353481285274029
Iteration 3413: Loss = 0.015348594635725021
Iteration 3414: Loss = 0.015344655141234398
Iteration 3415: Loss = 0.0153427729383111
Iteration 3416: Loss = 0.015342345461249352
Iteration 3417: Loss = 0.015341821126639843
Iteration 3418: Loss = 0.015340045094490051
Iteration 3419: Loss = 0.015337012708187103
Iteration 3420: Loss = 0.01533365249633789
Iteration 3421: Loss = 0.015330900438129902
Iteration 3422: Loss = 0.015329151414334774
Iteration 3423: Loss = 0.015328011475503445
Iteration 3424: Loss = 0.01532676536589861
Iteration 3425: Loss = 0.015324916690587997
Iteration 3426: Loss = 0.01532247569411993
Iteration 3427: Loss = 0.015319839119911194
Iteration 3428: Loss = 0.015317483805119991
Iteration 3429: Loss = 0.015315583907067776
Iteration 3430: Loss = 0.015314019285142422
Iteration 3431: Loss = 0.015312468633055687
Iteration 3432: Loss = 0.015310687012970448
Iteration 3433: Loss = 0.015308612026274204
Iteration 3434: Loss = 0.01530639547854662
Iteration 3435: Loss = 0.015304241329431534
Iteration 3436: Loss = 0.015302271582186222
Iteration 3437: Loss = 0.015300484374165535
Iteration 3438: Loss = 0.015298784710466862
Iteration 3439: Loss = 0.015297014266252518
Iteration 3440: Loss = 0.015295141376554966
Iteration 3441: Loss = 0.015293171629309654
Iteration 3442: Loss = 0.015291172079741955
Iteration 3443: Loss = 0.015289192087948322
Iteration 3444: Loss = 0.015287303365767002
Iteration 3445: Loss = 0.015285497531294823
Iteration 3446: Loss = 0.015283709391951561
Iteration 3447: Loss = 0.015281911939382553
Iteration 3448: Loss = 0.015280070714652538
Iteration 3449: Loss = 0.015278183855116367
Iteration 3450: Loss = 0.015276280231773853
Iteration 3451: Loss = 0.015274387784302235
Iteration 3452: Loss = 0.015272530727088451
Iteration 3453: Loss = 0.015270695090293884
Iteration 3454: Loss = 0.015268894843757153
Iteration 3455: Loss = 0.01526709645986557
Iteration 3456: Loss = 0.01526528038084507
Iteration 3457: Loss = 0.015263380482792854
Iteration 3458: Loss = 0.015261453576385975
Iteration 3459: Loss = 0.015259507112205029
Iteration 3460: Loss = 0.01525755226612091
Iteration 3461: Loss = 0.01525559276342392
Iteration 3462: Loss = 0.015253654681146145
Iteration 3463: Loss = 0.015251739881932735
Iteration 3464: Loss = 0.015249807387590408
Iteration 3465: Loss = 0.015247891657054424
Iteration 3466: Loss = 0.015245961956679821
Iteration 3467: Loss = 0.01524403691291809
Iteration 3468: Loss = 0.015242094174027443
Iteration 3469: Loss = 0.015240163542330265
Iteration 3470: Loss = 0.015238214284181595
Iteration 3471: Loss = 0.015236282721161842
Iteration 3472: Loss = 0.015234357677400112
Iteration 3473: Loss = 0.015232425183057785
Iteration 3474: Loss = 0.015230507589876652
Iteration 3475: Loss = 0.015228591859340668
Iteration 3476: Loss = 0.01522667333483696
Iteration 3477: Loss = 0.015224756672978401
Iteration 3478: Loss = 0.015222854912281036
Iteration 3479: Loss = 0.015220947563648224
Iteration 3480: Loss = 0.015219035558402538
Iteration 3481: Loss = 0.015217134729027748
Iteration 3482: Loss = 0.015215238556265831
Iteration 3483: Loss = 0.015213333070278168
Iteration 3484: Loss = 0.015211434103548527
Iteration 3485: Loss = 0.015209559351205826
Iteration 3486: Loss = 0.015207662247121334
Iteration 3487: Loss = 0.015205773524940014
Iteration 3488: Loss = 0.015203898772597313
Iteration 3489: Loss = 0.015202011913061142
Iteration 3490: Loss = 0.01520014088600874
Iteration 3491: Loss = 0.015198273584246635
Iteration 3492: Loss = 0.015196406282484531
Iteration 3493: Loss = 0.015194541774690151
Iteration 3494: Loss = 0.015192673541605473
Iteration 3495: Loss = 0.015190817415714264
Iteration 3496: Loss = 0.015188965946435928
Iteration 3497: Loss = 0.015187103301286697
Iteration 3498: Loss = 0.015185264870524406
Iteration 3499: Loss = 0.015183414332568645
Iteration 3500: Loss = 0.015181570313870907
Iteration 3501: Loss = 0.015179736539721489
Iteration 3502: Loss = 0.015177900902926922
Iteration 3503: Loss = 0.0151760783046484
Iteration 3504: Loss = 0.01517423614859581
Iteration 3505: Loss = 0.015172416344285011
Iteration 3506: Loss = 0.015170595608651638
Iteration 3507: Loss = 0.015168767422437668
Iteration 3508: Loss = 0.015166952274739742
Iteration 3509: Loss = 0.015165143646299839
Iteration 3510: Loss = 0.01516333594918251
Iteration 3511: Loss = 0.015161532908678055
Iteration 3512: Loss = 0.01515972800552845
Iteration 3513: Loss = 0.015157938934862614
Iteration 3514: Loss = 0.015156116336584091
Iteration 3515: Loss = 0.015154311433434486
Iteration 3516: Loss = 0.015152504667639732
Iteration 3517: Loss = 0.015150720253586769
Iteration 3518: Loss = 0.015148953534662724
Iteration 3519: Loss = 0.015147197991609573
Iteration 3520: Loss = 0.015145458281040192
Iteration 3521: Loss = 0.015143774449825287
Iteration 3522: Loss = 0.015142136253416538
Iteration 3523: Loss = 0.015140603296458721
Iteration 3524: Loss = 0.015139196999371052
Iteration 3525: Loss = 0.015138007700443268
Iteration 3526: Loss = 0.01513716857880354
Iteration 3527: Loss = 0.01513686589896679
Iteration 3528: Loss = 0.015137441456317902
Iteration 3529: Loss = 0.015139365568757057
Iteration 3530: Loss = 0.015143431723117828
Iteration 3531: Loss = 0.015150743536651134
Iteration 3532: Loss = 0.015163836069405079
Iteration 3533: Loss = 0.015183968469500542
Iteration 3534: Loss = 0.015212890692055225
Iteration 3535: Loss = 0.015244041569530964
Iteration 3536: Loss = 0.015270897187292576
Iteration 3537: Loss = 0.015272877179086208
Iteration 3538: Loss = 0.015241050161421299
Iteration 3539: Loss = 0.015180728398263454
Iteration 3540: Loss = 0.0151274548843503
Iteration 3541: Loss = 0.015108692459762096
Iteration 3542: Loss = 0.015126068145036697
Iteration 3543: Loss = 0.015156012028455734
Iteration 3544: Loss = 0.015170060098171234
Iteration 3545: Loss = 0.0151562774553895
Iteration 3546: Loss = 0.015124994330108166
Iteration 3547: Loss = 0.015101369470357895
Iteration 3548: Loss = 0.015100507996976376
Iteration 3549: Loss = 0.01511544082313776
Iteration 3550: Loss = 0.01512701902538538
Iteration 3551: Loss = 0.015122535638511181
Iteration 3552: Loss = 0.01510634459555149
Iteration 3553: Loss = 0.015091584995388985
Iteration 3554: Loss = 0.01508869044482708
Iteration 3555: Loss = 0.015095463022589684
Iteration 3556: Loss = 0.015101493336260319
Iteration 3557: Loss = 0.015099669806659222
Iteration 3558: Loss = 0.015090394765138626
Iteration 3559: Loss = 0.01508133951574564
Iteration 3560: Loss = 0.015078612603247166
Iteration 3561: Loss = 0.015081466175615788
Iteration 3562: Loss = 0.015084288083016872
Iteration 3563: Loss = 0.01508259680122137
Iteration 3564: Loss = 0.015077244490385056
Iteration 3565: Loss = 0.015071545727550983
Iteration 3566: Loss = 0.015068931505084038
Iteration 3567: Loss = 0.01506943628191948
Iteration 3568: Loss = 0.015070369467139244
Iteration 3569: Loss = 0.015069538727402687
Iteration 3570: Loss = 0.015066241845488548
Iteration 3571: Loss = 0.015062387101352215
Iteration 3572: Loss = 0.015059622935950756
Iteration 3573: Loss = 0.015058613382279873
Iteration 3574: Loss = 0.015058447606861591
Iteration 3575: Loss = 0.015057684853672981
Iteration 3576: Loss = 0.015055883675813675
Iteration 3577: Loss = 0.015053215436637402
Iteration 3578: Loss = 0.015050659887492657
Iteration 3579: Loss = 0.015048978850245476
Iteration 3580: Loss = 0.015048051252961159
Iteration 3581: Loss = 0.015047210268676281
Iteration 3582: Loss = 0.015045836567878723
Iteration 3583: Loss = 0.015043945051729679
Iteration 3584: Loss = 0.015041782520711422
Iteration 3585: Loss = 0.015039811842143536
Iteration 3586: Loss = 0.01503816619515419
Iteration 3587: Loss = 0.01503682043403387
Iteration 3588: Loss = 0.015035610646009445
Iteration 3589: Loss = 0.01503426767885685
Iteration 3590: Loss = 0.01503269374370575
Iteration 3591: Loss = 0.015030882321298122
Iteration 3592: Loss = 0.01502904575318098
Iteration 3593: Loss = 0.015027297660708427
Iteration 3594: Loss = 0.015025719068944454
Iteration 3595: Loss = 0.015024290420114994
Iteration 3596: Loss = 0.015022896230220795
Iteration 3597: Loss = 0.015021469444036484
Iteration 3598: Loss = 0.015019928105175495
Iteration 3599: Loss = 0.01501830667257309
Iteration 3600: Loss = 0.015016627497971058
Iteration 3601: Loss = 0.015014969743788242
Iteration 3602: Loss = 0.015013362281024456
Iteration 3603: Loss = 0.015011802315711975
Iteration 3604: Loss = 0.015010281465947628
Iteration 3605: Loss = 0.015008771792054176
Iteration 3606: Loss = 0.015007270500063896
Iteration 3607: Loss = 0.015005801804363728
Iteration 3608: Loss = 0.015004327520728111
Iteration 3609: Loss = 0.015002841129899025
Iteration 3610: Loss = 0.015001313760876656
Iteration 3611: Loss = 0.014999796636402607
Iteration 3612: Loss = 0.014998222701251507
Iteration 3613: Loss = 0.014996692538261414
Iteration 3614: Loss = 0.014995137229561806
Iteration 3615: Loss = 0.014993593096733093
Iteration 3616: Loss = 0.01499205268919468
Iteration 3617: Loss = 0.014990562573075294
Iteration 3618: Loss = 0.01498908270150423
Iteration 3619: Loss = 0.014987613074481487
Iteration 3620: Loss = 0.014986173249781132
Iteration 3621: Loss = 0.01498473435640335
Iteration 3622: Loss = 0.014983291737735271
Iteration 3623: Loss = 0.014981839805841446
Iteration 3624: Loss = 0.014980368316173553
Iteration 3625: Loss = 0.014978880994021893
Iteration 3626: Loss = 0.014977372251451015
Iteration 3627: Loss = 0.014975883066654205
Iteration 3628: Loss = 0.014974359422922134
Iteration 3629: Loss = 0.014972859993577003
Iteration 3630: Loss = 0.014971382915973663
Iteration 3631: Loss = 0.01496989093720913
Iteration 3632: Loss = 0.014968397095799446
Iteration 3633: Loss = 0.014966907911002636
Iteration 3634: Loss = 0.014965428970754147
Iteration 3635: Loss = 0.014963964000344276
Iteration 3636: Loss = 0.014962531626224518
Iteration 3637: Loss = 0.014961098320782185
Iteration 3638: Loss = 0.01495965477079153
Iteration 3639: Loss = 0.014958265237510204
Iteration 3640: Loss = 0.014956875704228878
Iteration 3641: Loss = 0.014955520629882812
Iteration 3642: Loss = 0.014954165555536747
Iteration 3643: Loss = 0.014952835626900196
Iteration 3644: Loss = 0.014951471239328384
Iteration 3645: Loss = 0.01495012454688549
Iteration 3646: Loss = 0.01494873221963644
Iteration 3647: Loss = 0.01494737807661295
Iteration 3648: Loss = 0.014945946633815765
Iteration 3649: Loss = 0.014944436959922314
Iteration 3650: Loss = 0.01494288258254528
Iteration 3651: Loss = 0.014941317029297352
Iteration 3652: Loss = 0.014939789660274982
Iteration 3653: Loss = 0.01493826787918806
Iteration 3654: Loss = 0.014936809428036213
Iteration 3655: Loss = 0.014935377053916454
Iteration 3656: Loss = 0.014934000559151173
Iteration 3657: Loss = 0.014932641759514809
Iteration 3658: Loss = 0.01493129227310419
Iteration 3659: Loss = 0.014929933473467827
Iteration 3660: Loss = 0.014928575605154037
Iteration 3661: Loss = 0.014927204698324203
Iteration 3662: Loss = 0.014925825409591198
Iteration 3663: Loss = 0.014924434944987297
Iteration 3664: Loss = 0.014923101291060448
Iteration 3665: Loss = 0.014921766705811024
Iteration 3666: Loss = 0.014920542947947979
Iteration 3667: Loss = 0.01491930615156889
Iteration 3668: Loss = 0.014918209984898567
Iteration 3669: Loss = 0.014917089603841305
Iteration 3670: Loss = 0.014915961772203445
Iteration 3671: Loss = 0.014914793893694878
Iteration 3672: Loss = 0.014913615770637989
Iteration 3673: Loss = 0.014912406913936138
Iteration 3674: Loss = 0.01491119246929884
Iteration 3675: Loss = 0.014909961260855198
Iteration 3676: Loss = 0.014908750541508198
Iteration 3677: Loss = 0.014907524921000004
Iteration 3678: Loss = 0.014906631782650948
Iteration 3679: Loss = 0.014905771240592003
Iteration 3680: Loss = 0.014905290678143501
Iteration 3681: Loss = 0.014904959127306938
Iteration 3682: Loss = 0.014905128628015518
Iteration 3683: Loss = 0.014905532822012901
Iteration 3684: Loss = 0.014906623400747776
Iteration 3685: Loss = 0.014908067882061005
Iteration 3686: Loss = 0.01491034496575594
Iteration 3687: Loss = 0.014912985265254974
Iteration 3688: Loss = 0.014916309155523777
Iteration 3689: Loss = 0.014919550158083439
Iteration 3690: Loss = 0.01492268219590187
Iteration 3691: Loss = 0.01492445170879364
Iteration 3692: Loss = 0.014924556948244572
Iteration 3693: Loss = 0.014921719208359718
Iteration 3694: Loss = 0.014916233718395233
Iteration 3695: Loss = 0.014907995238900185
Iteration 3696: Loss = 0.014898735098540783
Iteration 3697: Loss = 0.014889446087181568
Iteration 3698: Loss = 0.014881771989166737
Iteration 3699: Loss = 0.014876853674650192
Iteration 3700: Loss = 0.014874844811856747
Iteration 3701: Loss = 0.014875167980790138
Iteration 3702: Loss = 0.014876770786941051
Iteration 3703: Loss = 0.014878515154123306
Iteration 3704: Loss = 0.014879497699439526
Iteration 3705: Loss = 0.014879156835377216
Iteration 3706: Loss = 0.014877376146614552
Iteration 3707: Loss = 0.014874414540827274
Iteration 3708: Loss = 0.014870773069560528
Iteration 3709: Loss = 0.01486707292497158
Iteration 3710: Loss = 0.014863843098282814
Iteration 3711: Loss = 0.014861367642879486
Iteration 3712: Loss = 0.014859745278954506
Iteration 3713: Loss = 0.014858799055218697
Iteration 3714: Loss = 0.014858311042189598
Iteration 3715: Loss = 0.01485797856003046
Iteration 3716: Loss = 0.014857543632388115
Iteration 3717: Loss = 0.014856849797070026
Iteration 3718: Loss = 0.014855817891657352
Iteration 3719: Loss = 0.014854435808956623
Iteration 3720: Loss = 0.014852792955935001
Iteration 3721: Loss = 0.014850977808237076
Iteration 3722: Loss = 0.014849123544991016
Iteration 3723: Loss = 0.01484731212258339
Iteration 3724: Loss = 0.01484561525285244
Iteration 3725: Loss = 0.014844062738120556
Iteration 3726: Loss = 0.014842664822936058
Iteration 3727: Loss = 0.014841402880847454
Iteration 3728: Loss = 0.014840262942016125
Iteration 3729: Loss = 0.014839177951216698
Iteration 3730: Loss = 0.014838150702416897
Iteration 3731: Loss = 0.01483713649213314
Iteration 3732: Loss = 0.014836091548204422
Iteration 3733: Loss = 0.014835041016340256
Iteration 3734: Loss = 0.014833957888185978
Iteration 3735: Loss = 0.01483282819390297
Iteration 3736: Loss = 0.014831668697297573
Iteration 3737: Loss = 0.014830492436885834
Iteration 3738: Loss = 0.014829291962087154
Iteration 3739: Loss = 0.014828095212578773
Iteration 3740: Loss = 0.014826898463070393
Iteration 3741: Loss = 0.014825697056949139
Iteration 3742: Loss = 0.014824503101408482
Iteration 3743: Loss = 0.014823324978351593
Iteration 3744: Loss = 0.014822159893810749
Iteration 3745: Loss = 0.014821028336882591
Iteration 3746: Loss = 0.014819908887147903
Iteration 3747: Loss = 0.014818844385445118
Iteration 3748: Loss = 0.014817829243838787
Iteration 3749: Loss = 0.014816852286458015
Iteration 3750: Loss = 0.014815964736044407
Iteration 3751: Loss = 0.014815159142017365
Iteration 3752: Loss = 0.014814477413892746
Iteration 3753: Loss = 0.01481397170573473
Iteration 3754: Loss = 0.014813664369285107
Iteration 3755: Loss = 0.014813647605478764
Iteration 3756: Loss = 0.014814005233347416
Iteration 3757: Loss = 0.014814842492341995
Iteration 3758: Loss = 0.014816273003816605
Iteration 3759: Loss = 0.014819121919572353
Iteration 3760: Loss = 0.014823032543063164
Iteration 3761: Loss = 0.014828821644186974
Iteration 3762: Loss = 0.0148359015583992
Iteration 3763: Loss = 0.01484457217156887
Iteration 3764: Loss = 0.014853128232061863
Iteration 3765: Loss = 0.014860362745821476
Iteration 3766: Loss = 0.014862895011901855
Iteration 3767: Loss = 0.014858771115541458
Iteration 3768: Loss = 0.0148465596139431
Iteration 3769: Loss = 0.014828934334218502
Iteration 3770: Loss = 0.014810002408921719
Iteration 3771: Loss = 0.014795337803661823
Iteration 3772: Loss = 0.014788498170673847
Iteration 3773: Loss = 0.014789475128054619
Iteration 3774: Loss = 0.014795332215726376
Iteration 3775: Loss = 0.014801915735006332
Iteration 3776: Loss = 0.01480557955801487
Iteration 3777: Loss = 0.014804461970925331
Iteration 3778: Loss = 0.0147988460958004
Iteration 3779: Loss = 0.014790941961109638
Iteration 3780: Loss = 0.014783569611608982
Iteration 3781: Loss = 0.014778959564864635
Iteration 3782: Loss = 0.014777769334614277
Iteration 3783: Loss = 0.01477909181267023
Iteration 3784: Loss = 0.01478126086294651
Iteration 3785: Loss = 0.014782562851905823
Iteration 3786: Loss = 0.014782031066715717
Iteration 3787: Loss = 0.014779589138925076
Iteration 3788: Loss = 0.014775949530303478
Iteration 3789: Loss = 0.014772244729101658
Iteration 3790: Loss = 0.014769385568797588
Iteration 3791: Loss = 0.014767777174711227
Iteration 3792: Loss = 0.014767293818295002
Iteration 3793: Loss = 0.014767423272132874
Iteration 3794: Loss = 0.014767507091164589
Iteration 3795: Loss = 0.014767097309231758
Iteration 3796: Loss = 0.014765986241400242
Iteration 3797: Loss = 0.01476424839347601
Iteration 3798: Loss = 0.014762231148779392
Iteration 3799: Loss = 0.014760241843760014
Iteration 3800: Loss = 0.014758548699319363
Iteration 3801: Loss = 0.014757250435650349
Iteration 3802: Loss = 0.014756335876882076
Iteration 3803: Loss = 0.014755668118596077
Iteration 3804: Loss = 0.014755035750567913
Iteration 3805: Loss = 0.014754321426153183
Iteration 3806: Loss = 0.01475343108177185
Iteration 3807: Loss = 0.014752324670553207
Iteration 3808: Loss = 0.01475105807185173
Iteration 3809: Loss = 0.01474971417337656
Iteration 3810: Loss = 0.014748375862836838
Iteration 3811: Loss = 0.014747102744877338
Iteration 3812: Loss = 0.014745940454304218
Iteration 3813: Loss = 0.014744878746569157
Iteration 3814: Loss = 0.014743899926543236
Iteration 3815: Loss = 0.014742976985871792
Iteration 3816: Loss = 0.014742068946361542
Iteration 3817: Loss = 0.014741167426109314
Iteration 3818: Loss = 0.014740221202373505
Iteration 3819: Loss = 0.014739238657057285
Iteration 3820: Loss = 0.01473822258412838
Iteration 3821: Loss = 0.014737166464328766
Iteration 3822: Loss = 0.014736105687916279
Iteration 3823: Loss = 0.014735030941665173
Iteration 3824: Loss = 0.01473393477499485
Iteration 3825: Loss = 0.01473282277584076
Iteration 3826: Loss = 0.01473171729594469
Iteration 3827: Loss = 0.0147306052967906
Iteration 3828: Loss = 0.014729526825249195
Iteration 3829: Loss = 0.01472843624651432
Iteration 3830: Loss = 0.014727364294230938
Iteration 3831: Loss = 0.014726283960044384
Iteration 3832: Loss = 0.014725208282470703
Iteration 3833: Loss = 0.014724158681929111
Iteration 3834: Loss = 0.014723098836839199
Iteration 3835: Loss = 0.01472201757133007
Iteration 3836: Loss = 0.014720967970788479
Iteration 3837: Loss = 0.01471991278231144
Iteration 3838: Loss = 0.014718860387802124
Iteration 3839: Loss = 0.014717803336679935
Iteration 3840: Loss = 0.014716750010848045
Iteration 3841: Loss = 0.014715700410306454
Iteration 3842: Loss = 0.014714652672410011
Iteration 3843: Loss = 0.014713611453771591
Iteration 3844: Loss = 0.014712578617036343
Iteration 3845: Loss = 0.014711554162204266
Iteration 3846: Loss = 0.014710542745888233
Iteration 3847: Loss = 0.014709518291056156
Iteration 3848: Loss = 0.014708553440868855
Iteration 3849: Loss = 0.01470760628581047
Iteration 3850: Loss = 0.014706693589687347
Iteration 3851: Loss = 0.014705824665725231
Iteration 3852: Loss = 0.014705035835504532
Iteration 3853: Loss = 0.014704336412250996
Iteration 3854: Loss = 0.014703779481351376
Iteration 3855: Loss = 0.014703434891998768
Iteration 3856: Loss = 0.014703376218676567
Iteration 3857: Loss = 0.01470373198390007
Iteration 3858: Loss = 0.01470470242202282
Iteration 3859: Loss = 0.014706541784107685
Iteration 3860: Loss = 0.014709601178765297
Iteration 3861: Loss = 0.014714259654283524
Iteration 3862: Loss = 0.014721168205142021
Iteration 3863: Loss = 0.01473172102123499
Iteration 3864: Loss = 0.014745592139661312
Iteration 3865: Loss = 0.01476301345974207
Iteration 3866: Loss = 0.01478064525872469
Iteration 3867: Loss = 0.014791551046073437
Iteration 3868: Loss = 0.014790771529078484
Iteration 3869: Loss = 0.014772497117519379
Iteration 3870: Loss = 0.014741763472557068
Iteration 3871: Loss = 0.014709974639117718
Iteration 3872: Loss = 0.014688354916870594
Iteration 3873: Loss = 0.014683404937386513
Iteration 3874: Loss = 0.014692487195134163
Iteration 3875: Loss = 0.014706607908010483
Iteration 3876: Loss = 0.01471595000475645
Iteration 3877: Loss = 0.014714688993990421
Iteration 3878: Loss = 0.014703543856739998
Iteration 3879: Loss = 0.014688828960061073
Iteration 3880: Loss = 0.014678195118904114
Iteration 3881: Loss = 0.014675700105726719
Iteration 3882: Loss = 0.014680027030408382
Iteration 3883: Loss = 0.01468623522669077
Iteration 3884: Loss = 0.01468923781067133
Iteration 3885: Loss = 0.014686801470816135
Iteration 3886: Loss = 0.014680271036922932
Iteration 3887: Loss = 0.014673260971903801
Iteration 3888: Loss = 0.014669019728899002
Iteration 3889: Loss = 0.014668635092675686
Iteration 3890: Loss = 0.01467075850814581
Iteration 3891: Loss = 0.014672882854938507
Iteration 3892: Loss = 0.014673065394163132
Iteration 3893: Loss = 0.014670739881694317
Iteration 3894: Loss = 0.014667026698589325
Iteration 3895: Loss = 0.01466356310993433
Iteration 3896: Loss = 0.014661524444818497
Iteration 3897: Loss = 0.014661120250821114
Iteration 3898: Loss = 0.014661633409559727
Iteration 3899: Loss = 0.014662010595202446
Iteration 3900: Loss = 0.014661506749689579
Iteration 3901: Loss = 0.014659994281828403
Iteration 3902: Loss = 0.01465789508074522
Iteration 3903: Loss = 0.014655846171081066
Iteration 3904: Loss = 0.014654370956122875
Iteration 3905: Loss = 0.014653568156063557
Iteration 3906: Loss = 0.014653226360678673
Iteration 3907: Loss = 0.01465293113142252
Iteration 3908: Loss = 0.014652363024652004
Iteration 3909: Loss = 0.014651380479335785
Iteration 3910: Loss = 0.014650098979473114
Iteration 3911: Loss = 0.014648700132966042
Iteration 3912: Loss = 0.014647429808974266
Iteration 3913: Loss = 0.014646390452980995
Iteration 3914: Loss = 0.014645620249211788
Iteration 3915: Loss = 0.014644979499280453
Iteration 3916: Loss = 0.014644335024058819
Iteration 3917: Loss = 0.014643594622612
Iteration 3918: Loss = 0.014642700552940369
Iteration 3919: Loss = 0.014641696587204933
Iteration 3920: Loss = 0.014640627428889275
Iteration 3921: Loss = 0.014639604836702347
Iteration 3922: Loss = 0.014638635329902172
Iteration 3923: Loss = 0.014637763611972332
Iteration 3924: Loss = 0.014636958949267864
Iteration 3925: Loss = 0.014636192470788956
Iteration 3926: Loss = 0.014635417610406876
Iteration 3927: Loss = 0.01463460735976696
Iteration 3928: Loss = 0.01463375985622406
Iteration 3929: Loss = 0.0146328741684556
Iteration 3930: Loss = 0.014631958678364754
Iteration 3931: Loss = 0.014631054364144802
Iteration 3932: Loss = 0.014630161225795746
Iteration 3933: Loss = 0.014629284851253033
Iteration 3934: Loss = 0.014628443866968155
Iteration 3935: Loss = 0.014627636410295963
Iteration 3936: Loss = 0.014626804739236832
Iteration 3937: Loss = 0.014626001939177513
Iteration 3938: Loss = 0.014625179581344128
Iteration 3939: Loss = 0.014624366536736488
Iteration 3940: Loss = 0.014623528346419334
Iteration 3941: Loss = 0.014622699469327927
Iteration 3942: Loss = 0.014621851965785027
Iteration 3943: Loss = 0.014621015638113022
Iteration 3944: Loss = 0.014620175585150719
Iteration 3945: Loss = 0.014619339257478714
Iteration 3946: Loss = 0.014618503861129284
Iteration 3947: Loss = 0.014617687091231346
Iteration 3948: Loss = 0.014616861008107662
Iteration 3949: Loss = 0.014616057276725769
Iteration 3950: Loss = 0.014615245163440704
Iteration 3951: Loss = 0.014614435844123363
Iteration 3952: Loss = 0.014613629318773746
Iteration 3953: Loss = 0.014612828381359577
Iteration 3954: Loss = 0.014612018130719662
Iteration 3955: Loss = 0.014611219055950642
Iteration 3956: Loss = 0.014610418118536472
Iteration 3957: Loss = 0.014609615318477154
Iteration 3958: Loss = 0.014608819968998432
Iteration 3959: Loss = 0.014608019031584263
Iteration 3960: Loss = 0.014607214368879795
Iteration 3961: Loss = 0.0146064143627882
Iteration 3962: Loss = 0.014605626463890076
Iteration 3963: Loss = 0.014604823663830757
Iteration 3964: Loss = 0.014604042284190655
Iteration 3965: Loss = 0.014603250660002232
Iteration 3966: Loss = 0.014602463692426682
Iteration 3967: Loss = 0.014601674862205982
Iteration 3968: Loss = 0.014600894413888454
Iteration 3969: Loss = 0.014600111171603203
Iteration 3970: Loss = 0.014599335379898548
Iteration 3971: Loss = 0.014598551206290722
Iteration 3972: Loss = 0.014597784727811813
Iteration 3973: Loss = 0.014597008004784584
Iteration 3974: Loss = 0.014596247114241123
Iteration 3975: Loss = 0.014595483429729939
Iteration 3976: Loss = 0.014594740234315395
Iteration 3977: Loss = 0.014593998901546001
Iteration 3978: Loss = 0.014593280851840973
Iteration 3979: Loss = 0.014592557214200497
Iteration 3980: Loss = 0.014591892249882221
Iteration 3981: Loss = 0.014591239392757416
Iteration 3982: Loss = 0.014590653590857983
Iteration 3983: Loss = 0.014590136706829071
Iteration 3984: Loss = 0.014589743688702583
Iteration 3985: Loss = 0.014589514583349228
Iteration 3986: Loss = 0.014589554630219936
Iteration 3987: Loss = 0.01458999514579773
Iteration 3988: Loss = 0.014591031707823277
Iteration 3989: Loss = 0.014592966064810753
Iteration 3990: Loss = 0.014596262015402317
Iteration 3991: Loss = 0.014601565897464752
Iteration 3992: Loss = 0.014609718695282936
Iteration 3993: Loss = 0.014621204696595669
Iteration 3994: Loss = 0.014637208543717861
Iteration 3995: Loss = 0.014657242223620415
Iteration 3996: Loss = 0.01467668917030096
Iteration 3997: Loss = 0.01469232328236103
Iteration 3998: Loss = 0.014693861827254295
Iteration 3999: Loss = 0.014676336199045181
Iteration 4000: Loss = 0.014641428366303444
Iteration 4001: Loss = 0.014603746123611927
Iteration 4002: Loss = 0.014579498209059238
Iteration 4003: Loss = 0.014576001092791557
Iteration 4004: Loss = 0.014588993974030018
Iteration 4005: Loss = 0.014606521464884281
Iteration 4006: Loss = 0.014616941101849079
Iteration 4007: Loss = 0.014613376930356026
Iteration 4008: Loss = 0.014598564244806767
Iteration 4009: Loss = 0.014581249095499516
Iteration 4010: Loss = 0.014570695348083973
Iteration 4011: Loss = 0.01457052119076252
Iteration 4012: Loss = 0.014577577821910381
Iteration 4013: Loss = 0.01458506565541029
Iteration 4014: Loss = 0.01458725892007351
Iteration 4015: Loss = 0.014582699164748192
Iteration 4016: Loss = 0.014574341475963593
Iteration 4017: Loss = 0.014567065984010696
Iteration 4018: Loss = 0.014564222656190395
Iteration 4019: Loss = 0.014565866440534592
Iteration 4020: Loss = 0.014569168910384178
Iteration 4021: Loss = 0.014571030624210835
Iteration 4022: Loss = 0.014569864608347416
Iteration 4023: Loss = 0.014566193334758282
Iteration 4024: Loss = 0.014561973512172699
Iteration 4025: Loss = 0.014559118077158928
Iteration 4026: Loss = 0.014558400958776474
Iteration 4027: Loss = 0.014559173956513405
Iteration 4028: Loss = 0.014560115523636341
Iteration 4029: Loss = 0.014560047537088394
Iteration 4030: Loss = 0.014558623544871807
Iteration 4031: Loss = 0.014556326903402805
Iteration 4032: Loss = 0.014554038643836975
Iteration 4033: Loss = 0.01455248985439539
Iteration 4034: Loss = 0.014551836997270584
Iteration 4035: Loss = 0.014551755972206593
Iteration 4036: Loss = 0.014551704749464989
Iteration 4037: Loss = 0.014551205560564995
Iteration 4038: Loss = 0.014550140127539635
Iteration 4039: Loss = 0.0145487105473876
Iteration 4040: Loss = 0.014547254890203476
Iteration 4041: Loss = 0.014546052552759647
Iteration 4042: Loss = 0.014545217156410217
Iteration 4043: Loss = 0.01454467698931694
Iteration 4044: Loss = 0.014544199220836163
Iteration 4045: Loss = 0.014543630182743073
Iteration 4046: Loss = 0.014542857185006142
Iteration 4047: Loss = 0.014541893266141415
Iteration 4048: Loss = 0.014540835283696651
Iteration 4049: Loss = 0.014539800584316254
Iteration 4050: Loss = 0.014538870193064213
Iteration 4051: Loss = 0.014538087882101536
Iteration 4052: Loss = 0.014537389390170574
Iteration 4053: Loss = 0.014536747708916664
Iteration 4054: Loss = 0.014536060392856598
Iteration 4055: Loss = 0.014535311609506607
Iteration 4056: Loss = 0.014534500427544117
Iteration 4057: Loss = 0.014533638022840023
Iteration 4058: Loss = 0.014532770961523056
Iteration 4059: Loss = 0.014531916007399559
Iteration 4060: Loss = 0.014531106688082218
Iteration 4061: Loss = 0.014530343003571033
Iteration 4062: Loss = 0.014529608190059662
Iteration 4063: Loss = 0.014528902247548103
Iteration 4064: Loss = 0.014528175815939903
Iteration 4065: Loss = 0.014527437277138233
Iteration 4066: Loss = 0.014526674523949623
Iteration 4067: Loss = 0.014525900594890118
Iteration 4068: Loss = 0.014525116421282291
Iteration 4069: Loss = 0.014524335972964764
Iteration 4070: Loss = 0.014523555524647236
Iteration 4071: Loss = 0.0145227937027812
Iteration 4072: Loss = 0.01452204491943121
Iteration 4073: Loss = 0.014521308243274689
Iteration 4074: Loss = 0.014520581811666489
Iteration 4075: Loss = 0.014519849792122841
Iteration 4076: Loss = 0.014519114047288895
Iteration 4077: Loss = 0.01451838482171297
Iteration 4078: Loss = 0.014517657458782196
Iteration 4079: Loss = 0.014516917988657951
Iteration 4080: Loss = 0.014516178518533707
Iteration 4081: Loss = 0.014515441842377186
Iteration 4082: Loss = 0.014514713548123837
Iteration 4083: Loss = 0.014513975009322166
Iteration 4084: Loss = 0.014513242989778519
Iteration 4085: Loss = 0.014512518420815468
Iteration 4086: Loss = 0.014511793851852417
Iteration 4087: Loss = 0.014511073008179665
Iteration 4088: Loss = 0.014510348439216614
Iteration 4089: Loss = 0.014509632252156734
Iteration 4090: Loss = 0.014508913271129131
Iteration 4091: Loss = 0.014508206397294998
Iteration 4092: Loss = 0.014507492072880268
Iteration 4093: Loss = 0.014506782405078411
Iteration 4094: Loss = 0.014506070874631405
Iteration 4095: Loss = 0.014505361206829548
Iteration 4096: Loss = 0.014504660852253437
Iteration 4097: Loss = 0.014503948390483856
Iteration 4098: Loss = 0.014503255486488342
Iteration 4099: Loss = 0.014502551406621933
Iteration 4100: Loss = 0.014501864090561867
Iteration 4101: Loss = 0.01450107991695404
Iteration 4102: Loss = 0.014500259421765804
Iteration 4103: Loss = 0.014499446377158165
Iteration 4104: Loss = 0.014498613774776459
Iteration 4105: Loss = 0.014497769996523857
Iteration 4106: Loss = 0.01449691690504551
Iteration 4107: Loss = 0.014496059156954288
Iteration 4108: Loss = 0.014495198614895344
Iteration 4109: Loss = 0.014494335278868675
Iteration 4110: Loss = 0.014493469148874283
Iteration 4111: Loss = 0.014492585323750973
Iteration 4112: Loss = 0.014491726644337177
Iteration 4113: Loss = 0.014490845613181591
Iteration 4114: Loss = 0.014489969238638878
Iteration 4115: Loss = 0.014489106833934784
Iteration 4116: Loss = 0.014488241635262966
Iteration 4117: Loss = 0.014487365260720253
Iteration 4118: Loss = 0.014486501924693584
Iteration 4119: Loss = 0.014485630206763744
Iteration 4120: Loss = 0.014484764076769352
Iteration 4121: Loss = 0.01448391005396843
Iteration 4122: Loss = 0.014483051374554634
Iteration 4123: Loss = 0.014482215978205204
Iteration 4124: Loss = 0.014481382444500923
Iteration 4125: Loss = 0.014480551704764366
Iteration 4126: Loss = 0.01447975728660822
Iteration 4127: Loss = 0.014478995464742184
Iteration 4128: Loss = 0.014478284865617752
Iteration 4129: Loss = 0.014477667398750782
Iteration 4130: Loss = 0.01447721105068922
Iteration 4131: Loss = 0.01447699312120676
Iteration 4132: Loss = 0.014477180317044258
Iteration 4133: Loss = 0.01447806041687727
Iteration 4134: Loss = 0.014480111189186573
Iteration 4135: Loss = 0.014484112150967121
Iteration 4136: Loss = 0.014491341076791286
Iteration 4137: Loss = 0.014503822661936283
Iteration 4138: Loss = 0.014524336904287338
Iteration 4139: Loss = 0.014555334113538265
Iteration 4140: Loss = 0.014598763547837734
Iteration 4141: Loss = 0.014648715034127235
Iteration 4142: Loss = 0.014685191214084625
Iteration 4143: Loss = 0.01467664260417223
Iteration 4144: Loss = 0.014610284008085728
Iteration 4145: Loss = 0.014520163647830486
Iteration 4146: Loss = 0.014466558583080769
Iteration 4147: Loss = 0.014477891847491264
Iteration 4148: Loss = 0.014524243772029877
Iteration 4149: Loss = 0.014556732028722763
Iteration 4150: Loss = 0.014542392455041409
Iteration 4151: Loss = 0.014496424235403538
Iteration 4152: Loss = 0.014461595565080643
Iteration 4153: Loss = 0.01446910947561264
Iteration 4154: Loss = 0.014499727636575699
Iteration 4155: Loss = 0.014512719586491585
Iteration 4156: Loss = 0.014496752992272377
Iteration 4157: Loss = 0.014467624947428703
Iteration 4158: Loss = 0.014455659314990044
Iteration 4159: Loss = 0.014468725770711899
Iteration 4160: Loss = 0.014485926367342472
Iteration 4161: Loss = 0.014484205283224583
Iteration 4162: Loss = 0.014466630294919014
Iteration 4163: Loss = 0.014452701434493065
Iteration 4164: Loss = 0.014454728923738003
Iteration 4165: Loss = 0.014465454034507275
Iteration 4166: Loss = 0.01447011437267065
Iteration 4167: Loss = 0.014461243525147438
Iteration 4168: Loss = 0.014450200833380222
Iteration 4169: Loss = 0.014448113739490509
Iteration 4170: Loss = 0.014453379437327385
Iteration 4171: Loss = 0.014457846991717815
Iteration 4172: Loss = 0.014454978518188
Iteration 4173: Loss = 0.014448651112616062
Iteration 4174: Loss = 0.014444011263549328
Iteration 4175: Loss = 0.01444513350725174
Iteration 4176: Loss = 0.014448150061070919
Iteration 4177: Loss = 0.014447915367782116
Iteration 4178: Loss = 0.014444599859416485
Iteration 4179: Loss = 0.01444180216640234
Iteration 4180: Loss = 0.01444148737937212
Iteration 4181: Loss = 0.014441565610468388
Iteration 4182: Loss = 0.014442182146012783
Iteration 4183: Loss = 0.014441186562180519
Iteration 4184: Loss = 0.014438414014875889
Iteration 4185: Loss = 0.014436857774853706
Iteration 4186: Loss = 0.014437643811106682
Iteration 4187: Loss = 0.01443824078887701
Iteration 4188: Loss = 0.014437052421271801
Iteration 4189: Loss = 0.014435628429055214
Iteration 4190: Loss = 0.014434377662837505
Iteration 4191: Loss = 0.014433515258133411
Iteration 4192: Loss = 0.01443355530500412
Iteration 4193: Loss = 0.014434006996452808
Iteration 4194: Loss = 0.014433528296649456
Iteration 4195: Loss = 0.014431159943342209
Iteration 4196: Loss = 0.014430240727961063
Iteration 4197: Loss = 0.014430318027734756
Iteration 4198: Loss = 0.01443011686205864
Iteration 4199: Loss = 0.014429653063416481
Iteration 4200: Loss = 0.014429464004933834
Iteration 4201: Loss = 0.014428344555199146
Iteration 4202: Loss = 0.0144261559471488
Iteration 4203: Loss = 0.014426033943891525
Iteration 4204: Loss = 0.014426507987082005
Iteration 4205: Loss = 0.014426111243665218
Iteration 4206: Loss = 0.014425109140574932
Iteration 4207: Loss = 0.014424546621739864
Iteration 4208: Loss = 0.014423472806811333
Iteration 4209: Loss = 0.01442175917327404
Iteration 4210: Loss = 0.014421968720853329
Iteration 4211: Loss = 0.014422385022044182
Iteration 4212: Loss = 0.014421846717596054
Iteration 4213: Loss = 0.014420629478991032
Iteration 4214: Loss = 0.014420023187994957
Iteration 4215: Loss = 0.014419198036193848
Iteration 4216: Loss = 0.014417543075978756
Iteration 4217: Loss = 0.014417859725654125
Iteration 4218: Loss = 0.014418217353522778
Iteration 4219: Loss = 0.014417585916817188
Iteration 4220: Loss = 0.01441631093621254
Iteration 4221: Loss = 0.014415893703699112
Iteration 4222: Loss = 0.014415067620575428
Iteration 4223: Loss = 0.01441342756152153
Iteration 4224: Loss = 0.014413692057132721
Iteration 4225: Loss = 0.014412689954042435
Iteration 4226: Loss = 0.014412371441721916
Iteration 4227: Loss = 0.014412043616175652
Iteration 4228: Loss = 0.014410732313990593
Iteration 4229: Loss = 0.014410399831831455
Iteration 4230: Loss = 0.014409434050321579
Iteration 4231: Loss = 0.0144088389351964
Iteration 4232: Loss = 0.014408598653972149
Iteration 4233: Loss = 0.014407739974558353
Iteration 4234: Loss = 0.014407387934625149
Iteration 4235: Loss = 0.014406617730855942
Iteration 4236: Loss = 0.01440585870295763
Iteration 4237: Loss = 0.014405397698283195
Iteration 4238: Loss = 0.014404624700546265
Iteration 4239: Loss = 0.014404227957129478
Iteration 4240: Loss = 0.01440365705639124
Iteration 4241: Loss = 0.014403015375137329
Iteration 4242: Loss = 0.014402521774172783
Iteration 4243: Loss = 0.014401779510080814
Iteration 4244: Loss = 0.014401243068277836
Iteration 4245: Loss = 0.014400668442249298
Iteration 4246: Loss = 0.014400063082575798
Iteration 4247: Loss = 0.014399589970707893
Iteration 4248: Loss = 0.014398974366486073
Iteration 4249: Loss = 0.014398440718650818
Iteration 4250: Loss = 0.014397861436009407
Iteration 4251: Loss = 0.014397235587239265
Iteration 4252: Loss = 0.014396718703210354
Iteration 4253: Loss = 0.01439612079411745
Iteration 4254: Loss = 0.01439558994024992
Iteration 4255: Loss = 0.014395052567124367
Iteration 4256: Loss = 0.014394482597708702
Iteration 4257: Loss = 0.014393960125744343
Iteration 4258: Loss = 0.014393391087651253
Iteration 4259: Loss = 0.014392832294106483
Iteration 4260: Loss = 0.014392292127013206
Iteration 4261: Loss = 0.014391724020242691
Iteration 4262: Loss = 0.01439119502902031
Iteration 4263: Loss = 0.014390646480023861
Iteration 4264: Loss = 0.014390113763511181
Iteration 4265: Loss = 0.014389573596417904
Iteration 4266: Loss = 0.014389025047421455
Iteration 4267: Loss = 0.014388492330908775
Iteration 4268: Loss = 0.014387952163815498
Iteration 4269: Loss = 0.014387410134077072
Iteration 4270: Loss = 0.014386884868144989
Iteration 4271: Loss = 0.014386356808245182
Iteration 4272: Loss = 0.014385825023055077
Iteration 4273: Loss = 0.014385289512574673
Iteration 4274: Loss = 0.014384769834578037
Iteration 4275: Loss = 0.014384235255420208
Iteration 4276: Loss = 0.014383715577423573
Iteration 4277: Loss = 0.014383194968104362
Iteration 4278: Loss = 0.01438265759497881
Iteration 4279: Loss = 0.0143821332603693
Iteration 4280: Loss = 0.014381609857082367
Iteration 4281: Loss = 0.014381092973053455
Iteration 4282: Loss = 0.014380577020347118
Iteration 4283: Loss = 0.014380060136318207
Iteration 4284: Loss = 0.014379539526998997
Iteration 4285: Loss = 0.01437902357429266
Iteration 4286: Loss = 0.01437851507216692
Iteration 4287: Loss = 0.01437800470739603
Iteration 4288: Loss = 0.014377475716173649
Iteration 4289: Loss = 0.014376943930983543
Iteration 4290: Loss = 0.014376407489180565
Iteration 4291: Loss = 0.01437586359679699
Iteration 4292: Loss = 0.014375312253832817
Iteration 4293: Loss = 0.014374775812029839
Iteration 4294: Loss = 0.014374240301549435
Iteration 4295: Loss = 0.014373693615198135
Iteration 4296: Loss = 0.014373144134879112
Iteration 4297: Loss = 0.01437260489910841
Iteration 4298: Loss = 0.014372056350111961
Iteration 4299: Loss = 0.014371524564921856
Iteration 4300: Loss = 0.014370971359312534
Iteration 4301: Loss = 0.014370433986186981
Iteration 4302: Loss = 0.014369890093803406
Iteration 4303: Loss = 0.014369347132742405
Iteration 4304: Loss = 0.014368800446391106
Iteration 4305: Loss = 0.014368273317813873
Iteration 4306: Loss = 0.014367738738656044
Iteration 4307: Loss = 0.014367194846272469
Iteration 4308: Loss = 0.014366659335792065
Iteration 4309: Loss = 0.014366124756634235
Iteration 4310: Loss = 0.01436559110879898
Iteration 4311: Loss = 0.014365065842866898
Iteration 4312: Loss = 0.014364522881805897
Iteration 4313: Loss = 0.01436399295926094
Iteration 4314: Loss = 0.014363468624651432
Iteration 4315: Loss = 0.014362935908138752
Iteration 4316: Loss = 0.014362399466335773
Iteration 4317: Loss = 0.014361882582306862
Iteration 4318: Loss = 0.014361357316374779
Iteration 4319: Loss = 0.014360832050442696
Iteration 4320: Loss = 0.014360322616994381
Iteration 4321: Loss = 0.01435978151857853
Iteration 4322: Loss = 0.014359264634549618
Iteration 4323: Loss = 0.014358747750520706
Iteration 4324: Loss = 0.014358218759298325
Iteration 4325: Loss = 0.01435770932585001
Iteration 4326: Loss = 0.014357202686369419
Iteration 4327: Loss = 0.014356679283082485
Iteration 4328: Loss = 0.014356172643601894
Iteration 4329: Loss = 0.014355650171637535
Iteration 4330: Loss = 0.014355139806866646
Iteration 4331: Loss = 0.01435462199151516
Iteration 4332: Loss = 0.014354121871292591
Iteration 4333: Loss = 0.014353612437844276
Iteration 4334: Loss = 0.014353109523653984
Iteration 4335: Loss = 0.014352604746818542
Iteration 4336: Loss = 0.014352099969983101
Iteration 4337: Loss = 0.014351597055792809
Iteration 4338: Loss = 0.014351093210279942
Iteration 4339: Loss = 0.014350583776831627
Iteration 4340: Loss = 0.014350097626447678
Iteration 4341: Loss = 0.01434960775077343
Iteration 4342: Loss = 0.014349100179970264
Iteration 4343: Loss = 0.014348597265779972
Iteration 4344: Loss = 0.014348112978041172
Iteration 4345: Loss = 0.014347614720463753
Iteration 4346: Loss = 0.014347133226692677
Iteration 4347: Loss = 0.014346647076308727
Iteration 4348: Loss = 0.014346162788569927
Iteration 4349: Loss = 0.014345689676702023
Iteration 4350: Loss = 0.014345229603350163
Iteration 4351: Loss = 0.014344796538352966
Iteration 4352: Loss = 0.014344385825097561
Iteration 4353: Loss = 0.014344033785164356
Iteration 4354: Loss = 0.014343786053359509
Iteration 4355: Loss = 0.014343698509037495
Iteration 4356: Loss = 0.014343880116939545
Iteration 4357: Loss = 0.014344555325806141
Iteration 4358: Loss = 0.014346079900860786
Iteration 4359: Loss = 0.014349129982292652
Iteration 4360: Loss = 0.014354829676449299
Iteration 4361: Loss = 0.014365289360284805
Iteration 4362: Loss = 0.014383601024746895
Iteration 4363: Loss = 0.014414557255804539
Iteration 4364: Loss = 0.014463159255683422
Iteration 4365: Loss = 0.014530343934893608
Iteration 4366: Loss = 0.014600911177694798
Iteration 4367: Loss = 0.014636761508882046
Iteration 4368: Loss = 0.014589947648346424
Iteration 4369: Loss = 0.014468507841229439
Iteration 4370: Loss = 0.01435739267617464
Iteration 4371: Loss = 0.014342918060719967
Iteration 4372: Loss = 0.014410000294446945
Iteration 4373: Loss = 0.01447064708918333
Iteration 4374: Loss = 0.014454790391027927
Iteration 4375: Loss = 0.014379915781319141
Iteration 4376: Loss = 0.014334028586745262
Iteration 4377: Loss = 0.014357110485434532
Iteration 4378: Loss = 0.01440295297652483
Iteration 4379: Loss = 0.014406771399080753
Iteration 4380: Loss = 0.014365355484187603
Iteration 4381: Loss = 0.014332694932818413
Iteration 4382: Loss = 0.014343301765620708
Iteration 4383: Loss = 0.014371227473020554
Iteration 4384: Loss = 0.01437368057668209
Iteration 4385: Loss = 0.01434851810336113
Iteration 4386: Loss = 0.014329875819385052
Iteration 4387: Loss = 0.014337707310914993
Iteration 4388: Loss = 0.014353916049003601
Iteration 4389: Loss = 0.014353123493492603
Iteration 4390: Loss = 0.014337224885821342
Iteration 4391: Loss = 0.014327574521303177
Iteration 4392: Loss = 0.014333648607134819
Iteration 4393: Loss = 0.014342596754431725
Iteration 4394: Loss = 0.014340347610414028
Iteration 4395: Loss = 0.014330345205962658
Iteration 4396: Loss = 0.014325689524412155
Iteration 4397: Loss = 0.014330090954899788
Iteration 4398: Loss = 0.014334755949676037
Iteration 4399: Loss = 0.01433230098336935
Iteration 4400: Loss = 0.014326118864119053
Iteration 4401: Loss = 0.014323904179036617
Iteration 4402: Loss = 0.014326729811728
Iteration 4403: Loss = 0.014329042285680771
Iteration 4404: Loss = 0.014327037148177624
Iteration 4405: Loss = 0.014323245733976364
Iteration 4406: Loss = 0.01432203408330679
Iteration 4407: Loss = 0.014323672279715538
Iteration 4408: Loss = 0.014324778690934181
Iteration 4409: Loss = 0.014323320239782333
Iteration 4410: Loss = 0.014320946298539639
Iteration 4411: Loss = 0.014320124872028828
Iteration 4412: Loss = 0.014320955611765385
Iteration 4413: Loss = 0.014321450144052505
Iteration 4414: Loss = 0.014320400543510914
Iteration 4415: Loss = 0.014318777248263359
Iteration 4416: Loss = 0.01431807316839695
Iteration 4417: Loss = 0.014318354427814484
Iteration 4418: Loss = 0.014318504370748997
Iteration 4419: Loss = 0.01431779284030199
Iteration 4420: Loss = 0.01431665662676096
Iteration 4421: Loss = 0.014315984211862087
Iteration 4422: Loss = 0.014315938577055931
Iteration 4423: Loss = 0.014315931126475334
Iteration 4424: Loss = 0.01431539747864008
Iteration 4425: Loss = 0.014314578846096992
Iteration 4426: Loss = 0.014313939958810806
Iteration 4427: Loss = 0.01431370060890913
Iteration 4428: Loss = 0.014313542284071445
Iteration 4429: Loss = 0.014313139952719212
Iteration 4430: Loss = 0.014312511309981346
Iteration 4431: Loss = 0.01431192085146904
Iteration 4432: Loss = 0.014311565086245537
Iteration 4433: Loss = 0.014311309903860092
Iteration 4434: Loss = 0.014310968108475208
Iteration 4435: Loss = 0.014310456812381744
Iteration 4436: Loss = 0.014309938065707684
Iteration 4437: Loss = 0.014309507794678211
Iteration 4438: Loss = 0.014309195801615715
Iteration 4439: Loss = 0.014308852143585682
Iteration 4440: Loss = 0.014308440499007702
Iteration 4441: Loss = 0.014307955279946327
Iteration 4442: Loss = 0.014307514764368534
Iteration 4443: Loss = 0.014307145960628986
Iteration 4444: Loss = 0.014306796714663506
Iteration 4445: Loss = 0.014306417666375637
Iteration 4446: Loss = 0.01430598832666874
Iteration 4447: Loss = 0.01430555246770382
Iteration 4448: Loss = 0.014305154792964458
Iteration 4449: Loss = 0.014304785057902336
Iteration 4450: Loss = 0.014304420910775661
Iteration 4451: Loss = 0.014304021373391151
Iteration 4452: Loss = 0.014303604140877724
Iteration 4453: Loss = 0.014303198084235191
Iteration 4454: Loss = 0.014302819035947323
Iteration 4455: Loss = 0.0143024493008852
Iteration 4456: Loss = 0.01430208794772625
Iteration 4457: Loss = 0.014301695860922337
Iteration 4458: Loss = 0.014301296323537827
Iteration 4459: Loss = 0.014300907962024212
Iteration 4460: Loss = 0.014300517737865448
Iteration 4461: Loss = 0.01430015079677105
Iteration 4462: Loss = 0.01429977361112833
Iteration 4463: Loss = 0.014299402013421059
Iteration 4464: Loss = 0.014299011789262295
Iteration 4465: Loss = 0.0142986373975873
Iteration 4466: Loss = 0.014298257417976856
Iteration 4467: Loss = 0.01429788302630186
Iteration 4468: Loss = 0.014297514222562313
Iteration 4469: Loss = 0.014297130517661572
Iteration 4470: Loss = 0.014296764507889748
Iteration 4471: Loss = 0.014296376146376133
Iteration 4472: Loss = 0.01429600641131401
Iteration 4473: Loss = 0.01429564319550991
Iteration 4474: Loss = 0.014295274391770363
Iteration 4475: Loss = 0.014294902794063091
Iteration 4476: Loss = 0.014294539578258991
Iteration 4477: Loss = 0.01429416611790657
Iteration 4478: Loss = 0.014293800108134747
Iteration 4479: Loss = 0.014293435961008072
Iteration 4480: Loss = 0.014293071813881397
Iteration 4481: Loss = 0.014292703941464424
Iteration 4482: Loss = 0.014292349107563496
Iteration 4483: Loss = 0.014291981235146523
Iteration 4484: Loss = 0.014291619881987572
Iteration 4485: Loss = 0.014291251078248024
Iteration 4486: Loss = 0.014290898106992245
Iteration 4487: Loss = 0.014290548861026764
Iteration 4488: Loss = 0.014290183782577515
Iteration 4489: Loss = 0.014289820566773415
Iteration 4490: Loss = 0.014289462938904762
Iteration 4491: Loss = 0.014289104379713535
Iteration 4492: Loss = 0.014288745820522308
Iteration 4493: Loss = 0.014288399368524551
Iteration 4494: Loss = 0.014288046397268772
Iteration 4495: Loss = 0.014287693426012993
Iteration 4496: Loss = 0.014287336729466915
Iteration 4497: Loss = 0.014286989346146584
Iteration 4498: Loss = 0.01428664568811655
Iteration 4499: Loss = 0.014286288060247898
Iteration 4500: Loss = 0.014285928569734097
Iteration 4501: Loss = 0.014285576529800892
Iteration 4502: Loss = 0.014285239391028881
Iteration 4503: Loss = 0.014284898526966572
Iteration 4504: Loss = 0.014284537173807621
Iteration 4505: Loss = 0.014284204691648483
Iteration 4506: Loss = 0.014283859170973301
Iteration 4507: Loss = 0.014283515512943268
Iteration 4508: Loss = 0.01428315695375204
Iteration 4509: Loss = 0.014282827265560627
Iteration 4510: Loss = 0.014282491989433765
Iteration 4511: Loss = 0.014282144606113434
Iteration 4512: Loss = 0.014281799085438251
Iteration 4513: Loss = 0.014281462877988815
Iteration 4514: Loss = 0.014281129464507103
Iteration 4515: Loss = 0.014280790463089943
Iteration 4516: Loss = 0.014280445873737335
Iteration 4517: Loss = 0.014280106872320175
Iteration 4518: Loss = 0.01427977904677391
Iteration 4519: Loss = 0.014279440976679325
Iteration 4520: Loss = 0.01427910290658474
Iteration 4521: Loss = 0.014278766699135303
Iteration 4522: Loss = 0.014278436079621315
Iteration 4523: Loss = 0.014278114773333073
Iteration 4524: Loss = 0.014277772977948189
Iteration 4525: Loss = 0.014277447015047073
Iteration 4526: Loss = 0.01427710521966219
Iteration 4527: Loss = 0.014276781119406223
Iteration 4528: Loss = 0.01427644956856966
Iteration 4529: Loss = 0.014276119880378246
Iteration 4530: Loss = 0.01427579764276743
Iteration 4531: Loss = 0.014275465160608292
Iteration 4532: Loss = 0.014275149442255497
Iteration 4533: Loss = 0.014274819754064083
Iteration 4534: Loss = 0.014274492859840393
Iteration 4535: Loss = 0.014274166896939278
Iteration 4536: Loss = 0.014273841865360737
Iteration 4537: Loss = 0.014273530803620815
Iteration 4538: Loss = 0.014273194596171379
Iteration 4539: Loss = 0.014272884465754032
Iteration 4540: Loss = 0.014272565953433514
Iteration 4541: Loss = 0.014272238127887249
Iteration 4542: Loss = 0.014271916821599007
Iteration 4543: Loss = 0.014271599240601063
Iteration 4544: Loss = 0.014271299354732037
Iteration 4545: Loss = 0.01427096500992775
Iteration 4546: Loss = 0.014270657673478127
Iteration 4547: Loss = 0.014270296320319176
Iteration 4548: Loss = 0.014269927516579628
Iteration 4549: Loss = 0.014269556850194931
Iteration 4550: Loss = 0.014269178733229637
Iteration 4551: Loss = 0.014268783852458
Iteration 4552: Loss = 0.014268371276557446
Iteration 4553: Loss = 0.014267970807850361
Iteration 4554: Loss = 0.014267570339143276
Iteration 4555: Loss = 0.0142671512439847
Iteration 4556: Loss = 0.014266747049987316
Iteration 4557: Loss = 0.014266325160861015
Iteration 4558: Loss = 0.014265908859670162
Iteration 4559: Loss = 0.014265495352447033
Iteration 4560: Loss = 0.014265086501836777
Iteration 4561: Loss = 0.014264671131968498
Iteration 4562: Loss = 0.014264238066971302
Iteration 4563: Loss = 0.014263845048844814
Iteration 4564: Loss = 0.01426343061029911
Iteration 4565: Loss = 0.014263017103075981
Iteration 4566: Loss = 0.014262604527175426
Iteration 4567: Loss = 0.014262187294661999
Iteration 4568: Loss = 0.014261768199503422
Iteration 4569: Loss = 0.014261370524764061
Iteration 4570: Loss = 0.014260963536798954
Iteration 4571: Loss = 0.01426053885370493
Iteration 4572: Loss = 0.014260144904255867
Iteration 4573: Loss = 0.014259746298193932
Iteration 4574: Loss = 0.014259333722293377
Iteration 4575: Loss = 0.014258943498134613
Iteration 4576: Loss = 0.014258535578846931
Iteration 4577: Loss = 0.014258138835430145
Iteration 4578: Loss = 0.014257733710110188
Iteration 4579: Loss = 0.014257350005209446
Iteration 4580: Loss = 0.014256943017244339
Iteration 4581: Loss = 0.014256559312343597
Iteration 4582: Loss = 0.014256162568926811
Iteration 4583: Loss = 0.014255765825510025
Iteration 4584: Loss = 0.014255374670028687
Iteration 4585: Loss = 0.01425499003380537
Iteration 4586: Loss = 0.01425460260361433
Iteration 4587: Loss = 0.014254224486649036
Iteration 4588: Loss = 0.014253823086619377
Iteration 4589: Loss = 0.014253444969654083
Iteration 4590: Loss = 0.014253051951527596
Iteration 4591: Loss = 0.014252673834562302
Iteration 4592: Loss = 0.014252296648919582
Iteration 4593: Loss = 0.014251911081373692
Iteration 4594: Loss = 0.014251538552343845
Iteration 4595: Loss = 0.014251168817281723
Iteration 4596: Loss = 0.014250785112380981
Iteration 4597: Loss = 0.014250412583351135
Iteration 4598: Loss = 0.014250032603740692
Iteration 4599: Loss = 0.014249664731323719
Iteration 4600: Loss = 0.014249294064939022
Iteration 4601: Loss = 0.014248931780457497
Iteration 4602: Loss = 0.014248562045395374
Iteration 4603: Loss = 0.01424818579107523
Iteration 4604: Loss = 0.014247830957174301
Iteration 4605: Loss = 0.014247470535337925
Iteration 4606: Loss = 0.014247123152017593
Iteration 4607: Loss = 0.014246753416955471
Iteration 4608: Loss = 0.014246414415538311
Iteration 4609: Loss = 0.014246098697185516
Iteration 4610: Loss = 0.01424577459692955
Iteration 4611: Loss = 0.014245489612221718
Iteration 4612: Loss = 0.014245254918932915
Iteration 4613: Loss = 0.014245077967643738
Iteration 4614: Loss = 0.014245018362998962
Iteration 4615: Loss = 0.014245113357901573
Iteration 4616: Loss = 0.014245483092963696
Iteration 4617: Loss = 0.014246325939893723
Iteration 4618: Loss = 0.014247856102883816
Iteration 4619: Loss = 0.014250596053898335
Iteration 4620: Loss = 0.014255221001803875
Iteration 4621: Loss = 0.0142629100009799
Iteration 4622: Loss = 0.01427535805851221
Iteration 4623: Loss = 0.01429484598338604
Iteration 4624: Loss = 0.014323894865810871
Iteration 4625: Loss = 0.014363364316523075
Iteration 4626: Loss = 0.014406705275177956
Iteration 4627: Loss = 0.01444149762392044
Iteration 4628: Loss = 0.014436629600822926
Iteration 4629: Loss = 0.014384995214641094
Iteration 4630: Loss = 0.014308259822428226
Iteration 4631: Loss = 0.014250405132770538
Iteration 4632: Loss = 0.014240563847124577
Iteration 4633: Loss = 0.014271581545472145
Iteration 4634: Loss = 0.014309949241578579
Iteration 4635: Loss = 0.014322244562208652
Iteration 4636: Loss = 0.014298544265329838
Iteration 4637: Loss = 0.014259631745517254
Iteration 4638: Loss = 0.014237071387469769
Iteration 4639: Loss = 0.01424382347613573
Iteration 4640: Loss = 0.014265761710703373
Iteration 4641: Loss = 0.01427852176129818
Iteration 4642: Loss = 0.014270075596868992
Iteration 4643: Loss = 0.014249402098357677
Iteration 4644: Loss = 0.014235352165997028
Iteration 4645: Loss = 0.014237595722079277
Iteration 4646: Loss = 0.014249294996261597
Iteration 4647: Loss = 0.014256445690989494
Iteration 4648: Loss = 0.014251884073019028
Iteration 4649: Loss = 0.014240623451769352
Iteration 4650: Loss = 0.014233076013624668
Iteration 4651: Loss = 0.014234372414648533
Iteration 4652: Loss = 0.014240599237382412
Iteration 4653: Loss = 0.01424417458474636
Iteration 4654: Loss = 0.014241436496376991
Iteration 4655: Loss = 0.014235229231417179
Iteration 4656: Loss = 0.01423109881579876
Iteration 4657: Loss = 0.014231708832085133
Iteration 4658: Loss = 0.014234930276870728
Iteration 4659: Loss = 0.014236688613891602
Iteration 4660: Loss = 0.014235001057386398
Iteration 4661: Loss = 0.014231403358280659
Iteration 4662: Loss = 0.014229066669940948
Iteration 4663: Loss = 0.014229238964617252
Iteration 4664: Loss = 0.014230783097445965
Iteration 4665: Loss = 0.014231531880795956
Iteration 4666: Loss = 0.014230499044060707
Iteration 4667: Loss = 0.014228413812816143
Iteration 4668: Loss = 0.014226782135665417
Iteration 4669: Loss = 0.0142264598980546
Iteration 4670: Loss = 0.014227018691599369
Iteration 4671: Loss = 0.014227391220629215
Iteration 4672: Loss = 0.014226861298084259
Iteration 4673: Loss = 0.014225655235350132
Iteration 4674: Loss = 0.014224465936422348
Iteration 4675: Loss = 0.014223880134522915
Iteration 4676: Loss = 0.014223862439393997
Iteration 4677: Loss = 0.014223955571651459
Iteration 4678: Loss = 0.014223698526620865
Iteration 4679: Loss = 0.014222991652786732
Iteration 4680: Loss = 0.01422213762998581
Iteration 4681: Loss = 0.014221475459635258
Iteration 4682: Loss = 0.014221140183508396
Iteration 4683: Loss = 0.014221001416444778
Iteration 4684: Loss = 0.014220790937542915
Iteration 4685: Loss = 0.014220384880900383
Iteration 4686: Loss = 0.01421979907900095
Iteration 4687: Loss = 0.014219185337424278
Iteration 4688: Loss = 0.014218728989362717
Iteration 4689: Loss = 0.014218400232493877
Iteration 4690: Loss = 0.014218145981431007
Iteration 4691: Loss = 0.014217838644981384
Iteration 4692: Loss = 0.014217420481145382
Iteration 4693: Loss = 0.014216944575309753
Iteration 4694: Loss = 0.014216462150216103
Iteration 4695: Loss = 0.014216047711670399
Iteration 4696: Loss = 0.014215683564543724
Iteration 4697: Loss = 0.014215393923223019
Iteration 4698: Loss = 0.014215049333870411
Iteration 4699: Loss = 0.014214669354259968
Iteration 4700: Loss = 0.014214255847036839
Iteration 4701: Loss = 0.01421383023262024
Iteration 4702: Loss = 0.014213434420526028
Iteration 4703: Loss = 0.014213072136044502
Iteration 4704: Loss = 0.01421272847801447
Iteration 4705: Loss = 0.014212392270565033
Iteration 4706: Loss = 0.014212035574018955
Iteration 4707: Loss = 0.014211656525731087
Iteration 4708: Loss = 0.014211265370249748
Iteration 4709: Loss = 0.01421088445931673
Iteration 4710: Loss = 0.01421052124351263
Iteration 4711: Loss = 0.014210171066224575
Iteration 4712: Loss = 0.01420983113348484
Iteration 4713: Loss = 0.01420949213206768
Iteration 4714: Loss = 0.01420912891626358
Iteration 4715: Loss = 0.014208775945007801
Iteration 4716: Loss = 0.01420840434730053
Iteration 4717: Loss = 0.014208035543560982
Iteration 4718: Loss = 0.014207679778337479
Iteration 4719: Loss = 0.014207334257662296
Iteration 4720: Loss = 0.014206995256245136
Iteration 4721: Loss = 0.0142066590487957
Iteration 4722: Loss = 0.014206314459443092
Iteration 4723: Loss = 0.01420597080141306
Iteration 4724: Loss = 0.014205614104866982
Iteration 4725: Loss = 0.014205272309482098
Iteration 4726: Loss = 0.014204911887645721
Iteration 4727: Loss = 0.014204578474164009
Iteration 4728: Loss = 0.014204239472746849
Iteration 4729: Loss = 0.014203902333974838
Iteration 4730: Loss = 0.014203567057847977
Iteration 4731: Loss = 0.01420323085039854
Iteration 4732: Loss = 0.014202895574271679
Iteration 4733: Loss = 0.014202547259628773
Iteration 4734: Loss = 0.014202216640114784
Iteration 4735: Loss = 0.014201882295310497
Iteration 4736: Loss = 0.014201545156538486
Iteration 4737: Loss = 0.014201216399669647
Iteration 4738: Loss = 0.014200880192220211
Iteration 4739: Loss = 0.01420055516064167
Iteration 4740: Loss = 0.014200234785676003
Iteration 4741: Loss = 0.014199899509549141
Iteration 4742: Loss = 0.01419957634061575
Iteration 4743: Loss = 0.014199246652424335
Iteration 4744: Loss = 0.014198921620845795
Iteration 4745: Loss = 0.014198599383234978
Iteration 4746: Loss = 0.014198265969753265
Iteration 4747: Loss = 0.014197943732142448
Iteration 4748: Loss = 0.014197621494531631
Iteration 4749: Loss = 0.01419730857014656
Iteration 4750: Loss = 0.014196988195180893
Iteration 4751: Loss = 0.0141966687515378
Iteration 4752: Loss = 0.014196343719959259
Iteration 4753: Loss = 0.014196041040122509
Iteration 4754: Loss = 0.014195711351931095
Iteration 4755: Loss = 0.014195400290191174
Iteration 4756: Loss = 0.01419508084654808
Iteration 4757: Loss = 0.01419476792216301
Iteration 4758: Loss = 0.014194452203810215
Iteration 4759: Loss = 0.014194142073392868
Iteration 4760: Loss = 0.014193831011652946
Iteration 4761: Loss = 0.014193525537848473
Iteration 4762: Loss = 0.014193214476108551
Iteration 4763: Loss = 0.01419290341436863
Iteration 4764: Loss = 0.014192599803209305
Iteration 4765: Loss = 0.014192245900630951
Iteration 4766: Loss = 0.014191904105246067
Iteration 4767: Loss = 0.014191551133990288
Iteration 4768: Loss = 0.014191205613315105
Iteration 4769: Loss = 0.01419085543602705
Iteration 4770: Loss = 0.01419050619006157
Iteration 4771: Loss = 0.014190157875418663
Iteration 4772: Loss = 0.014189804904162884
Iteration 4773: Loss = 0.014189448207616806
Iteration 4774: Loss = 0.014189090579748154
Iteration 4775: Loss = 0.01418872456997633
Iteration 4776: Loss = 0.014188366942107677
Iteration 4777: Loss = 0.014188025146722794
Iteration 4778: Loss = 0.014187673106789589
Iteration 4779: Loss = 0.014187319204211235
Iteration 4780: Loss = 0.014186978340148926
Iteration 4781: Loss = 0.014186607673764229
Iteration 4782: Loss = 0.014186264015734196
Iteration 4783: Loss = 0.014185904525220394
Iteration 4784: Loss = 0.014185559935867786
Iteration 4785: Loss = 0.014185206964612007
Iteration 4786: Loss = 0.0141848623752594
Iteration 4787: Loss = 0.01418451126664877
Iteration 4788: Loss = 0.014184171333909035
Iteration 4789: Loss = 0.014183812774717808
Iteration 4790: Loss = 0.014183471910655499
Iteration 4791: Loss = 0.014183130115270615
Iteration 4792: Loss = 0.01418277807533741
Iteration 4793: Loss = 0.014182440005242825
Iteration 4794: Loss = 0.014182104729115963
Iteration 4795: Loss = 0.014181765727698803
Iteration 4796: Loss = 0.014181423932313919
Iteration 4797: Loss = 0.014181085862219334
Iteration 4798: Loss = 0.014180748723447323
Iteration 4799: Loss = 0.014180412515997887
Iteration 4800: Loss = 0.014180080033838749
Iteration 4801: Loss = 0.014179744757711887
Iteration 4802: Loss = 0.014179416932165623
Iteration 4803: Loss = 0.014179080724716187
Iteration 4804: Loss = 0.014178738929331303
Iteration 4805: Loss = 0.014178412966430187
Iteration 4806: Loss = 0.014178085140883923
Iteration 4807: Loss = 0.014177761040627956
Iteration 4808: Loss = 0.014177434146404266
Iteration 4809: Loss = 0.014177106320858002
Iteration 4810: Loss = 0.014176786877214909
Iteration 4811: Loss = 0.014176469296216965
Iteration 4812: Loss = 0.014176138676702976
Iteration 4813: Loss = 0.014175823889672756
Iteration 4814: Loss = 0.014175506308674812
Iteration 4815: Loss = 0.014175176620483398
Iteration 4816: Loss = 0.01417484786361456
Iteration 4817: Loss = 0.014174503274261951
Iteration 4818: Loss = 0.014174177311360836
Iteration 4819: Loss = 0.014173855073750019
Iteration 4820: Loss = 0.01417352631688118
Iteration 4821: Loss = 0.014173216186463833
Iteration 4822: Loss = 0.014172916300594807
Iteration 4823: Loss = 0.014172670431435108
Iteration 4824: Loss = 0.014172452501952648
Iteration 4825: Loss = 0.014172346331179142
Iteration 4826: Loss = 0.014172411523759365
Iteration 4827: Loss = 0.014172762632369995
Iteration 4828: Loss = 0.014173656702041626
Iteration 4829: Loss = 0.014175480231642723
Iteration 4830: Loss = 0.014178963378071785
Iteration 4831: Loss = 0.014185437932610512
Iteration 4832: Loss = 0.014197137206792831
Iteration 4833: Loss = 0.014217767864465714
Iteration 4834: Loss = 0.014252512715756893
Iteration 4835: Loss = 0.0143019063398242
Iteration 4836: Loss = 0.01436711847782135
Iteration 4837: Loss = 0.014431409537792206
Iteration 4838: Loss = 0.014459186233580112
Iteration 4839: Loss = 0.014410076662898064
Iteration 4840: Loss = 0.014294210821390152
Iteration 4841: Loss = 0.014189362525939941
Iteration 4842: Loss = 0.01417181733995676
Iteration 4843: Loss = 0.014230945147573948
Iteration 4844: Loss = 0.014288023114204407
Iteration 4845: Loss = 0.014280647970736027
Iteration 4846: Loss = 0.014217417687177658
Iteration 4847: Loss = 0.014168761670589447
Iteration 4848: Loss = 0.01417731586843729
Iteration 4849: Loss = 0.014217822812497616
Iteration 4850: Loss = 0.014235220849514008
Iteration 4851: Loss = 0.014207192696630955
Iteration 4852: Loss = 0.014171337708830833
Iteration 4853: Loss = 0.014166362583637238
Iteration 4854: Loss = 0.014188574627041817
Iteration 4855: Loss = 0.01420383621007204
Iteration 4856: Loss = 0.014190510846674442
Iteration 4857: Loss = 0.01416860707104206
Iteration 4858: Loss = 0.014163246378302574
Iteration 4859: Loss = 0.014175348915159702
Iteration 4860: Loss = 0.014185251668095589
Iteration 4861: Loss = 0.014177916571497917
Iteration 4862: Loss = 0.014165077358484268
Iteration 4863: Loss = 0.014161528088152409
Iteration 4864: Loss = 0.014168288558721542
Iteration 4865: Loss = 0.014174121432006359
Iteration 4866: Loss = 0.014171134680509567
Iteration 4867: Loss = 0.014163385145366192
Iteration 4868: Loss = 0.014159882441163063
Iteration 4869: Loss = 0.014162976294755936
Iteration 4870: Loss = 0.014166916720569134
Iteration 4871: Loss = 0.01416612695902586
Iteration 4872: Loss = 0.014161648228764534
Iteration 4873: Loss = 0.014158667996525764
Iteration 4874: Loss = 0.014159697107970715
Iteration 4875: Loss = 0.014162154868245125
Iteration 4876: Loss = 0.014162369072437286
Iteration 4877: Loss = 0.014159967191517353
Iteration 4878: Loss = 0.014157629571855068
Iteration 4879: Loss = 0.014157523401081562
Iteration 4880: Loss = 0.014158831909298897
Iteration 4881: Loss = 0.014159372076392174
Iteration 4882: Loss = 0.014158250764012337
Iteration 4883: Loss = 0.014156611636281013
Iteration 4884: Loss = 0.014155995100736618
Iteration 4885: Loss = 0.014156484976410866
Iteration 4886: Loss = 0.014156978577375412
Iteration 4887: Loss = 0.014156565070152283
Iteration 4888: Loss = 0.014155539683997631
Iteration 4889: Loss = 0.014154776930809021
Iteration 4890: Loss = 0.014154746197164059
Iteration 4891: Loss = 0.014155016280710697
Iteration 4892: Loss = 0.014154943637549877
Iteration 4893: Loss = 0.014154371805489063
Iteration 4894: Loss = 0.014153707772493362
Iteration 4895: Loss = 0.01415337435901165
Iteration 4896: Loss = 0.01415338460355997
Iteration 4897: Loss = 0.014153379946947098
Iteration 4898: Loss = 0.014153126627206802
Iteration 4899: Loss = 0.014152643270790577
Iteration 4900: Loss = 0.01415224839001894
Iteration 4901: Loss = 0.014152055606245995
Iteration 4902: Loss = 0.014152001589536667
Iteration 4903: Loss = 0.014151860028505325
Iteration 4904: Loss = 0.014151562005281448
Iteration 4905: Loss = 0.014151216484606266
Iteration 4906: Loss = 0.01415091659873724
Iteration 4907: Loss = 0.01415074523538351
Iteration 4908: Loss = 0.01415062416344881
Iteration 4909: Loss = 0.014150427654385567
Iteration 4910: Loss = 0.014150160364806652
Iteration 4911: Loss = 0.014149878174066544
Iteration 4912: Loss = 0.014149632304906845
Iteration 4913: Loss = 0.014149453490972519
Iteration 4914: Loss = 0.014149277471005917
Iteration 4915: Loss = 0.014149081893265247
Iteration 4916: Loss = 0.014148836955428123
Iteration 4917: Loss = 0.014148578979074955
Iteration 4918: Loss = 0.01414836011826992
Iteration 4919: Loss = 0.014148167334496975
Iteration 4920: Loss = 0.014147975482046604
Iteration 4921: Loss = 0.014147772453725338
Iteration 4922: Loss = 0.014147543348371983
Iteration 4923: Loss = 0.014147327281534672
Iteration 4924: Loss = 0.014147108420729637
Iteration 4925: Loss = 0.01414690911769867
Iteration 4926: Loss = 0.014146724715828896
Iteration 4927: Loss = 0.014146520756185055
Iteration 4928: Loss = 0.014146300964057446
Iteration 4929: Loss = 0.014146080240607262
Iteration 4930: Loss = 0.014145874418318272
Iteration 4931: Loss = 0.014145679771900177
Iteration 4932: Loss = 0.014145479537546635
Iteration 4933: Loss = 0.014145287685096264
Iteration 4934: Loss = 0.0141450772061944
Iteration 4935: Loss = 0.014144857414066792
Iteration 4936: Loss = 0.014144646935164928
Iteration 4937: Loss = 0.014144462533295155
Iteration 4938: Loss = 0.01414425391703844
Iteration 4939: Loss = 0.014144056476652622
Iteration 4940: Loss = 0.014143864624202251
Iteration 4941: Loss = 0.01414366066455841
Iteration 4942: Loss = 0.014143459498882294
Iteration 4943: Loss = 0.01414326298981905
Iteration 4944: Loss = 0.014143059030175209
Iteration 4945: Loss = 0.014142865315079689
Iteration 4946: Loss = 0.014142673462629318
Iteration 4947: Loss = 0.014142464846372604
Iteration 4948: Loss = 0.01414227019995451
Iteration 4949: Loss = 0.014142070896923542
Iteration 4950: Loss = 0.014141879044473171
Iteration 4951: Loss = 0.014141690917313099
Iteration 4952: Loss = 0.014141486957669258
Iteration 4953: Loss = 0.014141291379928589
Iteration 4954: Loss = 0.014141101390123367
Iteration 4955: Loss = 0.01414091233164072
Iteration 4956: Loss = 0.0141407186165452
Iteration 4957: Loss = 0.014140517450869083
Iteration 4958: Loss = 0.014140326529741287
Iteration 4959: Loss = 0.0141401132568717
Iteration 4960: Loss = 0.014139937236905098
Iteration 4961: Loss = 0.014139750972390175
Iteration 4962: Loss = 0.014139562845230103
Iteration 4963: Loss = 0.014139368198812008
Iteration 4964: Loss = 0.014139177277684212
Iteration 4965: Loss = 0.014138993807137012
Iteration 4966: Loss = 0.014138800092041492
Iteration 4967: Loss = 0.014138615690171719
Iteration 4968: Loss = 0.014138428494334221
Iteration 4969: Loss = 0.014138235710561275
Iteration 4970: Loss = 0.0141380550339818
Iteration 4971: Loss = 0.014137866906821728
Iteration 4972: Loss = 0.014137673191726208
Iteration 4973: Loss = 0.014137495309114456
Iteration 4974: Loss = 0.01413730625063181
Iteration 4975: Loss = 0.01413712464272976
Iteration 4976: Loss = 0.014136935584247112
Iteration 4977: Loss = 0.01413674745708704
Iteration 4978: Loss = 0.014136563055217266
Iteration 4979: Loss = 0.014136392623186111
Iteration 4980: Loss = 0.014136194251477718
Iteration 4981: Loss = 0.014136010780930519
Iteration 4982: Loss = 0.014135840348899364
Iteration 4983: Loss = 0.014135644771158695
Iteration 4984: Loss = 0.014135461300611496
Iteration 4985: Loss = 0.014135286211967468
Iteration 4986: Loss = 0.014135103672742844
Iteration 4987: Loss = 0.014134918339550495
Iteration 4988: Loss = 0.014134741388261318
Iteration 4989: Loss = 0.014134561643004417
Iteration 4990: Loss = 0.014134381897747517
Iteration 4991: Loss = 0.014134205877780914
Iteration 4992: Loss = 0.01413402147591114
Iteration 4993: Loss = 0.01413385383784771
Iteration 4994: Loss = 0.014133669435977936
Iteration 4995: Loss = 0.014133496209979057
Iteration 4996: Loss = 0.014133320190012455
Iteration 4997: Loss = 0.014133132062852383
Iteration 4998: Loss = 0.014132962562143803
Iteration 4999: Loss = 0.01413277443498373
Iteration 5000: Loss = 0.0141326067969203


Total training time (seconds): 51.76
