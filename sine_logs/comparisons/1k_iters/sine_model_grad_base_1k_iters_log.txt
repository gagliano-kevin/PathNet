Iteration 1: Loss = 0.4626210629940033
Iteration 2: Loss = 0.4573349356651306
Iteration 3: Loss = 0.4527782201766968
Iteration 4: Loss = 0.4489513635635376
Iteration 5: Loss = 0.44582781195640564
Iteration 6: Loss = 0.4433635473251343
Iteration 7: Loss = 0.44149813055992126
Iteration 8: Loss = 0.4401616156101227
Iteration 9: Loss = 0.43927502632141113
Iteration 10: Loss = 0.43875277042388916
Iteration 11: Loss = 0.4385034739971161
Iteration 12: Loss = 0.4384362995624542
Iteration 13: Loss = 0.43846845626831055
Iteration 14: Loss = 0.4385316073894501
Iteration 15: Loss = 0.43857690691947937
Iteration 16: Loss = 0.43857985734939575
Iteration 17: Loss = 0.4385329782962799
Iteration 18: Loss = 0.43844762444496155
Iteration 19: Loss = 0.4383392333984375
Iteration 20: Loss = 0.43821561336517334
Iteration 21: Loss = 0.43807199597358704
Iteration 22: Loss = 0.43789732456207275
Iteration 23: Loss = 0.4376826882362366
Iteration 24: Loss = 0.4374293088912964
Iteration 25: Loss = 0.4371463656425476
Iteration 26: Loss = 0.43684789538383484
Iteration 27: Loss = 0.43655073642730713
Iteration 28: Loss = 0.436270534992218
Iteration 29: Loss = 0.43602320551872253
Iteration 30: Loss = 0.4358176589012146
Iteration 31: Loss = 0.43566060066223145
Iteration 32: Loss = 0.43554800748825073
Iteration 33: Loss = 0.43547144532203674
Iteration 34: Loss = 0.43541836738586426
Iteration 35: Loss = 0.43537455797195435
Iteration 36: Loss = 0.4353286325931549
Iteration 37: Loss = 0.43527117371559143
Iteration 38: Loss = 0.43519696593284607
Iteration 39: Loss = 0.43510401248931885
Iteration 40: Loss = 0.43499305844306946
Iteration 41: Loss = 0.434867799282074
Iteration 42: Loss = 0.43473249673843384
Iteration 43: Loss = 0.43459296226501465
Iteration 44: Loss = 0.4344553053379059
Iteration 45: Loss = 0.43432360887527466
Iteration 46: Loss = 0.4342021048069
Iteration 47: Loss = 0.43409234285354614
Iteration 48: Loss = 0.4339933693408966
Iteration 49: Loss = 0.43390321731567383
Iteration 50: Loss = 0.433819055557251
Iteration 51: Loss = 0.43373802304267883
Iteration 52: Loss = 0.4336579144001007
Iteration 53: Loss = 0.43357720971107483
Iteration 54: Loss = 0.43349525332450867
Iteration 55: Loss = 0.43341222405433655
Iteration 56: Loss = 0.4333285689353943
Iteration 57: Loss = 0.433244526386261
Iteration 58: Loss = 0.4331606328487396
Iteration 59: Loss = 0.43307632207870483
Iteration 60: Loss = 0.43299221992492676
Iteration 61: Loss = 0.4329085052013397
Iteration 62: Loss = 0.43282565474510193
Iteration 63: Loss = 0.43274420499801636
Iteration 64: Loss = 0.4326649308204651
Iteration 65: Loss = 0.4325881004333496
Iteration 66: Loss = 0.4325139820575714
Iteration 67: Loss = 0.4324425756931305
Iteration 68: Loss = 0.43237340450286865
Iteration 69: Loss = 0.4323057234287262
Iteration 70: Loss = 0.4322388768196106
Iteration 71: Loss = 0.43217238783836365
Iteration 72: Loss = 0.4321056306362152
Iteration 73: Loss = 0.43203869462013245
Iteration 74: Loss = 0.4319719970226288
Iteration 75: Loss = 0.4319056570529938
Iteration 76: Loss = 0.4318402111530304
Iteration 77: Loss = 0.43177610635757446
Iteration 78: Loss = 0.43171343207359314
Iteration 79: Loss = 0.43165209889411926
Iteration 80: Loss = 0.43159207701683044
Iteration 81: Loss = 0.4315331280231476
Iteration 82: Loss = 0.43147534132003784
Iteration 83: Loss = 0.43141844868659973
Iteration 84: Loss = 0.4313623607158661
Iteration 85: Loss = 0.43130701780319214
Iteration 86: Loss = 0.43125247955322266
Iteration 87: Loss = 0.4311985969543457
Iteration 88: Loss = 0.43114545941352844
Iteration 89: Loss = 0.4310929775238037
Iteration 90: Loss = 0.4310411512851715
Iteration 91: Loss = 0.43098998069763184
Iteration 92: Loss = 0.4309394955635071
Iteration 93: Loss = 0.4308898448944092
Iteration 94: Loss = 0.43084079027175903
Iteration 95: Loss = 0.43079259991645813
Iteration 96: Loss = 0.4307452440261841
Iteration 97: Loss = 0.4306986331939697
Iteration 98: Loss = 0.43065276741981506
Iteration 99: Loss = 0.43060752749443054
Iteration 100: Loss = 0.4305630624294281
Iteration 101: Loss = 0.430519163608551
Iteration 102: Loss = 0.43047577142715454
Iteration 103: Loss = 0.4304330050945282
Iteration 104: Loss = 0.43039077520370483
Iteration 105: Loss = 0.43034908175468445
Iteration 106: Loss = 0.4303080439567566
Iteration 107: Loss = 0.4302677512168884
Iteration 108: Loss = 0.4302279055118561
Iteration 109: Loss = 0.4301886558532715
Iteration 110: Loss = 0.4301501512527466
Iteration 111: Loss = 0.4301120638847351
Iteration 112: Loss = 0.43007445335388184
Iteration 113: Loss = 0.4300372898578644
Iteration 114: Loss = 0.4300006330013275
Iteration 115: Loss = 0.4299643933773041
Iteration 116: Loss = 0.42992860078811646
Iteration 117: Loss = 0.42989328503608704
Iteration 118: Loss = 0.4298584759235382
Iteration 119: Loss = 0.42982402443885803
Iteration 120: Loss = 0.4297899901866913
Iteration 121: Loss = 0.4297563135623932
Iteration 122: Loss = 0.4297230839729309
Iteration 123: Loss = 0.4296901226043701
Iteration 124: Loss = 0.42965763807296753
Iteration 125: Loss = 0.42962557077407837
Iteration 126: Loss = 0.42959386110305786
Iteration 127: Loss = 0.42956244945526123
Iteration 128: Loss = 0.429531455039978
Iteration 129: Loss = 0.42950084805488586
Iteration 130: Loss = 0.4294705390930176
Iteration 131: Loss = 0.42944052815437317
Iteration 132: Loss = 0.4294106960296631
Iteration 133: Loss = 0.4293813407421112
Iteration 134: Loss = 0.42935216426849365
Iteration 135: Loss = 0.42932331562042236
Iteration 136: Loss = 0.4292945861816406
Iteration 137: Loss = 0.42926618456840515
Iteration 138: Loss = 0.429237961769104
Iteration 139: Loss = 0.42921000719070435
Iteration 140: Loss = 0.4291822016239166
Iteration 141: Loss = 0.42915451526641846
Iteration 142: Loss = 0.429127037525177
Iteration 143: Loss = 0.4290998876094818
Iteration 144: Loss = 0.4290728271007538
Iteration 145: Loss = 0.4290459454059601
Iteration 146: Loss = 0.4290192127227783
Iteration 147: Loss = 0.4289926290512085
Iteration 148: Loss = 0.4289661943912506
Iteration 149: Loss = 0.4289397895336151
Iteration 150: Loss = 0.42891350388526917
Iteration 151: Loss = 0.428887277841568
Iteration 152: Loss = 0.42886117100715637
Iteration 153: Loss = 0.4288351237773895
Iteration 154: Loss = 0.42880937457084656
Iteration 155: Loss = 0.4287836253643036
Iteration 156: Loss = 0.4287579357624054
Iteration 157: Loss = 0.428732305765152
Iteration 158: Loss = 0.42870667576789856
Iteration 159: Loss = 0.42868107557296753
Iteration 160: Loss = 0.4286556839942932
Iteration 161: Loss = 0.4286303222179413
Iteration 162: Loss = 0.4286050498485565
Iteration 163: Loss = 0.42857974767684937
Iteration 164: Loss = 0.4285544157028198
Iteration 165: Loss = 0.42852911353111267
Iteration 166: Loss = 0.42850378155708313
Iteration 167: Loss = 0.4284784495830536
Iteration 168: Loss = 0.4284532070159912
Iteration 169: Loss = 0.42842793464660645
Iteration 170: Loss = 0.42840275168418884
Iteration 171: Loss = 0.4283774793148041
Iteration 172: Loss = 0.42835214734077454
Iteration 173: Loss = 0.4283267855644226
Iteration 174: Loss = 0.42830145359039307
Iteration 175: Loss = 0.4282759726047516
Iteration 176: Loss = 0.4282504618167877
Iteration 177: Loss = 0.42822495102882385
Iteration 178: Loss = 0.4281994104385376
Iteration 179: Loss = 0.42817381024360657
Iteration 180: Loss = 0.4281481206417084
Iteration 181: Loss = 0.4281224012374878
Iteration 182: Loss = 0.42809662222862244
Iteration 183: Loss = 0.4280708134174347
Iteration 184: Loss = 0.428044855594635
Iteration 185: Loss = 0.4280189275741577
Iteration 186: Loss = 0.42799288034439087
Iteration 187: Loss = 0.42796680331230164
Iteration 188: Loss = 0.4279405474662781
Iteration 189: Loss = 0.42791423201560974
Iteration 190: Loss = 0.4278879165649414
Iteration 191: Loss = 0.4278615117073059
Iteration 192: Loss = 0.4278349280357361
Iteration 193: Loss = 0.42780837416648865
Iteration 194: Loss = 0.42778173089027405
Iteration 195: Loss = 0.4277549386024475
Iteration 196: Loss = 0.42772820591926575
Iteration 197: Loss = 0.4277012050151825
Iteration 198: Loss = 0.4276742935180664
Iteration 199: Loss = 0.4276471734046936
Iteration 200: Loss = 0.427619993686676
Iteration 201: Loss = 0.4275927245616913
Iteration 202: Loss = 0.4275652766227722
Iteration 203: Loss = 0.4275377690792084
Iteration 204: Loss = 0.42751020193099976
Iteration 205: Loss = 0.4274824559688568
Iteration 206: Loss = 0.4274545907974243
Iteration 207: Loss = 0.42742660641670227
Iteration 208: Loss = 0.42739859223365784
Iteration 209: Loss = 0.4273703694343567
Iteration 210: Loss = 0.42734211683273315
Iteration 211: Loss = 0.42731377482414246
Iteration 212: Loss = 0.4272852838039398
Iteration 213: Loss = 0.4272567331790924
Iteration 214: Loss = 0.42722806334495544
Iteration 215: Loss = 0.42719924449920654
Iteration 216: Loss = 0.4271703064441681
Iteration 217: Loss = 0.42714130878448486
Iteration 218: Loss = 0.42711207270622253
Iteration 219: Loss = 0.42708277702331543
Iteration 220: Loss = 0.42705339193344116
Iteration 221: Loss = 0.42702391743659973
Iteration 222: Loss = 0.42699432373046875
Iteration 223: Loss = 0.42696458101272583
Iteration 224: Loss = 0.4269348084926605
Iteration 225: Loss = 0.4269048571586609
Iteration 226: Loss = 0.4268747568130493
Iteration 227: Loss = 0.42684459686279297
Iteration 228: Loss = 0.42681437730789185
Iteration 229: Loss = 0.426783949136734
Iteration 230: Loss = 0.4267534911632538
Iteration 231: Loss = 0.426722913980484
Iteration 232: Loss = 0.4266921877861023
Iteration 233: Loss = 0.42666131258010864
Iteration 234: Loss = 0.42663031816482544
Iteration 235: Loss = 0.4265992343425751
Iteration 236: Loss = 0.42656806111335754
Iteration 237: Loss = 0.4265367388725281
Iteration 238: Loss = 0.42650535702705383
Iteration 239: Loss = 0.42647379636764526
Iteration 240: Loss = 0.42644208669662476
Iteration 241: Loss = 0.4264103174209595
Iteration 242: Loss = 0.42637839913368225
Iteration 243: Loss = 0.4263463318347931
Iteration 244: Loss = 0.42631417512893677
Iteration 245: Loss = 0.42628195881843567
Iteration 246: Loss = 0.42624959349632263
Iteration 247: Loss = 0.42621710896492004
Iteration 248: Loss = 0.42618444561958313
Iteration 249: Loss = 0.42615175247192383
Iteration 250: Loss = 0.4261188805103302
Iteration 251: Loss = 0.426085889339447
Iteration 252: Loss = 0.42605268955230713
Iteration 253: Loss = 0.42601945996284485
Iteration 254: Loss = 0.42598608136177063
Iteration 255: Loss = 0.425952672958374
Iteration 256: Loss = 0.4259189963340759
Iteration 257: Loss = 0.42588526010513306
Iteration 258: Loss = 0.42585137486457825
Iteration 259: Loss = 0.4258174002170563
Iteration 260: Loss = 0.42578330636024475
Iteration 261: Loss = 0.4257490336894989
Iteration 262: Loss = 0.4257146418094635
Iteration 263: Loss = 0.4256801903247833
Iteration 264: Loss = 0.4256455898284912
Iteration 265: Loss = 0.42561087012290955
Iteration 266: Loss = 0.42557603120803833
Iteration 267: Loss = 0.42554113268852234
Iteration 268: Loss = 0.425506055355072
Iteration 269: Loss = 0.425470769405365
Iteration 270: Loss = 0.4254354238510132
Iteration 271: Loss = 0.4253999590873718
Iteration 272: Loss = 0.4253643751144409
Iteration 273: Loss = 0.42532867193222046
Iteration 274: Loss = 0.42529281973838806
Iteration 275: Loss = 0.4252568781375885
Iteration 276: Loss = 0.4252208471298218
Iteration 277: Loss = 0.4251846373081207
Iteration 278: Loss = 0.42514827847480774
Iteration 279: Loss = 0.4251117408275604
Iteration 280: Loss = 0.4250752031803131
Iteration 281: Loss = 0.42503851652145386
Iteration 282: Loss = 0.42500171065330505
Iteration 283: Loss = 0.4249647259712219
Iteration 284: Loss = 0.42492762207984924
Iteration 285: Loss = 0.4248906075954437
Iteration 286: Loss = 0.42485326528549194
Iteration 287: Loss = 0.424815833568573
Iteration 288: Loss = 0.42477819323539734
Iteration 289: Loss = 0.42474058270454407
Iteration 290: Loss = 0.42470279335975647
Iteration 291: Loss = 0.42466479539871216
Iteration 292: Loss = 0.42462679743766785
Iteration 293: Loss = 0.4245886504650116
Iteration 294: Loss = 0.424550324678421
Iteration 295: Loss = 0.42451196908950806
Iteration 296: Loss = 0.4244733452796936
Iteration 297: Loss = 0.42443472146987915
Iteration 298: Loss = 0.42439600825309753
Iteration 299: Loss = 0.4243570566177368
Iteration 300: Loss = 0.42431798577308655
Iteration 301: Loss = 0.4242788255214691
Iteration 302: Loss = 0.4242395758628845
Iteration 303: Loss = 0.424200177192688
Iteration 304: Loss = 0.42416059970855713
Iteration 305: Loss = 0.4241209924221039
Iteration 306: Loss = 0.42408132553100586
Iteration 307: Loss = 0.42404142022132874
Iteration 308: Loss = 0.42400139570236206
Iteration 309: Loss = 0.4239614009857178
Iteration 310: Loss = 0.4239211976528168
Iteration 311: Loss = 0.4238808751106262
Iteration 312: Loss = 0.42384034395217896
Iteration 313: Loss = 0.42379966378211975
Iteration 314: Loss = 0.4237590730190277
Iteration 315: Loss = 0.42371833324432373
Iteration 316: Loss = 0.42367732524871826
Iteration 317: Loss = 0.42363619804382324
Iteration 318: Loss = 0.42359498143196106
Iteration 319: Loss = 0.4235537350177765
Iteration 320: Loss = 0.4235123097896576
Iteration 321: Loss = 0.423470675945282
Iteration 322: Loss = 0.42342907190322876
Iteration 323: Loss = 0.4233873784542084
Iteration 324: Loss = 0.4233454763889313
Iteration 325: Loss = 0.42330339550971985
Iteration 326: Loss = 0.42326125502586365
Iteration 327: Loss = 0.4232190251350403
Iteration 328: Loss = 0.423176646232605
Iteration 329: Loss = 0.4231342673301697
Iteration 330: Loss = 0.4230916202068329
Iteration 331: Loss = 0.4230489432811737
Iteration 332: Loss = 0.42300617694854736
Iteration 333: Loss = 0.42296332120895386
Iteration 334: Loss = 0.4229203164577484
Iteration 335: Loss = 0.4228771924972534
Iteration 336: Loss = 0.4228339195251465
Iteration 337: Loss = 0.42279052734375
Iteration 338: Loss = 0.42274710536003113
Iteration 339: Loss = 0.4227035641670227
Iteration 340: Loss = 0.42265990376472473
Iteration 341: Loss = 0.4226161241531372
Iteration 342: Loss = 0.42257219552993774
Iteration 343: Loss = 0.42252814769744873
Iteration 344: Loss = 0.42248407006263733
Iteration 345: Loss = 0.4224398732185364
Iteration 346: Loss = 0.4223955273628235
Iteration 347: Loss = 0.42235106229782104
Iteration 348: Loss = 0.4223066568374634
Iteration 349: Loss = 0.4222620129585266
Iteration 350: Loss = 0.4222172200679779
Iteration 351: Loss = 0.4221723973751068
Iteration 352: Loss = 0.42212751507759094
Iteration 353: Loss = 0.42208242416381836
Iteration 354: Loss = 0.4220373034477234
Iteration 355: Loss = 0.4219920039176941
Iteration 356: Loss = 0.4219466745853424
Iteration 357: Loss = 0.42190128564834595
Iteration 358: Loss = 0.42185571789741516
Iteration 359: Loss = 0.421810120344162
Iteration 360: Loss = 0.4217643737792969
Iteration 361: Loss = 0.421718567609787
Iteration 362: Loss = 0.42167267203330994
Iteration 363: Loss = 0.42162659764289856
Iteration 364: Loss = 0.4215804934501648
Iteration 365: Loss = 0.4215342402458191
Iteration 366: Loss = 0.421487957239151
Iteration 367: Loss = 0.42144152522087097
Iteration 368: Loss = 0.42139503359794617
Iteration 369: Loss = 0.4213483929634094
Iteration 370: Loss = 0.42130181193351746
Iteration 371: Loss = 0.4212549924850464
Iteration 372: Loss = 0.42120808362960815
Iteration 373: Loss = 0.42116111516952515
Iteration 374: Loss = 0.421114057302475
Iteration 375: Loss = 0.4210668206214905
Iteration 376: Loss = 0.4210195541381836
Iteration 377: Loss = 0.42097216844558716
Iteration 378: Loss = 0.42092475295066833
Iteration 379: Loss = 0.42087721824645996
Iteration 380: Loss = 0.4208295941352844
Iteration 381: Loss = 0.4207818806171417
Iteration 382: Loss = 0.42073410749435425
Iteration 383: Loss = 0.4206862449645996
Iteration 384: Loss = 0.42063820362091064
Iteration 385: Loss = 0.4205901622772217
Iteration 386: Loss = 0.4205419719219208
Iteration 387: Loss = 0.4204937815666199
Iteration 388: Loss = 0.42044544219970703
Iteration 389: Loss = 0.420397013425827
Iteration 390: Loss = 0.4203484356403351
Iteration 391: Loss = 0.42029982805252075
Iteration 392: Loss = 0.42025113105773926
Iteration 393: Loss = 0.4202023446559906
Iteration 394: Loss = 0.42015340924263
Iteration 395: Loss = 0.420104444026947
Iteration 396: Loss = 0.4200552999973297
Iteration 397: Loss = 0.4200061559677124
Iteration 398: Loss = 0.4199569821357727
Iteration 399: Loss = 0.4199075996875763
Iteration 400: Loss = 0.41985830664634705
Iteration 401: Loss = 0.4198088049888611
Iteration 402: Loss = 0.4197593331336975
Iteration 403: Loss = 0.419709712266922
Iteration 404: Loss = 0.41965994238853455
Iteration 405: Loss = 0.41961026191711426
Iteration 406: Loss = 0.4195604622364044
Iteration 407: Loss = 0.41951045393943787
Iteration 408: Loss = 0.4194604456424713
Iteration 409: Loss = 0.41941046714782715
Iteration 410: Loss = 0.4193602204322815
Iteration 411: Loss = 0.419310063123703
Iteration 412: Loss = 0.4192596971988678
Iteration 413: Loss = 0.4192095398902893
Iteration 414: Loss = 0.4191589951515198
Iteration 415: Loss = 0.419108510017395
Iteration 416: Loss = 0.4190579950809479
Iteration 417: Loss = 0.41900739073753357
Iteration 418: Loss = 0.4189567267894745
Iteration 419: Loss = 0.41890600323677063
Iteration 420: Loss = 0.418855220079422
Iteration 421: Loss = 0.4188043177127838
Iteration 422: Loss = 0.41875341534614563
Iteration 423: Loss = 0.4187023341655731
Iteration 424: Loss = 0.41865119338035583
Iteration 425: Loss = 0.4185999631881714
Iteration 426: Loss = 0.4185487627983093
Iteration 427: Loss = 0.4184975326061249
Iteration 428: Loss = 0.4184461534023285
Iteration 429: Loss = 0.4183947443962097
Iteration 430: Loss = 0.41834330558776855
Iteration 431: Loss = 0.41829177737236023
Iteration 432: Loss = 0.4182400703430176
Iteration 433: Loss = 0.41818851232528687
Iteration 434: Loss = 0.4181367754936218
Iteration 435: Loss = 0.4180849492549896
Iteration 436: Loss = 0.4180332124233246
Iteration 437: Loss = 0.41798144578933716
Iteration 438: Loss = 0.4179295301437378
Iteration 439: Loss = 0.4178774356842041
Iteration 440: Loss = 0.41782572865486145
Iteration 441: Loss = 0.4177737236022949
Iteration 442: Loss = 0.4177214503288269
Iteration 443: Loss = 0.4176693558692932
Iteration 444: Loss = 0.4176172614097595
Iteration 445: Loss = 0.41756510734558105
Iteration 446: Loss = 0.4175129234790802
Iteration 447: Loss = 0.4174605906009674
Iteration 448: Loss = 0.4174083471298218
Iteration 449: Loss = 0.417356014251709
Iteration 450: Loss = 0.4173036515712738
Iteration 451: Loss = 0.4172511696815491
Iteration 452: Loss = 0.41719862818717957
Iteration 453: Loss = 0.4171460270881653
Iteration 454: Loss = 0.41709351539611816
Iteration 455: Loss = 0.4170408844947815
Iteration 456: Loss = 0.4169883131980896
Iteration 457: Loss = 0.41693565249443054
Iteration 458: Loss = 0.41688308119773865
Iteration 459: Loss = 0.4168303608894348
Iteration 460: Loss = 0.4167775511741638
Iteration 461: Loss = 0.4167247712612152
Iteration 462: Loss = 0.4166719913482666
Iteration 463: Loss = 0.41661903262138367
Iteration 464: Loss = 0.41656622290611267
Iteration 465: Loss = 0.4165134131908417
Iteration 466: Loss = 0.4164605438709259
Iteration 467: Loss = 0.41640758514404297
Iteration 468: Loss = 0.4163547456264496
Iteration 469: Loss = 0.4163016378879547
Iteration 470: Loss = 0.416248619556427
Iteration 471: Loss = 0.4161956310272217
Iteration 472: Loss = 0.4161425828933716
Iteration 473: Loss = 0.41608962416648865
Iteration 474: Loss = 0.4160365164279938
Iteration 475: Loss = 0.4159834384918213
Iteration 476: Loss = 0.4159304201602936
Iteration 477: Loss = 0.41587719321250916
Iteration 478: Loss = 0.4158239960670471
Iteration 479: Loss = 0.4157707393169403
Iteration 480: Loss = 0.4157175123691559
Iteration 481: Loss = 0.41566431522369385
Iteration 482: Loss = 0.4156111478805542
Iteration 483: Loss = 0.41555771231651306
Iteration 484: Loss = 0.4155046343803406
Iteration 485: Loss = 0.41545137763023376
Iteration 486: Loss = 0.4153980016708374
Iteration 487: Loss = 0.41534456610679626
Iteration 488: Loss = 0.41529127955436707
Iteration 489: Loss = 0.41523802280426025
Iteration 490: Loss = 0.41518470644950867
Iteration 491: Loss = 0.4151313006877899
Iteration 492: Loss = 0.41507789492607117
Iteration 493: Loss = 0.4150245189666748
Iteration 494: Loss = 0.4149712026119232
Iteration 495: Loss = 0.4149177670478821
Iteration 496: Loss = 0.4148644804954529
Iteration 497: Loss = 0.41481107473373413
Iteration 498: Loss = 0.41475769877433777
Iteration 499: Loss = 0.414704293012619
Iteration 500: Loss = 0.4146508276462555
Iteration 501: Loss = 0.41459736227989197
Iteration 502: Loss = 0.41454383730888367
Iteration 503: Loss = 0.4144902527332306
Iteration 504: Loss = 0.4144367575645447
Iteration 505: Loss = 0.41438326239585876
Iteration 506: Loss = 0.41432973742485046
Iteration 507: Loss = 0.4142763316631317
Iteration 508: Loss = 0.4142228066921234
Iteration 509: Loss = 0.41416919231414795
Iteration 510: Loss = 0.41411566734313965
Iteration 511: Loss = 0.41406211256980896
Iteration 512: Loss = 0.4140087068080902
Iteration 513: Loss = 0.4139549434185028
Iteration 514: Loss = 0.4139016270637512
Iteration 515: Loss = 0.41384828090667725
Iteration 516: Loss = 0.413794606924057
Iteration 517: Loss = 0.4137409031391144
Iteration 518: Loss = 0.4136873185634613
Iteration 519: Loss = 0.41363418102264404
Iteration 520: Loss = 0.41358035802841187
Iteration 521: Loss = 0.4135267734527588
Iteration 522: Loss = 0.4134732484817505
Iteration 523: Loss = 0.4134196937084198
Iteration 524: Loss = 0.4133661389350891
Iteration 525: Loss = 0.41331249475479126
Iteration 526: Loss = 0.4132590591907501
Iteration 527: Loss = 0.4132053256034851
Iteration 528: Loss = 0.4131518006324768
Iteration 529: Loss = 0.4130982458591461
Iteration 530: Loss = 0.41304492950439453
Iteration 531: Loss = 0.412991464138031
Iteration 532: Loss = 0.4129379391670227
Iteration 533: Loss = 0.41288429498672485
Iteration 534: Loss = 0.41283079981803894
Iteration 535: Loss = 0.4127773642539978
Iteration 536: Loss = 0.4127237796783447
Iteration 537: Loss = 0.412670373916626
Iteration 538: Loss = 0.4126169681549072
Iteration 539: Loss = 0.4125635325908661
Iteration 540: Loss = 0.41251009702682495
Iteration 541: Loss = 0.4124566614627838
Iteration 542: Loss = 0.41240328550338745
Iteration 543: Loss = 0.41234996914863586
Iteration 544: Loss = 0.4122965633869171
Iteration 545: Loss = 0.412243127822876
Iteration 546: Loss = 0.41218966245651245
Iteration 547: Loss = 0.41213610768318176
Iteration 548: Loss = 0.4120831787586212
Iteration 549: Loss = 0.4120297133922577
Iteration 550: Loss = 0.41197606921195984
Iteration 551: Loss = 0.4119229018688202
Iteration 552: Loss = 0.41186949610710144
Iteration 553: Loss = 0.4118163287639618
Iteration 554: Loss = 0.4117630422115326
Iteration 555: Loss = 0.411709725856781
Iteration 556: Loss = 0.4116564691066742
Iteration 557: Loss = 0.41160327196121216
Iteration 558: Loss = 0.4115500748157501
Iteration 559: Loss = 0.41149696707725525
Iteration 560: Loss = 0.41144391894340515
Iteration 561: Loss = 0.4113907516002655
Iteration 562: Loss = 0.41133761405944824
Iteration 563: Loss = 0.41128453612327576
Iteration 564: Loss = 0.41123148798942566
Iteration 565: Loss = 0.41117843985557556
Iteration 566: Loss = 0.4111252725124359
Iteration 567: Loss = 0.41107213497161865
Iteration 568: Loss = 0.41101908683776855
Iteration 569: Loss = 0.4109661281108856
Iteration 570: Loss = 0.4109129011631012
Iteration 571: Loss = 0.4108598828315735
Iteration 572: Loss = 0.4108069837093353
Iteration 573: Loss = 0.41075384616851807
Iteration 574: Loss = 0.4107009470462799
Iteration 575: Loss = 0.41064801812171936
Iteration 576: Loss = 0.4105950593948364
Iteration 577: Loss = 0.4105421006679535
Iteration 578: Loss = 0.41048914194107056
Iteration 579: Loss = 0.4104362726211548
Iteration 580: Loss = 0.41038328409194946
Iteration 581: Loss = 0.41033047437667847
Iteration 582: Loss = 0.4102776348590851
Iteration 583: Loss = 0.4102247953414917
Iteration 584: Loss = 0.41017189621925354
Iteration 585: Loss = 0.4101189970970154
Iteration 586: Loss = 0.41006603837013245
Iteration 587: Loss = 0.410013347864151
Iteration 588: Loss = 0.4099603593349457
Iteration 589: Loss = 0.4099076986312866
Iteration 590: Loss = 0.4098548889160156
Iteration 591: Loss = 0.40980198979377747
Iteration 592: Loss = 0.409749299287796
Iteration 593: Loss = 0.40969640016555786
Iteration 594: Loss = 0.4096435606479645
Iteration 595: Loss = 0.40959060192108154
Iteration 596: Loss = 0.4095378518104553
Iteration 597: Loss = 0.4094850420951843
Iteration 598: Loss = 0.4094322919845581
Iteration 599: Loss = 0.40937939286231995
Iteration 600: Loss = 0.40932658314704895
Iteration 601: Loss = 0.40927377343177795
Iteration 602: Loss = 0.40922093391418457
Iteration 603: Loss = 0.40916797518730164
Iteration 604: Loss = 0.40911492705345154
Iteration 605: Loss = 0.4090620279312134
Iteration 606: Loss = 0.4090089499950409
Iteration 607: Loss = 0.4089564085006714
Iteration 608: Loss = 0.40890341997146606
Iteration 609: Loss = 0.40885019302368164
Iteration 610: Loss = 0.40879732370376587
Iteration 611: Loss = 0.40874427556991577
Iteration 612: Loss = 0.4086911380290985
Iteration 613: Loss = 0.4086379110813141
Iteration 614: Loss = 0.40858474373817444
Iteration 615: Loss = 0.40853163599967957
Iteration 616: Loss = 0.4084784686565399
Iteration 617: Loss = 0.40842506289482117
Iteration 618: Loss = 0.40837162733078003
Iteration 619: Loss = 0.4083181619644165
Iteration 620: Loss = 0.4082646369934082
Iteration 621: Loss = 0.4082110822200775
Iteration 622: Loss = 0.4081576466560364
Iteration 623: Loss = 0.40810394287109375
Iteration 624: Loss = 0.4080498516559601
Iteration 625: Loss = 0.40799659490585327
Iteration 626: Loss = 0.4079427421092987
Iteration 627: Loss = 0.4078885018825531
Iteration 628: Loss = 0.40783432126045227
Iteration 629: Loss = 0.40778079628944397
Iteration 630: Loss = 0.40772581100463867
Iteration 631: Loss = 0.4076713025569916
Iteration 632: Loss = 0.4076169431209564
Iteration 633: Loss = 0.40756237506866455
Iteration 634: Loss = 0.4075075387954712
Iteration 635: Loss = 0.4074525237083435
Iteration 636: Loss = 0.4073975682258606
Iteration 637: Loss = 0.40734246373176575
Iteration 638: Loss = 0.4072871208190918
Iteration 639: Loss = 0.4072313606739044
Iteration 640: Loss = 0.4071755111217499
Iteration 641: Loss = 0.4071195721626282
Iteration 642: Loss = 0.4070633053779602
Iteration 643: Loss = 0.4070068895816803
Iteration 644: Loss = 0.4069502055644989
Iteration 645: Loss = 0.40689384937286377
Iteration 646: Loss = 0.4068368673324585
Iteration 647: Loss = 0.40677937865257263
Iteration 648: Loss = 0.406721830368042
Iteration 649: Loss = 0.4066643714904785
Iteration 650: Loss = 0.40660563111305237
Iteration 651: Loss = 0.40654727816581726
Iteration 652: Loss = 0.4064887762069702
Iteration 653: Loss = 0.40642961859703064
Iteration 654: Loss = 0.4063701033592224
Iteration 655: Loss = 0.40631046891212463
Iteration 656: Loss = 0.40625038743019104
Iteration 657: Loss = 0.40618982911109924
Iteration 658: Loss = 0.406128853559494
Iteration 659: Loss = 0.4060673117637634
Iteration 660: Loss = 0.4060054421424866
Iteration 661: Loss = 0.40594297647476196
Iteration 662: Loss = 0.4058799147605896
Iteration 663: Loss = 0.40581628680229187
Iteration 664: Loss = 0.405752569437027
Iteration 665: Loss = 0.40568751096725464
Iteration 666: Loss = 0.40562260150909424
Iteration 667: Loss = 0.4055568277835846
Iteration 668: Loss = 0.4054899513721466
Iteration 669: Loss = 0.40542250871658325
Iteration 670: Loss = 0.4053545594215393
Iteration 671: Loss = 0.40528619289398193
Iteration 672: Loss = 0.4052159786224365
Iteration 673: Loss = 0.4051458537578583
Iteration 674: Loss = 0.4050748646259308
Iteration 675: Loss = 0.4050023853778839
Iteration 676: Loss = 0.40492892265319824
Iteration 677: Loss = 0.40485480427742004
Iteration 678: Loss = 0.40477994084358215
Iteration 679: Loss = 0.40470337867736816
Iteration 680: Loss = 0.4046255052089691
Iteration 681: Loss = 0.404546320438385
Iteration 682: Loss = 0.404465913772583
Iteration 683: Loss = 0.40438365936279297
Iteration 684: Loss = 0.40430009365081787
Iteration 685: Loss = 0.40421491861343384
Iteration 686: Loss = 0.40412771701812744
Iteration 687: Loss = 0.40403905510902405
Iteration 688: Loss = 0.403948575258255
Iteration 689: Loss = 0.4038563072681427
Iteration 690: Loss = 0.40376201272010803
Iteration 691: Loss = 0.40366512537002563
Iteration 692: Loss = 0.40356630086898804
Iteration 693: Loss = 0.4034649431705475
Iteration 694: Loss = 0.40336060523986816
Iteration 695: Loss = 0.40325361490249634
Iteration 696: Loss = 0.40314388275146484
Iteration 697: Loss = 0.40303099155426025
Iteration 698: Loss = 0.40291494131088257
Iteration 699: Loss = 0.40279561281204224
Iteration 700: Loss = 0.4026733338832855
Iteration 701: Loss = 0.4025472402572632
Iteration 702: Loss = 0.4024176001548767
Iteration 703: Loss = 0.4022841453552246
Iteration 704: Loss = 0.4021458327770233
Iteration 705: Loss = 0.40200260281562805
Iteration 706: Loss = 0.4018549621105194
Iteration 707: Loss = 0.4017014801502228
Iteration 708: Loss = 0.40154388546943665
Iteration 709: Loss = 0.4013794958591461
Iteration 710: Loss = 0.40121030807495117
Iteration 711: Loss = 0.40103498101234436
Iteration 712: Loss = 0.40085136890411377
Iteration 713: Loss = 0.4006606638431549
Iteration 714: Loss = 0.4004628360271454
Iteration 715: Loss = 0.4002571403980255
Iteration 716: Loss = 0.4000418484210968
Iteration 717: Loss = 0.3998192548751831
Iteration 718: Loss = 0.3995864689350128
Iteration 719: Loss = 0.39934372901916504
Iteration 720: Loss = 0.3990910053253174
Iteration 721: Loss = 0.39882707595825195
Iteration 722: Loss = 0.3985515236854553
Iteration 723: Loss = 0.39826491475105286
Iteration 724: Loss = 0.39796534180641174
Iteration 725: Loss = 0.397653192281723
Iteration 726: Loss = 0.3973280191421509
Iteration 727: Loss = 0.3969893157482147
Iteration 728: Loss = 0.3966362774372101
Iteration 729: Loss = 0.3962686359882355
Iteration 730: Loss = 0.39588674902915955
Iteration 731: Loss = 0.39548933506011963
Iteration 732: Loss = 0.3950764536857605
Iteration 733: Loss = 0.39464667439460754
Iteration 734: Loss = 0.39420008659362793
Iteration 735: Loss = 0.3937363624572754
Iteration 736: Loss = 0.3932562470436096
Iteration 737: Loss = 0.3927607536315918
Iteration 738: Loss = 0.39224979281425476
Iteration 739: Loss = 0.3917248547077179
Iteration 740: Loss = 0.39118531346321106
Iteration 741: Loss = 0.39063403010368347
Iteration 742: Loss = 0.3900696039199829
Iteration 743: Loss = 0.3894944489002228
Iteration 744: Loss = 0.38890963792800903
Iteration 745: Loss = 0.3883146047592163
Iteration 746: Loss = 0.38771259784698486
Iteration 747: Loss = 0.3871053457260132
Iteration 748: Loss = 0.38649672269821167
Iteration 749: Loss = 0.3858889639377594
Iteration 750: Loss = 0.3852849304676056
Iteration 751: Loss = 0.38468822836875916
Iteration 752: Loss = 0.3841020166873932
Iteration 753: Loss = 0.3835257589817047
Iteration 754: Loss = 0.3829624056816101
Iteration 755: Loss = 0.3824155032634735
Iteration 756: Loss = 0.38189053535461426
Iteration 757: Loss = 0.38138696551322937
Iteration 758: Loss = 0.3809058964252472
Iteration 759: Loss = 0.38044247031211853
Iteration 760: Loss = 0.37999311089515686
Iteration 761: Loss = 0.3795539140701294
Iteration 762: Loss = 0.3791208565235138
Iteration 763: Loss = 0.378685861825943
Iteration 764: Loss = 0.37824565172195435
Iteration 765: Loss = 0.3777948021888733
Iteration 766: Loss = 0.37733176350593567
Iteration 767: Loss = 0.37685418128967285
Iteration 768: Loss = 0.37636151909828186
Iteration 769: Loss = 0.3758571147918701
Iteration 770: Loss = 0.3753419816493988
Iteration 771: Loss = 0.3748185932636261
Iteration 772: Loss = 0.374291330575943
Iteration 773: Loss = 0.3737609386444092
Iteration 774: Loss = 0.37322911620140076
Iteration 775: Loss = 0.3726974427700043
Iteration 776: Loss = 0.37216809391975403
Iteration 777: Loss = 0.371640145778656
Iteration 778: Loss = 0.3711135685443878
Iteration 779: Loss = 0.37058818340301514
Iteration 780: Loss = 0.3700637221336365
Iteration 781: Loss = 0.369536429643631
Iteration 782: Loss = 0.36900854110717773
Iteration 783: Loss = 0.36847633123397827
Iteration 784: Loss = 0.367942214012146
Iteration 785: Loss = 0.36740338802337646
Iteration 786: Loss = 0.3668585419654846
Iteration 787: Loss = 0.36631008982658386
Iteration 788: Loss = 0.36575591564178467
Iteration 789: Loss = 0.36519676446914673
Iteration 790: Loss = 0.36463433504104614
Iteration 791: Loss = 0.36406856775283813
Iteration 792: Loss = 0.36349913477897644
Iteration 793: Loss = 0.3629264831542969
Iteration 794: Loss = 0.3623514473438263
Iteration 795: Loss = 0.36177319288253784
Iteration 796: Loss = 0.36119315028190613
Iteration 797: Loss = 0.3606095612049103
Iteration 798: Loss = 0.3600253760814667
Iteration 799: Loss = 0.359437495470047
Iteration 800: Loss = 0.3588467538356781
Iteration 801: Loss = 0.3582555055618286
Iteration 802: Loss = 0.35765790939331055
Iteration 803: Loss = 0.35705921053886414
Iteration 804: Loss = 0.3564569056034088
Iteration 805: Loss = 0.35585030913352966
Iteration 806: Loss = 0.3552416265010834
Iteration 807: Loss = 0.35462915897369385
Iteration 808: Loss = 0.35401254892349243
Iteration 809: Loss = 0.35339459776878357
Iteration 810: Loss = 0.352771520614624
Iteration 811: Loss = 0.35214877128601074
Iteration 812: Loss = 0.35152149200439453
Iteration 813: Loss = 0.3508911728858948
Iteration 814: Loss = 0.3502604365348816
Iteration 815: Loss = 0.3496231436729431
Iteration 816: Loss = 0.34898635745048523
Iteration 817: Loss = 0.3483460545539856
Iteration 818: Loss = 0.34770336747169495
Iteration 819: Loss = 0.34705787897109985
Iteration 820: Loss = 0.346409410238266
Iteration 821: Loss = 0.34575846791267395
Iteration 822: Loss = 0.34510475397109985
Iteration 823: Loss = 0.3444489538669586
Iteration 824: Loss = 0.34379053115844727
Iteration 825: Loss = 0.3431297540664673
Iteration 826: Loss = 0.34246668219566345
Iteration 827: Loss = 0.3418010473251343
Iteration 828: Loss = 0.341133177280426
Iteration 829: Loss = 0.3404633104801178
Iteration 830: Loss = 0.3397912085056305
Iteration 831: Loss = 0.3391169011592865
Iteration 832: Loss = 0.3384406268596649
Iteration 833: Loss = 0.33776208758354187
Iteration 834: Loss = 0.3370814919471741
Iteration 835: Loss = 0.3363988399505615
Iteration 836: Loss = 0.3357149064540863
Iteration 837: Loss = 0.3350280821323395
Iteration 838: Loss = 0.33433911204338074
Iteration 839: Loss = 0.33364981412887573
Iteration 840: Loss = 0.332955926656723
Iteration 841: Loss = 0.3322630822658539
Iteration 842: Loss = 0.3315655291080475
Iteration 843: Loss = 0.3308674693107605
Iteration 844: Loss = 0.33016711473464966
Iteration 845: Loss = 0.3294653296470642
Iteration 846: Loss = 0.3287627696990967
Iteration 847: Loss = 0.328057199716568
Iteration 848: Loss = 0.32735055685043335
Iteration 849: Loss = 0.32664138078689575
Iteration 850: Loss = 0.3259304463863373
Iteration 851: Loss = 0.3252182900905609
Iteration 852: Loss = 0.32450467348098755
Iteration 853: Loss = 0.32378968596458435
Iteration 854: Loss = 0.3230726420879364
Iteration 855: Loss = 0.32235437631607056
Iteration 856: Loss = 0.32163479924201965
Iteration 857: Loss = 0.32091325521469116
Iteration 858: Loss = 0.32019031047821045
Iteration 859: Loss = 0.31946638226509094
Iteration 860: Loss = 0.31874072551727295
Iteration 861: Loss = 0.31801387667655945
Iteration 862: Loss = 0.3172852098941803
Iteration 863: Loss = 0.3165567219257355
Iteration 864: Loss = 0.31582531332969666
Iteration 865: Loss = 0.3150945007801056
Iteration 866: Loss = 0.3143611252307892
Iteration 867: Loss = 0.3136279582977295
Iteration 868: Loss = 0.31289222836494446
Iteration 869: Loss = 0.31215614080429077
Iteration 870: Loss = 0.3114188611507416
Iteration 871: Loss = 0.31068122386932373
Iteration 872: Loss = 0.3099415898323059
Iteration 873: Loss = 0.30920085310935974
Iteration 874: Loss = 0.3084593117237091
Iteration 875: Loss = 0.3077167570590973
Iteration 876: Loss = 0.3069731891155243
Iteration 877: Loss = 0.3062286674976349
Iteration 878: Loss = 0.30548325181007385
Iteration 879: Loss = 0.3047366738319397
Iteration 880: Loss = 0.303989440202713
Iteration 881: Loss = 0.30324119329452515
Iteration 882: Loss = 0.30249249935150146
Iteration 883: Loss = 0.3017430901527405
Iteration 884: Loss = 0.300992876291275
Iteration 885: Loss = 0.3002416491508484
Iteration 886: Loss = 0.29949048161506653
Iteration 887: Loss = 0.29873791337013245
Iteration 888: Loss = 0.2979857921600342
Iteration 889: Loss = 0.297231525182724
Iteration 890: Loss = 0.29647767543792725
Iteration 891: Loss = 0.2957228422164917
Iteration 892: Loss = 0.29496681690216064
Iteration 893: Loss = 0.2942105829715729
Iteration 894: Loss = 0.29345521330833435
Iteration 895: Loss = 0.2926981747150421
Iteration 896: Loss = 0.2919408679008484
Iteration 897: Loss = 0.29118257761001587
Iteration 898: Loss = 0.2904238998889923
Iteration 899: Loss = 0.2896649241447449
Iteration 900: Loss = 0.2889062464237213
Iteration 901: Loss = 0.288146048784256
Iteration 902: Loss = 0.28738561272621155
Iteration 903: Loss = 0.286625474691391
Iteration 904: Loss = 0.2858630120754242
Iteration 905: Loss = 0.28510329127311707
Iteration 906: Loss = 0.28433918952941895
Iteration 907: Loss = 0.2835788130760193
Iteration 908: Loss = 0.2828141152858734
Iteration 909: Loss = 0.28205326199531555
Iteration 910: Loss = 0.2812877595424652
Iteration 911: Loss = 0.2805260121822357
Iteration 912: Loss = 0.27976059913635254
Iteration 913: Loss = 0.27899882197380066
Iteration 914: Loss = 0.2782343029975891
Iteration 915: Loss = 0.2774708867073059
Iteration 916: Loss = 0.27670642733573914
Iteration 917: Loss = 0.27594494819641113
Iteration 918: Loss = 0.2751799523830414
Iteration 919: Loss = 0.27441754937171936
Iteration 920: Loss = 0.2736530005931854
Iteration 921: Loss = 0.27288997173309326
Iteration 922: Loss = 0.2721256911754608
Iteration 923: Loss = 0.27136310935020447
Iteration 924: Loss = 0.2706001400947571
Iteration 925: Loss = 0.26983699202537537
Iteration 926: Loss = 0.2690744996070862
Iteration 927: Loss = 0.26831120252609253
Iteration 928: Loss = 0.267548531293869
Iteration 929: Loss = 0.26678723096847534
Iteration 930: Loss = 0.26602479815483093
Iteration 931: Loss = 0.26526379585266113
Iteration 932: Loss = 0.2645008862018585
Iteration 933: Loss = 0.2637403607368469
Iteration 934: Loss = 0.262977659702301
Iteration 935: Loss = 0.2622174918651581
Iteration 936: Loss = 0.26145562529563904
Iteration 937: Loss = 0.26069560647010803
Iteration 938: Loss = 0.25993600487709045
Iteration 939: Loss = 0.2591765820980072
Iteration 940: Loss = 0.258417010307312
Iteration 941: Loss = 0.2576580345630646
Iteration 942: Loss = 0.2569005489349365
Iteration 943: Loss = 0.25614133477211
Iteration 944: Loss = 0.2553841769695282
Iteration 945: Loss = 0.25462645292282104
Iteration 946: Loss = 0.25386950373649597
Iteration 947: Loss = 0.2531126141548157
Iteration 948: Loss = 0.2523564398288727
Iteration 949: Loss = 0.25160083174705505
Iteration 950: Loss = 0.2508452236652374
Iteration 951: Loss = 0.2500914931297302
Iteration 952: Loss = 0.24933789670467377
Iteration 953: Loss = 0.24858488142490387
Iteration 954: Loss = 0.24783161282539368
Iteration 955: Loss = 0.2470785677433014
Iteration 956: Loss = 0.24632659554481506
Iteration 957: Loss = 0.24557669460773468
Iteration 958: Loss = 0.2448260486125946
Iteration 959: Loss = 0.24407684803009033
Iteration 960: Loss = 0.24332751333713531
Iteration 961: Loss = 0.24257943034172058
Iteration 962: Loss = 0.2418329268693924
Iteration 963: Loss = 0.2410857081413269
Iteration 964: Loss = 0.2403404712677002
Iteration 965: Loss = 0.2395961880683899
Iteration 966: Loss = 0.23885224759578705
Iteration 967: Loss = 0.23810860514640808
Iteration 968: Loss = 0.2373669445514679
Iteration 969: Loss = 0.23662686347961426
Iteration 970: Loss = 0.23588667809963226
Iteration 971: Loss = 0.23514798283576965
Iteration 972: Loss = 0.23441006243228912
Iteration 973: Loss = 0.23367391526699066
Iteration 974: Loss = 0.23293794691562653
Iteration 975: Loss = 0.23220354318618774
Iteration 976: Loss = 0.23146896064281464
Iteration 977: Loss = 0.23073692619800568
Iteration 978: Loss = 0.23000715672969818
Iteration 979: Loss = 0.2292768806219101
Iteration 980: Loss = 0.2285485863685608
Iteration 981: Loss = 0.22782090306282043
Iteration 982: Loss = 0.22709502279758453
Iteration 983: Loss = 0.2263699173927307
Iteration 984: Loss = 0.225645512342453
Iteration 985: Loss = 0.22492162883281708
Iteration 986: Loss = 0.22420060634613037
Iteration 987: Loss = 0.22348086535930634
Iteration 988: Loss = 0.22276170551776886
Iteration 989: Loss = 0.22204351425170898
Iteration 990: Loss = 0.22132638096809387
Iteration 991: Loss = 0.22061091661453247
Iteration 992: Loss = 0.21989628672599792
Iteration 993: Loss = 0.21918299794197083
Iteration 994: Loss = 0.21847128868103027
Iteration 995: Loss = 0.2177635133266449
Iteration 996: Loss = 0.21705634891986847
Iteration 997: Loss = 0.21634621918201447
Iteration 998: Loss = 0.2156430333852768
Iteration 999: Loss = 0.2149360030889511
Iteration 1000: Loss = 0.21423351764678955


Total training time (seconds): 12.61
