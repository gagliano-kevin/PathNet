Iteration 1: Loss = 0.8674599528312683
Iteration 2: Loss = 0.8556638956069946
Iteration 3: Loss = 0.8441368341445923
Iteration 4: Loss = 0.8328684568405151
Iteration 5: Loss = 0.8218385577201843
Iteration 6: Loss = 0.8110345602035522
Iteration 7: Loss = 0.8004545569419861
Iteration 8: Loss = 0.7901002168655396
Iteration 9: Loss = 0.7799726724624634
Iteration 10: Loss = 0.7700744867324829
Iteration 11: Loss = 0.7604042887687683
Iteration 12: Loss = 0.7509614825248718
Iteration 13: Loss = 0.7417478561401367
Iteration 14: Loss = 0.7327666878700256
Iteration 15: Loss = 0.7240157127380371
Iteration 16: Loss = 0.7154956459999084
Iteration 17: Loss = 0.7072054147720337
Iteration 18: Loss = 0.6991460919380188
Iteration 19: Loss = 0.6913143396377563
Iteration 20: Loss = 0.683711588382721
Iteration 21: Loss = 0.6763374209403992
Iteration 22: Loss = 0.6691900491714478
Iteration 23: Loss = 0.662269651889801
Iteration 24: Loss = 0.655573844909668
Iteration 25: Loss = 0.6491014957427979
Iteration 26: Loss = 0.6428471803665161
Iteration 27: Loss = 0.6368096470832825
Iteration 28: Loss = 0.6309849619865417
Iteration 29: Loss = 0.6253703832626343
Iteration 30: Loss = 0.6199628114700317
Iteration 31: Loss = 0.6147557497024536
Iteration 32: Loss = 0.6097466945648193
Iteration 33: Loss = 0.6049321889877319
Iteration 34: Loss = 0.6003069877624512
Iteration 35: Loss = 0.5958673357963562
Iteration 36: Loss = 0.5916076302528381
Iteration 37: Loss = 0.5875222086906433
Iteration 38: Loss = 0.5836055874824524
Iteration 39: Loss = 0.5798525214195251
Iteration 40: Loss = 0.5762574672698975
Iteration 41: Loss = 0.5728139877319336
Iteration 42: Loss = 0.5695174932479858
Iteration 43: Loss = 0.5663609504699707
Iteration 44: Loss = 0.5633386373519897
Iteration 45: Loss = 0.5604432225227356
Iteration 46: Loss = 0.5576675534248352
Iteration 47: Loss = 0.5550050139427185
Iteration 48: Loss = 0.5524517893791199
Iteration 49: Loss = 0.550002932548523
Iteration 50: Loss = 0.547653079032898
Iteration 51: Loss = 0.5453972220420837
Iteration 52: Loss = 0.5432287454605103
Iteration 53: Loss = 0.5411424040794373
Iteration 54: Loss = 0.53913414478302
Iteration 55: Loss = 0.5372009873390198
Iteration 56: Loss = 0.5353391170501709
Iteration 57: Loss = 0.5335444211959839
Iteration 58: Loss = 0.5318143367767334
Iteration 59: Loss = 0.5301455855369568
Iteration 60: Loss = 0.5285347104072571
Iteration 61: Loss = 0.526978611946106
Iteration 62: Loss = 0.5254745483398438
Iteration 63: Loss = 0.5240194201469421
Iteration 64: Loss = 0.5226116180419922
Iteration 65: Loss = 0.5212494730949402
Iteration 66: Loss = 0.5199328660964966
Iteration 67: Loss = 0.5186594128608704
Iteration 68: Loss = 0.5174267292022705
Iteration 69: Loss = 0.5162330269813538
Iteration 70: Loss = 0.5150769948959351
Iteration 71: Loss = 0.513957142829895
Iteration 72: Loss = 0.5128716230392456
Iteration 73: Loss = 0.5118206143379211
Iteration 74: Loss = 0.5108018517494202
Iteration 75: Loss = 0.5098139047622681
Iteration 76: Loss = 0.5088561773300171
Iteration 77: Loss = 0.5079267621040344
Iteration 78: Loss = 0.5070251822471619
Iteration 79: Loss = 0.5061506628990173
Iteration 80: Loss = 0.5053016543388367
Iteration 81: Loss = 0.5044766664505005
Iteration 82: Loss = 0.5036746263504028
Iteration 83: Loss = 0.5028943419456482
Iteration 84: Loss = 0.5021343231201172
Iteration 85: Loss = 0.5013923048973083
Iteration 86: Loss = 0.5006678700447083
Iteration 87: Loss = 0.4999592900276184
Iteration 88: Loss = 0.49926528334617615
Iteration 89: Loss = 0.4985837936401367
Iteration 90: Loss = 0.49791356921195984
Iteration 91: Loss = 0.49725306034088135
Iteration 92: Loss = 0.49660131335258484
Iteration 93: Loss = 0.4959567189216614
Iteration 94: Loss = 0.49531635642051697
Iteration 95: Loss = 0.4946769177913666
Iteration 96: Loss = 0.4940367341041565
Iteration 97: Loss = 0.4933931231498718
Iteration 98: Loss = 0.4927438795566559
Iteration 99: Loss = 0.4920859932899475
Iteration 100: Loss = 0.49141672253608704
Iteration 101: Loss = 0.49073222279548645
Iteration 102: Loss = 0.49002882838249207
Iteration 103: Loss = 0.4893050193786621
Iteration 104: Loss = 0.48856011033058167
Iteration 105: Loss = 0.4877898693084717
Iteration 106: Loss = 0.4869930148124695
Iteration 107: Loss = 0.4861702620983124
Iteration 108: Loss = 0.4853211045265198
Iteration 109: Loss = 0.4844520390033722
Iteration 110: Loss = 0.48357006907463074
Iteration 111: Loss = 0.48268458247184753
Iteration 112: Loss = 0.4818107783794403
Iteration 113: Loss = 0.4809642434120178
Iteration 114: Loss = 0.4801674783229828
Iteration 115: Loss = 0.4794342815876007
Iteration 116: Loss = 0.47877830266952515
Iteration 117: Loss = 0.47820860147476196
Iteration 118: Loss = 0.4777217507362366
Iteration 119: Loss = 0.47730889916419983
Iteration 120: Loss = 0.4769621193408966
Iteration 121: Loss = 0.47666099667549133
Iteration 122: Loss = 0.4763915538787842
Iteration 123: Loss = 0.47613802552223206
Iteration 124: Loss = 0.4758903980255127
Iteration 125: Loss = 0.47564056515693665
Iteration 126: Loss = 0.47538644075393677
Iteration 127: Loss = 0.4751279652118683
Iteration 128: Loss = 0.47487059235572815
Iteration 129: Loss = 0.4746145009994507
Iteration 130: Loss = 0.4743597209453583
Iteration 131: Loss = 0.4741063416004181
Iteration 132: Loss = 0.47385406494140625
Iteration 133: Loss = 0.47360357642173767
Iteration 134: Loss = 0.4733541011810303
Iteration 135: Loss = 0.4731062650680542
Iteration 136: Loss = 0.4728592038154602
Iteration 137: Loss = 0.4726136326789856
Iteration 138: Loss = 0.47236862778663635
Iteration 139: Loss = 0.472124844789505
Iteration 140: Loss = 0.47188156843185425
Iteration 141: Loss = 0.4716394543647766
Iteration 142: Loss = 0.4713979959487915
Iteration 143: Loss = 0.471157968044281
Iteration 144: Loss = 0.4709184169769287
Iteration 145: Loss = 0.47067955136299133
Iteration 146: Loss = 0.4704410433769226
Iteration 147: Loss = 0.47020307183265686
Iteration 148: Loss = 0.4699653685092926
Iteration 149: Loss = 0.4697277843952179
Iteration 150: Loss = 0.4694902300834656
Iteration 151: Loss = 0.469252347946167
Iteration 152: Loss = 0.4690154492855072
Iteration 153: Loss = 0.4687778949737549
Iteration 154: Loss = 0.4685402810573578
Iteration 155: Loss = 0.46830230951309204
Iteration 156: Loss = 0.4680638313293457
Iteration 157: Loss = 0.4678250551223755
Iteration 158: Loss = 0.4675852060317993
Iteration 159: Loss = 0.46734458208084106
Iteration 160: Loss = 0.4671022593975067
Iteration 161: Loss = 0.4668583571910858
Iteration 162: Loss = 0.46661368012428284
Iteration 163: Loss = 0.4663669466972351
Iteration 164: Loss = 0.46611928939819336
Iteration 165: Loss = 0.4658694863319397
Iteration 166: Loss = 0.4656170606613159
Iteration 167: Loss = 0.46536314487457275
Iteration 168: Loss = 0.4651066064834595
Iteration 169: Loss = 0.4648500680923462
Iteration 170: Loss = 0.46459564566612244
Iteration 171: Loss = 0.46434319019317627
Iteration 172: Loss = 0.46409285068511963
Iteration 173: Loss = 0.4638445973396301
Iteration 174: Loss = 0.46359920501708984
Iteration 175: Loss = 0.46335649490356445
Iteration 176: Loss = 0.46311628818511963
Iteration 177: Loss = 0.46287816762924194
Iteration 178: Loss = 0.4626421332359314
Iteration 179: Loss = 0.46240824460983276
Iteration 180: Loss = 0.46217605471611023
Iteration 181: Loss = 0.4619462192058563
Iteration 182: Loss = 0.46171849966049194
Iteration 183: Loss = 0.4614933431148529
Iteration 184: Loss = 0.461270272731781
Iteration 185: Loss = 0.4610491096973419
Iteration 186: Loss = 0.46082934737205505
Iteration 187: Loss = 0.4606111943721771
Iteration 188: Loss = 0.4603944718837738
Iteration 189: Loss = 0.46017876267433167
Iteration 190: Loss = 0.4599643647670746
Iteration 191: Loss = 0.4597512185573578
Iteration 192: Loss = 0.45953935384750366
Iteration 193: Loss = 0.4593287408351898
Iteration 194: Loss = 0.45911887288093567
Iteration 195: Loss = 0.4589097201824188
Iteration 196: Loss = 0.4587012231349945
Iteration 197: Loss = 0.4584932327270508
Iteration 198: Loss = 0.45828625559806824
Iteration 199: Loss = 0.458079993724823
Iteration 200: Loss = 0.4578743875026703
Iteration 201: Loss = 0.45766937732696533
Iteration 202: Loss = 0.457465261220932
Iteration 203: Loss = 0.45726126432418823
Iteration 204: Loss = 0.4570571780204773
Iteration 205: Loss = 0.4568531811237335
Iteration 206: Loss = 0.4566497504711151
Iteration 207: Loss = 0.4564467966556549
Iteration 208: Loss = 0.4562437832355499
Iteration 209: Loss = 0.45604076981544495
Iteration 210: Loss = 0.45583832263946533
Iteration 211: Loss = 0.455636203289032
Iteration 212: Loss = 0.45543432235717773
Iteration 213: Loss = 0.45523321628570557
Iteration 214: Loss = 0.4550327658653259
Iteration 215: Loss = 0.4548328220844269
Iteration 216: Loss = 0.45463457703590393
Iteration 217: Loss = 0.4544375538825989
Iteration 218: Loss = 0.45424243807792664
Iteration 219: Loss = 0.454048752784729
Iteration 220: Loss = 0.45385733246803284
Iteration 221: Loss = 0.45366862416267395
Iteration 222: Loss = 0.45348259806632996
Iteration 223: Loss = 0.453299880027771
Iteration 224: Loss = 0.45312047004699707
Iteration 225: Loss = 0.4529452621936798
Iteration 226: Loss = 0.4527738094329834
Iteration 227: Loss = 0.45260685682296753
Iteration 228: Loss = 0.45244500041007996
Iteration 229: Loss = 0.45228925347328186
Iteration 230: Loss = 0.4521412253379822
Iteration 231: Loss = 0.45200052857398987
Iteration 232: Loss = 0.4518672525882721
Iteration 233: Loss = 0.4517405033111572
Iteration 234: Loss = 0.4516200125217438
Iteration 235: Loss = 0.45150524377822876
Iteration 236: Loss = 0.45139560103416443
Iteration 237: Loss = 0.45129016041755676
Iteration 238: Loss = 0.4511882960796356
Iteration 239: Loss = 0.45108917355537415
Iteration 240: Loss = 0.45099198818206787
Iteration 241: Loss = 0.4508959949016571
Iteration 242: Loss = 0.45080065727233887
Iteration 243: Loss = 0.4507053792476654
Iteration 244: Loss = 0.4506099224090576
Iteration 245: Loss = 0.4505137801170349
Iteration 246: Loss = 0.45041704177856445
Iteration 247: Loss = 0.45031967759132385
Iteration 248: Loss = 0.45022159814834595
Iteration 249: Loss = 0.45012298226356506
Iteration 250: Loss = 0.45002397894859314
Iteration 251: Loss = 0.44992467761039734
Iteration 252: Loss = 0.44982537627220154
Iteration 253: Loss = 0.4497261345386505
Iteration 254: Loss = 0.44962725043296814
Iteration 255: Loss = 0.44952869415283203
Iteration 256: Loss = 0.4494307339191437
Iteration 257: Loss = 0.44933339953422546
Iteration 258: Loss = 0.4492367208003998
Iteration 259: Loss = 0.44914087653160095
Iteration 260: Loss = 0.4490457773208618
Iteration 261: Loss = 0.4489514231681824
Iteration 262: Loss = 0.44885778427124023
Iteration 263: Loss = 0.4487648606300354
Iteration 264: Loss = 0.44867241382598877
Iteration 265: Loss = 0.44858068227767944
Iteration 266: Loss = 0.4484894275665283
Iteration 267: Loss = 0.4483986794948578
Iteration 268: Loss = 0.4483083188533783
Iteration 269: Loss = 0.44821834564208984
Iteration 270: Loss = 0.44812870025634766
Iteration 271: Loss = 0.44803935289382935
Iteration 272: Loss = 0.44795045256614685
Iteration 273: Loss = 0.44786176085472107
Iteration 274: Loss = 0.4477733373641968
Iteration 275: Loss = 0.44768527150154114
Iteration 276: Loss = 0.4475973844528198
Iteration 277: Loss = 0.447509765625
Iteration 278: Loss = 0.44742247462272644
Iteration 279: Loss = 0.44733554124832153
Iteration 280: Loss = 0.4472489058971405
Iteration 281: Loss = 0.44716259837150574
Iteration 282: Loss = 0.4470764696598053
Iteration 283: Loss = 0.4469907283782959
Iteration 284: Loss = 0.446905255317688
Iteration 285: Loss = 0.44682011008262634
Iteration 286: Loss = 0.4467352628707886
Iteration 287: Loss = 0.44665074348449707
Iteration 288: Loss = 0.446566641330719
Iteration 289: Loss = 0.4464828372001648
Iteration 290: Loss = 0.44639936089515686
Iteration 291: Loss = 0.4463162124156952
Iteration 292: Loss = 0.446233332157135
Iteration 293: Loss = 0.4461508095264435
Iteration 294: Loss = 0.44606855511665344
Iteration 295: Loss = 0.44598662853240967
Iteration 296: Loss = 0.4459052085876465
Iteration 297: Loss = 0.4458239674568176
Iteration 298: Loss = 0.4457431137561798
Iteration 299: Loss = 0.44566255807876587
Iteration 300: Loss = 0.44558224081993103
Iteration 301: Loss = 0.44550225138664246
Iteration 302: Loss = 0.44542258977890015
Iteration 303: Loss = 0.44534316658973694
Iteration 304: Loss = 0.4452640116214752
Iteration 305: Loss = 0.44518518447875977
Iteration 306: Loss = 0.4451066255569458
Iteration 307: Loss = 0.44502848386764526
Iteration 308: Loss = 0.44495049118995667
Iteration 309: Loss = 0.44487282633781433
Iteration 310: Loss = 0.44479551911354065
Iteration 311: Loss = 0.44471848011016846
Iteration 312: Loss = 0.4446418285369873
Iteration 313: Loss = 0.4445652365684509
Iteration 314: Loss = 0.444489061832428
Iteration 315: Loss = 0.4444131851196289
Iteration 316: Loss = 0.44433754682540894
Iteration 317: Loss = 0.44426229596138
Iteration 318: Loss = 0.44418734312057495
Iteration 319: Loss = 0.4441126585006714
Iteration 320: Loss = 0.4440383017063141
Iteration 321: Loss = 0.44396424293518066
Iteration 322: Loss = 0.4438904821872711
Iteration 323: Loss = 0.44381701946258545
Iteration 324: Loss = 0.44374385476112366
Iteration 325: Loss = 0.4436710476875305
Iteration 326: Loss = 0.44359850883483887
Iteration 327: Loss = 0.4435262978076935
Iteration 328: Loss = 0.4434543251991272
Iteration 329: Loss = 0.44338274002075195
Iteration 330: Loss = 0.4433114230632782
Iteration 331: Loss = 0.4432404339313507
Iteration 332: Loss = 0.44316986203193665
Iteration 333: Loss = 0.4430995583534241
Iteration 334: Loss = 0.443029522895813
Iteration 335: Loss = 0.44295984506607056
Iteration 336: Loss = 0.4428904056549072
Iteration 337: Loss = 0.44282129406929016
Iteration 338: Loss = 0.4427524507045746
Iteration 339: Loss = 0.4426839053630829
Iteration 340: Loss = 0.44261568784713745
Iteration 341: Loss = 0.4425477385520935
Iteration 342: Loss = 0.4424799084663391
Iteration 343: Loss = 0.44241243600845337
Iteration 344: Loss = 0.4423453211784363
Iteration 345: Loss = 0.4422784447669983
Iteration 346: Loss = 0.44221171736717224
Iteration 347: Loss = 0.44214531779289246
Iteration 348: Loss = 0.4420791566371918
Iteration 349: Loss = 0.44201335310935974
Iteration 350: Loss = 0.4419477581977844
Iteration 351: Loss = 0.44188234210014343
Iteration 352: Loss = 0.44181719422340393
Iteration 353: Loss = 0.44175243377685547
Iteration 354: Loss = 0.4416879713535309
Iteration 355: Loss = 0.441623717546463
Iteration 356: Loss = 0.44155973196029663
Iteration 357: Loss = 0.44149595499038696
Iteration 358: Loss = 0.4414325952529907
Iteration 359: Loss = 0.4413694441318512
Iteration 360: Loss = 0.44130659103393555
Iteration 361: Loss = 0.44124385714530945
Iteration 362: Loss = 0.4411814212799072
Iteration 363: Loss = 0.44111931324005127
Iteration 364: Loss = 0.4410575032234192
Iteration 365: Loss = 0.4409959018230438
Iteration 366: Loss = 0.4409344792366028
Iteration 367: Loss = 0.4408733546733856
Iteration 368: Loss = 0.44081252813339233
Iteration 369: Loss = 0.4407519996166229
Iteration 370: Loss = 0.4406917095184326
Iteration 371: Loss = 0.44063159823417664
Iteration 372: Loss = 0.440571665763855
Iteration 373: Loss = 0.44051215052604675
Iteration 374: Loss = 0.4404528737068176
Iteration 375: Loss = 0.4403937757015228
Iteration 376: Loss = 0.44033488631248474
Iteration 377: Loss = 0.44027620553970337
Iteration 378: Loss = 0.4402179419994354
Iteration 379: Loss = 0.4401599168777466
Iteration 380: Loss = 0.4401019513607025
Iteration 381: Loss = 0.4400442838668823
Iteration 382: Loss = 0.43998685479164124
Iteration 383: Loss = 0.439929723739624
Iteration 384: Loss = 0.4398728013038635
Iteration 385: Loss = 0.43981602787971497
Iteration 386: Loss = 0.4397595226764679
Iteration 387: Loss = 0.4397033154964447
Iteration 388: Loss = 0.4396473169326782
Iteration 389: Loss = 0.43959158658981323
Iteration 390: Loss = 0.43953603506088257
Iteration 391: Loss = 0.43948066234588623
Iteration 392: Loss = 0.43942561745643616
Iteration 393: Loss = 0.43937087059020996
Iteration 394: Loss = 0.43931636214256287
Iteration 395: Loss = 0.43926215171813965
Iteration 396: Loss = 0.4392080307006836
Iteration 397: Loss = 0.4391542673110962
Iteration 398: Loss = 0.4391007721424103
Iteration 399: Loss = 0.43904754519462585
Iteration 400: Loss = 0.43899455666542053
Iteration 401: Loss = 0.43894168734550476
Iteration 402: Loss = 0.4388890862464905
Iteration 403: Loss = 0.43883684277534485
Iteration 404: Loss = 0.4387846887111664
Iteration 405: Loss = 0.4387328326702118
Iteration 406: Loss = 0.43868115544319153
Iteration 407: Loss = 0.438629686832428
Iteration 408: Loss = 0.43857860565185547
Iteration 409: Loss = 0.4385277032852173
Iteration 410: Loss = 0.43847692012786865
Iteration 411: Loss = 0.4384264349937439
Iteration 412: Loss = 0.4383760094642639
Iteration 413: Loss = 0.43832606077194214
Iteration 414: Loss = 0.4382762014865875
Iteration 415: Loss = 0.4382266700267792
Iteration 416: Loss = 0.43817734718322754
Iteration 417: Loss = 0.43812814354896545
Iteration 418: Loss = 0.43807926774024963
Iteration 419: Loss = 0.4380306601524353
Iteration 420: Loss = 0.4379822909832001
Iteration 421: Loss = 0.43793413043022156
Iteration 422: Loss = 0.43788617849349976
Iteration 423: Loss = 0.4378383159637451
Iteration 424: Loss = 0.4377909302711487
Iteration 425: Loss = 0.4377437233924866
Iteration 426: Loss = 0.4376967251300812
Iteration 427: Loss = 0.4376499056816101
Iteration 428: Loss = 0.43760326504707336
Iteration 429: Loss = 0.4375568926334381
Iteration 430: Loss = 0.4375108778476715
Iteration 431: Loss = 0.4374650716781616
Iteration 432: Loss = 0.43741941452026367
Iteration 433: Loss = 0.43737396597862244
Iteration 434: Loss = 0.43732860684394836
Iteration 435: Loss = 0.43728357553482056
Iteration 436: Loss = 0.43723878264427185
Iteration 437: Loss = 0.4371941089630127
Iteration 438: Loss = 0.43714970350265503
Iteration 439: Loss = 0.4371054470539093
Iteration 440: Loss = 0.4370613992214203
Iteration 441: Loss = 0.43701761960983276
Iteration 442: Loss = 0.43697404861450195
Iteration 443: Loss = 0.4369306266307831
Iteration 444: Loss = 0.43688738346099854
Iteration 445: Loss = 0.4368443191051483
Iteration 446: Loss = 0.43680140376091003
Iteration 447: Loss = 0.43675875663757324
Iteration 448: Loss = 0.43671637773513794
Iteration 449: Loss = 0.4366741478443146
Iteration 450: Loss = 0.43663209676742554
Iteration 451: Loss = 0.436590313911438
Iteration 452: Loss = 0.43654865026474
Iteration 453: Loss = 0.43650713562965393
Iteration 454: Loss = 0.4364659786224365
Iteration 455: Loss = 0.43642497062683105
Iteration 456: Loss = 0.4363841116428375
Iteration 457: Loss = 0.4363434314727783
Iteration 458: Loss = 0.43630293011665344
Iteration 459: Loss = 0.4362625777721405
Iteration 460: Loss = 0.43622249364852905
Iteration 461: Loss = 0.4361826777458191
Iteration 462: Loss = 0.43614310026168823
Iteration 463: Loss = 0.43610361218452454
Iteration 464: Loss = 0.4360642433166504
Iteration 465: Loss = 0.43602505326271057
Iteration 466: Loss = 0.43598607182502747
Iteration 467: Loss = 0.43594738841056824
Iteration 468: Loss = 0.43590882420539856
Iteration 469: Loss = 0.43587037920951843
Iteration 470: Loss = 0.4358321726322174
Iteration 471: Loss = 0.43579405546188354
Iteration 472: Loss = 0.4357561469078064
Iteration 473: Loss = 0.4357184171676636
Iteration 474: Loss = 0.43568089604377747
Iteration 475: Loss = 0.43564358353614807
Iteration 476: Loss = 0.435606449842453
Iteration 477: Loss = 0.4355694055557251
Iteration 478: Loss = 0.4355325698852539
Iteration 479: Loss = 0.4354958236217499
Iteration 480: Loss = 0.43545928597450256
Iteration 481: Loss = 0.43542295694351196
Iteration 482: Loss = 0.4353867471218109
Iteration 483: Loss = 0.4353506565093994
Iteration 484: Loss = 0.43531468510627747
Iteration 485: Loss = 0.43527886271476746
Iteration 486: Loss = 0.435243159532547
Iteration 487: Loss = 0.43520769476890564
Iteration 488: Loss = 0.43517252802848816
Iteration 489: Loss = 0.43513748049736023
Iteration 490: Loss = 0.43510258197784424
Iteration 491: Loss = 0.4350677728652954
Iteration 492: Loss = 0.4350331425666809
Iteration 493: Loss = 0.43499866127967834
Iteration 494: Loss = 0.43496423959732056
Iteration 495: Loss = 0.43493011593818665
Iteration 496: Loss = 0.4348961114883423
Iteration 497: Loss = 0.4348622262477875
Iteration 498: Loss = 0.434828519821167
Iteration 499: Loss = 0.43479493260383606
Iteration 500: Loss = 0.4347614049911499
Iteration 501: Loss = 0.43472805619239807
Iteration 502: Loss = 0.43469488620758057
Iteration 503: Loss = 0.43466201424598694
Iteration 504: Loss = 0.4346292018890381
Iteration 505: Loss = 0.43459653854370117
Iteration 506: Loss = 0.4345639944076538
Iteration 507: Loss = 0.4345315098762512
Iteration 508: Loss = 0.43449920415878296
Iteration 509: Loss = 0.43446704745292664
Iteration 510: Loss = 0.434435099363327
Iteration 511: Loss = 0.4344033896923065
Iteration 512: Loss = 0.43437179923057556
Iteration 513: Loss = 0.43434038758277893
Iteration 514: Loss = 0.43430906534194946
Iteration 515: Loss = 0.43427780270576477
Iteration 516: Loss = 0.4342467188835144
Iteration 517: Loss = 0.4342156648635864
Iteration 518: Loss = 0.434184730052948
Iteration 519: Loss = 0.4341541826725006
Iteration 520: Loss = 0.4341236650943756
Iteration 521: Loss = 0.4340934157371521
Iteration 522: Loss = 0.4340631663799286
Iteration 523: Loss = 0.4340331554412842
Iteration 524: Loss = 0.43400314450263977
Iteration 525: Loss = 0.4339732825756073
Iteration 526: Loss = 0.4339434802532196
Iteration 527: Loss = 0.43391382694244385
Iteration 528: Loss = 0.43388447165489197
Iteration 529: Loss = 0.4338551163673401
Iteration 530: Loss = 0.4338259696960449
Iteration 531: Loss = 0.43379682302474976
Iteration 532: Loss = 0.43376782536506653
Iteration 533: Loss = 0.4337388873100281
Iteration 534: Loss = 0.4337100684642792
Iteration 535: Loss = 0.4336813688278198
Iteration 536: Loss = 0.43365269899368286
Iteration 537: Loss = 0.43362438678741455
Iteration 538: Loss = 0.433596134185791
Iteration 539: Loss = 0.43356794118881226
Iteration 540: Loss = 0.43353989720344543
Iteration 541: Loss = 0.4335119128227234
Iteration 542: Loss = 0.4334840178489685
Iteration 543: Loss = 0.4334562420845032
Iteration 544: Loss = 0.43342849612236023
Iteration 545: Loss = 0.43340083956718445
Iteration 546: Loss = 0.4333733022212982
Iteration 547: Loss = 0.4333459138870239
Iteration 548: Loss = 0.4333186745643616
Iteration 549: Loss = 0.433291494846344
Iteration 550: Loss = 0.4332644045352936
Iteration 551: Loss = 0.43323737382888794
Iteration 552: Loss = 0.43321046233177185
Iteration 553: Loss = 0.43318361043930054
Iteration 554: Loss = 0.433156818151474
Iteration 555: Loss = 0.4331301152706146
Iteration 556: Loss = 0.4331034719944
Iteration 557: Loss = 0.4330770969390869
Iteration 558: Loss = 0.4330507516860962
Iteration 559: Loss = 0.43302449584007263
Iteration 560: Loss = 0.43299832940101624
Iteration 561: Loss = 0.432972252368927
Iteration 562: Loss = 0.43294623494148254
Iteration 563: Loss = 0.43292033672332764
Iteration 564: Loss = 0.4328944683074951
Iteration 565: Loss = 0.43286871910095215
Iteration 566: Loss = 0.4328429698944092
Iteration 567: Loss = 0.4328172504901886
Iteration 568: Loss = 0.4327917993068695
Iteration 569: Loss = 0.4327663779258728
Iteration 570: Loss = 0.43274107575416565
Iteration 571: Loss = 0.43271583318710327
Iteration 572: Loss = 0.4326906204223633
Iteration 573: Loss = 0.43266552686691284
Iteration 574: Loss = 0.4326404333114624
Iteration 575: Loss = 0.43261539936065674
Iteration 576: Loss = 0.43259045481681824
Iteration 577: Loss = 0.4325655400753021
Iteration 578: Loss = 0.43254077434539795
Iteration 579: Loss = 0.43251606822013855
Iteration 580: Loss = 0.4324915111064911
Iteration 581: Loss = 0.432466983795166
Iteration 582: Loss = 0.4324425458908081
Iteration 583: Loss = 0.4324181079864502
Iteration 584: Loss = 0.43239375948905945
Iteration 585: Loss = 0.4323694407939911
Iteration 586: Loss = 0.4323452115058899
Iteration 587: Loss = 0.43232107162475586
Iteration 588: Loss = 0.4322969317436218
Iteration 589: Loss = 0.43227288126945496
Iteration 590: Loss = 0.4322488009929657
Iteration 591: Loss = 0.43222495913505554
Iteration 592: Loss = 0.4322011172771454
Iteration 593: Loss = 0.4321773648262024
Iteration 594: Loss = 0.4321536421775818
Iteration 595: Loss = 0.43213003873825073
Iteration 596: Loss = 0.4321063756942749
Iteration 597: Loss = 0.4320828318595886
Iteration 598: Loss = 0.4320593774318695
Iteration 599: Loss = 0.4320359528064728
Iteration 600: Loss = 0.4320125877857208
Iteration 601: Loss = 0.43198925256729126
Iteration 602: Loss = 0.4319659471511841
Iteration 603: Loss = 0.43194273114204407
Iteration 604: Loss = 0.431919664144516
Iteration 605: Loss = 0.4318965673446655
Iteration 606: Loss = 0.4318736791610718
Iteration 607: Loss = 0.43185073137283325
Iteration 608: Loss = 0.4318278431892395
Iteration 609: Loss = 0.4318050146102905
Iteration 610: Loss = 0.43178218603134155
Iteration 611: Loss = 0.43175944685935974
Iteration 612: Loss = 0.4317367374897003
Iteration 613: Loss = 0.4317140579223633
Iteration 614: Loss = 0.43169140815734863
Iteration 615: Loss = 0.43166878819465637
Iteration 616: Loss = 0.4316462576389313
Iteration 617: Loss = 0.43162375688552856
Iteration 618: Loss = 0.431601345539093
Iteration 619: Loss = 0.4315790832042694
Iteration 620: Loss = 0.4315567910671234
Iteration 621: Loss = 0.4315345883369446
Iteration 622: Loss = 0.43151238560676575
Iteration 623: Loss = 0.4314902424812317
Iteration 624: Loss = 0.43146806955337524
Iteration 625: Loss = 0.43144598603248596
Iteration 626: Loss = 0.43142393231391907
Iteration 627: Loss = 0.43140190839767456
Iteration 628: Loss = 0.43137991428375244
Iteration 629: Loss = 0.4313579499721527
Iteration 630: Loss = 0.43133604526519775
Iteration 631: Loss = 0.4313141405582428
Iteration 632: Loss = 0.43129226565361023
Iteration 633: Loss = 0.43127042055130005
Iteration 634: Loss = 0.4312487244606018
Iteration 635: Loss = 0.43122705817222595
Iteration 636: Loss = 0.4312053620815277
Iteration 637: Loss = 0.431183785200119
Iteration 638: Loss = 0.43116217851638794
Iteration 639: Loss = 0.43114057183265686
Iteration 640: Loss = 0.43111899495124817
Iteration 641: Loss = 0.43109747767448425
Iteration 642: Loss = 0.4310759902000427
Iteration 643: Loss = 0.4310545027256012
Iteration 644: Loss = 0.4310329854488373
Iteration 645: Loss = 0.4310115873813629
Iteration 646: Loss = 0.4309900999069214
Iteration 647: Loss = 0.430968701839447
Iteration 648: Loss = 0.43094730377197266
Iteration 649: Loss = 0.4309259057044983
Iteration 650: Loss = 0.4309045374393463
Iteration 651: Loss = 0.4308833181858063
Iteration 652: Loss = 0.43086206912994385
Iteration 653: Loss = 0.4308408796787262
Iteration 654: Loss = 0.43081969022750854
Iteration 655: Loss = 0.4307985305786133
Iteration 656: Loss = 0.430777370929718
Iteration 657: Loss = 0.43075621128082275
Iteration 658: Loss = 0.43073511123657227
Iteration 659: Loss = 0.4307139813899994
Iteration 660: Loss = 0.4306928813457489
Iteration 661: Loss = 0.4306717813014984
Iteration 662: Loss = 0.4306506812572479
Iteration 663: Loss = 0.4306296408176422
Iteration 664: Loss = 0.4306085407733917
Iteration 665: Loss = 0.4305874705314636
Iteration 666: Loss = 0.4305664002895355
Iteration 667: Loss = 0.4305453896522522
Iteration 668: Loss = 0.43052446842193604
Iteration 669: Loss = 0.4305035173892975
Iteration 670: Loss = 0.4304825961589813
Iteration 671: Loss = 0.43046170473098755
Iteration 672: Loss = 0.4304406940937042
Iteration 673: Loss = 0.43041983246803284
Iteration 674: Loss = 0.4303989112377167
Iteration 675: Loss = 0.4303780198097229
Iteration 676: Loss = 0.4303571283817291
Iteration 677: Loss = 0.4303362965583801
Iteration 678: Loss = 0.43031540513038635
Iteration 679: Loss = 0.4302945137023926
Iteration 680: Loss = 0.4302736818790436
Iteration 681: Loss = 0.4302528202533722
Iteration 682: Loss = 0.4302319884300232
Iteration 683: Loss = 0.4302111864089966
Iteration 684: Loss = 0.4301902949810028
Iteration 685: Loss = 0.4301694333553314
Iteration 686: Loss = 0.4301486015319824
Iteration 687: Loss = 0.4301278293132782
Iteration 688: Loss = 0.43010714650154114
Iteration 689: Loss = 0.4300864040851593
Iteration 690: Loss = 0.43006569147109985
Iteration 691: Loss = 0.43004491925239563
Iteration 692: Loss = 0.4300241768360138
Iteration 693: Loss = 0.43000346422195435
Iteration 694: Loss = 0.4299826920032501
Iteration 695: Loss = 0.4299619793891907
Iteration 696: Loss = 0.42994123697280884
Iteration 697: Loss = 0.4299204349517822
Iteration 698: Loss = 0.429899662733078
Iteration 699: Loss = 0.42987900972366333
Iteration 700: Loss = 0.4298582375049591
Iteration 701: Loss = 0.42983758449554443
Iteration 702: Loss = 0.4298168122768402
Iteration 703: Loss = 0.42979609966278076
Iteration 704: Loss = 0.4297753572463989
Iteration 705: Loss = 0.4297545850276947
Iteration 706: Loss = 0.4297338128089905
Iteration 707: Loss = 0.4297131299972534
Iteration 708: Loss = 0.4296923279762268
Iteration 709: Loss = 0.42967167496681213
Iteration 710: Loss = 0.4296509921550751
Iteration 711: Loss = 0.42963024973869324
Iteration 712: Loss = 0.42960959672927856
Iteration 713: Loss = 0.42958885431289673
Iteration 714: Loss = 0.4295681118965149
Iteration 715: Loss = 0.42954739928245544
Iteration 716: Loss = 0.429526686668396
Iteration 717: Loss = 0.4295059144496918
Iteration 718: Loss = 0.42948517203330994
Iteration 719: Loss = 0.4294644296169281
Iteration 720: Loss = 0.4294436275959015
Iteration 721: Loss = 0.4294228255748749
Iteration 722: Loss = 0.42940208315849304
Iteration 723: Loss = 0.42938128113746643
Iteration 724: Loss = 0.4293605089187622
Iteration 725: Loss = 0.4293396770954132
Iteration 726: Loss = 0.429318904876709
Iteration 727: Loss = 0.4292980432510376
Iteration 728: Loss = 0.4292771816253662
Iteration 729: Loss = 0.42925629019737244
Iteration 730: Loss = 0.42923539876937866
Iteration 731: Loss = 0.4292145371437073
Iteration 732: Loss = 0.4291936755180359
Iteration 733: Loss = 0.42917272448539734
Iteration 734: Loss = 0.42915189266204834
Iteration 735: Loss = 0.42913103103637695
Iteration 736: Loss = 0.4291101396083832
Iteration 737: Loss = 0.4290892481803894
Iteration 738: Loss = 0.42906826734542847
Iteration 739: Loss = 0.4290473759174347
Iteration 740: Loss = 0.42902636528015137
Iteration 741: Loss = 0.4290054440498352
Iteration 742: Loss = 0.4289844036102295
Iteration 743: Loss = 0.42896345257759094
Iteration 744: Loss = 0.42894241213798523
Iteration 745: Loss = 0.42892134189605713
Iteration 746: Loss = 0.4289003014564514
Iteration 747: Loss = 0.4288792610168457
Iteration 748: Loss = 0.4288581609725952
Iteration 749: Loss = 0.4288371205329895
Iteration 750: Loss = 0.4288159906864166
Iteration 751: Loss = 0.42879486083984375
Iteration 752: Loss = 0.4287737011909485
Iteration 753: Loss = 0.4287525415420532
Iteration 754: Loss = 0.42873135209083557
Iteration 755: Loss = 0.42871010303497314
Iteration 756: Loss = 0.4286889135837555
Iteration 757: Loss = 0.4286676049232483
Iteration 758: Loss = 0.4286462962627411
Iteration 759: Loss = 0.42862507700920105
Iteration 760: Loss = 0.42860379815101624
Iteration 761: Loss = 0.4285825192928314
Iteration 762: Loss = 0.4285612106323242
Iteration 763: Loss = 0.42853987216949463
Iteration 764: Loss = 0.4285185635089874
Iteration 765: Loss = 0.42849716544151306
Iteration 766: Loss = 0.4284757375717163
Iteration 767: Loss = 0.42845430970191956
Iteration 768: Loss = 0.4284328520298004
Iteration 769: Loss = 0.4284113645553589
Iteration 770: Loss = 0.42838984727859497
Iteration 771: Loss = 0.42836835980415344
Iteration 772: Loss = 0.42834681272506714
Iteration 773: Loss = 0.42832526564598083
Iteration 774: Loss = 0.42830362915992737
Iteration 775: Loss = 0.4282819926738739
Iteration 776: Loss = 0.42826032638549805
Iteration 777: Loss = 0.4282386004924774
Iteration 778: Loss = 0.4282168745994568
Iteration 779: Loss = 0.4281952381134033
Iteration 780: Loss = 0.4281734526157379
Iteration 781: Loss = 0.4281516671180725
Iteration 782: Loss = 0.4281298518180847
Iteration 783: Loss = 0.4281080365180969
Iteration 784: Loss = 0.42808619141578674
Iteration 785: Loss = 0.4280642569065094
Iteration 786: Loss = 0.42804229259490967
Iteration 787: Loss = 0.42802050709724426
Iteration 788: Loss = 0.4279985725879669
Iteration 789: Loss = 0.4279766380786896
Iteration 790: Loss = 0.42795470356941223
Iteration 791: Loss = 0.4279327392578125
Iteration 792: Loss = 0.4279107451438904
Iteration 793: Loss = 0.4278886616230011
Iteration 794: Loss = 0.4278666377067566
Iteration 795: Loss = 0.4278446137905121
Iteration 796: Loss = 0.42782244086265564
Iteration 797: Loss = 0.4278002977371216
Iteration 798: Loss = 0.4277781546115875
Iteration 799: Loss = 0.4277559518814087
Iteration 800: Loss = 0.4277336597442627
Iteration 801: Loss = 0.42771145701408386
Iteration 802: Loss = 0.42768919467926025
Iteration 803: Loss = 0.4276668429374695
Iteration 804: Loss = 0.4276444613933563
Iteration 805: Loss = 0.42762207984924316
Iteration 806: Loss = 0.42759963870048523
Iteration 807: Loss = 0.4275771677494049
Iteration 808: Loss = 0.4275546967983246
Iteration 809: Loss = 0.4275321364402771
Iteration 810: Loss = 0.42750951647758484
Iteration 811: Loss = 0.4274868965148926
Iteration 812: Loss = 0.42746424674987793
Iteration 813: Loss = 0.42744165658950806
Iteration 814: Loss = 0.42741891741752625
Iteration 815: Loss = 0.42739617824554443
Iteration 816: Loss = 0.4273734390735626
Iteration 817: Loss = 0.4273507297039032
Iteration 818: Loss = 0.4273279309272766
Iteration 819: Loss = 0.42730513215065
Iteration 820: Loss = 0.4272823631763458
Iteration 821: Loss = 0.4272594749927521
Iteration 822: Loss = 0.4272366166114807
Iteration 823: Loss = 0.4272136390209198
Iteration 824: Loss = 0.4271906912326813
Iteration 825: Loss = 0.42716771364212036
Iteration 826: Loss = 0.4271446466445923
Iteration 827: Loss = 0.4271215498447418
Iteration 828: Loss = 0.42709845304489136
Iteration 829: Loss = 0.4270753264427185
Iteration 830: Loss = 0.4270521402359009
Iteration 831: Loss = 0.42702892422676086
Iteration 832: Loss = 0.42700567841529846
Iteration 833: Loss = 0.42698243260383606
Iteration 834: Loss = 0.4269590973854065
Iteration 835: Loss = 0.42693573236465454
Iteration 836: Loss = 0.4269122779369354
Iteration 837: Loss = 0.4268888831138611
Iteration 838: Loss = 0.42686542868614197
Iteration 839: Loss = 0.4268418848514557
Iteration 840: Loss = 0.4268183708190918
Iteration 841: Loss = 0.42679473757743835
Iteration 842: Loss = 0.4267711937427521
Iteration 843: Loss = 0.42674753069877625
Iteration 844: Loss = 0.4267238676548004
Iteration 845: Loss = 0.4267002046108246
Iteration 846: Loss = 0.42667651176452637
Iteration 847: Loss = 0.4266526997089386
Iteration 848: Loss = 0.4266289174556732
Iteration 849: Loss = 0.4266050159931183
Iteration 850: Loss = 0.42658111453056335
Iteration 851: Loss = 0.42655718326568604
Iteration 852: Loss = 0.42653316259384155
Iteration 853: Loss = 0.4265090823173523
Iteration 854: Loss = 0.42648500204086304
Iteration 855: Loss = 0.4264609217643738
Iteration 856: Loss = 0.4264366924762726
Iteration 857: Loss = 0.4264124631881714
Iteration 858: Loss = 0.4263882339000702
Iteration 859: Loss = 0.426364004611969
Iteration 860: Loss = 0.426339715719223
Iteration 861: Loss = 0.4263153672218323
Iteration 862: Loss = 0.42629098892211914
Iteration 863: Loss = 0.426266610622406
Iteration 864: Loss = 0.42624208331108093
Iteration 865: Loss = 0.42621752619743347
Iteration 866: Loss = 0.4261929988861084
Iteration 867: Loss = 0.426168292760849
Iteration 868: Loss = 0.4261436462402344
Iteration 869: Loss = 0.4261189103126526
Iteration 870: Loss = 0.4260941445827484
Iteration 871: Loss = 0.42606934905052185
Iteration 872: Loss = 0.42604443430900574
Iteration 873: Loss = 0.4260195195674896
Iteration 874: Loss = 0.4259946942329407
Iteration 875: Loss = 0.4259697496891022
Iteration 876: Loss = 0.4259447753429413
Iteration 877: Loss = 0.4259197413921356
Iteration 878: Loss = 0.4258946478366852
Iteration 879: Loss = 0.42586949467658997
Iteration 880: Loss = 0.42584431171417236
Iteration 881: Loss = 0.42581906914711
Iteration 882: Loss = 0.42579376697540283
Iteration 883: Loss = 0.4257684648036957
Iteration 884: Loss = 0.42574307322502136
Iteration 885: Loss = 0.42571765184402466
Iteration 886: Loss = 0.4256921410560608
Iteration 887: Loss = 0.42566660046577454
Iteration 888: Loss = 0.4256410300731659
Iteration 889: Loss = 0.4256153702735901
Iteration 890: Loss = 0.4255897104740143
Iteration 891: Loss = 0.42556390166282654
Iteration 892: Loss = 0.42553815245628357
Iteration 893: Loss = 0.4255122244358063
Iteration 894: Loss = 0.42548632621765137
Iteration 895: Loss = 0.4254603385925293
Iteration 896: Loss = 0.4254343509674072
Iteration 897: Loss = 0.425408273935318
Iteration 898: Loss = 0.42538222670555115
Iteration 899: Loss = 0.4253561198711395
Iteration 900: Loss = 0.42532989382743835
Iteration 901: Loss = 0.4253036379814148
Iteration 902: Loss = 0.42527735233306885
Iteration 903: Loss = 0.42525091767311096
Iteration 904: Loss = 0.4252244532108307
Iteration 905: Loss = 0.42519789934158325
Iteration 906: Loss = 0.425171434879303
Iteration 907: Loss = 0.42514488101005554
Iteration 908: Loss = 0.4251182973384857
Iteration 909: Loss = 0.42509162425994873
Iteration 910: Loss = 0.42506495118141174
Iteration 911: Loss = 0.42503821849823
Iteration 912: Loss = 0.42501142621040344
Iteration 913: Loss = 0.42498454451560974
Iteration 914: Loss = 0.42495763301849365
Iteration 915: Loss = 0.42493072152137756
Iteration 916: Loss = 0.42490366101264954
Iteration 917: Loss = 0.4248766005039215
Iteration 918: Loss = 0.4248494803905487
Iteration 919: Loss = 0.42482230067253113
Iteration 920: Loss = 0.4247950315475464
Iteration 921: Loss = 0.42476776242256165
Iteration 922: Loss = 0.42474040389060974
Iteration 923: Loss = 0.42471298575401306
Iteration 924: Loss = 0.424685537815094
Iteration 925: Loss = 0.42465803027153015
Iteration 926: Loss = 0.42463040351867676
Iteration 927: Loss = 0.424602746963501
Iteration 928: Loss = 0.4245750606060028
Iteration 929: Loss = 0.4245472848415375
Iteration 930: Loss = 0.424519419670105
Iteration 931: Loss = 0.4244914650917053
Iteration 932: Loss = 0.4244634807109833
Iteration 933: Loss = 0.42443543672561646
Iteration 934: Loss = 0.4244072735309601
Iteration 935: Loss = 0.4243791103363037
Iteration 936: Loss = 0.42435088753700256
Iteration 937: Loss = 0.4243226647377014
Iteration 938: Loss = 0.4242944121360779
Iteration 939: Loss = 0.42426609992980957
Iteration 940: Loss = 0.42423775792121887
Iteration 941: Loss = 0.424209326505661
Iteration 942: Loss = 0.42418089509010315
Iteration 943: Loss = 0.42415234446525574
Iteration 944: Loss = 0.42412373423576355
Iteration 945: Loss = 0.424095094203949
Iteration 946: Loss = 0.4240663945674896
Iteration 947: Loss = 0.4240376055240631
Iteration 948: Loss = 0.424008846282959
Iteration 949: Loss = 0.4239799380302429
Iteration 950: Loss = 0.42395099997520447
Iteration 951: Loss = 0.42392200231552124
Iteration 952: Loss = 0.42389291524887085
Iteration 953: Loss = 0.4238637685775757
Iteration 954: Loss = 0.42383456230163574
Iteration 955: Loss = 0.42380526661872864
Iteration 956: Loss = 0.42377591133117676
Iteration 957: Loss = 0.4237464964389801
Iteration 958: Loss = 0.42371705174446106
Iteration 959: Loss = 0.4236874580383301
Iteration 960: Loss = 0.4236578345298767
Iteration 961: Loss = 0.42362815141677856
Iteration 962: Loss = 0.42359837889671326
Iteration 963: Loss = 0.42356860637664795
Iteration 964: Loss = 0.4235386848449707
Iteration 965: Loss = 0.42350876331329346
Iteration 966: Loss = 0.4234788119792938
Iteration 967: Loss = 0.42344874143600464
Iteration 968: Loss = 0.42341867089271545
Iteration 969: Loss = 0.4233885109424591
Iteration 970: Loss = 0.4233582615852356
Iteration 971: Loss = 0.4233279526233673
Iteration 972: Loss = 0.42329761385917664
Iteration 973: Loss = 0.4232671558856964
Iteration 974: Loss = 0.4232366383075714
Iteration 975: Loss = 0.42320603132247925
Iteration 976: Loss = 0.42317548394203186
Iteration 977: Loss = 0.42314478754997253
Iteration 978: Loss = 0.42311400175094604
Iteration 979: Loss = 0.42308321595191956
Iteration 980: Loss = 0.4230523109436035
Iteration 981: Loss = 0.42302125692367554
Iteration 982: Loss = 0.42299026250839233
Iteration 983: Loss = 0.4229590892791748
Iteration 984: Loss = 0.4229278862476349
Iteration 985: Loss = 0.4228966534137726
Iteration 986: Loss = 0.4228653907775879
Iteration 987: Loss = 0.42283397912979126
Iteration 988: Loss = 0.42280256748199463
Iteration 989: Loss = 0.42277100682258606
Iteration 990: Loss = 0.4227393865585327
Iteration 991: Loss = 0.4227076768875122
Iteration 992: Loss = 0.4226759374141693
Iteration 993: Loss = 0.4226441979408264
Iteration 994: Loss = 0.42261236906051636
Iteration 995: Loss = 0.4225805103778839
Iteration 996: Loss = 0.4225485622882843
Iteration 997: Loss = 0.4225165545940399
Iteration 998: Loss = 0.422484427690506
Iteration 999: Loss = 0.42245230078697205
Iteration 1000: Loss = 0.42242002487182617


Total training time (seconds): 11.57
