Iteration 1: Loss = 0.6313536763191223
Iteration 2: Loss = 0.6201868653297424
Iteration 3: Loss = 0.6098490357398987
Iteration 4: Loss = 0.6003503799438477
Iteration 5: Loss = 0.5916967988014221
Iteration 6: Loss = 0.5838863849639893
Iteration 7: Loss = 0.5769107341766357
Iteration 8: Loss = 0.5707553625106812
Iteration 9: Loss = 0.565399169921875
Iteration 10: Loss = 0.5608112812042236
Iteration 11: Loss = 0.556951642036438
Iteration 12: Loss = 0.5537735819816589
Iteration 13: Loss = 0.5512188076972961
Iteration 14: Loss = 0.5492218732833862
Iteration 15: Loss = 0.5477105379104614
Iteration 16: Loss = 0.5466061234474182
Iteration 17: Loss = 0.5458288788795471
Iteration 18: Loss = 0.5452957153320312
Iteration 19: Loss = 0.5449288487434387
Iteration 20: Loss = 0.5446569323539734
Iteration 21: Loss = 0.5444163680076599
Iteration 22: Loss = 0.5441523194313049
Iteration 23: Loss = 0.5438274145126343
Iteration 24: Loss = 0.5434114933013916
Iteration 25: Loss = 0.5428887009620667
Iteration 26: Loss = 0.5422534942626953
Iteration 27: Loss = 0.5415096282958984
Iteration 28: Loss = 0.5406677722930908
Iteration 29: Loss = 0.5397433638572693
Iteration 30: Loss = 0.5387555956840515
Iteration 31: Loss = 0.5377247929573059
Iteration 32: Loss = 0.5366699695587158
Iteration 33: Loss = 0.5356106758117676
Iteration 34: Loss = 0.5345640778541565
Iteration 35: Loss = 0.5335424542427063
Iteration 36: Loss = 0.5325559377670288
Iteration 37: Loss = 0.5316122770309448
Iteration 38: Loss = 0.5307151079177856
Iteration 39: Loss = 0.5298636555671692
Iteration 40: Loss = 0.5290579199790955
Iteration 41: Loss = 0.5282931923866272
Iteration 42: Loss = 0.5275620222091675
Iteration 43: Loss = 0.5268591642379761
Iteration 44: Loss = 0.5261777639389038
Iteration 45: Loss = 0.5255088210105896
Iteration 46: Loss = 0.5248481631278992
Iteration 47: Loss = 0.5241899490356445
Iteration 48: Loss = 0.5235279202461243
Iteration 49: Loss = 0.5228602290153503
Iteration 50: Loss = 0.5221858024597168
Iteration 51: Loss = 0.5215024948120117
Iteration 52: Loss = 0.5208112597465515
Iteration 53: Loss = 0.520114004611969
Iteration 54: Loss = 0.519411563873291
Iteration 55: Loss = 0.5187075734138489
Iteration 56: Loss = 0.5180036425590515
Iteration 57: Loss = 0.517300009727478
Iteration 58: Loss = 0.5166016817092896
Iteration 59: Loss = 0.5159094333648682
Iteration 60: Loss = 0.5152229070663452
Iteration 61: Loss = 0.5145447254180908
Iteration 62: Loss = 0.513874888420105
Iteration 63: Loss = 0.513212263584137
Iteration 64: Loss = 0.5125570893287659
Iteration 65: Loss = 0.5119072794914246
Iteration 66: Loss = 0.5112634897232056
Iteration 67: Loss = 0.5106241703033447
Iteration 68: Loss = 0.5099864602088928
Iteration 69: Loss = 0.5093522667884827
Iteration 70: Loss = 0.5087196230888367
Iteration 71: Loss = 0.5080878138542175
Iteration 72: Loss = 0.5074576735496521
Iteration 73: Loss = 0.5068265795707703
Iteration 74: Loss = 0.5061979293823242
Iteration 75: Loss = 0.5055699944496155
Iteration 76: Loss = 0.5049431324005127
Iteration 77: Loss = 0.5043187141418457
Iteration 78: Loss = 0.5036947131156921
Iteration 79: Loss = 0.5030745267868042
Iteration 80: Loss = 0.5024557709693909
Iteration 81: Loss = 0.5018396377563477
Iteration 82: Loss = 0.5012263059616089
Iteration 83: Loss = 0.5006150603294373
Iteration 84: Loss = 0.5000079274177551
Iteration 85: Loss = 0.49940139055252075
Iteration 86: Loss = 0.498798131942749
Iteration 87: Loss = 0.49819615483283997
Iteration 88: Loss = 0.49759671092033386
Iteration 89: Loss = 0.49699920415878296
Iteration 90: Loss = 0.4964028000831604
Iteration 91: Loss = 0.49580785632133484
Iteration 92: Loss = 0.49521344900131226
Iteration 93: Loss = 0.49462124705314636
Iteration 94: Loss = 0.49402904510498047
Iteration 95: Loss = 0.4934390187263489
Iteration 96: Loss = 0.49284863471984863
Iteration 97: Loss = 0.49226051568984985
Iteration 98: Loss = 0.49167299270629883
Iteration 99: Loss = 0.491087943315506
Iteration 100: Loss = 0.490502268075943
Iteration 101: Loss = 0.4899188280105591
Iteration 102: Loss = 0.4893355071544647
Iteration 103: Loss = 0.48875486850738525
Iteration 104: Loss = 0.48817354440689087
Iteration 105: Loss = 0.48759400844573975
Iteration 106: Loss = 0.4870142936706543
Iteration 107: Loss = 0.4864365756511688
Iteration 108: Loss = 0.48585912585258484
Iteration 109: Loss = 0.4852820634841919
Iteration 110: Loss = 0.4847051203250885
Iteration 111: Loss = 0.4841282367706299
Iteration 112: Loss = 0.48355305194854736
Iteration 113: Loss = 0.482977032661438
Iteration 114: Loss = 0.4824022948741913
Iteration 115: Loss = 0.4818263351917267
Iteration 116: Loss = 0.4812515079975128
Iteration 117: Loss = 0.4806768298149109
Iteration 118: Loss = 0.4801015853881836
Iteration 119: Loss = 0.4795270562171936
Iteration 120: Loss = 0.47895142436027527
Iteration 121: Loss = 0.4783768951892853
Iteration 122: Loss = 0.4778018295764923
Iteration 123: Loss = 0.477225661277771
Iteration 124: Loss = 0.47664958238601685
Iteration 125: Loss = 0.4760722517967224
Iteration 126: Loss = 0.4754946827888489
Iteration 127: Loss = 0.47491729259490967
Iteration 128: Loss = 0.4743387997150421
Iteration 129: Loss = 0.47376012802124023
Iteration 130: Loss = 0.4731823205947876
Iteration 131: Loss = 0.472602903842926
Iteration 132: Loss = 0.4720228910446167
Iteration 133: Loss = 0.47144240140914917
Iteration 134: Loss = 0.47086137533187866
Iteration 135: Loss = 0.470279335975647
Iteration 136: Loss = 0.46969661116600037
Iteration 137: Loss = 0.46911269426345825
Iteration 138: Loss = 0.468526691198349
Iteration 139: Loss = 0.4679401218891144
Iteration 140: Loss = 0.4673524796962738
Iteration 141: Loss = 0.4667631983757019
Iteration 142: Loss = 0.4661718010902405
Iteration 143: Loss = 0.4655797779560089
Iteration 144: Loss = 0.4649859666824341
Iteration 145: Loss = 0.4643901586532593
Iteration 146: Loss = 0.4637923836708069
Iteration 147: Loss = 0.4631936252117157
Iteration 148: Loss = 0.4625927805900574
Iteration 149: Loss = 0.4619896709918976
Iteration 150: Loss = 0.46138498187065125
Iteration 151: Loss = 0.4607788920402527
Iteration 152: Loss = 0.46017029881477356
Iteration 153: Loss = 0.45955947041511536
Iteration 154: Loss = 0.45894697308540344
Iteration 155: Loss = 0.45833221077919006
Iteration 156: Loss = 0.4577142000198364
Iteration 157: Loss = 0.45709332823753357
Iteration 158: Loss = 0.4564698338508606
Iteration 159: Loss = 0.455843985080719
Iteration 160: Loss = 0.45521485805511475
Iteration 161: Loss = 0.4545825719833374
Iteration 162: Loss = 0.4539485275745392
Iteration 163: Loss = 0.4533114731311798
Iteration 164: Loss = 0.45267102122306824
Iteration 165: Loss = 0.45202672481536865
Iteration 166: Loss = 0.4513799846172333
Iteration 167: Loss = 0.45072904229164124
Iteration 168: Loss = 0.45007362961769104
Iteration 169: Loss = 0.4494144320487976
Iteration 170: Loss = 0.44875267148017883
Iteration 171: Loss = 0.4480874240398407
Iteration 172: Loss = 0.4474181532859802
Iteration 173: Loss = 0.44674545526504517
Iteration 174: Loss = 0.44606953859329224
Iteration 175: Loss = 0.44538989663124084
Iteration 176: Loss = 0.44470617175102234
Iteration 177: Loss = 0.4440188407897949
Iteration 178: Loss = 0.4433267116546631
Iteration 179: Loss = 0.4426303207874298
Iteration 180: Loss = 0.4419308304786682
Iteration 181: Loss = 0.44122618436813354
Iteration 182: Loss = 0.44051697850227356
Iteration 183: Loss = 0.4398028254508972
Iteration 184: Loss = 0.4390866160392761
Iteration 185: Loss = 0.43836694955825806
Iteration 186: Loss = 0.4376415014266968
Iteration 187: Loss = 0.4369131922721863
Iteration 188: Loss = 0.43618133664131165
Iteration 189: Loss = 0.43544524908065796
Iteration 190: Loss = 0.43470513820648193
Iteration 191: Loss = 0.4339621365070343
Iteration 192: Loss = 0.43321460485458374
Iteration 193: Loss = 0.4324618875980377
Iteration 194: Loss = 0.43170711398124695
Iteration 195: Loss = 0.43094998598098755
Iteration 196: Loss = 0.43018949031829834
Iteration 197: Loss = 0.42942848801612854
Iteration 198: Loss = 0.4286660850048065
Iteration 199: Loss = 0.42790091037750244
Iteration 200: Loss = 0.4271342158317566
Iteration 201: Loss = 0.4263661503791809
Iteration 202: Loss = 0.4255959987640381
Iteration 203: Loss = 0.4248247444629669
Iteration 204: Loss = 0.42405200004577637
Iteration 205: Loss = 0.4232794940471649
Iteration 206: Loss = 0.422506183385849
Iteration 207: Loss = 0.4217328131198883
Iteration 208: Loss = 0.42095947265625
Iteration 209: Loss = 0.42018750309944153
Iteration 210: Loss = 0.4194171130657196
Iteration 211: Loss = 0.4186471104621887
Iteration 212: Loss = 0.4178781807422638
Iteration 213: Loss = 0.417113333940506
Iteration 214: Loss = 0.4163528382778168
Iteration 215: Loss = 0.4155964255332947
Iteration 216: Loss = 0.41484522819519043
Iteration 217: Loss = 0.4140981435775757
Iteration 218: Loss = 0.4133554697036743
Iteration 219: Loss = 0.412619948387146
Iteration 220: Loss = 0.411892294883728
Iteration 221: Loss = 0.4111717641353607
Iteration 222: Loss = 0.4104587137699127
Iteration 223: Loss = 0.40975427627563477
Iteration 224: Loss = 0.4090588390827179
Iteration 225: Loss = 0.40837323665618896
Iteration 226: Loss = 0.40769848227500916
Iteration 227: Loss = 0.4070361256599426
Iteration 228: Loss = 0.40638601779937744
Iteration 229: Loss = 0.4057488739490509
Iteration 230: Loss = 0.40512707829475403
Iteration 231: Loss = 0.40452080965042114
Iteration 232: Loss = 0.4039284288883209
Iteration 233: Loss = 0.4033510982990265
Iteration 234: Loss = 0.40279075503349304
Iteration 235: Loss = 0.40224555134773254
Iteration 236: Loss = 0.40171632170677185
Iteration 237: Loss = 0.40120428800582886
Iteration 238: Loss = 0.4007105231285095
Iteration 239: Loss = 0.4002349376678467
Iteration 240: Loss = 0.39977818727493286
Iteration 241: Loss = 0.39934051036834717
Iteration 242: Loss = 0.39892199635505676
Iteration 243: Loss = 0.39852094650268555
Iteration 244: Loss = 0.39813655614852905
Iteration 245: Loss = 0.39777088165283203
Iteration 246: Loss = 0.3974207043647766
Iteration 247: Loss = 0.3970867097377777
Iteration 248: Loss = 0.3967682123184204
Iteration 249: Loss = 0.39646655321121216
Iteration 250: Loss = 0.3961806893348694
Iteration 251: Loss = 0.3959093391895294
Iteration 252: Loss = 0.39565232396125793
Iteration 253: Loss = 0.3954088091850281
Iteration 254: Loss = 0.39517781138420105
Iteration 255: Loss = 0.39495837688446045
Iteration 256: Loss = 0.39474987983703613
Iteration 257: Loss = 0.3945513069629669
Iteration 258: Loss = 0.3943615257740021
Iteration 259: Loss = 0.39418014883995056
Iteration 260: Loss = 0.3940063416957855
Iteration 261: Loss = 0.39383912086486816
Iteration 262: Loss = 0.3936774730682373
Iteration 263: Loss = 0.3935213088989258
Iteration 264: Loss = 0.39336955547332764
Iteration 265: Loss = 0.39322149753570557
Iteration 266: Loss = 0.39307740330696106
Iteration 267: Loss = 0.3929361402988434
Iteration 268: Loss = 0.3927971124649048
Iteration 269: Loss = 0.39266085624694824
Iteration 270: Loss = 0.3925260603427887
Iteration 271: Loss = 0.39239272475242615
Iteration 272: Loss = 0.3922606110572815
Iteration 273: Loss = 0.39212995767593384
Iteration 274: Loss = 0.3920004069805145
Iteration 275: Loss = 0.39187169075012207
Iteration 276: Loss = 0.39174383878707886
Iteration 277: Loss = 0.39161670207977295
Iteration 278: Loss = 0.39149048924446106
Iteration 279: Loss = 0.3913652300834656
Iteration 280: Loss = 0.39124077558517456
Iteration 281: Loss = 0.3911170959472656
Iteration 282: Loss = 0.39099419116973877
Iteration 283: Loss = 0.3908720016479492
Iteration 284: Loss = 0.3907507061958313
Iteration 285: Loss = 0.39063137769699097
Iteration 286: Loss = 0.3905128836631775
Iteration 287: Loss = 0.39039528369903564
Iteration 288: Loss = 0.39027854800224304
Iteration 289: Loss = 0.39016351103782654
Iteration 290: Loss = 0.3900494873523712
Iteration 291: Loss = 0.38993632793426514
Iteration 292: Loss = 0.38982412219047546
Iteration 293: Loss = 0.3897135555744171
Iteration 294: Loss = 0.3896038830280304
Iteration 295: Loss = 0.3894953727722168
Iteration 296: Loss = 0.3893878757953644
Iteration 297: Loss = 0.3892819881439209
Iteration 298: Loss = 0.38917699456214905
Iteration 299: Loss = 0.3890727460384369
Iteration 300: Loss = 0.38896945118904114
Iteration 301: Loss = 0.3888677656650543
Iteration 302: Loss = 0.3887668251991272
Iteration 303: Loss = 0.3886668384075165
Iteration 304: Loss = 0.3885675370693207
Iteration 305: Loss = 0.3884694278240204
Iteration 306: Loss = 0.38837262988090515
Iteration 307: Loss = 0.38827675580978394
Iteration 308: Loss = 0.3881817162036896
Iteration 309: Loss = 0.3880873918533325
Iteration 310: Loss = 0.38799402117729187
Iteration 311: Loss = 0.38790184259414673
Iteration 312: Loss = 0.38781043887138367
Iteration 313: Loss = 0.3877197206020355
Iteration 314: Loss = 0.38762980699539185
Iteration 315: Loss = 0.3875405490398407
Iteration 316: Loss = 0.387452095746994
Iteration 317: Loss = 0.3873644173145294
Iteration 318: Loss = 0.3872777223587036
Iteration 319: Loss = 0.3871917128562927
Iteration 320: Loss = 0.38710644841194153
Iteration 321: Loss = 0.3870217502117157
Iteration 322: Loss = 0.38693779706954956
Iteration 323: Loss = 0.38685449957847595
Iteration 324: Loss = 0.38677188754081726
Iteration 325: Loss = 0.38669002056121826
Iteration 326: Loss = 0.38660913705825806
Iteration 327: Loss = 0.3865289092063904
Iteration 328: Loss = 0.3864493668079376
Iteration 329: Loss = 0.38637033104896545
Iteration 330: Loss = 0.3862919509410858
Iteration 331: Loss = 0.3862141966819763
Iteration 332: Loss = 0.3861369788646698
Iteration 333: Loss = 0.3860604166984558
Iteration 334: Loss = 0.3859843909740448
Iteration 335: Loss = 0.38590896129608154
Iteration 336: Loss = 0.3858339786529541
Iteration 337: Loss = 0.3857599198818207
Iteration 338: Loss = 0.3856864273548126
Iteration 339: Loss = 0.38561341166496277
Iteration 340: Loss = 0.3855409324169159
Iteration 341: Loss = 0.385468989610672
Iteration 342: Loss = 0.3853974938392639
Iteration 343: Loss = 0.3853265941143036
Iteration 344: Loss = 0.3852561116218567
Iteration 345: Loss = 0.3851861357688904
Iteration 346: Loss = 0.3851165771484375
Iteration 347: Loss = 0.3850475549697876
Iteration 348: Loss = 0.3849790096282959
Iteration 349: Loss = 0.38491111993789673
Iteration 350: Loss = 0.3848436772823334
Iteration 351: Loss = 0.3847767412662506
Iteration 352: Loss = 0.3847101330757141
Iteration 353: Loss = 0.3846439719200134
Iteration 354: Loss = 0.38457828760147095
Iteration 355: Loss = 0.38451293110847473
Iteration 356: Loss = 0.38444799184799194
Iteration 357: Loss = 0.3843834698200226
Iteration 358: Loss = 0.38431939482688904
Iteration 359: Loss = 0.38425561785697937
Iteration 360: Loss = 0.38419249653816223
Iteration 361: Loss = 0.38412994146347046
Iteration 362: Loss = 0.38406771421432495
Iteration 363: Loss = 0.3840058147907257
Iteration 364: Loss = 0.3839443027973175
Iteration 365: Loss = 0.38388314843177795
Iteration 366: Loss = 0.3838222622871399
Iteration 367: Loss = 0.3837617039680481
Iteration 368: Loss = 0.3837015628814697
Iteration 369: Loss = 0.38364171981811523
Iteration 370: Loss = 0.38358211517333984
Iteration 371: Loss = 0.3835228681564331
Iteration 372: Loss = 0.38346385955810547
Iteration 373: Loss = 0.3834054172039032
Iteration 374: Loss = 0.3833472430706024
Iteration 375: Loss = 0.3832893371582031
Iteration 376: Loss = 0.3832317292690277
Iteration 377: Loss = 0.38317444920539856
Iteration 378: Loss = 0.3831173777580261
Iteration 379: Loss = 0.3830605447292328
Iteration 380: Loss = 0.3830040693283081
Iteration 381: Loss = 0.38294774293899536
Iteration 382: Loss = 0.3828917145729065
Iteration 383: Loss = 0.38283589482307434
Iteration 384: Loss = 0.38278040289878845
Iteration 385: Loss = 0.38272491097450256
Iteration 386: Loss = 0.3826698660850525
Iteration 387: Loss = 0.38261523842811584
Iteration 388: Loss = 0.38256096839904785
Iteration 389: Loss = 0.3825069069862366
Iteration 390: Loss = 0.38245296478271484
Iteration 391: Loss = 0.3823993504047394
Iteration 392: Loss = 0.38234588503837585
Iteration 393: Loss = 0.38229265809059143
Iteration 394: Loss = 0.38223958015441895
Iteration 395: Loss = 0.38218677043914795
Iteration 396: Loss = 0.38213416934013367
Iteration 397: Loss = 0.38208165764808655
Iteration 398: Loss = 0.3820294141769409
Iteration 399: Loss = 0.3819773197174072
Iteration 400: Loss = 0.3819253742694855
Iteration 401: Loss = 0.38187360763549805
Iteration 402: Loss = 0.38182201981544495
Iteration 403: Loss = 0.38177064061164856
Iteration 404: Loss = 0.3817194402217865
Iteration 405: Loss = 0.38166847825050354
Iteration 406: Loss = 0.3816176950931549
Iteration 407: Loss = 0.3815671503543854
Iteration 408: Loss = 0.3815166652202606
Iteration 409: Loss = 0.3814663589000702
Iteration 410: Loss = 0.3814162313938141
Iteration 411: Loss = 0.38136616349220276
Iteration 412: Loss = 0.38131627440452576
Iteration 413: Loss = 0.3812665343284607
Iteration 414: Loss = 0.38121694326400757
Iteration 415: Loss = 0.381167471408844
Iteration 416: Loss = 0.3811180293560028
Iteration 417: Loss = 0.38106876611709595
Iteration 418: Loss = 0.38101962208747864
Iteration 419: Loss = 0.38097065687179565
Iteration 420: Loss = 0.3809216618537903
Iteration 421: Loss = 0.3808728754520416
Iteration 422: Loss = 0.38082408905029297
Iteration 423: Loss = 0.38077545166015625
Iteration 424: Loss = 0.3807269036769867
Iteration 425: Loss = 0.380678653717041
Iteration 426: Loss = 0.3806304335594177
Iteration 427: Loss = 0.38058236241340637
Iteration 428: Loss = 0.3805343508720398
Iteration 429: Loss = 0.38048654794692993
Iteration 430: Loss = 0.3804387152194977
Iteration 431: Loss = 0.3803909718990326
Iteration 432: Loss = 0.38034334778785706
Iteration 433: Loss = 0.38029584288597107
Iteration 434: Loss = 0.38024845719337463
Iteration 435: Loss = 0.3802010715007782
Iteration 436: Loss = 0.38015374541282654
Iteration 437: Loss = 0.3801066279411316
Iteration 438: Loss = 0.38005948066711426
Iteration 439: Loss = 0.3800123631954193
Iteration 440: Loss = 0.3799653649330139
Iteration 441: Loss = 0.3799184262752533
Iteration 442: Loss = 0.37987154722213745
Iteration 443: Loss = 0.379824697971344
Iteration 444: Loss = 0.3797779381275177
Iteration 445: Loss = 0.37973132729530334
Iteration 446: Loss = 0.3796848952770233
Iteration 447: Loss = 0.37963852286338806
Iteration 448: Loss = 0.3795921802520752
Iteration 449: Loss = 0.3795459270477295
Iteration 450: Loss = 0.37949976325035095
Iteration 451: Loss = 0.3794535994529724
Iteration 452: Loss = 0.37940752506256104
Iteration 453: Loss = 0.37936145067214966
Iteration 454: Loss = 0.37931546568870544
Iteration 455: Loss = 0.379269540309906
Iteration 456: Loss = 0.37922364473342896
Iteration 457: Loss = 0.3791777491569519
Iteration 458: Loss = 0.3791320025920868
Iteration 459: Loss = 0.3790862262248993
Iteration 460: Loss = 0.3790404498577118
Iteration 461: Loss = 0.37899482250213623
Iteration 462: Loss = 0.3789491355419159
Iteration 463: Loss = 0.3789035379886627
Iteration 464: Loss = 0.37885794043540955
Iteration 465: Loss = 0.37881234288215637
Iteration 466: Loss = 0.37876689434051514
Iteration 467: Loss = 0.3787213861942291
Iteration 468: Loss = 0.3786759376525879
Iteration 469: Loss = 0.37863054871559143
Iteration 470: Loss = 0.3785850703716278
Iteration 471: Loss = 0.37853971123695374
Iteration 472: Loss = 0.37849438190460205
Iteration 473: Loss = 0.37844905257225037
Iteration 474: Loss = 0.3784039318561554
Iteration 475: Loss = 0.3783588111400604
Iteration 476: Loss = 0.37831375002861023
Iteration 477: Loss = 0.37826868891716003
Iteration 478: Loss = 0.37822362780570984
Iteration 479: Loss = 0.3781786561012268
Iteration 480: Loss = 0.378133624792099
Iteration 481: Loss = 0.37808868288993835
Iteration 482: Loss = 0.3780437707901001
Iteration 483: Loss = 0.37799882888793945
Iteration 484: Loss = 0.3779539167881012
Iteration 485: Loss = 0.3779090940952301
Iteration 486: Loss = 0.377864271402359
Iteration 487: Loss = 0.3778194189071655
Iteration 488: Loss = 0.3777746558189392
Iteration 489: Loss = 0.3777299225330353
Iteration 490: Loss = 0.3776852488517761
Iteration 491: Loss = 0.37764063477516174
Iteration 492: Loss = 0.3775959610939026
Iteration 493: Loss = 0.3775513768196106
Iteration 494: Loss = 0.3775067627429962
Iteration 495: Loss = 0.3774622082710266
Iteration 496: Loss = 0.377417653799057
Iteration 497: Loss = 0.3773730993270874
Iteration 498: Loss = 0.3773286044597626
Iteration 499: Loss = 0.37728407979011536
Iteration 500: Loss = 0.3772396147251129
Iteration 501: Loss = 0.3771950900554657
Iteration 502: Loss = 0.37715062499046326
Iteration 503: Loss = 0.3771061301231384
Iteration 504: Loss = 0.377061665058136
Iteration 505: Loss = 0.37701719999313354
Iteration 506: Loss = 0.37697285413742065
Iteration 507: Loss = 0.3769283890724182
Iteration 508: Loss = 0.37688392400741577
Iteration 509: Loss = 0.37683945894241333
Iteration 510: Loss = 0.37679505348205566
Iteration 511: Loss = 0.3767506182193756
Iteration 512: Loss = 0.37670618295669556
Iteration 513: Loss = 0.3766617476940155
Iteration 514: Loss = 0.3766173720359802
Iteration 515: Loss = 0.3765729069709778
Iteration 516: Loss = 0.37652847170829773
Iteration 517: Loss = 0.37648409605026245
Iteration 518: Loss = 0.37643963098526
Iteration 519: Loss = 0.37639522552490234
Iteration 520: Loss = 0.37635087966918945
Iteration 521: Loss = 0.3763064444065094
Iteration 522: Loss = 0.37626200914382935
Iteration 523: Loss = 0.3762178122997284
Iteration 524: Loss = 0.37617355585098267
Iteration 525: Loss = 0.3761293292045593
Iteration 526: Loss = 0.3760850727558136
Iteration 527: Loss = 0.37604081630706787
Iteration 528: Loss = 0.37599658966064453
Iteration 529: Loss = 0.37595224380493164
Iteration 530: Loss = 0.3759080171585083
Iteration 531: Loss = 0.37586382031440735
Iteration 532: Loss = 0.37581974267959595
Iteration 533: Loss = 0.37577560544013977
Iteration 534: Loss = 0.37573152780532837
Iteration 535: Loss = 0.37568747997283936
Iteration 536: Loss = 0.37564340233802795
Iteration 537: Loss = 0.37559932470321655
Iteration 538: Loss = 0.37555527687072754
Iteration 539: Loss = 0.3755112290382385
Iteration 540: Loss = 0.3754672110080719
Iteration 541: Loss = 0.37542322278022766
Iteration 542: Loss = 0.37537917494773865
Iteration 543: Loss = 0.3753351867198944
Iteration 544: Loss = 0.37529119849205017
Iteration 545: Loss = 0.37524718046188354
Iteration 546: Loss = 0.3752032518386841
Iteration 547: Loss = 0.37515923380851746
Iteration 548: Loss = 0.3751152753829956
Iteration 549: Loss = 0.37507128715515137
Iteration 550: Loss = 0.3750273585319519
Iteration 551: Loss = 0.37498340010643005
Iteration 552: Loss = 0.3749394118785858
Iteration 553: Loss = 0.37489551305770874
Iteration 554: Loss = 0.3748515546321869
Iteration 555: Loss = 0.37480759620666504
Iteration 556: Loss = 0.3747636675834656
Iteration 557: Loss = 0.3747197389602661
Iteration 558: Loss = 0.37467581033706665
Iteration 559: Loss = 0.3746317923069
Iteration 560: Loss = 0.37458789348602295
Iteration 561: Loss = 0.3745439946651459
Iteration 562: Loss = 0.3745000660419464
Iteration 563: Loss = 0.37445610761642456
Iteration 564: Loss = 0.3744121789932251
Iteration 565: Loss = 0.37436822056770325
Iteration 566: Loss = 0.37432435154914856
Iteration 567: Loss = 0.3742804229259491
Iteration 568: Loss = 0.37423649430274963
Iteration 569: Loss = 0.37419262528419495
Iteration 570: Loss = 0.37414881587028503
Iteration 571: Loss = 0.37410494685173035
Iteration 572: Loss = 0.37406110763549805
Iteration 573: Loss = 0.37401720881462097
Iteration 574: Loss = 0.37397342920303345
Iteration 575: Loss = 0.37392953038215637
Iteration 576: Loss = 0.37388575077056885
Iteration 577: Loss = 0.37384194135665894
Iteration 578: Loss = 0.373798131942749
Iteration 579: Loss = 0.3737542927265167
Iteration 580: Loss = 0.3737105131149292
Iteration 581: Loss = 0.3736667335033417
Iteration 582: Loss = 0.37362295389175415
Iteration 583: Loss = 0.37357914447784424
Iteration 584: Loss = 0.3735353648662567
Iteration 585: Loss = 0.37349170446395874
Iteration 586: Loss = 0.373447984457016
Iteration 587: Loss = 0.373404324054718
Iteration 588: Loss = 0.37336063385009766
Iteration 589: Loss = 0.3733168840408325
Iteration 590: Loss = 0.37327325344085693
Iteration 591: Loss = 0.3732295632362366
Iteration 592: Loss = 0.3731859028339386
Iteration 593: Loss = 0.3731422424316406
Iteration 594: Loss = 0.37309861183166504
Iteration 595: Loss = 0.3730548620223999
Iteration 596: Loss = 0.3730112612247467
Iteration 597: Loss = 0.37296760082244873
Iteration 598: Loss = 0.37292394042015076
Iteration 599: Loss = 0.37288033962249756
Iteration 600: Loss = 0.37283676862716675
Iteration 601: Loss = 0.37279313802719116
Iteration 602: Loss = 0.3727496266365051
Iteration 603: Loss = 0.37270599603652954
Iteration 604: Loss = 0.37266242504119873
Iteration 605: Loss = 0.3726188838481903
Iteration 606: Loss = 0.3725753426551819
Iteration 607: Loss = 0.372531920671463
Iteration 608: Loss = 0.3724885582923889
Iteration 609: Loss = 0.3724451959133148
Iteration 610: Loss = 0.3724018335342407
Iteration 611: Loss = 0.3723585307598114
Iteration 612: Loss = 0.3723151981830597
Iteration 613: Loss = 0.3722718358039856
Iteration 614: Loss = 0.37222856283187866
Iteration 615: Loss = 0.37218523025512695
Iteration 616: Loss = 0.3721420168876648
Iteration 617: Loss = 0.37209874391555786
Iteration 618: Loss = 0.3720554709434509
Iteration 619: Loss = 0.37201225757598877
Iteration 620: Loss = 0.3719690442085266
Iteration 621: Loss = 0.37192580103874207
Iteration 622: Loss = 0.3718826174736023
Iteration 623: Loss = 0.37183937430381775
Iteration 624: Loss = 0.37179625034332275
Iteration 625: Loss = 0.37175312638282776
Iteration 626: Loss = 0.371709942817688
Iteration 627: Loss = 0.3716667592525482
Iteration 628: Loss = 0.3716236650943756
Iteration 629: Loss = 0.3715805411338806
Iteration 630: Loss = 0.37153738737106323
Iteration 631: Loss = 0.371494323015213
Iteration 632: Loss = 0.37145116925239563
Iteration 633: Loss = 0.371408075094223
Iteration 634: Loss = 0.3713649809360504
Iteration 635: Loss = 0.3713219463825226
Iteration 636: Loss = 0.37127894163131714
Iteration 637: Loss = 0.3712359070777893
Iteration 638: Loss = 0.3711928725242615
Iteration 639: Loss = 0.37114986777305603
Iteration 640: Loss = 0.3711068630218506
Iteration 641: Loss = 0.37106388807296753
Iteration 642: Loss = 0.3710208535194397
Iteration 643: Loss = 0.37097784876823425
Iteration 644: Loss = 0.37093493342399597
Iteration 645: Loss = 0.3708919584751129
Iteration 646: Loss = 0.370849072933197
Iteration 647: Loss = 0.37080615758895874
Iteration 648: Loss = 0.37076327204704285
Iteration 649: Loss = 0.37072035670280457
Iteration 650: Loss = 0.3706774413585663
Iteration 651: Loss = 0.37063470482826233
Iteration 652: Loss = 0.3705918490886688
Iteration 653: Loss = 0.37054914236068726
Iteration 654: Loss = 0.37050628662109375
Iteration 655: Loss = 0.3704635500907898
Iteration 656: Loss = 0.37042078375816345
Iteration 657: Loss = 0.3703781068325043
Iteration 658: Loss = 0.3703354001045227
Iteration 659: Loss = 0.37029266357421875
Iteration 660: Loss = 0.37025001645088196
Iteration 661: Loss = 0.3702073395252228
Iteration 662: Loss = 0.3701646625995636
Iteration 663: Loss = 0.3701220750808716
Iteration 664: Loss = 0.3700794577598572
Iteration 665: Loss = 0.37003690004348755
Iteration 666: Loss = 0.36999431252479553
Iteration 667: Loss = 0.3699518144130707
Iteration 668: Loss = 0.3699093461036682
Iteration 669: Loss = 0.36986681818962097
Iteration 670: Loss = 0.3698243498802185
Iteration 671: Loss = 0.36978185176849365
Iteration 672: Loss = 0.3697394132614136
Iteration 673: Loss = 0.3696969747543335
Iteration 674: Loss = 0.3696545362472534
Iteration 675: Loss = 0.3696122169494629
Iteration 676: Loss = 0.3695698082447052
Iteration 677: Loss = 0.3695274591445923
Iteration 678: Loss = 0.3694850206375122
Iteration 679: Loss = 0.36944276094436646
Iteration 680: Loss = 0.3694004416465759
Iteration 681: Loss = 0.3693581521511078
Iteration 682: Loss = 0.3693159222602844
Iteration 683: Loss = 0.36927369236946106
Iteration 684: Loss = 0.3692314624786377
Iteration 685: Loss = 0.3691892921924591
Iteration 686: Loss = 0.3691471517086029
Iteration 687: Loss = 0.3691049814224243
Iteration 688: Loss = 0.3690628707408905
Iteration 689: Loss = 0.3690207600593567
Iteration 690: Loss = 0.3689786493778229
Iteration 691: Loss = 0.36893656849861145
Iteration 692: Loss = 0.36889466643333435
Iteration 693: Loss = 0.3688527047634125
Iteration 694: Loss = 0.368810772895813
Iteration 695: Loss = 0.3687688708305359
Iteration 696: Loss = 0.36872705817222595
Iteration 697: Loss = 0.36868518590927124
Iteration 698: Loss = 0.3686433434486389
Iteration 699: Loss = 0.36860156059265137
Iteration 700: Loss = 0.36855974793434143
Iteration 701: Loss = 0.36851799488067627
Iteration 702: Loss = 0.3684762716293335
Iteration 703: Loss = 0.3684345781803131
Iteration 704: Loss = 0.36839282512664795
Iteration 705: Loss = 0.36835119128227234
Iteration 706: Loss = 0.36830949783325195
Iteration 707: Loss = 0.3682679533958435
Iteration 708: Loss = 0.3682263195514679
Iteration 709: Loss = 0.3681846857070923
Iteration 710: Loss = 0.3681431710720062
Iteration 711: Loss = 0.36810165643692017
Iteration 712: Loss = 0.3680601418018341
Iteration 713: Loss = 0.3680187165737152
Iteration 714: Loss = 0.36797720193862915
Iteration 715: Loss = 0.36793583631515503
Iteration 716: Loss = 0.36789438128471375
Iteration 717: Loss = 0.3678530156612396
Iteration 718: Loss = 0.3678116500377655
Iteration 719: Loss = 0.36777031421661377
Iteration 720: Loss = 0.3677290081977844
Iteration 721: Loss = 0.36768773198127747
Iteration 722: Loss = 0.3676464259624481
Iteration 723: Loss = 0.36760514974594116
Iteration 724: Loss = 0.36756399273872375
Iteration 725: Loss = 0.36752283573150635
Iteration 726: Loss = 0.36748167872428894
Iteration 727: Loss = 0.36744052171707153
Iteration 728: Loss = 0.3673994541168213
Iteration 729: Loss = 0.3673582971096039
Iteration 730: Loss = 0.36731722950935364
Iteration 731: Loss = 0.36727622151374817
Iteration 732: Loss = 0.3672352433204651
Iteration 733: Loss = 0.36719420552253723
Iteration 734: Loss = 0.3671532869338989
Iteration 735: Loss = 0.36711233854293823
Iteration 736: Loss = 0.36707139015197754
Iteration 737: Loss = 0.3670305907726288
Iteration 738: Loss = 0.3669898211956024
Iteration 739: Loss = 0.366949200630188
Iteration 740: Loss = 0.36690858006477356
Iteration 741: Loss = 0.3668680489063263
Iteration 742: Loss = 0.36682751774787903
Iteration 743: Loss = 0.3667869567871094
Iteration 744: Loss = 0.3667465150356293
Iteration 745: Loss = 0.3667060434818268
Iteration 746: Loss = 0.36666569113731384
Iteration 747: Loss = 0.36662527918815613
Iteration 748: Loss = 0.36658501625061035
Iteration 749: Loss = 0.3665446639060974
Iteration 750: Loss = 0.366504430770874
Iteration 751: Loss = 0.36646419763565063
Iteration 752: Loss = 0.3664240539073944
Iteration 753: Loss = 0.3663838803768158
Iteration 754: Loss = 0.36634379625320435
Iteration 755: Loss = 0.3663037419319153
Iteration 756: Loss = 0.36626365780830383
Iteration 757: Loss = 0.36622369289398193
Iteration 758: Loss = 0.3661837577819824
Iteration 759: Loss = 0.3661437928676605
Iteration 760: Loss = 0.3661039471626282
Iteration 761: Loss = 0.3660641014575958
Iteration 762: Loss = 0.36602428555488586
Iteration 763: Loss = 0.3659845292568207
Iteration 764: Loss = 0.3659447729587555
Iteration 765: Loss = 0.3659050464630127
Iteration 766: Loss = 0.3658653497695923
Iteration 767: Loss = 0.36582571268081665
Iteration 768: Loss = 0.365786075592041
Iteration 769: Loss = 0.36574655771255493
Iteration 770: Loss = 0.3657069802284241
Iteration 771: Loss = 0.3656674921512604
Iteration 772: Loss = 0.3656280040740967
Iteration 773: Loss = 0.36558860540390015
Iteration 774: Loss = 0.3655491769313812
Iteration 775: Loss = 0.3655098080635071
Iteration 776: Loss = 0.3654704689979553
Iteration 777: Loss = 0.36543115973472595
Iteration 778: Loss = 0.36539191007614136
Iteration 779: Loss = 0.36535269021987915
Iteration 780: Loss = 0.36531344056129456
Iteration 781: Loss = 0.3652742803096771
Iteration 782: Loss = 0.3652351498603821
Iteration 783: Loss = 0.3651960790157318
Iteration 784: Loss = 0.36515697836875916
Iteration 785: Loss = 0.3651179373264313
Iteration 786: Loss = 0.3650790750980377
Iteration 787: Loss = 0.36504000425338745
Iteration 788: Loss = 0.3650011420249939
Iteration 789: Loss = 0.3649623394012451
Iteration 790: Loss = 0.3649234473705292
Iteration 791: Loss = 0.3648846447467804
Iteration 792: Loss = 0.36484596133232117
Iteration 793: Loss = 0.36480727791786194
Iteration 794: Loss = 0.3647685945034027
Iteration 795: Loss = 0.36473003029823303
Iteration 796: Loss = 0.36469149589538574
Iteration 797: Loss = 0.3646530508995056
Iteration 798: Loss = 0.3646145462989807
Iteration 799: Loss = 0.3645761013031006
Iteration 800: Loss = 0.36453771591186523
Iteration 801: Loss = 0.36449939012527466
Iteration 802: Loss = 0.3644610643386841
Iteration 803: Loss = 0.3644227981567383
Iteration 804: Loss = 0.36438465118408203
Iteration 805: Loss = 0.3643464148044586
Iteration 806: Loss = 0.36430832743644714
Iteration 807: Loss = 0.36427024006843567
Iteration 808: Loss = 0.36423221230506897
Iteration 809: Loss = 0.36419424414634705
Iteration 810: Loss = 0.3641563057899475
Iteration 811: Loss = 0.3641183376312256
Iteration 812: Loss = 0.364080548286438
Iteration 813: Loss = 0.3640426993370056
Iteration 814: Loss = 0.36400488018989563
Iteration 815: Loss = 0.3639671802520752
Iteration 816: Loss = 0.36392948031425476
Iteration 817: Loss = 0.3638917803764343
Iteration 818: Loss = 0.36385416984558105
Iteration 819: Loss = 0.36381664872169495
Iteration 820: Loss = 0.3637789785861969
Iteration 821: Loss = 0.36374160647392273
Iteration 822: Loss = 0.363704115152359
Iteration 823: Loss = 0.36366674304008484
Iteration 824: Loss = 0.36362937092781067
Iteration 825: Loss = 0.3635920584201813
Iteration 826: Loss = 0.3635547161102295
Iteration 827: Loss = 0.36351755261421204
Iteration 828: Loss = 0.3634803891181946
Iteration 829: Loss = 0.36344316601753235
Iteration 830: Loss = 0.36340609192848206
Iteration 831: Loss = 0.3633689880371094
Iteration 832: Loss = 0.36333197355270386
Iteration 833: Loss = 0.3632950186729431
Iteration 834: Loss = 0.36325803399086
Iteration 835: Loss = 0.363221138715744
Iteration 836: Loss = 0.3631843030452728
Iteration 837: Loss = 0.3631475269794464
Iteration 838: Loss = 0.3631107211112976
Iteration 839: Loss = 0.36307400465011597
Iteration 840: Loss = 0.3630373775959015
Iteration 841: Loss = 0.36300066113471985
Iteration 842: Loss = 0.36296403408050537
Iteration 843: Loss = 0.36292752623558044
Iteration 844: Loss = 0.36289098858833313
Iteration 845: Loss = 0.3628544807434082
Iteration 846: Loss = 0.3628180921077728
Iteration 847: Loss = 0.36278170347213745
Iteration 848: Loss = 0.3627453148365021
Iteration 849: Loss = 0.36270901560783386
Iteration 850: Loss = 0.36267271637916565
Iteration 851: Loss = 0.3626365661621094
Iteration 852: Loss = 0.3626003563404083
Iteration 853: Loss = 0.3625642955303192
Iteration 854: Loss = 0.3625282347202301
Iteration 855: Loss = 0.3624921143054962
Iteration 856: Loss = 0.36245617270469666
Iteration 857: Loss = 0.36242038011550903
Iteration 858: Loss = 0.362384557723999
Iteration 859: Loss = 0.3623487651348114
Iteration 860: Loss = 0.36231303215026855
Iteration 861: Loss = 0.3622772991657257
Iteration 862: Loss = 0.36224180459976196
Iteration 863: Loss = 0.3622061610221863
Iteration 864: Loss = 0.36217063665390015
Iteration 865: Loss = 0.3621351718902588
Iteration 866: Loss = 0.3620997667312622
Iteration 867: Loss = 0.3620644509792328
Iteration 868: Loss = 0.3620293140411377
Iteration 869: Loss = 0.3619941473007202
Iteration 870: Loss = 0.36195892095565796
Iteration 871: Loss = 0.36192378401756287
Iteration 872: Loss = 0.36188873648643494
Iteration 873: Loss = 0.3618537485599518
Iteration 874: Loss = 0.36181890964508057
Iteration 875: Loss = 0.3617839515209198
Iteration 876: Loss = 0.36174917221069336
Iteration 877: Loss = 0.36171436309814453
Iteration 878: Loss = 0.3616796135902405
Iteration 879: Loss = 0.36164501309394836
Iteration 880: Loss = 0.3616103231906891
Iteration 881: Loss = 0.361575722694397
Iteration 882: Loss = 0.3615413010120392
Iteration 883: Loss = 0.36150676012039185
Iteration 884: Loss = 0.36147236824035645
Iteration 885: Loss = 0.36143800616264343
Iteration 886: Loss = 0.3614037036895752
Iteration 887: Loss = 0.36136943101882935
Iteration 888: Loss = 0.36133521795272827
Iteration 889: Loss = 0.36130109429359436
Iteration 890: Loss = 0.36126697063446045
Iteration 891: Loss = 0.3612329065799713
Iteration 892: Loss = 0.36119890213012695
Iteration 893: Loss = 0.36116498708724976
Iteration 894: Loss = 0.3611309826374054
Iteration 895: Loss = 0.36109718680381775
Iteration 896: Loss = 0.3610633611679077
Iteration 897: Loss = 0.3610295355319977
Iteration 898: Loss = 0.36099591851234436
Iteration 899: Loss = 0.3609621524810791
Iteration 900: Loss = 0.36092859506607056
Iteration 901: Loss = 0.3608950972557068
Iteration 902: Loss = 0.36086153984069824
Iteration 903: Loss = 0.36082807183265686
Iteration 904: Loss = 0.3607947528362274
Iteration 905: Loss = 0.3607613742351532
Iteration 906: Loss = 0.36072802543640137
Iteration 907: Loss = 0.3606948256492615
Iteration 908: Loss = 0.3606616258621216
Iteration 909: Loss = 0.36062848567962646
Iteration 910: Loss = 0.36059534549713135
Iteration 911: Loss = 0.3605622947216034
Iteration 912: Loss = 0.3605293929576874
Iteration 913: Loss = 0.3604963719844818
Iteration 914: Loss = 0.3604635000228882
Iteration 915: Loss = 0.36043065786361694
Iteration 916: Loss = 0.3603980243206024
Iteration 917: Loss = 0.3603653907775879
Iteration 918: Loss = 0.36033278703689575
Iteration 919: Loss = 0.3603002429008484
Iteration 920: Loss = 0.36026760935783386
Iteration 921: Loss = 0.3602351248264313
Iteration 922: Loss = 0.36020269989967346
Iteration 923: Loss = 0.36017048358917236
Iteration 924: Loss = 0.36013826727867126
Iteration 925: Loss = 0.36010611057281494
Iteration 926: Loss = 0.36007389426231384
Iteration 927: Loss = 0.3600417971611023
Iteration 928: Loss = 0.3600097894668579
Iteration 929: Loss = 0.3599779009819031
Iteration 930: Loss = 0.35994601249694824
Iteration 931: Loss = 0.35991421341896057
Iteration 932: Loss = 0.35988250374794006
Iteration 933: Loss = 0.35985085368156433
Iteration 934: Loss = 0.3598192632198334
Iteration 935: Loss = 0.35978779196739197
Iteration 936: Loss = 0.35975632071495056
Iteration 937: Loss = 0.35972505807876587
Iteration 938: Loss = 0.35969364643096924
Iteration 939: Loss = 0.35966241359710693
Iteration 940: Loss = 0.3596312701702118
Iteration 941: Loss = 0.35960012674331665
Iteration 942: Loss = 0.35956916213035583
Iteration 943: Loss = 0.35953816771507263
Iteration 944: Loss = 0.35950717329978943
Iteration 945: Loss = 0.35947635769844055
Iteration 946: Loss = 0.35944560170173645
Iteration 947: Loss = 0.3594147861003876
Iteration 948: Loss = 0.35938408970832825
Iteration 949: Loss = 0.35935357213020325
Iteration 950: Loss = 0.3593229353427887
Iteration 951: Loss = 0.3592924475669861
Iteration 952: Loss = 0.35926201939582825
Iteration 953: Loss = 0.3592316210269928
Iteration 954: Loss = 0.3592012822628021
Iteration 955: Loss = 0.3591710329055786
Iteration 956: Loss = 0.3591408133506775
Iteration 957: Loss = 0.35911065340042114
Iteration 958: Loss = 0.35908055305480957
Iteration 959: Loss = 0.3590504825115204
Iteration 960: Loss = 0.35902053117752075
Iteration 961: Loss = 0.3589905798435211
Iteration 962: Loss = 0.35896068811416626
Iteration 963: Loss = 0.35893091559410095
Iteration 964: Loss = 0.35890114307403564
Iteration 965: Loss = 0.3588714599609375
Iteration 966: Loss = 0.35884174704551697
Iteration 967: Loss = 0.35881227254867554
Iteration 968: Loss = 0.35878273844718933
Iteration 969: Loss = 0.3587532043457031
Iteration 970: Loss = 0.35872381925582886
Iteration 971: Loss = 0.35869449377059937
Iteration 972: Loss = 0.35866522789001465
Iteration 973: Loss = 0.35863596200942993
Iteration 974: Loss = 0.3586067855358124
Iteration 975: Loss = 0.3585776686668396
Iteration 976: Loss = 0.3585486114025116
Iteration 977: Loss = 0.35851964354515076
Iteration 978: Loss = 0.35849064588546753
Iteration 979: Loss = 0.35846173763275146
Iteration 980: Loss = 0.3584328889846802
Iteration 981: Loss = 0.3584042191505432
Iteration 982: Loss = 0.35837551951408386
Iteration 983: Loss = 0.35834696888923645
Iteration 984: Loss = 0.3583183288574219
Iteration 985: Loss = 0.3582898676395416
Iteration 986: Loss = 0.35826143622398376
Iteration 987: Loss = 0.35823309421539307
Iteration 988: Loss = 0.35820472240448
Iteration 989: Loss = 0.35817644000053406
Iteration 990: Loss = 0.3581482470035553
Iteration 991: Loss = 0.3581201732158661
Iteration 992: Loss = 0.3580920696258545
Iteration 993: Loss = 0.35806408524513245
Iteration 994: Loss = 0.3580361306667328
Iteration 995: Loss = 0.3580082952976227
Iteration 996: Loss = 0.35798048973083496
Iteration 997: Loss = 0.35795268416404724
Iteration 998: Loss = 0.3579249978065491
Iteration 999: Loss = 0.3578973412513733
Iteration 1000: Loss = 0.3578697443008423


Total training time (seconds): 10.00
