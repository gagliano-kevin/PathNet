Iteration 1: Loss = 0.5464254021644592
Iteration 2: Loss = 0.544251561164856
Iteration 3: Loss = 0.5421406030654907
Iteration 4: Loss = 0.540092945098877
Iteration 5: Loss = 0.5381090044975281
Iteration 6: Loss = 0.5361889004707336
Iteration 7: Loss = 0.534332811832428
Iteration 8: Loss = 0.5325405597686768
Iteration 9: Loss = 0.5308120250701904
Iteration 10: Loss = 0.5291467308998108
Iteration 11: Loss = 0.5275441408157349
Iteration 12: Loss = 0.5260035395622253
Iteration 13: Loss = 0.5245241522789001
Iteration 14: Loss = 0.5231050848960876
Iteration 15: Loss = 0.5217453241348267
Iteration 16: Loss = 0.5204435586929321
Iteration 17: Loss = 0.519198477268219
Iteration 18: Loss = 0.5180087685585022
Iteration 19: Loss = 0.5168730020523071
Iteration 20: Loss = 0.5157896280288696
Iteration 21: Loss = 0.5147570967674255
Iteration 22: Loss = 0.513773500919342
Iteration 23: Loss = 0.5128375291824341
Iteration 24: Loss = 0.5119472146034241
Iteration 25: Loss = 0.5111008286476135
Iteration 26: Loss = 0.510296642780304
Iteration 27: Loss = 0.5095330476760864
Iteration 28: Loss = 0.5088080167770386
Iteration 29: Loss = 0.508120059967041
Iteration 30: Loss = 0.5074673295021057
Iteration 31: Loss = 0.5068482160568237
Iteration 32: Loss = 0.506260871887207
Iteration 33: Loss = 0.5057039260864258
Iteration 34: Loss = 0.5051756501197815
Iteration 35: Loss = 0.5046745538711548
Iteration 36: Loss = 0.504199206829071
Iteration 37: Loss = 0.5037480592727661
Iteration 38: Loss = 0.5033197402954102
Iteration 39: Loss = 0.5029129981994629
Iteration 40: Loss = 0.5025265216827393
Iteration 41: Loss = 0.5021591186523438
Iteration 42: Loss = 0.5018095374107361
Iteration 43: Loss = 0.5014767050743103
Iteration 44: Loss = 0.5011595487594604
Iteration 45: Loss = 0.5008571743965149
Iteration 46: Loss = 0.5005684494972229
Iteration 47: Loss = 0.5002924203872681
Iteration 48: Loss = 0.5000284910202026
Iteration 49: Loss = 0.4997756779193878
Iteration 50: Loss = 0.49953317642211914
Iteration 51: Loss = 0.49930036067962646
Iteration 52: Loss = 0.4990764558315277
Iteration 53: Loss = 0.4988608956336975
Iteration 54: Loss = 0.49865302443504333
Iteration 55: Loss = 0.49845221638679504
Iteration 56: Loss = 0.4982580244541168
Iteration 57: Loss = 0.4980699419975281
Iteration 58: Loss = 0.4978874623775482
Iteration 59: Loss = 0.49771010875701904
Iteration 60: Loss = 0.4975374937057495
Iteration 61: Loss = 0.49736931920051575
Iteration 62: Loss = 0.49720504879951477
Iteration 63: Loss = 0.49704447388648987
Iteration 64: Loss = 0.49688720703125
Iteration 65: Loss = 0.4967329800128937
Iteration 66: Loss = 0.496581494808197
Iteration 67: Loss = 0.49643248319625854
Iteration 68: Loss = 0.4962857663631439
Iteration 69: Loss = 0.4961410462856293
Iteration 70: Loss = 0.4959981143474579
Iteration 71: Loss = 0.49585679173469543
Iteration 72: Loss = 0.49571692943573
Iteration 73: Loss = 0.4955783188343048
Iteration 74: Loss = 0.4954407513141632
Iteration 75: Loss = 0.4953041970729828
Iteration 76: Loss = 0.49516844749450684
Iteration 77: Loss = 0.4950333535671234
Iteration 78: Loss = 0.49489888548851013
Iteration 79: Loss = 0.49476489424705505
Iteration 80: Loss = 0.49463117122650146
Iteration 81: Loss = 0.49449780583381653
Iteration 82: Loss = 0.49436455965042114
Iteration 83: Loss = 0.4942314326763153
Iteration 84: Loss = 0.49409833550453186
Iteration 85: Loss = 0.493965208530426
Iteration 86: Loss = 0.493831992149353
Iteration 87: Loss = 0.4936985969543457
Iteration 88: Loss = 0.49356505274772644
Iteration 89: Loss = 0.4934311807155609
Iteration 90: Loss = 0.4932970404624939
Iteration 91: Loss = 0.4931625723838806
Iteration 92: Loss = 0.4930277168750763
Iteration 93: Loss = 0.49289244413375854
Iteration 94: Loss = 0.49275675415992737
Iteration 95: Loss = 0.4926206171512604
Iteration 96: Loss = 0.4924840033054352
Iteration 97: Loss = 0.4923468232154846
Iteration 98: Loss = 0.49220919609069824
Iteration 99: Loss = 0.4920709729194641
Iteration 100: Loss = 0.4919322729110718
Iteration 101: Loss = 0.4917929768562317
Iteration 102: Loss = 0.4916531443595886
Iteration 103: Loss = 0.4915126860141754
Iteration 104: Loss = 0.4913717210292816
Iteration 105: Loss = 0.4912301003932953
Iteration 106: Loss = 0.4910878837108612
Iteration 107: Loss = 0.49094510078430176
Iteration 108: Loss = 0.49080172181129456
Iteration 109: Loss = 0.490657776594162
Iteration 110: Loss = 0.4905131757259369
Iteration 111: Loss = 0.4903680384159088
Iteration 112: Loss = 0.4902222454547882
Iteration 113: Loss = 0.4900759160518646
Iteration 114: Loss = 0.4899290204048157
Iteration 115: Loss = 0.4897814989089966
Iteration 116: Loss = 0.4896334111690521
Iteration 117: Loss = 0.4894848167896271
Iteration 118: Loss = 0.4893355667591095
Iteration 119: Loss = 0.48918578028678894
Iteration 120: Loss = 0.4890355169773102
Iteration 121: Loss = 0.48888465762138367
Iteration 122: Loss = 0.4887332022190094
Iteration 123: Loss = 0.4885813295841217
Iteration 124: Loss = 0.48842889070510864
Iteration 125: Loss = 0.4882758855819702
Iteration 126: Loss = 0.48812243342399597
Iteration 127: Loss = 0.48796847462654114
Iteration 128: Loss = 0.4878140389919281
Iteration 129: Loss = 0.4876590669155121
Iteration 130: Loss = 0.4875035881996155
Iteration 131: Loss = 0.48734772205352783
Iteration 132: Loss = 0.48719140887260437
Iteration 133: Loss = 0.48703452944755554
Iteration 134: Loss = 0.48687732219696045
Iteration 135: Loss = 0.48671963810920715
Iteration 136: Loss = 0.48656147718429565
Iteration 137: Loss = 0.4864029288291931
Iteration 138: Loss = 0.48624393343925476
Iteration 139: Loss = 0.486084520816803
Iteration 140: Loss = 0.48592478036880493
Iteration 141: Loss = 0.48576459288597107
Iteration 142: Loss = 0.48560404777526855
Iteration 143: Loss = 0.4854430854320526
Iteration 144: Loss = 0.485281765460968
Iteration 145: Loss = 0.4851200580596924
Iteration 146: Loss = 0.4849579632282257
Iteration 147: Loss = 0.48479560017585754
Iteration 148: Loss = 0.4846328794956207
Iteration 149: Loss = 0.48446977138519287
Iteration 150: Loss = 0.48430630564689636
Iteration 151: Loss = 0.484142541885376
Iteration 152: Loss = 0.4839785099029541
Iteration 153: Loss = 0.4838140904903412
Iteration 154: Loss = 0.483649343252182
Iteration 155: Loss = 0.4834843873977661
Iteration 156: Loss = 0.48331907391548157
Iteration 157: Loss = 0.48315349221229553
Iteration 158: Loss = 0.4829876124858856
Iteration 159: Loss = 0.4828214645385742
Iteration 160: Loss = 0.48265501856803894
Iteration 161: Loss = 0.48248833417892456
Iteration 162: Loss = 0.4823214113712311
Iteration 163: Loss = 0.4821541905403137
Iteration 164: Loss = 0.4819868505001068
Iteration 165: Loss = 0.48181915283203125
Iteration 166: Loss = 0.4816512167453766
Iteration 167: Loss = 0.48148313164711
Iteration 168: Loss = 0.4813147485256195
Iteration 169: Loss = 0.4811461865901947
Iteration 170: Loss = 0.4809774160385132
Iteration 171: Loss = 0.48080846667289734
Iteration 172: Loss = 0.48063933849334717
Iteration 173: Loss = 0.4804700016975403
Iteration 174: Loss = 0.4803004562854767
Iteration 175: Loss = 0.48013073205947876
Iteration 176: Loss = 0.47996091842651367
Iteration 177: Loss = 0.4797908365726471
Iteration 178: Loss = 0.47962069511413574
Iteration 179: Loss = 0.4794503450393677
Iteration 180: Loss = 0.47927990555763245
Iteration 181: Loss = 0.4791092574596405
Iteration 182: Loss = 0.4789385497570038
Iteration 183: Loss = 0.4787676930427551
Iteration 184: Loss = 0.4785967171192169
Iteration 185: Loss = 0.47842562198638916
Iteration 186: Loss = 0.4782544672489166
Iteration 187: Loss = 0.47808322310447693
Iteration 188: Loss = 0.4779118299484253
Iteration 189: Loss = 0.47774040699005127
Iteration 190: Loss = 0.4775688648223877
Iteration 191: Loss = 0.47739726305007935
Iteration 192: Loss = 0.47722554206848145
Iteration 193: Loss = 0.4770539104938507
Iteration 194: Loss = 0.47688212990760803
Iteration 195: Loss = 0.47671031951904297
Iteration 196: Loss = 0.4765385091304779
Iteration 197: Loss = 0.4763665795326233
Iteration 198: Loss = 0.47619470953941345
Iteration 199: Loss = 0.47602277994155884
Iteration 200: Loss = 0.4758508503437042
Iteration 201: Loss = 0.4756789207458496
Iteration 202: Loss = 0.4755069613456726
Iteration 203: Loss = 0.475335031747818
Iteration 204: Loss = 0.475163072347641
Iteration 205: Loss = 0.4749911427497864
Iteration 206: Loss = 0.47481927275657654
Iteration 207: Loss = 0.4746474027633667
Iteration 208: Loss = 0.47447559237480164
Iteration 209: Loss = 0.47430384159088135
Iteration 210: Loss = 0.47413209080696106
Iteration 211: Loss = 0.47396039962768555
Iteration 212: Loss = 0.4737887680530548
Iteration 213: Loss = 0.47361722588539124
Iteration 214: Loss = 0.47344571352005005
Iteration 215: Loss = 0.473274290561676
Iteration 216: Loss = 0.4731029272079468
Iteration 217: Loss = 0.47293171286582947
Iteration 218: Loss = 0.47276052832603455
Iteration 219: Loss = 0.47258952260017395
Iteration 220: Loss = 0.47241851687431335
Iteration 221: Loss = 0.4722476601600647
Iteration 222: Loss = 0.4720768928527832
Iteration 223: Loss = 0.47190630435943604
Iteration 224: Loss = 0.47173580527305603
Iteration 225: Loss = 0.4715654253959656
Iteration 226: Loss = 0.47139525413513184
Iteration 227: Loss = 0.47122514247894287
Iteration 228: Loss = 0.4710552394390106
Iteration 229: Loss = 0.47088536620140076
Iteration 230: Loss = 0.47071579098701477
Iteration 231: Loss = 0.4705463647842407
Iteration 232: Loss = 0.47037702798843384
Iteration 233: Loss = 0.47020789980888367
Iteration 234: Loss = 0.4700389504432678
Iteration 235: Loss = 0.46987012028694153
Iteration 236: Loss = 0.46970152854919434
Iteration 237: Loss = 0.46953314542770386
Iteration 238: Loss = 0.4693649709224701
Iteration 239: Loss = 0.46919697523117065
Iteration 240: Loss = 0.46902912855148315
Iteration 241: Loss = 0.46886157989501953
Iteration 242: Loss = 0.46869418025016785
Iteration 243: Loss = 0.46852707862854004
Iteration 244: Loss = 0.4683600962162018
Iteration 245: Loss = 0.4681933522224426
Iteration 246: Loss = 0.46802687644958496
Iteration 247: Loss = 0.4678606688976288
Iteration 248: Loss = 0.46769464015960693
Iteration 249: Loss = 0.46752890944480896
Iteration 250: Loss = 0.4673634171485901
Iteration 251: Loss = 0.4671981632709503
Iteration 252: Loss = 0.46703314781188965
Iteration 253: Loss = 0.46686840057373047
Iteration 254: Loss = 0.46670395135879517
Iteration 255: Loss = 0.4665397107601166
Iteration 256: Loss = 0.46637582778930664
Iteration 257: Loss = 0.4662121832370758
Iteration 258: Loss = 0.46604883670806885
Iteration 259: Loss = 0.46588581800460815
Iteration 260: Loss = 0.465722918510437
Iteration 261: Loss = 0.4655604958534241
Iteration 262: Loss = 0.46539825201034546
Iteration 263: Loss = 0.4652363657951355
Iteration 264: Loss = 0.465074747800827
Iteration 265: Loss = 0.4649134576320648
Iteration 266: Loss = 0.4647524654865265
Iteration 267: Loss = 0.4645918011665344
Iteration 268: Loss = 0.4644314646720886
Iteration 269: Loss = 0.4642714262008667
Iteration 270: Loss = 0.46411171555519104
Iteration 271: Loss = 0.46395233273506165
Iteration 272: Loss = 0.4637933373451233
Iteration 273: Loss = 0.4636346101760864
Iteration 274: Loss = 0.463476300239563
Iteration 275: Loss = 0.46331822872161865
Iteration 276: Loss = 0.46316054463386536
Iteration 277: Loss = 0.4630032181739807
Iteration 278: Loss = 0.46284621953964233
Iteration 279: Loss = 0.462689608335495
Iteration 280: Loss = 0.4625333547592163
Iteration 281: Loss = 0.4623774290084839
Iteration 282: Loss = 0.4622219204902649
Iteration 283: Loss = 0.4620667099952698
Iteration 284: Loss = 0.4619118571281433
Iteration 285: Loss = 0.4617574214935303
Iteration 286: Loss = 0.46160340309143066
Iteration 287: Loss = 0.4614497125148773
Iteration 288: Loss = 0.4612963795661926
Iteration 289: Loss = 0.46114346385002136
Iteration 290: Loss = 0.46099090576171875
Iteration 291: Loss = 0.4608387351036072
Iteration 292: Loss = 0.46068698167800903
Iteration 293: Loss = 0.46053561568260193
Iteration 294: Loss = 0.4603845775127411
Iteration 295: Loss = 0.46023404598236084
Iteration 296: Loss = 0.46008384227752686
Iteration 297: Loss = 0.4599340558052063
Iteration 298: Loss = 0.4597846567630768
Iteration 299: Loss = 0.4596356451511383
Iteration 300: Loss = 0.45948711037635803
Iteration 301: Loss = 0.4593389332294464
Iteration 302: Loss = 0.4591912031173706
Iteration 303: Loss = 0.4590438902378082
Iteration 304: Loss = 0.4588969647884369
Iteration 305: Loss = 0.4587504267692566
Iteration 306: Loss = 0.4586043953895569
Iteration 307: Loss = 0.4584587514400482
Iteration 308: Loss = 0.4583134651184082
Iteration 309: Loss = 0.45816871523857117
Iteration 310: Loss = 0.4580243229866028
Iteration 311: Loss = 0.4578803777694702
Iteration 312: Loss = 0.4577368497848511
Iteration 313: Loss = 0.45759379863739014
Iteration 314: Loss = 0.4574511647224426
Iteration 315: Loss = 0.45730894804000854
Iteration 316: Loss = 0.4571671485900879
Iteration 317: Loss = 0.4570258855819702
Iteration 318: Loss = 0.4568849503993988
Iteration 319: Loss = 0.45674455165863037
Iteration 320: Loss = 0.4566044807434082
Iteration 321: Loss = 0.456464946269989
Iteration 322: Loss = 0.45632585883140564
Iteration 323: Loss = 0.4561871886253357
Iteration 324: Loss = 0.45604902505874634
Iteration 325: Loss = 0.455911248922348
Iteration 326: Loss = 0.4557739198207855
Iteration 327: Loss = 0.4556370973587036
Iteration 328: Loss = 0.45550066232681274
Iteration 329: Loss = 0.45536476373672485
Iteration 330: Loss = 0.4552293121814728
Iteration 331: Loss = 0.45509424805641174
Iteration 332: Loss = 0.4549597501754761
Iteration 333: Loss = 0.45482560992240906
Iteration 334: Loss = 0.454692006111145
Iteration 335: Loss = 0.4545588791370392
Iteration 336: Loss = 0.4544261395931244
Iteration 337: Loss = 0.4542939066886902
Iteration 338: Loss = 0.4541621208190918
Iteration 339: Loss = 0.454030841588974
Iteration 340: Loss = 0.45389997959136963
Iteration 341: Loss = 0.45376962423324585
Iteration 342: Loss = 0.4536397457122803
Iteration 343: Loss = 0.4535103142261505
Iteration 344: Loss = 0.45338135957717896
Iteration 345: Loss = 0.4532528817653656
Iteration 346: Loss = 0.4531248211860657
Iteration 347: Loss = 0.4529973566532135
Iteration 348: Loss = 0.45287024974823
Iteration 349: Loss = 0.45274367928504944
Iteration 350: Loss = 0.4526175856590271
Iteration 351: Loss = 0.4524919390678406
Iteration 352: Loss = 0.45236679911613464
Iteration 353: Loss = 0.4522421360015869
Iteration 354: Loss = 0.4521178901195526
Iteration 355: Loss = 0.4519941806793213
Iteration 356: Loss = 0.4518709182739258
Iteration 357: Loss = 0.45174816250801086
Iteration 358: Loss = 0.45162588357925415
Iteration 359: Loss = 0.45150405168533325
Iteration 360: Loss = 0.45138275623321533
Iteration 361: Loss = 0.4512617290019989
Iteration 362: Loss = 0.45114120841026306
Iteration 363: Loss = 0.45102113485336304
Iteration 364: Loss = 0.4509015381336212
Iteration 365: Loss = 0.45078244805336
Iteration 366: Loss = 0.4506637752056122
Iteration 367: Loss = 0.4505455791950226
Iteration 368: Loss = 0.4504278004169464
Iteration 369: Loss = 0.45031052827835083
Iteration 370: Loss = 0.4501936733722687
Iteration 371: Loss = 0.45007723569869995
Iteration 372: Loss = 0.44996124505996704
Iteration 373: Loss = 0.44984570145606995
Iteration 374: Loss = 0.44973066449165344
Iteration 375: Loss = 0.4496159851551056
Iteration 376: Loss = 0.44950181245803833
Iteration 377: Loss = 0.4493880867958069
Iteration 378: Loss = 0.4492747485637665
Iteration 379: Loss = 0.44916191697120667
Iteration 380: Loss = 0.4490494728088379
Iteration 381: Loss = 0.4489375650882721
Iteration 382: Loss = 0.4488261044025421
Iteration 383: Loss = 0.44871506094932556
Iteration 384: Loss = 0.4486044943332672
Iteration 385: Loss = 0.4484943151473999
Iteration 386: Loss = 0.4483846426010132
Iteration 387: Loss = 0.44827544689178467
Iteration 388: Loss = 0.4481666684150696
Iteration 389: Loss = 0.4480583369731903
Iteration 390: Loss = 0.447950541973114
Iteration 391: Loss = 0.44784316420555115
Iteration 392: Loss = 0.4477362632751465
Iteration 393: Loss = 0.4476298689842224
Iteration 394: Loss = 0.44752389192581177
Iteration 395: Loss = 0.4474184513092041
Iteration 396: Loss = 0.4473133981227875
Iteration 397: Loss = 0.4472087323665619
Iteration 398: Loss = 0.4471045732498169
Iteration 399: Loss = 0.44700098037719727
Iteration 400: Loss = 0.4468977749347687
Iteration 401: Loss = 0.4467950165271759
Iteration 402: Loss = 0.44669273495674133
Iteration 403: Loss = 0.44659093022346497
Iteration 404: Loss = 0.44648969173431396
Iteration 405: Loss = 0.44638878107070923
Iteration 406: Loss = 0.44628840684890747
Iteration 407: Loss = 0.4461885094642639
Iteration 408: Loss = 0.44608908891677856
Iteration 409: Loss = 0.44599011540412903
Iteration 410: Loss = 0.4458915591239929
Iteration 411: Loss = 0.4457934498786926
Iteration 412: Loss = 0.44569578766822815
Iteration 413: Loss = 0.44559863209724426
Iteration 414: Loss = 0.4455018937587738
Iteration 415: Loss = 0.4454055726528168
Iteration 416: Loss = 0.44530972838401794
Iteration 417: Loss = 0.44521433115005493
Iteration 418: Loss = 0.4451194703578949
Iteration 419: Loss = 0.4450249671936035
Iteration 420: Loss = 0.44493094086647034
Iteration 421: Loss = 0.44483739137649536
Iteration 422: Loss = 0.4447442591190338
Iteration 423: Loss = 0.44465160369873047
Iteration 424: Loss = 0.4445594251155853
Iteration 425: Loss = 0.4444677233695984
Iteration 426: Loss = 0.4443763792514801
Iteration 427: Loss = 0.44428548216819763
Iteration 428: Loss = 0.44419512152671814
Iteration 429: Loss = 0.44410523772239685
Iteration 430: Loss = 0.4440157413482666
Iteration 431: Loss = 0.4439266622066498
Iteration 432: Loss = 0.44383805990219116
Iteration 433: Loss = 0.4437498152256012
Iteration 434: Loss = 0.4436620771884918
Iteration 435: Loss = 0.4435747265815735
Iteration 436: Loss = 0.44348785281181335
Iteration 437: Loss = 0.44340142607688904
Iteration 438: Loss = 0.443315327167511
Iteration 439: Loss = 0.4432297348976135
Iteration 440: Loss = 0.4431445896625519
Iteration 441: Loss = 0.44305986166000366
Iteration 442: Loss = 0.44297555088996887
Iteration 443: Loss = 0.4428916871547699
Iteration 444: Loss = 0.4428083598613739
Iteration 445: Loss = 0.44272539019584656
Iteration 446: Loss = 0.4426428973674774
Iteration 447: Loss = 0.4425608515739441
Iteration 448: Loss = 0.4424792528152466
Iteration 449: Loss = 0.4423981010913849
Iteration 450: Loss = 0.4423173666000366
Iteration 451: Loss = 0.44223707914352417
Iteration 452: Loss = 0.4421573281288147
Iteration 453: Loss = 0.4420778751373291
Iteration 454: Loss = 0.4419989585876465
Iteration 455: Loss = 0.4419204294681549
Iteration 456: Loss = 0.44184234738349915
Iteration 457: Loss = 0.4417647123336792
Iteration 458: Loss = 0.4416874647140503
Iteration 459: Loss = 0.4416106939315796
Iteration 460: Loss = 0.4415344297885895
Iteration 461: Loss = 0.44145846366882324
Iteration 462: Loss = 0.4413830041885376
Iteration 463: Loss = 0.4413079619407654
Iteration 464: Loss = 0.441233366727829
Iteration 465: Loss = 0.441159188747406
Iteration 466: Loss = 0.44108545780181885
Iteration 467: Loss = 0.4410122036933899
Iteration 468: Loss = 0.44093939661979675
Iteration 469: Loss = 0.44086700677871704
Iteration 470: Loss = 0.440794974565506
Iteration 471: Loss = 0.4407234191894531
Iteration 472: Loss = 0.4406522512435913
Iteration 473: Loss = 0.44058147072792053
Iteration 474: Loss = 0.44051119685173035
Iteration 475: Loss = 0.44044122099876404
Iteration 476: Loss = 0.4403717517852783
Iteration 477: Loss = 0.44030267000198364
Iteration 478: Loss = 0.44023406505584717
Iteration 479: Loss = 0.44016581773757935
Iteration 480: Loss = 0.44009801745414734
Iteration 481: Loss = 0.44003063440322876
Iteration 482: Loss = 0.43996357917785645
Iteration 483: Loss = 0.4398970305919647
Iteration 484: Loss = 0.4398308992385864
Iteration 485: Loss = 0.43976518511772156
Iteration 486: Loss = 0.43969985842704773
Iteration 487: Loss = 0.43963494896888733
Iteration 488: Loss = 0.43957042694091797
Iteration 489: Loss = 0.4395063519477844
Iteration 490: Loss = 0.4394426643848419
Iteration 491: Loss = 0.43937933444976807
Iteration 492: Loss = 0.4393164813518524
Iteration 493: Loss = 0.43925392627716064
Iteration 494: Loss = 0.43919187784194946
Iteration 495: Loss = 0.4391302168369293
Iteration 496: Loss = 0.43906891345977783
Iteration 497: Loss = 0.43900805711746216
Iteration 498: Loss = 0.4389476180076599
Iteration 499: Loss = 0.4388876259326935
Iteration 500: Loss = 0.4388279616832733
Iteration 501: Loss = 0.43876874446868896
Iteration 502: Loss = 0.43870997428894043
Iteration 503: Loss = 0.43865156173706055
Iteration 504: Loss = 0.4385935962200165
Iteration 505: Loss = 0.43853598833084106
Iteration 506: Loss = 0.43847882747650146
Iteration 507: Loss = 0.4384220838546753
Iteration 508: Loss = 0.4383656680583954
Iteration 509: Loss = 0.4383097290992737
Iteration 510: Loss = 0.438254177570343
Iteration 511: Loss = 0.4381990432739258
Iteration 512: Loss = 0.4381442368030548
Iteration 513: Loss = 0.4380898177623749
Iteration 514: Loss = 0.43803584575653076
Iteration 515: Loss = 0.4379822015762329
Iteration 516: Loss = 0.4379288852214813
Iteration 517: Loss = 0.4378761053085327
Iteration 518: Loss = 0.43782365322113037
Iteration 519: Loss = 0.4377715587615967
Iteration 520: Loss = 0.43771985173225403
Iteration 521: Loss = 0.4376685917377472
Iteration 522: Loss = 0.4376176595687866
Iteration 523: Loss = 0.4375671148300171
Iteration 524: Loss = 0.43751686811447144
Iteration 525: Loss = 0.437467098236084
Iteration 526: Loss = 0.4374177157878876
Iteration 527: Loss = 0.4373686909675598
Iteration 528: Loss = 0.43731993436813354
Iteration 529: Loss = 0.43727168440818787
Iteration 530: Loss = 0.43722379207611084
Iteration 531: Loss = 0.4371761977672577
Iteration 532: Loss = 0.4371289610862732
Iteration 533: Loss = 0.4370821416378021
Iteration 534: Loss = 0.4370356798171997
Iteration 535: Loss = 0.43698954582214355
Iteration 536: Loss = 0.43694373965263367
Iteration 537: Loss = 0.4368983209133148
Iteration 538: Loss = 0.4368533194065094
Iteration 539: Loss = 0.43680864572525024
Iteration 540: Loss = 0.4367642402648926
Iteration 541: Loss = 0.43672022223472595
Iteration 542: Loss = 0.4366767108440399
Iteration 543: Loss = 0.43663349747657776
Iteration 544: Loss = 0.4365905225276947
Iteration 545: Loss = 0.4365479052066803
Iteration 546: Loss = 0.4365057051181793
Iteration 547: Loss = 0.4364638328552246
Iteration 548: Loss = 0.43642231822013855
Iteration 549: Loss = 0.43638110160827637
Iteration 550: Loss = 0.43634018301963806
Iteration 551: Loss = 0.4362998306751251
Iteration 552: Loss = 0.43625974655151367
Iteration 553: Loss = 0.4362199604511261
Iteration 554: Loss = 0.4361805319786072
Iteration 555: Loss = 0.4361414909362793
Iteration 556: Loss = 0.4361027181148529
Iteration 557: Loss = 0.4360642731189728
Iteration 558: Loss = 0.4360261559486389
Iteration 559: Loss = 0.43598833680152893
Iteration 560: Loss = 0.4359508454799652
Iteration 561: Loss = 0.43591365218162537
Iteration 562: Loss = 0.435876727104187
Iteration 563: Loss = 0.4358401596546173
Iteration 564: Loss = 0.4358038306236267
Iteration 565: Loss = 0.43576785922050476
Iteration 566: Loss = 0.4357322156429291
Iteration 567: Loss = 0.4356968104839325
Iteration 568: Loss = 0.4356617033481598
Iteration 569: Loss = 0.4356268644332886
Iteration 570: Loss = 0.4355924129486084
Iteration 571: Loss = 0.4355582594871521
Iteration 572: Loss = 0.4355243444442749
Iteration 573: Loss = 0.43549075722694397
Iteration 574: Loss = 0.43545740842819214
Iteration 575: Loss = 0.4354243278503418
Iteration 576: Loss = 0.4353916347026825
Iteration 577: Loss = 0.4353591799736023
Iteration 578: Loss = 0.43532702326774597
Iteration 579: Loss = 0.43529510498046875
Iteration 580: Loss = 0.435263454914093
Iteration 581: Loss = 0.43523213267326355
Iteration 582: Loss = 0.43520107865333557
Iteration 583: Loss = 0.4351702332496643
Iteration 584: Loss = 0.4351396858692169
Iteration 585: Loss = 0.4351094663143158
Iteration 586: Loss = 0.4350793659687042
Iteration 587: Loss = 0.4350496828556061
Iteration 588: Loss = 0.43502020835876465
Iteration 589: Loss = 0.4349910020828247
Iteration 590: Loss = 0.4349620044231415
Iteration 591: Loss = 0.43493327498435974
Iteration 592: Loss = 0.4349047839641571
Iteration 593: Loss = 0.43487662076950073
Iteration 594: Loss = 0.43484869599342346
Iteration 595: Loss = 0.4348209798336029
Iteration 596: Loss = 0.43479353189468384
Iteration 597: Loss = 0.43476632237434387
Iteration 598: Loss = 0.4347393810749054
Iteration 599: Loss = 0.43471264839172363
Iteration 600: Loss = 0.43468615412712097
Iteration 601: Loss = 0.4346599876880646
Iteration 602: Loss = 0.43463391065597534
Iteration 603: Loss = 0.43460813164711
Iteration 604: Loss = 0.43458259105682373
Iteration 605: Loss = 0.43455731868743896
Iteration 606: Loss = 0.4345322549343109
Iteration 607: Loss = 0.43450745940208435
Iteration 608: Loss = 0.4344828426837921
Iteration 609: Loss = 0.434458464384079
Iteration 610: Loss = 0.43443426489830017
Iteration 611: Loss = 0.4344103932380676
Iteration 612: Loss = 0.434386670589447
Iteration 613: Loss = 0.43436315655708313
Iteration 614: Loss = 0.4343399107456207
Iteration 615: Loss = 0.4343167841434479
Iteration 616: Loss = 0.4342939257621765
Iteration 617: Loss = 0.43427127599716187
Iteration 618: Loss = 0.4342489242553711
Iteration 619: Loss = 0.43422678112983704
Iteration 620: Loss = 0.4342048168182373
Iteration 621: Loss = 0.4341830015182495
Iteration 622: Loss = 0.4341614544391632
Iteration 623: Loss = 0.43414008617401123
Iteration 624: Loss = 0.4341188371181488
Iteration 625: Loss = 0.43409794569015503
Iteration 626: Loss = 0.43407708406448364
Iteration 627: Loss = 0.4340565502643585
Iteration 628: Loss = 0.43403613567352295
Iteration 629: Loss = 0.4340158998966217
Iteration 630: Loss = 0.4339958429336548
Iteration 631: Loss = 0.4339759647846222
Iteration 632: Loss = 0.4339563250541687
Iteration 633: Loss = 0.4339368939399719
Iteration 634: Loss = 0.4339176118373871
Iteration 635: Loss = 0.4338985085487366
Iteration 636: Loss = 0.4338795840740204
Iteration 637: Loss = 0.43386080861091614
Iteration 638: Loss = 0.433842271566391
Iteration 639: Loss = 0.433823823928833
Iteration 640: Loss = 0.4338056147098541
Iteration 641: Loss = 0.43378758430480957
Iteration 642: Loss = 0.4337696433067322
Iteration 643: Loss = 0.4337519705295563
Iteration 644: Loss = 0.4337344169616699
Iteration 645: Loss = 0.4337170124053955
Iteration 646: Loss = 0.43369972705841064
Iteration 647: Loss = 0.43368270993232727
Iteration 648: Loss = 0.43366584181785583
Iteration 649: Loss = 0.4336492121219635
Iteration 650: Loss = 0.4336327016353607
Iteration 651: Loss = 0.4336163401603699
Iteration 652: Loss = 0.43360015749931335
Iteration 653: Loss = 0.4335840940475464
Iteration 654: Loss = 0.43356823921203613
Iteration 655: Loss = 0.43355250358581543
Iteration 656: Loss = 0.4335368871688843
Iteration 657: Loss = 0.43352141976356506
Iteration 658: Loss = 0.4335062503814697
Iteration 659: Loss = 0.4334911108016968
Iteration 660: Loss = 0.4334762692451477
Iteration 661: Loss = 0.43346139788627625
Iteration 662: Loss = 0.4334467053413391
Iteration 663: Loss = 0.4334322512149811
Iteration 664: Loss = 0.4334179162979126
Iteration 665: Loss = 0.4334036707878113
Iteration 666: Loss = 0.43338945508003235
Iteration 667: Loss = 0.43337559700012207
Iteration 668: Loss = 0.43336182832717896
Iteration 669: Loss = 0.4333481788635254
Iteration 670: Loss = 0.433334618806839
Iteration 671: Loss = 0.4333212673664093
Iteration 672: Loss = 0.433307945728302
Iteration 673: Loss = 0.43329480290412903
Iteration 674: Loss = 0.433281809091568
Iteration 675: Loss = 0.43326884508132935
Iteration 676: Loss = 0.4332561194896698
Iteration 677: Loss = 0.4332435131072998
Iteration 678: Loss = 0.43323102593421936
Iteration 679: Loss = 0.43321865797042847
Iteration 680: Loss = 0.4332064092159271
Iteration 681: Loss = 0.4331943392753601
Iteration 682: Loss = 0.43318232893943787
Iteration 683: Loss = 0.4331704378128052
Iteration 684: Loss = 0.4331586956977844
Iteration 685: Loss = 0.43314704298973083
Iteration 686: Loss = 0.4331355094909668
Iteration 687: Loss = 0.4331240653991699
Iteration 688: Loss = 0.433112770318985
Iteration 689: Loss = 0.43310150504112244
Iteration 690: Loss = 0.4330904483795166
Iteration 691: Loss = 0.4330795407295227
Iteration 692: Loss = 0.4330686926841736
Iteration 693: Loss = 0.433057963848114
Iteration 694: Loss = 0.433047354221344
Iteration 695: Loss = 0.43303683400154114
Iteration 696: Loss = 0.43302640318870544
Iteration 697: Loss = 0.4330161213874817
Iteration 698: Loss = 0.4330058991909027
Iteration 699: Loss = 0.4329957962036133
Iteration 700: Loss = 0.432985782623291
Iteration 701: Loss = 0.4329758584499359
Iteration 702: Loss = 0.4329659938812256
Iteration 703: Loss = 0.4329563081264496
Iteration 704: Loss = 0.43294674158096313
Iteration 705: Loss = 0.43293723464012146
Iteration 706: Loss = 0.43292784690856934
Iteration 707: Loss = 0.43291860818862915
Iteration 708: Loss = 0.43290939927101135
Iteration 709: Loss = 0.4329002797603607
Iteration 710: Loss = 0.43289124965667725
Iteration 711: Loss = 0.4328823387622833
Iteration 712: Loss = 0.4328734874725342
Iteration 713: Loss = 0.4328647553920746
Iteration 714: Loss = 0.4328560531139374
Iteration 715: Loss = 0.4328474700450897
Iteration 716: Loss = 0.43283897638320923
Iteration 717: Loss = 0.4328306019306183
Iteration 718: Loss = 0.43282225728034973
Iteration 719: Loss = 0.43281394243240356
Iteration 720: Loss = 0.43280577659606934
Iteration 721: Loss = 0.43279775977134705
Iteration 722: Loss = 0.43278971314430237
Iteration 723: Loss = 0.43278181552886963
Iteration 724: Loss = 0.43277400732040405
Iteration 725: Loss = 0.43276628851890564
Iteration 726: Loss = 0.4327585995197296
Iteration 727: Loss = 0.43275099992752075
Iteration 728: Loss = 0.43274345993995667
Iteration 729: Loss = 0.43273603916168213
Iteration 730: Loss = 0.43272870779037476
Iteration 731: Loss = 0.4327213764190674
Iteration 732: Loss = 0.43271416425704956
Iteration 733: Loss = 0.4327070116996765
Iteration 734: Loss = 0.43269988894462585
Iteration 735: Loss = 0.43269288539886475
Iteration 736: Loss = 0.432685911655426
Iteration 737: Loss = 0.43267905712127686
Iteration 738: Loss = 0.4326722323894501
Iteration 739: Loss = 0.43266546726226807
Iteration 740: Loss = 0.4326587915420532
Iteration 741: Loss = 0.432652086019516
Iteration 742: Loss = 0.4326455891132355
Iteration 743: Loss = 0.43263909220695496
Iteration 744: Loss = 0.4326326549053192
Iteration 745: Loss = 0.43262630701065063
Iteration 746: Loss = 0.4326200485229492
Iteration 747: Loss = 0.4326138496398926
Iteration 748: Loss = 0.4326076805591583
Iteration 749: Loss = 0.4326016306877136
Iteration 750: Loss = 0.43259555101394653
Iteration 751: Loss = 0.432589590549469
Iteration 752: Loss = 0.43258363008499146
Iteration 753: Loss = 0.43257781863212585
Iteration 754: Loss = 0.43257206678390503
Iteration 755: Loss = 0.4325662851333618
Iteration 756: Loss = 0.4325605630874634
Iteration 757: Loss = 0.4325549602508545
Iteration 758: Loss = 0.4325493574142456
Iteration 759: Loss = 0.4325438439846039
Iteration 760: Loss = 0.43253833055496216
Iteration 761: Loss = 0.4325329661369324
Iteration 762: Loss = 0.4325275123119354
Iteration 763: Loss = 0.4325222074985504
Iteration 764: Loss = 0.4325169324874878
Iteration 765: Loss = 0.43251171708106995
Iteration 766: Loss = 0.4325065016746521
Iteration 767: Loss = 0.4325014054775238
Iteration 768: Loss = 0.4324963390827179
Iteration 769: Loss = 0.432491272687912
Iteration 770: Loss = 0.43248629570007324
Iteration 771: Loss = 0.4324813485145569
Iteration 772: Loss = 0.4324764609336853
Iteration 773: Loss = 0.4324716329574585
Iteration 774: Loss = 0.4324668049812317
Iteration 775: Loss = 0.43246206641197205
Iteration 776: Loss = 0.4324573278427124
Iteration 777: Loss = 0.4324526786804199
Iteration 778: Loss = 0.43244802951812744
Iteration 779: Loss = 0.43244343996047974
Iteration 780: Loss = 0.4324388802051544
Iteration 781: Loss = 0.4324343800544739
Iteration 782: Loss = 0.4324299693107605
Iteration 783: Loss = 0.43242549896240234
Iteration 784: Loss = 0.43242114782333374
Iteration 785: Loss = 0.43241676688194275
Iteration 786: Loss = 0.43241244554519653
Iteration 787: Loss = 0.43240824341773987
Iteration 788: Loss = 0.4324039816856384
Iteration 789: Loss = 0.43239980936050415
Iteration 790: Loss = 0.4323956370353699
Iteration 791: Loss = 0.43239155411720276
Iteration 792: Loss = 0.43238747119903564
Iteration 793: Loss = 0.4323834478855133
Iteration 794: Loss = 0.43237945437431335
Iteration 795: Loss = 0.4323754608631134
Iteration 796: Loss = 0.4323715567588806
Iteration 797: Loss = 0.4323676526546478
Iteration 798: Loss = 0.4323638081550598
Iteration 799: Loss = 0.4323599934577942
Iteration 800: Loss = 0.43235620856285095
Iteration 801: Loss = 0.4323524534702301
Iteration 802: Loss = 0.43234872817993164
Iteration 803: Loss = 0.43234503269195557
Iteration 804: Loss = 0.4323413372039795
Iteration 805: Loss = 0.4323377311229706
Iteration 806: Loss = 0.43233412504196167
Iteration 807: Loss = 0.4323306083679199
Iteration 808: Loss = 0.43232712149620056
Iteration 809: Loss = 0.4323236048221588
Iteration 810: Loss = 0.43232011795043945
Iteration 811: Loss = 0.43231669068336487
Iteration 812: Loss = 0.43231329321861267
Iteration 813: Loss = 0.43230992555618286
Iteration 814: Loss = 0.43230658769607544
Iteration 815: Loss = 0.432303249835968
Iteration 816: Loss = 0.43230000138282776
Iteration 817: Loss = 0.4322966933250427
Iteration 818: Loss = 0.43229347467422485
Iteration 819: Loss = 0.43229028582572937
Iteration 820: Loss = 0.43228715658187866
Iteration 821: Loss = 0.4322839677333832
Iteration 822: Loss = 0.43228089809417725
Iteration 823: Loss = 0.43227776885032654
Iteration 824: Loss = 0.4322746992111206
Iteration 825: Loss = 0.43227165937423706
Iteration 826: Loss = 0.4322687089443207
Iteration 827: Loss = 0.43226566910743713
Iteration 828: Loss = 0.43226271867752075
Iteration 829: Loss = 0.43225976824760437
Iteration 830: Loss = 0.43225690722465515
Iteration 831: Loss = 0.43225398659706116
Iteration 832: Loss = 0.4322511553764343
Iteration 833: Loss = 0.4322482943534851
Iteration 834: Loss = 0.43224552273750305
Iteration 835: Loss = 0.43224266171455383
Iteration 836: Loss = 0.43223991990089417
Iteration 837: Loss = 0.4322372078895569
Iteration 838: Loss = 0.4322344660758972
Iteration 839: Loss = 0.4322317838668823
Iteration 840: Loss = 0.4322291612625122
Iteration 841: Loss = 0.4322264790534973
Iteration 842: Loss = 0.4322238266468048
Iteration 843: Loss = 0.4322212338447571
Iteration 844: Loss = 0.43221861124038696
Iteration 845: Loss = 0.432216078042984
Iteration 846: Loss = 0.43221354484558105
Iteration 847: Loss = 0.4322110414505005
Iteration 848: Loss = 0.43220850825309753
Iteration 849: Loss = 0.43220603466033936
Iteration 850: Loss = 0.4322035610675812
Iteration 851: Loss = 0.432201087474823
Iteration 852: Loss = 0.432198703289032
Iteration 853: Loss = 0.4321962594985962
Iteration 854: Loss = 0.4321938753128052
Iteration 855: Loss = 0.43219152092933655
Iteration 856: Loss = 0.43218913674354553
Iteration 857: Loss = 0.4321868419647217
Iteration 858: Loss = 0.43218451738357544
Iteration 859: Loss = 0.4321822226047516
Iteration 860: Loss = 0.43217992782592773
Iteration 861: Loss = 0.43217766284942627
Iteration 862: Loss = 0.4321754276752472
Iteration 863: Loss = 0.4321732521057129
Iteration 864: Loss = 0.4321710169315338
Iteration 865: Loss = 0.4321688413619995
Iteration 866: Loss = 0.4321666955947876
Iteration 867: Loss = 0.4321644604206085
Iteration 868: Loss = 0.432162344455719
Iteration 869: Loss = 0.43216022849082947
Iteration 870: Loss = 0.43215811252593994
Iteration 871: Loss = 0.4321559965610504
Iteration 872: Loss = 0.43215399980545044
Iteration 873: Loss = 0.4321518838405609
Iteration 874: Loss = 0.43214982748031616
Iteration 875: Loss = 0.4321477711200714
Iteration 876: Loss = 0.43214577436447144
Iteration 877: Loss = 0.4321437478065491
Iteration 878: Loss = 0.4321417808532715
Iteration 879: Loss = 0.4321398437023163
Iteration 880: Loss = 0.4321378171443939
Iteration 881: Loss = 0.4321359395980835
Iteration 882: Loss = 0.4321339726448059
Iteration 883: Loss = 0.4321320056915283
Iteration 884: Loss = 0.4321300983428955
Iteration 885: Loss = 0.4321281909942627
Iteration 886: Loss = 0.43212634325027466
Iteration 887: Loss = 0.4321245551109314
Iteration 888: Loss = 0.4321226477622986
Iteration 889: Loss = 0.4321208596229553
Iteration 890: Loss = 0.43211907148361206
Iteration 891: Loss = 0.4321173131465912
Iteration 892: Loss = 0.43211549520492554
Iteration 893: Loss = 0.43211379647254944
Iteration 894: Loss = 0.43211206793785095
Iteration 895: Loss = 0.4321103096008301
Iteration 896: Loss = 0.43210864067077637
Iteration 897: Loss = 0.43210694193840027
Iteration 898: Loss = 0.4321051836013794
Iteration 899: Loss = 0.43210354447364807
Iteration 900: Loss = 0.43210187554359436
Iteration 901: Loss = 0.43210023641586304
Iteration 902: Loss = 0.4320985972881317
Iteration 903: Loss = 0.4320969879627228
Iteration 904: Loss = 0.4320954382419586
Iteration 905: Loss = 0.4320937693119049
Iteration 906: Loss = 0.43209215998649597
Iteration 907: Loss = 0.4320906400680542
Iteration 908: Loss = 0.43208906054496765
Iteration 909: Loss = 0.4320874810218811
Iteration 910: Loss = 0.43208596110343933
Iteration 911: Loss = 0.43208444118499756
Iteration 912: Loss = 0.4320829212665558
Iteration 913: Loss = 0.4320814609527588
Iteration 914: Loss = 0.43207991123199463
Iteration 915: Loss = 0.43207845091819763
Iteration 916: Loss = 0.43207693099975586
Iteration 917: Loss = 0.4320754408836365
Iteration 918: Loss = 0.43207404017448425
Iteration 919: Loss = 0.43207255005836487
Iteration 920: Loss = 0.43207111954689026
Iteration 921: Loss = 0.43206968903541565
Iteration 922: Loss = 0.43206822872161865
Iteration 923: Loss = 0.4320668578147888
Iteration 924: Loss = 0.4320654273033142
Iteration 925: Loss = 0.432064026594162
Iteration 926: Loss = 0.43206271529197693
Iteration 927: Loss = 0.4320613443851471
Iteration 928: Loss = 0.4320599436759949
Iteration 929: Loss = 0.4320586025714874
Iteration 930: Loss = 0.43205726146698
Iteration 931: Loss = 0.4320559501647949
Iteration 932: Loss = 0.43205463886260986
Iteration 933: Loss = 0.4320533573627472
Iteration 934: Loss = 0.4320520758628845
Iteration 935: Loss = 0.43205082416534424
Iteration 936: Loss = 0.43204954266548157
Iteration 937: Loss = 0.4320482611656189
Iteration 938: Loss = 0.4320469796657562
Iteration 939: Loss = 0.43204572796821594
Iteration 940: Loss = 0.43204450607299805
Iteration 941: Loss = 0.43204331398010254
Iteration 942: Loss = 0.43204212188720703
Iteration 943: Loss = 0.43204087018966675
Iteration 944: Loss = 0.43203967809677124
Iteration 945: Loss = 0.43203848600387573
Iteration 946: Loss = 0.4320372939109802
Iteration 947: Loss = 0.4320361316204071
Iteration 948: Loss = 0.4320349395275116
Iteration 949: Loss = 0.4320337772369385
Iteration 950: Loss = 0.43203264474868774
Iteration 951: Loss = 0.4320314824581146
Iteration 952: Loss = 0.43203040957450867
Iteration 953: Loss = 0.43202921748161316
Iteration 954: Loss = 0.4320280849933624
Iteration 955: Loss = 0.4320269823074341
Iteration 956: Loss = 0.43202587962150574
Iteration 957: Loss = 0.432024747133255
Iteration 958: Loss = 0.43202367424964905
Iteration 959: Loss = 0.4320225715637207
Iteration 960: Loss = 0.43202143907546997
Iteration 961: Loss = 0.4320203959941864
Iteration 962: Loss = 0.43201932311058044
Iteration 963: Loss = 0.4320182204246521
Iteration 964: Loss = 0.4320172071456909
Iteration 965: Loss = 0.43201613426208496
Iteration 966: Loss = 0.4320151209831238
Iteration 967: Loss = 0.4320141077041626
Iteration 968: Loss = 0.4320130944252014
Iteration 969: Loss = 0.43201205134391785
Iteration 970: Loss = 0.43201106786727905
Iteration 971: Loss = 0.43201011419296265
Iteration 972: Loss = 0.43200913071632385
Iteration 973: Loss = 0.43200814723968506
Iteration 974: Loss = 0.4320071339607239
Iteration 975: Loss = 0.43200623989105225
Iteration 976: Loss = 0.43200525641441345
Iteration 977: Loss = 0.43200433254241943
Iteration 978: Loss = 0.4320034086704254
Iteration 979: Loss = 0.432002454996109
Iteration 980: Loss = 0.432001531124115
Iteration 981: Loss = 0.43200063705444336
Iteration 982: Loss = 0.43199968338012695
Iteration 983: Loss = 0.4319988191127777
Iteration 984: Loss = 0.4319978654384613
Iteration 985: Loss = 0.43199700117111206
Iteration 986: Loss = 0.43199607729911804
Iteration 987: Loss = 0.4319952130317688
Iteration 988: Loss = 0.43199431896209717
Iteration 989: Loss = 0.4319934546947479
Iteration 990: Loss = 0.4319925606250763
Iteration 991: Loss = 0.43199166655540466
Iteration 992: Loss = 0.4319908618927002
Iteration 993: Loss = 0.43198999762535095
Iteration 994: Loss = 0.4319891333580017
Iteration 995: Loss = 0.4319882392883301
Iteration 996: Loss = 0.431987464427948
Iteration 997: Loss = 0.43198660016059875
Iteration 998: Loss = 0.4319857656955719
Iteration 999: Loss = 0.43198493123054504
Iteration 1000: Loss = 0.4319841265678406


Total training time (seconds): 9.28
