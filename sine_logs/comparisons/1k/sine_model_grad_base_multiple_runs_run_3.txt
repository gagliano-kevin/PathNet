Iteration 1: Loss = 1.4368772506713867
Iteration 2: Loss = 1.4353001117706299
Iteration 3: Loss = 1.433673620223999
Iteration 4: Loss = 1.431995153427124
Iteration 5: Loss = 1.4302618503570557
Iteration 6: Loss = 1.4284719228744507
Iteration 7: Loss = 1.4266225099563599
Iteration 8: Loss = 1.42471182346344
Iteration 9: Loss = 1.4227361679077148
Iteration 10: Loss = 1.4206929206848145
Iteration 11: Loss = 1.4185787439346313
Iteration 12: Loss = 1.4163910150527954
Iteration 13: Loss = 1.4141263961791992
Iteration 14: Loss = 1.411781668663025
Iteration 15: Loss = 1.4093528985977173
Iteration 16: Loss = 1.406836748123169
Iteration 17: Loss = 1.4042296409606934
Iteration 18: Loss = 1.4015275239944458
Iteration 19: Loss = 1.398726224899292
Iteration 20: Loss = 1.3958213329315186
Iteration 21: Loss = 1.3928078413009644
Iteration 22: Loss = 1.389681339263916
Iteration 23: Loss = 1.386437177658081
Iteration 24: Loss = 1.383070468902588
Iteration 25: Loss = 1.3795766830444336
Iteration 26: Loss = 1.3759503364562988
Iteration 27: Loss = 1.3721860647201538
Iteration 28: Loss = 1.3682780265808105
Iteration 29: Loss = 1.3642204999923706
Iteration 30: Loss = 1.3600066900253296
Iteration 31: Loss = 1.3556314706802368
Iteration 32: Loss = 1.3510879278182983
Iteration 33: Loss = 1.3463696241378784
Iteration 34: Loss = 1.3414698839187622
Iteration 35: Loss = 1.3363816738128662
Iteration 36: Loss = 1.3310964107513428
Iteration 37: Loss = 1.3256080150604248
Iteration 38: Loss = 1.3199087381362915
Iteration 39: Loss = 1.313990592956543
Iteration 40: Loss = 1.3078429698944092
Iteration 41: Loss = 1.3014562129974365
Iteration 42: Loss = 1.2948170900344849
Iteration 43: Loss = 1.2879106998443604
Iteration 44: Loss = 1.280719518661499
Iteration 45: Loss = 1.2732219696044922
Iteration 46: Loss = 1.2653942108154297
Iteration 47: Loss = 1.2572064399719238
Iteration 48: Loss = 1.2486244440078735
Iteration 49: Loss = 1.2396104335784912
Iteration 50: Loss = 1.2301225662231445
Iteration 51: Loss = 1.2201176881790161
Iteration 52: Loss = 1.2095476388931274
Iteration 53: Loss = 1.198364019393921
Iteration 54: Loss = 1.1865164041519165
Iteration 55: Loss = 1.1739531755447388
Iteration 56: Loss = 1.1606255769729614
Iteration 57: Loss = 1.1464823484420776
Iteration 58: Loss = 1.1314713954925537
Iteration 59: Loss = 1.1155439615249634
Iteration 60: Loss = 1.0986430644989014
Iteration 61: Loss = 1.0807201862335205
Iteration 62: Loss = 1.061720609664917
Iteration 63: Loss = 1.041596531867981
Iteration 64: Loss = 1.0203062295913696
Iteration 65: Loss = 0.9978209137916565
Iteration 66: Loss = 0.9741232991218567
Iteration 67: Loss = 0.9492140412330627
Iteration 68: Loss = 0.923132061958313
Iteration 69: Loss = 0.895965576171875
Iteration 70: Loss = 0.867842435836792
Iteration 71: Loss = 0.8389472365379333
Iteration 72: Loss = 0.8095489144325256
Iteration 73: Loss = 0.7799707055091858
Iteration 74: Loss = 0.7506078481674194
Iteration 75: Loss = 0.7219191789627075
Iteration 76: Loss = 0.6944218873977661
Iteration 77: Loss = 0.6686302423477173
Iteration 78: Loss = 0.6450572609901428
Iteration 79: Loss = 0.6241503953933716
Iteration 80: Loss = 0.6062518954277039
Iteration 81: Loss = 0.5915684103965759
Iteration 82: Loss = 0.5801444053649902
Iteration 83: Loss = 0.5718469619750977
Iteration 84: Loss = 0.5663835406303406
Iteration 85: Loss = 0.5633417367935181
Iteration 86: Loss = 0.5622326135635376
Iteration 87: Loss = 0.5625518560409546
Iteration 88: Loss = 0.563812792301178
Iteration 89: Loss = 0.5655857920646667
Iteration 90: Loss = 0.5675152540206909
Iteration 91: Loss = 0.5693243145942688
Iteration 92: Loss = 0.570815920829773
Iteration 93: Loss = 0.571860671043396
Iteration 94: Loss = 0.5723897814750671
Iteration 95: Loss = 0.5723820924758911
Iteration 96: Loss = 0.5718541145324707
Iteration 97: Loss = 0.5708490014076233
Iteration 98: Loss = 0.5694294571876526
Iteration 99: Loss = 0.5676700472831726
Iteration 100: Loss = 0.5656524896621704
Iteration 101: Loss = 0.5634596943855286
Iteration 102: Loss = 0.56117182970047
Iteration 103: Loss = 0.5588647723197937
Iteration 104: Loss = 0.55660480260849
Iteration 105: Loss = 0.5544477701187134
Iteration 106: Loss = 0.5524381399154663
Iteration 107: Loss = 0.5506071448326111
Iteration 108: Loss = 0.5489731431007385
Iteration 109: Loss = 0.54754239320755
Iteration 110: Loss = 0.5463097095489502
Iteration 111: Loss = 0.545261800289154
Iteration 112: Loss = 0.5443768501281738
Iteration 113: Loss = 0.5436281561851501
Iteration 114: Loss = 0.5429866909980774
Iteration 115: Loss = 0.5424230098724365
Iteration 116: Loss = 0.5419080853462219
Iteration 117: Loss = 0.5414156317710876
Iteration 118: Loss = 0.5409243702888489
Iteration 119: Loss = 0.5404159426689148
Iteration 120: Loss = 0.5398780107498169
Iteration 121: Loss = 0.5393027067184448
Iteration 122: Loss = 0.5386867523193359
Iteration 123: Loss = 0.5380310416221619
Iteration 124: Loss = 0.53733891248703
Iteration 125: Loss = 0.5366169810295105
Iteration 126: Loss = 0.5358719825744629
Iteration 127: Loss = 0.5351123213768005
Iteration 128: Loss = 0.5343453288078308
Iteration 129: Loss = 0.5335793495178223
Iteration 130: Loss = 0.5328207015991211
Iteration 131: Loss = 0.5320742726325989
Iteration 132: Loss = 0.5313442945480347
Iteration 133: Loss = 0.5306326150894165
Iteration 134: Loss = 0.5299407839775085
Iteration 135: Loss = 0.5292680859565735
Iteration 136: Loss = 0.5286136269569397
Iteration 137: Loss = 0.5279755592346191
Iteration 138: Loss = 0.5273512601852417
Iteration 139: Loss = 0.5267378687858582
Iteration 140: Loss = 0.5261327624320984
Iteration 141: Loss = 0.5255332589149475
Iteration 142: Loss = 0.524937093257904
Iteration 143: Loss = 0.5243423581123352
Iteration 144: Loss = 0.5237478017807007
Iteration 145: Loss = 0.5231526494026184
Iteration 146: Loss = 0.5225558280944824
Iteration 147: Loss = 0.5219576954841614
Iteration 148: Loss = 0.5213586688041687
Iteration 149: Loss = 0.5207586288452148
Iteration 150: Loss = 0.5201589465141296
Iteration 151: Loss = 0.5195595026016235
Iteration 152: Loss = 0.5189620852470398
Iteration 153: Loss = 0.5183663964271545
Iteration 154: Loss = 0.5177739262580872
Iteration 155: Loss = 0.5171841979026794
Iteration 156: Loss = 0.5165983438491821
Iteration 157: Loss = 0.5160154700279236
Iteration 158: Loss = 0.515436589717865
Iteration 159: Loss = 0.5148608684539795
Iteration 160: Loss = 0.5142886638641357
Iteration 161: Loss = 0.5137193202972412
Iteration 162: Loss = 0.5131525993347168
Iteration 163: Loss = 0.5125883221626282
Iteration 164: Loss = 0.512025773525238
Iteration 165: Loss = 0.511465311050415
Iteration 166: Loss = 0.510906457901001
Iteration 167: Loss = 0.5103487968444824
Iteration 168: Loss = 0.5097926259040833
Iteration 169: Loss = 0.5092378258705139
Iteration 170: Loss = 0.5086836814880371
Iteration 171: Loss = 0.5081306099891663
Iteration 172: Loss = 0.5075788497924805
Iteration 173: Loss = 0.5070282220840454
Iteration 174: Loss = 0.5064785480499268
Iteration 175: Loss = 0.5059300661087036
Iteration 176: Loss = 0.5053826570510864
Iteration 177: Loss = 0.5048367977142334
Iteration 178: Loss = 0.5042923092842102
Iteration 179: Loss = 0.503748893737793
Iteration 180: Loss = 0.5032066702842712
Iteration 181: Loss = 0.5026656985282898
Iteration 182: Loss = 0.50212562084198
Iteration 183: Loss = 0.5015868544578552
Iteration 184: Loss = 0.5010494589805603
Iteration 185: Loss = 0.50051349401474
Iteration 186: Loss = 0.4999788701534271
Iteration 187: Loss = 0.49944525957107544
Iteration 188: Loss = 0.49891266226768494
Iteration 189: Loss = 0.4983808398246765
Iteration 190: Loss = 0.4978499710559845
Iteration 191: Loss = 0.4973200559616089
Iteration 192: Loss = 0.49679118394851685
Iteration 193: Loss = 0.49626317620277405
Iteration 194: Loss = 0.4957360029220581
Iteration 195: Loss = 0.495209664106369
Iteration 196: Loss = 0.4946839213371277
Iteration 197: Loss = 0.4941588342189789
Iteration 198: Loss = 0.49363481998443604
Iteration 199: Loss = 0.49311158061027527
Iteration 200: Loss = 0.49258941411972046
Iteration 201: Loss = 0.4920685589313507
Iteration 202: Loss = 0.491549015045166
Iteration 203: Loss = 0.49103066325187683
Iteration 204: Loss = 0.4905136227607727
Iteration 205: Loss = 0.4899977445602417
Iteration 206: Loss = 0.4894830882549286
Iteration 207: Loss = 0.48896992206573486
Iteration 208: Loss = 0.4884580373764038
Iteration 209: Loss = 0.4879472553730011
Iteration 210: Loss = 0.48743727803230286
Iteration 211: Loss = 0.4869282841682434
Iteration 212: Loss = 0.48642024397850037
Iteration 213: Loss = 0.4859134554862976
Iteration 214: Loss = 0.48540759086608887
Iteration 215: Loss = 0.48490312695503235
Iteration 216: Loss = 0.4843998849391937
Iteration 217: Loss = 0.48389777541160583
Iteration 218: Loss = 0.48339685797691345
Iteration 219: Loss = 0.48289746046066284
Iteration 220: Loss = 0.48239952325820923
Iteration 221: Loss = 0.4819028377532959
Iteration 222: Loss = 0.4814070165157318
Iteration 223: Loss = 0.4809129536151886
Iteration 224: Loss = 0.48042064905166626
Iteration 225: Loss = 0.4799303412437439
Iteration 226: Loss = 0.47944143414497375
Iteration 227: Loss = 0.47895437479019165
Iteration 228: Loss = 0.47846904397010803
Iteration 229: Loss = 0.47798529267311096
Iteration 230: Loss = 0.47750335931777954
Iteration 231: Loss = 0.4770229160785675
Iteration 232: Loss = 0.47654470801353455
Iteration 233: Loss = 0.47606900334358215
Iteration 234: Loss = 0.47559526562690735
Iteration 235: Loss = 0.4751236140727997
Iteration 236: Loss = 0.4746538996696472
Iteration 237: Loss = 0.4741865396499634
Iteration 238: Loss = 0.4737215042114258
Iteration 239: Loss = 0.473258912563324
Iteration 240: Loss = 0.4727988839149475
Iteration 241: Loss = 0.4723411798477173
Iteration 242: Loss = 0.47188591957092285
Iteration 243: Loss = 0.4714330732822418
Iteration 244: Loss = 0.4709826707839966
Iteration 245: Loss = 0.4705347716808319
Iteration 246: Loss = 0.4700894057750702
Iteration 247: Loss = 0.4696464538574219
Iteration 248: Loss = 0.46920615434646606
Iteration 249: Loss = 0.46876832842826843
Iteration 250: Loss = 0.46833309531211853
Iteration 251: Loss = 0.46790048480033875
Iteration 252: Loss = 0.4674701988697052
Iteration 253: Loss = 0.4670426547527313
Iteration 254: Loss = 0.46661803126335144
Iteration 255: Loss = 0.46619629859924316
Iteration 256: Loss = 0.4657774269580841
Iteration 257: Loss = 0.4653613269329071
Iteration 258: Loss = 0.46494776010513306
Iteration 259: Loss = 0.4645366072654724
Iteration 260: Loss = 0.4641284644603729
Iteration 261: Loss = 0.4637230336666107
Iteration 262: Loss = 0.4633205235004425
Iteration 263: Loss = 0.4629208445549011
Iteration 264: Loss = 0.4625243842601776
Iteration 265: Loss = 0.4621305763721466
Iteration 266: Loss = 0.46173951029777527
Iteration 267: Loss = 0.4613513648509979
Iteration 268: Loss = 0.46096619963645935
Iteration 269: Loss = 0.46058380603790283
Iteration 270: Loss = 0.4602048099040985
Iteration 271: Loss = 0.45982909202575684
Iteration 272: Loss = 0.4594566226005554
Iteration 273: Loss = 0.4590868055820465
Iteration 274: Loss = 0.4587196409702301
Iteration 275: Loss = 0.45835551619529724
Iteration 276: Loss = 0.4579947292804718
Iteration 277: Loss = 0.4576372504234314
Iteration 278: Loss = 0.45728248357772827
Iteration 279: Loss = 0.456930547952652
Iteration 280: Loss = 0.4565814137458801
Iteration 281: Loss = 0.4562353789806366
Iteration 282: Loss = 0.45589199662208557
Iteration 283: Loss = 0.4555515646934509
Iteration 284: Loss = 0.4552137553691864
Iteration 285: Loss = 0.4548785984516144
Iteration 286: Loss = 0.454546719789505
Iteration 287: Loss = 0.4542178809642792
Iteration 288: Loss = 0.45389190316200256
Iteration 289: Loss = 0.45356887578964233
Iteration 290: Loss = 0.4532487690448761
Iteration 291: Loss = 0.4529319405555725
Iteration 292: Loss = 0.45261791348457336
Iteration 293: Loss = 0.45230644941329956
Iteration 294: Loss = 0.45199841260910034
Iteration 295: Loss = 0.451693058013916
Iteration 296: Loss = 0.4513903260231018
Iteration 297: Loss = 0.45109060406684875
Iteration 298: Loss = 0.45079362392425537
Iteration 299: Loss = 0.4504993259906769
Iteration 300: Loss = 0.45020782947540283
Iteration 301: Loss = 0.4499194324016571
Iteration 302: Loss = 0.4496336579322815
Iteration 303: Loss = 0.4493504464626312
Iteration 304: Loss = 0.44906988739967346
Iteration 305: Loss = 0.4487920105457306
Iteration 306: Loss = 0.4485166370868683
Iteration 307: Loss = 0.44824400544166565
Iteration 308: Loss = 0.4479737877845764
Iteration 309: Loss = 0.44770580530166626
Iteration 310: Loss = 0.44744035601615906
Iteration 311: Loss = 0.44717735052108765
Iteration 312: Loss = 0.44691693782806396
Iteration 313: Loss = 0.4466588795185089
Iteration 314: Loss = 0.4464031159877777
Iteration 315: Loss = 0.4461499750614166
Iteration 316: Loss = 0.4458988904953003
Iteration 317: Loss = 0.4456498324871063
Iteration 318: Loss = 0.4454036355018616
Iteration 319: Loss = 0.4451597332954407
Iteration 320: Loss = 0.4449186623096466
Iteration 321: Loss = 0.444679856300354
Iteration 322: Loss = 0.44444331526756287
Iteration 323: Loss = 0.4442092776298523
Iteration 324: Loss = 0.4439772367477417
Iteration 325: Loss = 0.44374755024909973
Iteration 326: Loss = 0.44351983070373535
Iteration 327: Loss = 0.4432946443557739
Iteration 328: Loss = 0.4430716931819916
Iteration 329: Loss = 0.44285115599632263
Iteration 330: Loss = 0.44263312220573425
Iteration 331: Loss = 0.44241705536842346
Iteration 332: Loss = 0.4422035217285156
Iteration 333: Loss = 0.4419919550418854
Iteration 334: Loss = 0.4417828321456909
Iteration 335: Loss = 0.44157546758651733
Iteration 336: Loss = 0.4413703680038452
Iteration 337: Loss = 0.4411671757698059
Iteration 338: Loss = 0.4409659802913666
Iteration 339: Loss = 0.44076672196388245
Iteration 340: Loss = 0.44056978821754456
Iteration 341: Loss = 0.4403747022151947
Iteration 342: Loss = 0.4401816129684448
Iteration 343: Loss = 0.4399905502796173
Iteration 344: Loss = 0.43980178236961365
Iteration 345: Loss = 0.4396148920059204
Iteration 346: Loss = 0.43942999839782715
Iteration 347: Loss = 0.4392470717430115
Iteration 348: Loss = 0.4390661120414734
Iteration 349: Loss = 0.4388868808746338
Iteration 350: Loss = 0.43870991468429565
Iteration 351: Loss = 0.43853455781936646
Iteration 352: Loss = 0.4383614659309387
Iteration 353: Loss = 0.4381897747516632
Iteration 354: Loss = 0.4380205273628235
Iteration 355: Loss = 0.4378526210784912
Iteration 356: Loss = 0.43768686056137085
Iteration 357: Loss = 0.43752241134643555
Iteration 358: Loss = 0.437360018491745
Iteration 359: Loss = 0.43719935417175293
Iteration 360: Loss = 0.4370403587818146
Iteration 361: Loss = 0.4368833601474762
Iteration 362: Loss = 0.4367277920246124
Iteration 363: Loss = 0.4365740418434143
Iteration 364: Loss = 0.4364214539527893
Iteration 365: Loss = 0.43627074360847473
Iteration 366: Loss = 0.43612152338027954
Iteration 367: Loss = 0.43597373366355896
Iteration 368: Loss = 0.4358273446559906
Iteration 369: Loss = 0.43568211793899536
Iteration 370: Loss = 0.43553879857063293
Iteration 371: Loss = 0.4353964924812317
Iteration 372: Loss = 0.4352555572986603
Iteration 373: Loss = 0.435116171836853
Iteration 374: Loss = 0.43497782945632935
Iteration 375: Loss = 0.4348413646221161
Iteration 376: Loss = 0.4347059726715088
Iteration 377: Loss = 0.43457189202308655
Iteration 378: Loss = 0.4344393014907837
Iteration 379: Loss = 0.43430763483047485
Iteration 380: Loss = 0.4341776669025421
Iteration 381: Loss = 0.4340488612651825
Iteration 382: Loss = 0.43392112851142883
Iteration 383: Loss = 0.4337948262691498
Iteration 384: Loss = 0.4336693584918976
Iteration 385: Loss = 0.4335455894470215
Iteration 386: Loss = 0.43342316150665283
Iteration 387: Loss = 0.4333016276359558
Iteration 388: Loss = 0.4331818222999573
Iteration 389: Loss = 0.43306320905685425
Iteration 390: Loss = 0.4329455494880676
Iteration 391: Loss = 0.43282946944236755
Iteration 392: Loss = 0.4327142834663391
Iteration 393: Loss = 0.43260014057159424
Iteration 394: Loss = 0.432487428188324
Iteration 395: Loss = 0.43237560987472534
Iteration 396: Loss = 0.4322648346424103
Iteration 397: Loss = 0.4321553707122803
Iteration 398: Loss = 0.4320467710494995
Iteration 399: Loss = 0.4319393038749695
Iteration 400: Loss = 0.43183305859565735
Iteration 401: Loss = 0.43172746896743774
Iteration 402: Loss = 0.4316229820251465
Iteration 403: Loss = 0.4315195381641388
Iteration 404: Loss = 0.4314168691635132
Iteration 405: Loss = 0.4313153624534607
Iteration 406: Loss = 0.4312148988246918
Iteration 407: Loss = 0.43111515045166016
Iteration 408: Loss = 0.4310164451599121
Iteration 409: Loss = 0.43091899156570435
Iteration 410: Loss = 0.4308221936225891
Iteration 411: Loss = 0.4307263493537903
Iteration 412: Loss = 0.43063151836395264
Iteration 413: Loss = 0.4305373430252075
Iteration 414: Loss = 0.4304441511631012
Iteration 415: Loss = 0.430352121591568
Iteration 416: Loss = 0.4302607774734497
Iteration 417: Loss = 0.4301699995994568
Iteration 418: Loss = 0.4300806224346161
Iteration 419: Loss = 0.42999181151390076
Iteration 420: Loss = 0.42990368604660034
Iteration 421: Loss = 0.4298167824745178
Iteration 422: Loss = 0.42973068356513977
Iteration 423: Loss = 0.4296451807022095
Iteration 424: Loss = 0.4295603930950165
Iteration 425: Loss = 0.4294765889644623
Iteration 426: Loss = 0.42939338088035583
Iteration 427: Loss = 0.42931073904037476
Iteration 428: Loss = 0.4292292594909668
Iteration 429: Loss = 0.4291483461856842
Iteration 430: Loss = 0.4290679693222046
Iteration 431: Loss = 0.42898839712142944
Iteration 432: Loss = 0.4289095997810364
Iteration 433: Loss = 0.4288312792778015
Iteration 434: Loss = 0.4287535548210144
Iteration 435: Loss = 0.4286768138408661
Iteration 436: Loss = 0.4286007583141327
Iteration 437: Loss = 0.4285251796245575
Iteration 438: Loss = 0.42845025658607483
Iteration 439: Loss = 0.4283762276172638
Iteration 440: Loss = 0.4283026456832886
Iteration 441: Loss = 0.4282294511795044
Iteration 442: Loss = 0.4281572103500366
Iteration 443: Loss = 0.4280855357646942
Iteration 444: Loss = 0.4280143976211548
Iteration 445: Loss = 0.4279436767101288
Iteration 446: Loss = 0.4278739392757416
Iteration 447: Loss = 0.4278045892715454
Iteration 448: Loss = 0.42773568630218506
Iteration 449: Loss = 0.4276673197746277
Iteration 450: Loss = 0.42760002613067627
Iteration 451: Loss = 0.42753317952156067
Iteration 452: Loss = 0.42746666073799133
Iteration 453: Loss = 0.4274007976055145
Iteration 454: Loss = 0.42733556032180786
Iteration 455: Loss = 0.4272708296775818
Iteration 456: Loss = 0.4272063672542572
Iteration 457: Loss = 0.4271424114704132
Iteration 458: Loss = 0.42707937955856323
Iteration 459: Loss = 0.42701664566993713
Iteration 460: Loss = 0.42695435881614685
Iteration 461: Loss = 0.4268925189971924
Iteration 462: Loss = 0.4268316328525543
Iteration 463: Loss = 0.4267711341381073
Iteration 464: Loss = 0.42671099305152893
Iteration 465: Loss = 0.4266512989997864
Iteration 466: Loss = 0.4265923500061035
Iteration 467: Loss = 0.4265337586402893
Iteration 468: Loss = 0.4264754354953766
Iteration 469: Loss = 0.4264175295829773
Iteration 470: Loss = 0.4263603091239929
Iteration 471: Loss = 0.42630353569984436
Iteration 472: Loss = 0.4262469410896301
Iteration 473: Loss = 0.42619073390960693
Iteration 474: Loss = 0.4261351227760315
Iteration 475: Loss = 0.4260798990726471
Iteration 476: Loss = 0.42602503299713135
Iteration 477: Loss = 0.4259704649448395
Iteration 478: Loss = 0.42591625452041626
Iteration 479: Loss = 0.42586278915405273
Iteration 480: Loss = 0.4258096516132355
Iteration 481: Loss = 0.4257568120956421
Iteration 482: Loss = 0.4257042109966278
Iteration 483: Loss = 0.4256521463394165
Iteration 484: Loss = 0.4256006181240082
Iteration 485: Loss = 0.42554932832717896
Iteration 486: Loss = 0.42549827694892883
Iteration 487: Loss = 0.42544758319854736
Iteration 488: Loss = 0.4253976345062256
Iteration 489: Loss = 0.4253479242324829
Iteration 490: Loss = 0.42529845237731934
Iteration 491: Loss = 0.42524927854537964
Iteration 492: Loss = 0.4252004027366638
Iteration 493: Loss = 0.4251522123813629
Iteration 494: Loss = 0.4251042604446411
Iteration 495: Loss = 0.4250565767288208
Iteration 496: Loss = 0.4250091016292572
Iteration 497: Loss = 0.4249621033668518
Iteration 498: Loss = 0.42491546273231506
Iteration 499: Loss = 0.4248690903186798
Iteration 500: Loss = 0.42482298612594604
Iteration 501: Loss = 0.4247770607471466
Iteration 502: Loss = 0.42473143339157104
Iteration 503: Loss = 0.42468634247779846
Iteration 504: Loss = 0.4246412515640259
Iteration 505: Loss = 0.42459654808044434
Iteration 506: Loss = 0.42455199360847473
Iteration 507: Loss = 0.4245077073574066
Iteration 508: Loss = 0.4244639277458191
Iteration 509: Loss = 0.42442020773887634
Iteration 510: Loss = 0.4243767261505127
Iteration 511: Loss = 0.4243335425853729
Iteration 512: Loss = 0.42429062724113464
Iteration 513: Loss = 0.4242480993270874
Iteration 514: Loss = 0.42420580983161926
Iteration 515: Loss = 0.4241636395454407
Iteration 516: Loss = 0.4241216480731964
Iteration 517: Loss = 0.4240797460079193
Iteration 518: Loss = 0.4240383803844452
Iteration 519: Loss = 0.42399734258651733
Iteration 520: Loss = 0.42395636439323425
Iteration 521: Loss = 0.4239155948162079
Iteration 522: Loss = 0.42387494444847107
Iteration 523: Loss = 0.4238346815109253
Iteration 524: Loss = 0.4237947463989258
Iteration 525: Loss = 0.42375504970550537
Iteration 526: Loss = 0.42371535301208496
Iteration 527: Loss = 0.4236759543418884
Iteration 528: Loss = 0.42363667488098145
Iteration 529: Loss = 0.42359796166419983
Iteration 530: Loss = 0.42355939745903015
Iteration 531: Loss = 0.4235210716724396
Iteration 532: Loss = 0.4234827160835266
Iteration 533: Loss = 0.42344462871551514
Iteration 534: Loss = 0.42340683937072754
Iteration 535: Loss = 0.4233694076538086
Iteration 536: Loss = 0.423332154750824
Iteration 537: Loss = 0.4232949912548065
Iteration 538: Loss = 0.4232580065727234
Iteration 539: Loss = 0.42322105169296265
Iteration 540: Loss = 0.42318442463874817
Iteration 541: Loss = 0.42314809560775757
Iteration 542: Loss = 0.4231119453907013
Iteration 543: Loss = 0.4230758845806122
Iteration 544: Loss = 0.42304009199142456
Iteration 545: Loss = 0.42300426959991455
Iteration 546: Loss = 0.4229688346385956
Iteration 547: Loss = 0.42293378710746765
Iteration 548: Loss = 0.4228988587856293
Iteration 549: Loss = 0.42286407947540283
Iteration 550: Loss = 0.42282938957214355
Iteration 551: Loss = 0.42279481887817383
Iteration 552: Loss = 0.4227604269981384
Iteration 553: Loss = 0.42272651195526123
Iteration 554: Loss = 0.4226926565170288
Iteration 555: Loss = 0.4226589798927307
Iteration 556: Loss = 0.42262542247772217
Iteration 557: Loss = 0.4225919246673584
Iteration 558: Loss = 0.42255857586860657
Iteration 559: Loss = 0.42252543568611145
Iteration 560: Loss = 0.42249253392219543
Iteration 561: Loss = 0.42245978116989136
Iteration 562: Loss = 0.42242714762687683
Iteration 563: Loss = 0.4223945736885071
Iteration 564: Loss = 0.4223621189594269
Iteration 565: Loss = 0.42232975363731384
Iteration 566: Loss = 0.42229777574539185
Iteration 567: Loss = 0.4222659468650818
Iteration 568: Loss = 0.4222341477870941
Iteration 569: Loss = 0.4222024977207184
Iteration 570: Loss = 0.42217087745666504
Iteration 571: Loss = 0.42213937640190125
Iteration 572: Loss = 0.422107994556427
Iteration 573: Loss = 0.4220768213272095
Iteration 574: Loss = 0.4220457971096039
Iteration 575: Loss = 0.42201486229896545
Iteration 576: Loss = 0.4219839572906494
Iteration 577: Loss = 0.42195311188697815
Iteration 578: Loss = 0.4219224452972412
Iteration 579: Loss = 0.4218917191028595
Iteration 580: Loss = 0.4218614399433136
Iteration 581: Loss = 0.421831339597702
Iteration 582: Loss = 0.42180126905441284
Iteration 583: Loss = 0.4217712879180908
Iteration 584: Loss = 0.42174145579338074
Iteration 585: Loss = 0.4217115044593811
Iteration 586: Loss = 0.42168182134628296
Iteration 587: Loss = 0.421652227640152
Iteration 588: Loss = 0.4216228425502777
Iteration 589: Loss = 0.4215935170650482
Iteration 590: Loss = 0.4215642213821411
Iteration 591: Loss = 0.42153501510620117
Iteration 592: Loss = 0.421505868434906
Iteration 593: Loss = 0.42147669196128845
Iteration 594: Loss = 0.42144763469696045
Iteration 595: Loss = 0.4214188754558563
Iteration 596: Loss = 0.421390175819397
Iteration 597: Loss = 0.42136162519454956
Iteration 598: Loss = 0.42133304476737976
Iteration 599: Loss = 0.42130449414253235
Iteration 600: Loss = 0.4212760627269745
Iteration 601: Loss = 0.4212477505207062
Iteration 602: Loss = 0.42121943831443787
Iteration 603: Loss = 0.4211914837360382
Iteration 604: Loss = 0.4211636185646057
Iteration 605: Loss = 0.42113572359085083
Iteration 606: Loss = 0.4211079180240631
Iteration 607: Loss = 0.4210801124572754
Iteration 608: Loss = 0.4210524260997772
Iteration 609: Loss = 0.42102473974227905
Iteration 610: Loss = 0.42099714279174805
Iteration 611: Loss = 0.42096978425979614
Iteration 612: Loss = 0.4209425449371338
Iteration 613: Loss = 0.42091527581214905
Iteration 614: Loss = 0.42088809609413147
Iteration 615: Loss = 0.42086097598075867
Iteration 616: Loss = 0.42083385586738586
Iteration 617: Loss = 0.42080676555633545
Iteration 618: Loss = 0.4207797348499298
Iteration 619: Loss = 0.4207528829574585
Iteration 620: Loss = 0.4207261800765991
Iteration 621: Loss = 0.4206995368003845
Iteration 622: Loss = 0.4206729233264923
Iteration 623: Loss = 0.4206463694572449
Iteration 624: Loss = 0.4206199049949646
Iteration 625: Loss = 0.4205934405326843
Iteration 626: Loss = 0.4205669164657593
Iteration 627: Loss = 0.42054057121276855
Iteration 628: Loss = 0.42051419615745544
Iteration 629: Loss = 0.42048802971839905
Iteration 630: Loss = 0.4204619228839874
Iteration 631: Loss = 0.42043575644493103
Iteration 632: Loss = 0.4204096496105194
Iteration 633: Loss = 0.4203835427761078
Iteration 634: Loss = 0.42035746574401855
Iteration 635: Loss = 0.4203314185142517
Iteration 636: Loss = 0.42030543088912964
Iteration 637: Loss = 0.42027950286865234
Iteration 638: Loss = 0.4202537536621094
Iteration 639: Loss = 0.420227974653244
Iteration 640: Loss = 0.42020219564437866
Iteration 641: Loss = 0.4201764762401581
Iteration 642: Loss = 0.4201507866382599
Iteration 643: Loss = 0.4201251268386841
Iteration 644: Loss = 0.42009949684143066
Iteration 645: Loss = 0.42007389664649963
Iteration 646: Loss = 0.42004823684692383
Iteration 647: Loss = 0.42002278566360474
Iteration 648: Loss = 0.4199973940849304
Iteration 649: Loss = 0.4199720323085785
Iteration 650: Loss = 0.41994670033454895
Iteration 651: Loss = 0.4199213981628418
Iteration 652: Loss = 0.41989609599113464
Iteration 653: Loss = 0.4198707938194275
Iteration 654: Loss = 0.4198455214500427
Iteration 655: Loss = 0.41982021927833557
Iteration 656: Loss = 0.4197950065135956
Iteration 657: Loss = 0.4197700321674347
Iteration 658: Loss = 0.41974499821662903
Iteration 659: Loss = 0.41972002387046814
Iteration 660: Loss = 0.4196951389312744
Iteration 661: Loss = 0.4196702241897583
Iteration 662: Loss = 0.4196453392505646
Iteration 663: Loss = 0.41962042450904846
Iteration 664: Loss = 0.41959553956985474
Iteration 665: Loss = 0.4195707142353058
Iteration 666: Loss = 0.41954582929611206
Iteration 667: Loss = 0.4195210933685303
Iteration 668: Loss = 0.4194963574409485
Iteration 669: Loss = 0.41947174072265625
Iteration 670: Loss = 0.41944703459739685
Iteration 671: Loss = 0.4194223880767822
Iteration 672: Loss = 0.4193978011608124
Iteration 673: Loss = 0.41937315464019775
Iteration 674: Loss = 0.4193485975265503
Iteration 675: Loss = 0.4193240702152252
Iteration 676: Loss = 0.4192993938922882
Iteration 677: Loss = 0.41927486658096313
Iteration 678: Loss = 0.41925033926963806
Iteration 679: Loss = 0.4192259609699249
Iteration 680: Loss = 0.4192016124725342
Iteration 681: Loss = 0.4191772937774658
Iteration 682: Loss = 0.4191529154777527
Iteration 683: Loss = 0.4191285967826843
Iteration 684: Loss = 0.4191042482852936
Iteration 685: Loss = 0.41907989978790283
Iteration 686: Loss = 0.41905564069747925
Iteration 687: Loss = 0.4190312922000885
Iteration 688: Loss = 0.4190070331096649
Iteration 689: Loss = 0.418982595205307
Iteration 690: Loss = 0.4189583361148834
Iteration 691: Loss = 0.418934166431427
Iteration 692: Loss = 0.4189099669456482
Iteration 693: Loss = 0.418885737657547
Iteration 694: Loss = 0.4188615679740906
Iteration 695: Loss = 0.4188373386859894
Iteration 696: Loss = 0.41881316900253296
Iteration 697: Loss = 0.41878899931907654
Iteration 698: Loss = 0.41876471042633057
Iteration 699: Loss = 0.41874054074287415
Iteration 700: Loss = 0.41871631145477295
Iteration 701: Loss = 0.41869211196899414
Iteration 702: Loss = 0.41866785287857056
Iteration 703: Loss = 0.41864368319511414
Iteration 704: Loss = 0.4186195731163025
Iteration 705: Loss = 0.41859546303749084
Iteration 706: Loss = 0.4185713827610016
Iteration 707: Loss = 0.41854727268218994
Iteration 708: Loss = 0.4185231328010559
Iteration 709: Loss = 0.41849902272224426
Iteration 710: Loss = 0.41847488284111023
Iteration 711: Loss = 0.4184507131576538
Iteration 712: Loss = 0.4184265732765198
Iteration 713: Loss = 0.41840243339538574
Iteration 714: Loss = 0.4183782935142517
Iteration 715: Loss = 0.4183541238307953
Iteration 716: Loss = 0.41832995414733887
Iteration 717: Loss = 0.4183058738708496
Iteration 718: Loss = 0.4182818830013275
Iteration 719: Loss = 0.41825777292251587
Iteration 720: Loss = 0.4182336926460266
Iteration 721: Loss = 0.41820964217185974
Iteration 722: Loss = 0.4181855320930481
Iteration 723: Loss = 0.41816142201423645
Iteration 724: Loss = 0.4181373119354248
Iteration 725: Loss = 0.41811317205429077
Iteration 726: Loss = 0.4180890917778015
Iteration 727: Loss = 0.4180648922920227
Iteration 728: Loss = 0.4180407226085663
Iteration 729: Loss = 0.4180165231227875
Iteration 730: Loss = 0.4179924428462982
Iteration 731: Loss = 0.41796839237213135
Iteration 732: Loss = 0.4179443418979645
Iteration 733: Loss = 0.4179202914237976
Iteration 734: Loss = 0.41789624094963074
Iteration 735: Loss = 0.4178721308708191
Iteration 736: Loss = 0.4178480803966522
Iteration 737: Loss = 0.41782402992248535
Iteration 738: Loss = 0.4177999198436737
Iteration 739: Loss = 0.41777586936950684
Iteration 740: Loss = 0.4177517592906952
Iteration 741: Loss = 0.41772764921188354
Iteration 742: Loss = 0.4177035689353943
Iteration 743: Loss = 0.4176793694496155
Iteration 744: Loss = 0.41765519976615906
Iteration 745: Loss = 0.4176310896873474
Iteration 746: Loss = 0.41760700941085815
Iteration 747: Loss = 0.4175829291343689
Iteration 748: Loss = 0.4175589084625244
Iteration 749: Loss = 0.4175347685813904
Iteration 750: Loss = 0.4175106883049011
Iteration 751: Loss = 0.4174865782260895
Iteration 752: Loss = 0.41746243834495544
Iteration 753: Loss = 0.4174382984638214
Iteration 754: Loss = 0.4174140691757202
Iteration 755: Loss = 0.4173898696899414
Iteration 756: Loss = 0.4173656702041626
Iteration 757: Loss = 0.4173414707183838
Iteration 758: Loss = 0.4173172116279602
Iteration 759: Loss = 0.4172929525375366
Iteration 760: Loss = 0.41726863384246826
Iteration 761: Loss = 0.4172442853450775
Iteration 762: Loss = 0.41722002625465393
Iteration 763: Loss = 0.41719579696655273
Iteration 764: Loss = 0.4171715974807739
Iteration 765: Loss = 0.41714733839035034
Iteration 766: Loss = 0.41712307929992676
Iteration 767: Loss = 0.4170988202095032
Iteration 768: Loss = 0.4170744717121124
Iteration 769: Loss = 0.41705018281936646
Iteration 770: Loss = 0.4170258641242981
Iteration 771: Loss = 0.41700148582458496
Iteration 772: Loss = 0.4169771373271942
Iteration 773: Loss = 0.4169527292251587
Iteration 774: Loss = 0.41692832112312317
Iteration 775: Loss = 0.41690385341644287
Iteration 776: Loss = 0.41687941551208496
Iteration 777: Loss = 0.4168548882007599
Iteration 778: Loss = 0.4168303906917572
Iteration 779: Loss = 0.41680583357810974
Iteration 780: Loss = 0.41678130626678467
Iteration 781: Loss = 0.4167567789554596
Iteration 782: Loss = 0.4167322814464569
Iteration 783: Loss = 0.41670775413513184
Iteration 784: Loss = 0.41668325662612915
Iteration 785: Loss = 0.4166586995124817
Iteration 786: Loss = 0.41663414239883423
Iteration 787: Loss = 0.416609525680542
Iteration 788: Loss = 0.41658493876457214
Iteration 789: Loss = 0.41656026244163513
Iteration 790: Loss = 0.4165356457233429
Iteration 791: Loss = 0.41651099920272827
Iteration 792: Loss = 0.4164862334728241
Iteration 793: Loss = 0.4164615571498871
Iteration 794: Loss = 0.4164367616176605
Iteration 795: Loss = 0.41641196608543396
Iteration 796: Loss = 0.416387140750885
Iteration 797: Loss = 0.41636234521865845
Iteration 798: Loss = 0.4163374602794647
Iteration 799: Loss = 0.416312575340271
Iteration 800: Loss = 0.4162876307964325
Iteration 801: Loss = 0.4162626564502716
Iteration 802: Loss = 0.4162377119064331
Iteration 803: Loss = 0.41621264815330505
Iteration 804: Loss = 0.41618767380714417
Iteration 805: Loss = 0.4161626994609833
Iteration 806: Loss = 0.4161376953125
Iteration 807: Loss = 0.41611266136169434
Iteration 808: Loss = 0.4160875678062439
Iteration 809: Loss = 0.41606250405311584
Iteration 810: Loss = 0.416037380695343
Iteration 811: Loss = 0.4160122573375702
Iteration 812: Loss = 0.4159870445728302
Iteration 813: Loss = 0.4159618616104126
Iteration 814: Loss = 0.4159366488456726
Iteration 815: Loss = 0.41591137647628784
Iteration 816: Loss = 0.4158861041069031
Iteration 817: Loss = 0.41586077213287354
Iteration 818: Loss = 0.4158353805541992
Iteration 819: Loss = 0.4158100485801697
Iteration 820: Loss = 0.4157845973968506
Iteration 821: Loss = 0.4157591760158539
Iteration 822: Loss = 0.4157336950302124
Iteration 823: Loss = 0.41570818424224854
Iteration 824: Loss = 0.41568267345428467
Iteration 825: Loss = 0.41565704345703125
Iteration 826: Loss = 0.415631502866745
Iteration 827: Loss = 0.4156057834625244
Iteration 828: Loss = 0.415580153465271
Iteration 829: Loss = 0.4155544638633728
Iteration 830: Loss = 0.4155287444591522
Iteration 831: Loss = 0.41550299525260925
Iteration 832: Loss = 0.41547727584838867
Iteration 833: Loss = 0.4154515266418457
Iteration 834: Loss = 0.41542574763298035
Iteration 835: Loss = 0.415399968624115
Iteration 836: Loss = 0.4153740704059601
Iteration 837: Loss = 0.41534826159477234
Iteration 838: Loss = 0.41532236337661743
Iteration 839: Loss = 0.41529637575149536
Iteration 840: Loss = 0.41527044773101807
Iteration 841: Loss = 0.41524451971054077
Iteration 842: Loss = 0.41521838307380676
Iteration 843: Loss = 0.4151923358440399
Iteration 844: Loss = 0.4151662588119507
Iteration 845: Loss = 0.4151401221752167
Iteration 846: Loss = 0.41511401534080505
Iteration 847: Loss = 0.4150877892971039
Iteration 848: Loss = 0.4150615930557251
Iteration 849: Loss = 0.41503527760505676
Iteration 850: Loss = 0.4150089919567108
Iteration 851: Loss = 0.41498270630836487
Iteration 852: Loss = 0.414956271648407
Iteration 853: Loss = 0.41492989659309387
Iteration 854: Loss = 0.4149033725261688
Iteration 855: Loss = 0.4148769676685333
Iteration 856: Loss = 0.4148504436016083
Iteration 857: Loss = 0.41482388973236084
Iteration 858: Loss = 0.414797306060791
Iteration 859: Loss = 0.4147706925868988
Iteration 860: Loss = 0.41474398970603943
Iteration 861: Loss = 0.41471734642982483
Iteration 862: Loss = 0.4146905839443207
Iteration 863: Loss = 0.4146638810634613
Iteration 864: Loss = 0.41463714838027954
Iteration 865: Loss = 0.414610356092453
Iteration 866: Loss = 0.4145835340023041
Iteration 867: Loss = 0.41455668210983276
Iteration 868: Loss = 0.4145297110080719
Iteration 869: Loss = 0.4145027995109558
Iteration 870: Loss = 0.4144758880138397
Iteration 871: Loss = 0.4144488573074341
Iteration 872: Loss = 0.41442182660102844
Iteration 873: Loss = 0.414394736289978
Iteration 874: Loss = 0.4143676161766052
Iteration 875: Loss = 0.4143404960632324
Iteration 876: Loss = 0.41431328654289246
Iteration 877: Loss = 0.4142860770225525
Iteration 878: Loss = 0.41425880789756775
Iteration 879: Loss = 0.4142315089702606
Iteration 880: Loss = 0.4142041504383087
Iteration 881: Loss = 0.4141768217086792
Iteration 882: Loss = 0.41414937376976013
Iteration 883: Loss = 0.41412195563316345
Iteration 884: Loss = 0.4140944182872772
Iteration 885: Loss = 0.4140669107437134
Iteration 886: Loss = 0.4140393137931824
Iteration 887: Loss = 0.41401177644729614
Iteration 888: Loss = 0.41398411989212036
Iteration 889: Loss = 0.4139564633369446
Iteration 890: Loss = 0.4139286279678345
Iteration 891: Loss = 0.4139009118080139
Iteration 892: Loss = 0.4138731062412262
Iteration 893: Loss = 0.4138452708721161
Iteration 894: Loss = 0.413817435503006
Iteration 895: Loss = 0.4137895405292511
Iteration 896: Loss = 0.4137614965438843
Iteration 897: Loss = 0.4137335419654846
Iteration 898: Loss = 0.4137055575847626
Iteration 899: Loss = 0.41367748379707336
Iteration 900: Loss = 0.41364941000938416
Iteration 901: Loss = 0.413621187210083
Iteration 902: Loss = 0.41359302401542664
Iteration 903: Loss = 0.4135648310184479
Iteration 904: Loss = 0.4135364890098572
Iteration 905: Loss = 0.41350826621055603
Iteration 906: Loss = 0.4134799838066101
Iteration 907: Loss = 0.4134516417980194
Iteration 908: Loss = 0.41342321038246155
Iteration 909: Loss = 0.41339483857154846
Iteration 910: Loss = 0.4133663773536682
Iteration 911: Loss = 0.4133378267288208
Iteration 912: Loss = 0.41330933570861816
Iteration 913: Loss = 0.4132806956768036
Iteration 914: Loss = 0.4132521152496338
Iteration 915: Loss = 0.4132234454154968
Iteration 916: Loss = 0.41319480538368225
Iteration 917: Loss = 0.41316598653793335
Iteration 918: Loss = 0.41313719749450684
Iteration 919: Loss = 0.4131084084510803
Iteration 920: Loss = 0.41307953000068665
Iteration 921: Loss = 0.41305065155029297
Iteration 922: Loss = 0.4130217432975769
Iteration 923: Loss = 0.4129927158355713
Iteration 924: Loss = 0.4129636585712433
Iteration 925: Loss = 0.4129346013069153
Iteration 926: Loss = 0.4129055142402649
Iteration 927: Loss = 0.41287633776664734
Iteration 928: Loss = 0.4128471910953522
Iteration 929: Loss = 0.41281792521476746
Iteration 930: Loss = 0.4127886891365051
Iteration 931: Loss = 0.41275933384895325
Iteration 932: Loss = 0.41272997856140137
Iteration 933: Loss = 0.4127006530761719
Iteration 934: Loss = 0.41267120838165283
Iteration 935: Loss = 0.412641704082489
Iteration 936: Loss = 0.4126121699810028
Iteration 937: Loss = 0.4125826358795166
Iteration 938: Loss = 0.41255301237106323
Iteration 939: Loss = 0.41252338886260986
Iteration 940: Loss = 0.41249367594718933
Iteration 941: Loss = 0.4124639928340912
Iteration 942: Loss = 0.4124341905117035
Iteration 943: Loss = 0.4124043881893158
Iteration 944: Loss = 0.4123745858669281
Iteration 945: Loss = 0.41234463453292847
Iteration 946: Loss = 0.41231468319892883
Iteration 947: Loss = 0.4122847020626068
Iteration 948: Loss = 0.41225466132164
Iteration 949: Loss = 0.4122246503829956
Iteration 950: Loss = 0.41219449043273926
Iteration 951: Loss = 0.4121643304824829
Iteration 952: Loss = 0.4121341109275818
Iteration 953: Loss = 0.41210389137268066
Iteration 954: Loss = 0.41207361221313477
Iteration 955: Loss = 0.4120433032512665
Iteration 956: Loss = 0.41201287508010864
Iteration 957: Loss = 0.4119824469089508
Iteration 958: Loss = 0.41195204854011536
Iteration 959: Loss = 0.41192153096199036
Iteration 960: Loss = 0.41189098358154297
Iteration 961: Loss = 0.4118604063987732
Iteration 962: Loss = 0.41182976961135864
Iteration 963: Loss = 0.4117991030216217
Iteration 964: Loss = 0.41176837682724
Iteration 965: Loss = 0.4117376506328583
Iteration 966: Loss = 0.4117067754268646
Iteration 967: Loss = 0.41167593002319336
Iteration 968: Loss = 0.4116450846195221
Iteration 969: Loss = 0.41161417961120605
Iteration 970: Loss = 0.41158318519592285
Iteration 971: Loss = 0.41155219078063965
Iteration 972: Loss = 0.41152113676071167
Iteration 973: Loss = 0.41148993372917175
Iteration 974: Loss = 0.4114588499069214
Iteration 975: Loss = 0.41142770648002625
Iteration 976: Loss = 0.41139641404151917
Iteration 977: Loss = 0.4113651514053345
Iteration 978: Loss = 0.4113338589668274
Iteration 979: Loss = 0.4113024175167084
Iteration 980: Loss = 0.4112710952758789
Iteration 981: Loss = 0.4112395942211151
Iteration 982: Loss = 0.41120806336402893
Iteration 983: Loss = 0.41117653250694275
Iteration 984: Loss = 0.4111449718475342
Iteration 985: Loss = 0.4111133813858032
Iteration 986: Loss = 0.4110816717147827
Iteration 987: Loss = 0.4110499620437622
Iteration 988: Loss = 0.41101813316345215
Iteration 989: Loss = 0.41098636388778687
Iteration 990: Loss = 0.41095447540283203
Iteration 991: Loss = 0.410922646522522
Iteration 992: Loss = 0.41089069843292236
Iteration 993: Loss = 0.4108586311340332
Iteration 994: Loss = 0.4108266532421112
Iteration 995: Loss = 0.41079455614089966
Iteration 996: Loss = 0.4107624292373657
Iteration 997: Loss = 0.4107302725315094
Iteration 998: Loss = 0.4106981158256531
Iteration 999: Loss = 0.4106658399105072
Iteration 1000: Loss = 0.41063350439071655


Total training time (seconds): 10.71
