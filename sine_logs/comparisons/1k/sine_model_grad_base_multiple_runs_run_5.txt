Iteration 1: Loss = 0.49310827255249023
Iteration 2: Loss = 0.48994842171669006
Iteration 3: Loss = 0.4867648780345917
Iteration 4: Loss = 0.483529269695282
Iteration 5: Loss = 0.4802405536174774
Iteration 6: Loss = 0.47692087292671204
Iteration 7: Loss = 0.47359487414360046
Iteration 8: Loss = 0.47028788924217224
Iteration 9: Loss = 0.46702665090560913
Iteration 10: Loss = 0.46383926272392273
Iteration 11: Loss = 0.4607505798339844
Iteration 12: Loss = 0.4577801525592804
Iteration 13: Loss = 0.45494624972343445
Iteration 14: Loss = 0.45226091146469116
Iteration 15: Loss = 0.44973471760749817
Iteration 16: Loss = 0.44737449288368225
Iteration 17: Loss = 0.4451855421066284
Iteration 18: Loss = 0.4431687891483307
Iteration 19: Loss = 0.4413253366947174
Iteration 20: Loss = 0.43965426087379456
Iteration 21: Loss = 0.4381532669067383
Iteration 22: Loss = 0.436815470457077
Iteration 23: Loss = 0.43563488125801086
Iteration 24: Loss = 0.43460363149642944
Iteration 25: Loss = 0.4337131977081299
Iteration 26: Loss = 0.4329540729522705
Iteration 27: Loss = 0.4323165714740753
Iteration 28: Loss = 0.4317895472049713
Iteration 29: Loss = 0.4313621520996094
Iteration 30: Loss = 0.43102309107780457
Iteration 31: Loss = 0.4307616949081421
Iteration 32: Loss = 0.43056684732437134
Iteration 33: Loss = 0.43042778968811035
Iteration 34: Loss = 0.43033453822135925
Iteration 35: Loss = 0.43027743697166443
Iteration 36: Loss = 0.43024781346321106
Iteration 37: Loss = 0.4302380084991455
Iteration 38: Loss = 0.4302408695220947
Iteration 39: Loss = 0.4302503168582916
Iteration 40: Loss = 0.4302615523338318
Iteration 41: Loss = 0.43027037382125854
Iteration 42: Loss = 0.43027356266975403
Iteration 43: Loss = 0.4302684962749481
Iteration 44: Loss = 0.4302537143230438
Iteration 45: Loss = 0.4302281439304352
Iteration 46: Loss = 0.43019160628318787
Iteration 47: Loss = 0.43014416098594666
Iteration 48: Loss = 0.43008652329444885
Iteration 49: Loss = 0.4300195276737213
Iteration 50: Loss = 0.4299444258213043
Iteration 51: Loss = 0.42986252903938293
Iteration 52: Loss = 0.4297751188278198
Iteration 53: Loss = 0.42968371510505676
Iteration 54: Loss = 0.4295895993709564
Iteration 55: Loss = 0.4294940233230591
Iteration 56: Loss = 0.4293981194496155
Iteration 57: Loss = 0.42930278182029724
Iteration 58: Loss = 0.42920902371406555
Iteration 59: Loss = 0.4291173219680786
Iteration 60: Loss = 0.42902812361717224
Iteration 61: Loss = 0.42894184589385986
Iteration 62: Loss = 0.4288586378097534
Iteration 63: Loss = 0.4287784993648529
Iteration 64: Loss = 0.4287012815475464
Iteration 65: Loss = 0.4286269545555115
Iteration 66: Loss = 0.4285550117492676
Iteration 67: Loss = 0.42848533391952515
Iteration 68: Loss = 0.42841753363609314
Iteration 69: Loss = 0.4283512532711029
Iteration 70: Loss = 0.428286075592041
Iteration 71: Loss = 0.42822152376174927
Iteration 72: Loss = 0.4281575381755829
Iteration 73: Loss = 0.4280935525894165
Iteration 74: Loss = 0.42802944779396057
Iteration 75: Loss = 0.42796486616134644
Iteration 76: Loss = 0.4278997480869293
Iteration 77: Loss = 0.4278339445590973
Iteration 78: Loss = 0.4277673065662384
Iteration 79: Loss = 0.4276996850967407
Iteration 80: Loss = 0.4276311695575714
Iteration 81: Loss = 0.4275617003440857
Iteration 82: Loss = 0.42749136686325073
Iteration 83: Loss = 0.42742016911506653
Iteration 84: Loss = 0.42734813690185547
Iteration 85: Loss = 0.42727532982826233
Iteration 86: Loss = 0.42720189690589905
Iteration 87: Loss = 0.427127867937088
Iteration 88: Loss = 0.42705321311950684
Iteration 89: Loss = 0.42697808146476746
Iteration 90: Loss = 0.42690256237983704
Iteration 91: Loss = 0.4268265962600708
Iteration 92: Loss = 0.4267502427101135
Iteration 93: Loss = 0.42667356133461
Iteration 94: Loss = 0.42659658193588257
Iteration 95: Loss = 0.4265192747116089
Iteration 96: Loss = 0.42644160985946655
Iteration 97: Loss = 0.4263637065887451
Iteration 98: Loss = 0.42628535628318787
Iteration 99: Loss = 0.4262067377567291
Iteration 100: Loss = 0.4261277914047241
Iteration 101: Loss = 0.4260483980178833
Iteration 102: Loss = 0.4259686768054962
Iteration 103: Loss = 0.4258885979652405
Iteration 104: Loss = 0.4258080720901489
Iteration 105: Loss = 0.4257270395755768
Iteration 106: Loss = 0.425645649433136
Iteration 107: Loss = 0.425563782453537
Iteration 108: Loss = 0.4254814684391022
Iteration 109: Loss = 0.42539870738983154
Iteration 110: Loss = 0.4253154397010803
Iteration 111: Loss = 0.4252316951751709
Iteration 112: Loss = 0.42514753341674805
Iteration 113: Loss = 0.4250628650188446
Iteration 114: Loss = 0.42497771978378296
Iteration 115: Loss = 0.4248921275138855
Iteration 116: Loss = 0.42480602860450745
Iteration 117: Loss = 0.42471951246261597
Iteration 118: Loss = 0.4246325194835663
Iteration 119: Loss = 0.4245450496673584
Iteration 120: Loss = 0.42445704340934753
Iteration 121: Loss = 0.42436864972114563
Iteration 122: Loss = 0.42427971959114075
Iteration 123: Loss = 0.42419034242630005
Iteration 124: Loss = 0.42410051822662354
Iteration 125: Loss = 0.42401012778282166
Iteration 126: Loss = 0.42391929030418396
Iteration 127: Loss = 0.42382797598838806
Iteration 128: Loss = 0.4237361252307892
Iteration 129: Loss = 0.4236437678337097
Iteration 130: Loss = 0.4235509932041168
Iteration 131: Loss = 0.42345768213272095
Iteration 132: Loss = 0.4233638346195221
Iteration 133: Loss = 0.4232695400714874
Iteration 134: Loss = 0.4231746792793274
Iteration 135: Loss = 0.42307934165000916
Iteration 136: Loss = 0.4229835569858551
Iteration 137: Loss = 0.4228872060775757
Iteration 138: Loss = 0.42279040813446045
Iteration 139: Loss = 0.4226931035518646
Iteration 140: Loss = 0.4225952923297882
Iteration 141: Loss = 0.4224969446659088
Iteration 142: Loss = 0.422398179769516
Iteration 143: Loss = 0.42229875922203064
Iteration 144: Loss = 0.42219898104667664
Iteration 145: Loss = 0.4220985770225525
Iteration 146: Loss = 0.4219977557659149
Iteration 147: Loss = 0.42189639806747437
Iteration 148: Loss = 0.4217945635318756
Iteration 149: Loss = 0.4216921925544739
Iteration 150: Loss = 0.42158931493759155
Iteration 151: Loss = 0.42148593068122864
Iteration 152: Loss = 0.4213820695877075
Iteration 153: Loss = 0.4212777018547058
Iteration 154: Loss = 0.42117276787757874
Iteration 155: Loss = 0.42106738686561584
Iteration 156: Loss = 0.4209614396095276
Iteration 157: Loss = 0.42085498571395874
Iteration 158: Loss = 0.4207480549812317
Iteration 159: Loss = 0.4206405580043793
Iteration 160: Loss = 0.42053261399269104
Iteration 161: Loss = 0.4204242527484894
Iteration 162: Loss = 0.42031535506248474
Iteration 163: Loss = 0.42020586133003235
Iteration 164: Loss = 0.42009595036506653
Iteration 165: Loss = 0.41998547315597534
Iteration 166: Loss = 0.41987451910972595
Iteration 167: Loss = 0.41976305842399597
Iteration 168: Loss = 0.4196510910987854
Iteration 169: Loss = 0.419538676738739
Iteration 170: Loss = 0.41942569613456726
Iteration 171: Loss = 0.4193122684955597
Iteration 172: Loss = 0.41919830441474915
Iteration 173: Loss = 0.4190838634967804
Iteration 174: Loss = 0.41896894574165344
Iteration 175: Loss = 0.4188535809516907
Iteration 176: Loss = 0.41873759031295776
Iteration 177: Loss = 0.41862115263938904
Iteration 178: Loss = 0.4185042083263397
Iteration 179: Loss = 0.4183867275714874
Iteration 180: Loss = 0.41826876997947693
Iteration 181: Loss = 0.4181503653526306
Iteration 182: Loss = 0.41803139448165894
Iteration 183: Loss = 0.41791194677352905
Iteration 184: Loss = 0.4177919924259186
Iteration 185: Loss = 0.4176715314388275
Iteration 186: Loss = 0.41755062341690063
Iteration 187: Loss = 0.41742920875549316
Iteration 188: Loss = 0.4173072874546051
Iteration 189: Loss = 0.417184978723526
Iteration 190: Loss = 0.4170621633529663
Iteration 191: Loss = 0.4169389009475708
Iteration 192: Loss = 0.4168151617050171
Iteration 193: Loss = 0.41669097542762756
Iteration 194: Loss = 0.41656625270843506
Iteration 195: Loss = 0.41644108295440674
Iteration 196: Loss = 0.41631537675857544
Iteration 197: Loss = 0.4161892235279083
Iteration 198: Loss = 0.4160626232624054
Iteration 199: Loss = 0.41593554615974426
Iteration 200: Loss = 0.4158080220222473
Iteration 201: Loss = 0.4156799912452698
Iteration 202: Loss = 0.4155515432357788
Iteration 203: Loss = 0.41542261838912964
Iteration 204: Loss = 0.41529324650764465
Iteration 205: Loss = 0.41516345739364624
Iteration 206: Loss = 0.4150332510471344
Iteration 207: Loss = 0.41490259766578674
Iteration 208: Loss = 0.41477155685424805
Iteration 209: Loss = 0.41464000940322876
Iteration 210: Loss = 0.41450804471969604
Iteration 211: Loss = 0.4143756628036499
Iteration 212: Loss = 0.4142428934574127
Iteration 213: Loss = 0.41410955786705017
Iteration 214: Loss = 0.4139759838581085
Iteration 215: Loss = 0.4138419032096863
Iteration 216: Loss = 0.413707435131073
Iteration 217: Loss = 0.4135725200176239
Iteration 218: Loss = 0.41343724727630615
Iteration 219: Loss = 0.41330161690711975
Iteration 220: Loss = 0.41316553950309753
Iteration 221: Loss = 0.41302910447120667
Iteration 222: Loss = 0.41289231181144714
Iteration 223: Loss = 0.4127550423145294
Iteration 224: Loss = 0.41261744499206543
Iteration 225: Loss = 0.4124794602394104
Iteration 226: Loss = 0.41234102845191956
Iteration 227: Loss = 0.41220220923423767
Iteration 228: Loss = 0.4120630621910095
Iteration 229: Loss = 0.41192352771759033
Iteration 230: Loss = 0.4117835760116577
Iteration 231: Loss = 0.41164323687553406
Iteration 232: Loss = 0.4115025997161865
Iteration 233: Loss = 0.4113616347312927
Iteration 234: Loss = 0.4112202823162079
Iteration 235: Loss = 0.4110785722732544
Iteration 236: Loss = 0.4109365940093994
Iteration 237: Loss = 0.41079437732696533
Iteration 238: Loss = 0.4106518626213074
Iteration 239: Loss = 0.4105089008808136
Iteration 240: Loss = 0.41036567091941833
Iteration 241: Loss = 0.41022202372550964
Iteration 242: Loss = 0.41007810831069946
Iteration 243: Loss = 0.4099338948726654
Iteration 244: Loss = 0.4097893536090851
Iteration 245: Loss = 0.40964463353157043
Iteration 246: Loss = 0.40949952602386475
Iteration 247: Loss = 0.40935423970222473
Iteration 248: Loss = 0.40920862555503845
Iteration 249: Loss = 0.40906277298927307
Iteration 250: Loss = 0.408916711807251
Iteration 251: Loss = 0.4087703824043274
Iteration 252: Loss = 0.40862375497817993
Iteration 253: Loss = 0.40847688913345337
Iteration 254: Loss = 0.4083297550678253
Iteration 255: Loss = 0.40818244218826294
Iteration 256: Loss = 0.40803489089012146
Iteration 257: Loss = 0.4078870713710785
Iteration 258: Loss = 0.4077391028404236
Iteration 259: Loss = 0.4075908958911896
Iteration 260: Loss = 0.40744251012802124
Iteration 261: Loss = 0.4072939455509186
Iteration 262: Loss = 0.4071451425552368
Iteration 263: Loss = 0.40699613094329834
Iteration 264: Loss = 0.40684691071510315
Iteration 265: Loss = 0.40669751167297363
Iteration 266: Loss = 0.4065479040145874
Iteration 267: Loss = 0.4063981771469116
Iteration 268: Loss = 0.4062483608722687
Iteration 269: Loss = 0.40609848499298096
Iteration 270: Loss = 0.4059484899044037
Iteration 271: Loss = 0.4057982861995697
Iteration 272: Loss = 0.40564802289009094
Iteration 273: Loss = 0.40549764037132263
Iteration 274: Loss = 0.4053470492362976
Iteration 275: Loss = 0.4051963686943054
Iteration 276: Loss = 0.40504565834999084
Iteration 277: Loss = 0.40489479899406433
Iteration 278: Loss = 0.40474390983581543
Iteration 279: Loss = 0.404592901468277
Iteration 280: Loss = 0.4044418931007385
Iteration 281: Loss = 0.4042908251285553
Iteration 282: Loss = 0.4041397273540497
Iteration 283: Loss = 0.40398865938186646
Iteration 284: Loss = 0.4038374125957489
Iteration 285: Loss = 0.40368613600730896
Iteration 286: Loss = 0.40353479981422424
Iteration 287: Loss = 0.4033834934234619
Iteration 288: Loss = 0.4032321572303772
Iteration 289: Loss = 0.4030808210372925
Iteration 290: Loss = 0.40292951464653015
Iteration 291: Loss = 0.4027782380580902
Iteration 292: Loss = 0.40262705087661743
Iteration 293: Loss = 0.40247592329978943
Iteration 294: Loss = 0.40232473611831665
Iteration 295: Loss = 0.40217354893684387
Iteration 296: Loss = 0.40202245116233826
Iteration 297: Loss = 0.4018714129924774
Iteration 298: Loss = 0.40172043442726135
Iteration 299: Loss = 0.40156957507133484
Iteration 300: Loss = 0.40141892433166504
Iteration 301: Loss = 0.40126821398735046
Iteration 302: Loss = 0.4011176824569702
Iteration 303: Loss = 0.4009673297405243
Iteration 304: Loss = 0.4008168876171112
Iteration 305: Loss = 0.40066662430763245
Iteration 306: Loss = 0.40051642060279846
Iteration 307: Loss = 0.4003664255142212
Iteration 308: Loss = 0.40021654963493347
Iteration 309: Loss = 0.4000668227672577
Iteration 310: Loss = 0.3999173641204834
Iteration 311: Loss = 0.39976802468299866
Iteration 312: Loss = 0.39961889386177063
Iteration 313: Loss = 0.39946988224983215
Iteration 314: Loss = 0.399321049451828
Iteration 315: Loss = 0.39917245507240295
Iteration 316: Loss = 0.39902403950691223
Iteration 317: Loss = 0.398875892162323
Iteration 318: Loss = 0.3987278938293457
Iteration 319: Loss = 0.3985802233219147
Iteration 320: Loss = 0.39843273162841797
Iteration 321: Loss = 0.39828550815582275
Iteration 322: Loss = 0.39813849329948425
Iteration 323: Loss = 0.3979916274547577
Iteration 324: Loss = 0.397845059633255
Iteration 325: Loss = 0.3976987302303314
Iteration 326: Loss = 0.3975527286529541
Iteration 327: Loss = 0.39740705490112305
Iteration 328: Loss = 0.39726170897483826
Iteration 329: Loss = 0.3971168100833893
Iteration 330: Loss = 0.3969721794128418
Iteration 331: Loss = 0.39682769775390625
Iteration 332: Loss = 0.39668360352516174
Iteration 333: Loss = 0.3965398371219635
Iteration 334: Loss = 0.3963964581489563
Iteration 335: Loss = 0.396253377199173
Iteration 336: Loss = 0.39611080288887024
Iteration 337: Loss = 0.395968496799469
Iteration 338: Loss = 0.39582666754722595
Iteration 339: Loss = 0.39568522572517395
Iteration 340: Loss = 0.3955440819263458
Iteration 341: Loss = 0.39540329575538635
Iteration 342: Loss = 0.3952629864215851
Iteration 343: Loss = 0.39512309432029724
Iteration 344: Loss = 0.39498370885849
Iteration 345: Loss = 0.394844651222229
Iteration 346: Loss = 0.394706130027771
Iteration 347: Loss = 0.3945680260658264
Iteration 348: Loss = 0.3944302797317505
Iteration 349: Loss = 0.3942929804325104
Iteration 350: Loss = 0.3941561281681061
Iteration 351: Loss = 0.39401975274086
Iteration 352: Loss = 0.39388391375541687
Iteration 353: Loss = 0.3937486410140991
Iteration 354: Loss = 0.39361387491226196
Iteration 355: Loss = 0.3934795558452606
Iteration 356: Loss = 0.3933456540107727
Iteration 357: Loss = 0.393212229013443
Iteration 358: Loss = 0.39307937026023865
Iteration 359: Loss = 0.39294707775115967
Iteration 360: Loss = 0.39281532168388367
Iteration 361: Loss = 0.39268407225608826
Iteration 362: Loss = 0.3925534784793854
Iteration 363: Loss = 0.3924233913421631
Iteration 364: Loss = 0.3922938108444214
Iteration 365: Loss = 0.3921647369861603
Iteration 366: Loss = 0.39203616976737976
Iteration 367: Loss = 0.3919082581996918
Iteration 368: Loss = 0.3917809724807739
Iteration 369: Loss = 0.39165419340133667
Iteration 370: Loss = 0.39152809977531433
Iteration 371: Loss = 0.39140260219573975
Iteration 372: Loss = 0.391277551651001
Iteration 373: Loss = 0.3911530673503876
Iteration 374: Loss = 0.3910292088985443
Iteration 375: Loss = 0.3909059464931488
Iteration 376: Loss = 0.39078328013420105
Iteration 377: Loss = 0.3906612694263458
Iteration 378: Loss = 0.3905397951602936
Iteration 379: Loss = 0.39041903614997864
Iteration 380: Loss = 0.3902987539768219
Iteration 381: Loss = 0.3901790976524353
Iteration 382: Loss = 0.3900600075721741
Iteration 383: Loss = 0.3899414539337158
Iteration 384: Loss = 0.38982370495796204
Iteration 385: Loss = 0.389706552028656
Iteration 386: Loss = 0.3895900249481201
Iteration 387: Loss = 0.3894740641117096
Iteration 388: Loss = 0.3893586993217468
Iteration 389: Loss = 0.3892441391944885
Iteration 390: Loss = 0.389130175113678
Iteration 391: Loss = 0.3890168070793152
Iteration 392: Loss = 0.3889041841030121
Iteration 393: Loss = 0.38879212737083435
Iteration 394: Loss = 0.38868075609207153
Iteration 395: Loss = 0.38857004046440125
Iteration 396: Loss = 0.3884599506855011
Iteration 397: Loss = 0.3883504867553711
Iteration 398: Loss = 0.388241708278656
Iteration 399: Loss = 0.38813355565071106
Iteration 400: Loss = 0.38802605867385864
Iteration 401: Loss = 0.38791927695274353
Iteration 402: Loss = 0.38781318068504333
Iteration 403: Loss = 0.38770776987075806
Iteration 404: Loss = 0.38760292530059814
Iteration 405: Loss = 0.3874986469745636
Iteration 406: Loss = 0.3873950242996216
Iteration 407: Loss = 0.3872920572757721
Iteration 408: Loss = 0.38718974590301514
Iteration 409: Loss = 0.3870880901813507
Iteration 410: Loss = 0.38698717951774597
Iteration 411: Loss = 0.38688695430755615
Iteration 412: Loss = 0.386787474155426
Iteration 413: Loss = 0.3866884708404541
Iteration 414: Loss = 0.3865901529788971
Iteration 415: Loss = 0.38649240136146545
Iteration 416: Loss = 0.3863953948020935
Iteration 417: Loss = 0.38629910349845886
Iteration 418: Loss = 0.38620343804359436
Iteration 419: Loss = 0.3861086368560791
Iteration 420: Loss = 0.38601428270339966
Iteration 421: Loss = 0.38592052459716797
Iteration 422: Loss = 0.3858274519443512
Iteration 423: Loss = 0.3857352137565613
Iteration 424: Loss = 0.38564354181289673
Iteration 425: Loss = 0.38555261492729187
Iteration 426: Loss = 0.3854622542858124
Iteration 427: Loss = 0.3853725790977478
Iteration 428: Loss = 0.3852834403514862
Iteration 429: Loss = 0.3851950466632843
Iteration 430: Loss = 0.38510724902153015
Iteration 431: Loss = 0.38502007722854614
Iteration 432: Loss = 0.3849335312843323
Iteration 433: Loss = 0.38484761118888855
Iteration 434: Loss = 0.38476231694221497
Iteration 435: Loss = 0.38467761874198914
Iteration 436: Loss = 0.38459348678588867
Iteration 437: Loss = 0.38451001048088074
Iteration 438: Loss = 0.3844272494316101
Iteration 439: Loss = 0.3843451142311096
Iteration 440: Loss = 0.3842635452747345
Iteration 441: Loss = 0.38418257236480713
Iteration 442: Loss = 0.3841022551059723
Iteration 443: Loss = 0.38402259349823
Iteration 444: Loss = 0.3839433491230011
Iteration 445: Loss = 0.3838649392127991
Iteration 446: Loss = 0.38378703594207764
Iteration 447: Loss = 0.38370975852012634
Iteration 448: Loss = 0.3836330473423004
Iteration 449: Loss = 0.38355696201324463
Iteration 450: Loss = 0.3834814727306366
Iteration 451: Loss = 0.3834065794944763
Iteration 452: Loss = 0.38333210349082947
Iteration 453: Loss = 0.3832583427429199
Iteration 454: Loss = 0.38318517804145813
Iteration 455: Loss = 0.3831126093864441
Iteration 456: Loss = 0.3830406069755554
Iteration 457: Loss = 0.3829692304134369
Iteration 458: Loss = 0.3828984200954437
Iteration 459: Loss = 0.38282811641693115
Iteration 460: Loss = 0.38275837898254395
Iteration 461: Loss = 0.38268914818763733
Iteration 462: Loss = 0.3826204538345337
Iteration 463: Loss = 0.38255229592323303
Iteration 464: Loss = 0.3824846148490906
Iteration 465: Loss = 0.3824174702167511
Iteration 466: Loss = 0.3823508322238922
Iteration 467: Loss = 0.38228482007980347
Iteration 468: Loss = 0.3822193443775177
Iteration 469: Loss = 0.382154256105423
Iteration 470: Loss = 0.3820897340774536
Iteration 471: Loss = 0.3820257782936096
Iteration 472: Loss = 0.3819625675678253
Iteration 473: Loss = 0.38189977407455444
Iteration 474: Loss = 0.38183751702308655
Iteration 475: Loss = 0.38177570700645447
Iteration 476: Loss = 0.3817143142223358
Iteration 477: Loss = 0.381653368473053
Iteration 478: Loss = 0.3815930187702179
Iteration 479: Loss = 0.3815332055091858
Iteration 480: Loss = 0.3814738392829895
Iteration 481: Loss = 0.3814150094985962
Iteration 482: Loss = 0.3813566267490387
Iteration 483: Loss = 0.3812987804412842
Iteration 484: Loss = 0.3812413215637207
Iteration 485: Loss = 0.38118433952331543
Iteration 486: Loss = 0.3811277747154236
Iteration 487: Loss = 0.38107168674468994
Iteration 488: Loss = 0.38101598620414734
Iteration 489: Loss = 0.3809608221054077
Iteration 490: Loss = 0.38090601563453674
Iteration 491: Loss = 0.3808516561985016
Iteration 492: Loss = 0.38079777359962463
Iteration 493: Loss = 0.3807442784309387
Iteration 494: Loss = 0.3806912899017334
Iteration 495: Loss = 0.3806389272212982
Iteration 496: Loss = 0.3805869221687317
Iteration 497: Loss = 0.380535364151001
Iteration 498: Loss = 0.3804841935634613
Iteration 499: Loss = 0.38043349981307983
Iteration 500: Loss = 0.38038304448127747
Iteration 501: Loss = 0.38033297657966614
Iteration 502: Loss = 0.38028329610824585
Iteration 503: Loss = 0.3802340030670166
Iteration 504: Loss = 0.38018524646759033
Iteration 505: Loss = 0.38013696670532227
Iteration 506: Loss = 0.38008901476860046
Iteration 507: Loss = 0.38004153966903687
Iteration 508: Loss = 0.37999427318573
Iteration 509: Loss = 0.3799474537372589
Iteration 510: Loss = 0.37990111112594604
Iteration 511: Loss = 0.37985503673553467
Iteration 512: Loss = 0.3798093795776367
Iteration 513: Loss = 0.37976402044296265
Iteration 514: Loss = 0.37971895933151245
Iteration 515: Loss = 0.37967434525489807
Iteration 516: Loss = 0.3796299695968628
Iteration 517: Loss = 0.3795858323574066
Iteration 518: Loss = 0.37954217195510864
Iteration 519: Loss = 0.37949880957603455
Iteration 520: Loss = 0.3794558048248291
Iteration 521: Loss = 0.37941333651542664
Iteration 522: Loss = 0.37937119603157043
Iteration 523: Loss = 0.3793293237686157
Iteration 524: Loss = 0.3792877495288849
Iteration 525: Loss = 0.37924644351005554
Iteration 526: Loss = 0.37920546531677246
Iteration 527: Loss = 0.37916478514671326
Iteration 528: Loss = 0.37912440299987793
Iteration 529: Loss = 0.3790842592716217
Iteration 530: Loss = 0.37904444336891174
Iteration 531: Loss = 0.3790051341056824
Iteration 532: Loss = 0.3789660632610321
Iteration 533: Loss = 0.37892720103263855
Iteration 534: Loss = 0.37888863682746887
Iteration 535: Loss = 0.37885022163391113
Iteration 536: Loss = 0.3788122534751892
Iteration 537: Loss = 0.378774493932724
Iteration 538: Loss = 0.37873706221580505
Iteration 539: Loss = 0.37869980931282043
Iteration 540: Loss = 0.3786627948284149
Iteration 541: Loss = 0.3786259889602661
Iteration 542: Loss = 0.3785894513130188
Iteration 543: Loss = 0.3785531520843506
Iteration 544: Loss = 0.37851718068122864
Iteration 545: Loss = 0.3784814178943634
Iteration 546: Loss = 0.3784460127353668
Iteration 547: Loss = 0.37841081619262695
Iteration 548: Loss = 0.3783758580684662
Iteration 549: Loss = 0.3783411383628845
Iteration 550: Loss = 0.3783065676689148
Iteration 551: Loss = 0.37827226519584656
Iteration 552: Loss = 0.3782382905483246
Iteration 553: Loss = 0.37820446491241455
Iteration 554: Loss = 0.378170907497406
Iteration 555: Loss = 0.378137469291687
Iteration 556: Loss = 0.3781042993068695
Iteration 557: Loss = 0.3780713677406311
Iteration 558: Loss = 0.378038614988327
Iteration 559: Loss = 0.3780059814453125
Iteration 560: Loss = 0.3779734969139099
Iteration 561: Loss = 0.37794145941734314
Iteration 562: Loss = 0.37790969014167786
Iteration 563: Loss = 0.3778781592845917
Iteration 564: Loss = 0.3778468072414398
Iteration 565: Loss = 0.3778156340122223
Iteration 566: Loss = 0.37778472900390625
Iteration 567: Loss = 0.37775394320487976
Iteration 568: Loss = 0.37772345542907715
Iteration 569: Loss = 0.3776930570602417
Iteration 570: Loss = 0.3776628375053406
Iteration 571: Loss = 0.37763282656669617
Iteration 572: Loss = 0.3776029646396637
Iteration 573: Loss = 0.3775733709335327
Iteration 574: Loss = 0.37754395604133606
Iteration 575: Loss = 0.37751469016075134
Iteration 576: Loss = 0.37748563289642334
Iteration 577: Loss = 0.3774566650390625
Iteration 578: Loss = 0.37742799520492554
Iteration 579: Loss = 0.3773994445800781
Iteration 580: Loss = 0.3773711025714874
Iteration 581: Loss = 0.37734296917915344
Iteration 582: Loss = 0.37731507420539856
Iteration 583: Loss = 0.3772873878479004
Iteration 584: Loss = 0.3772597312927246
Iteration 585: Loss = 0.3772321939468384
Iteration 586: Loss = 0.3772047758102417
Iteration 587: Loss = 0.37717753648757935
Iteration 588: Loss = 0.3771504759788513
Iteration 589: Loss = 0.37712353467941284
Iteration 590: Loss = 0.3770968019962311
Iteration 591: Loss = 0.3770701587200165
Iteration 592: Loss = 0.37704363465309143
Iteration 593: Loss = 0.37701714038848877
Iteration 594: Loss = 0.3769909739494324
Iteration 595: Loss = 0.37696486711502075
Iteration 596: Loss = 0.37693890929222107
Iteration 597: Loss = 0.3769131302833557
Iteration 598: Loss = 0.3768874406814575
Iteration 599: Loss = 0.37686190009117126
Iteration 600: Loss = 0.3768364489078522
Iteration 601: Loss = 0.37681108713150024
Iteration 602: Loss = 0.3767859637737274
Iteration 603: Loss = 0.37676092982292175
Iteration 604: Loss = 0.37673598527908325
Iteration 605: Loss = 0.3767112195491791
Iteration 606: Loss = 0.37668657302856445
Iteration 607: Loss = 0.37666210532188416
Iteration 608: Loss = 0.37663766741752625
Iteration 609: Loss = 0.3766133487224579
Iteration 610: Loss = 0.3765891194343567
Iteration 611: Loss = 0.37656503915786743
Iteration 612: Loss = 0.37654101848602295
Iteration 613: Loss = 0.37651708722114563
Iteration 614: Loss = 0.37649327516555786
Iteration 615: Loss = 0.3764696717262268
Iteration 616: Loss = 0.3764461874961853
Iteration 617: Loss = 0.37642282247543335
Iteration 618: Loss = 0.37639957666397095
Iteration 619: Loss = 0.37637630105018616
Iteration 620: Loss = 0.3763531446456909
Iteration 621: Loss = 0.37633010745048523
Iteration 622: Loss = 0.3763071298599243
Iteration 623: Loss = 0.37628427147865295
Iteration 624: Loss = 0.37626150250434875
Iteration 625: Loss = 0.37623876333236694
Iteration 626: Loss = 0.3762161135673523
Iteration 627: Loss = 0.37619349360466003
Iteration 628: Loss = 0.3761711120605469
Iteration 629: Loss = 0.37614887952804565
Iteration 630: Loss = 0.3761266767978668
Iteration 631: Loss = 0.37610453367233276
Iteration 632: Loss = 0.3760824501514435
Iteration 633: Loss = 0.3760603666305542
Iteration 634: Loss = 0.376038521528244
Iteration 635: Loss = 0.3760165870189667
Iteration 636: Loss = 0.3759947717189789
Iteration 637: Loss = 0.37597304582595825
Iteration 638: Loss = 0.37595134973526
Iteration 639: Loss = 0.3759298026561737
Iteration 640: Loss = 0.3759083151817322
Iteration 641: Loss = 0.3758869767189026
Iteration 642: Loss = 0.3758656978607178
Iteration 643: Loss = 0.37584447860717773
Iteration 644: Loss = 0.3758232295513153
Iteration 645: Loss = 0.3758021593093872
Iteration 646: Loss = 0.3757811188697815
Iteration 647: Loss = 0.3757600784301758
Iteration 648: Loss = 0.37573912739753723
Iteration 649: Loss = 0.3757181763648987
Iteration 650: Loss = 0.3756973147392273
Iteration 651: Loss = 0.3756764531135559
Iteration 652: Loss = 0.37565574049949646
Iteration 653: Loss = 0.37563493847846985
Iteration 654: Loss = 0.375614196062088
Iteration 655: Loss = 0.37559351325035095
Iteration 656: Loss = 0.3755728006362915
Iteration 657: Loss = 0.37555214762687683
Iteration 658: Loss = 0.3755316734313965
Iteration 659: Loss = 0.3755112588405609
Iteration 660: Loss = 0.37549102306365967
Iteration 661: Loss = 0.3754708468914032
Iteration 662: Loss = 0.37545058131217957
Iteration 663: Loss = 0.37543049454689026
Iteration 664: Loss = 0.3754102885723114
Iteration 665: Loss = 0.3753902316093445
Iteration 666: Loss = 0.37537017464637756
Iteration 667: Loss = 0.3753501772880554
Iteration 668: Loss = 0.3753302991390228
Iteration 669: Loss = 0.37531036138534546
Iteration 670: Loss = 0.3752904236316681
Iteration 671: Loss = 0.37527063488960266
Iteration 672: Loss = 0.37525078654289246
Iteration 673: Loss = 0.3752310276031494
Iteration 674: Loss = 0.37521132826805115
Iteration 675: Loss = 0.37519165873527527
Iteration 676: Loss = 0.3751719892024994
Iteration 677: Loss = 0.3751523494720459
Iteration 678: Loss = 0.37513282895088196
Iteration 679: Loss = 0.375113308429718
Iteration 680: Loss = 0.37509384751319885
Iteration 681: Loss = 0.3750743269920349
Iteration 682: Loss = 0.37505486607551575
Iteration 683: Loss = 0.37503546476364136
Iteration 684: Loss = 0.37501606345176697
Iteration 685: Loss = 0.37499675154685974
Iteration 686: Loss = 0.3749774694442749
Iteration 687: Loss = 0.3749580979347229
Iteration 688: Loss = 0.3749387264251709
Iteration 689: Loss = 0.37491944432258606
Iteration 690: Loss = 0.37490007281303406
Iteration 691: Loss = 0.3748807907104492
Iteration 692: Loss = 0.3748616576194763
Iteration 693: Loss = 0.37484249472618103
Iteration 694: Loss = 0.37482336163520813
Iteration 695: Loss = 0.37480416893959045
Iteration 696: Loss = 0.3747849762439728
Iteration 697: Loss = 0.3747657239437103
Iteration 698: Loss = 0.3747464716434479
Iteration 699: Loss = 0.3747273087501526
Iteration 700: Loss = 0.3747081160545349
Iteration 701: Loss = 0.37468892335891724
Iteration 702: Loss = 0.3746698498725891
Iteration 703: Loss = 0.3746506869792938
Iteration 704: Loss = 0.37463143467903137
Iteration 705: Loss = 0.37461230158805847
Iteration 706: Loss = 0.3745931386947632
Iteration 707: Loss = 0.37457403540611267
Iteration 708: Loss = 0.37455490231513977
Iteration 709: Loss = 0.37453576922416687
Iteration 710: Loss = 0.3745166063308716
Iteration 711: Loss = 0.3744974732398987
Iteration 712: Loss = 0.37447839975357056
Iteration 713: Loss = 0.3744593560695648
Iteration 714: Loss = 0.37444034218788147
Iteration 715: Loss = 0.3744213283061981
Iteration 716: Loss = 0.37440234422683716
Iteration 717: Loss = 0.3743833601474762
Iteration 718: Loss = 0.37436437606811523
Iteration 719: Loss = 0.3743453919887543
Iteration 720: Loss = 0.3743264377117157
Iteration 721: Loss = 0.37430742383003235
Iteration 722: Loss = 0.3742884695529938
Iteration 723: Loss = 0.3742695450782776
Iteration 724: Loss = 0.37425053119659424
Iteration 725: Loss = 0.37423157691955566
Iteration 726: Loss = 0.3742125928401947
Iteration 727: Loss = 0.37419360876083374
Iteration 728: Loss = 0.37417471408843994
Iteration 729: Loss = 0.3741558790206909
Iteration 730: Loss = 0.3741369843482971
Iteration 731: Loss = 0.37411805987358093
Iteration 732: Loss = 0.37409916520118713
Iteration 733: Loss = 0.37408021092414856
Iteration 734: Loss = 0.37406131625175476
Iteration 735: Loss = 0.37404242157936096
Iteration 736: Loss = 0.37402355670928955
Iteration 737: Loss = 0.37400469183921814
Iteration 738: Loss = 0.37398576736450195
Iteration 739: Loss = 0.3739669919013977
Iteration 740: Loss = 0.37394818663597107
Iteration 741: Loss = 0.37392935156822205
Iteration 742: Loss = 0.373910516500473
Iteration 743: Loss = 0.3738917112350464
Iteration 744: Loss = 0.3738729655742645
Iteration 745: Loss = 0.3738541901111603
Iteration 746: Loss = 0.37383535504341125
Iteration 747: Loss = 0.3738165497779846
Iteration 748: Loss = 0.3737976849079132
Iteration 749: Loss = 0.3737788796424866
Iteration 750: Loss = 0.37376004457473755
Iteration 751: Loss = 0.3737412095069885
Iteration 752: Loss = 0.37372246384620667
Iteration 753: Loss = 0.3737036883831024
Iteration 754: Loss = 0.3736848831176758
Iteration 755: Loss = 0.3736661374568939
Iteration 756: Loss = 0.3736473321914673
Iteration 757: Loss = 0.3736284673213959
Iteration 758: Loss = 0.373609721660614
Iteration 759: Loss = 0.373590886592865
Iteration 760: Loss = 0.3735720217227936
Iteration 761: Loss = 0.37355318665504456
Iteration 762: Loss = 0.3735343813896179
Iteration 763: Loss = 0.3735155463218689
Iteration 764: Loss = 0.3734967112541199
Iteration 765: Loss = 0.37347787618637085
Iteration 766: Loss = 0.3734590411186218
Iteration 767: Loss = 0.3734402358531952
Iteration 768: Loss = 0.37342146039009094
Iteration 769: Loss = 0.3734027147293091
Iteration 770: Loss = 0.3733839988708496
Iteration 771: Loss = 0.3733653426170349
Iteration 772: Loss = 0.37334662675857544
Iteration 773: Loss = 0.37332791090011597
Iteration 774: Loss = 0.3733091950416565
Iteration 775: Loss = 0.3732905685901642
Iteration 776: Loss = 0.3732718229293823
Iteration 777: Loss = 0.37325310707092285
Iteration 778: Loss = 0.373234361410141
Iteration 779: Loss = 0.37321561574935913
Iteration 780: Loss = 0.37319692969322205
Iteration 781: Loss = 0.3731782138347626
Iteration 782: Loss = 0.3731595277786255
Iteration 783: Loss = 0.37314075231552124
Iteration 784: Loss = 0.3731220066547394
Iteration 785: Loss = 0.3731032609939575
Iteration 786: Loss = 0.3730846047401428
Iteration 787: Loss = 0.37306588888168335
Iteration 788: Loss = 0.3730471730232239
Iteration 789: Loss = 0.3730284869670868
Iteration 790: Loss = 0.3730097711086273
Iteration 791: Loss = 0.37299099564552307
Iteration 792: Loss = 0.372972309589386
Iteration 793: Loss = 0.3729536235332489
Iteration 794: Loss = 0.37293484807014465
Iteration 795: Loss = 0.3729161322116852
Iteration 796: Loss = 0.3728973865509033
Iteration 797: Loss = 0.37287867069244385
Iteration 798: Loss = 0.3728598654270172
Iteration 799: Loss = 0.3728410601615906
Iteration 800: Loss = 0.37282222509384155
Iteration 801: Loss = 0.37280339002609253
Iteration 802: Loss = 0.3727845251560211
Iteration 803: Loss = 0.3727656900882721
Iteration 804: Loss = 0.37274685502052307
Iteration 805: Loss = 0.37272799015045166
Iteration 806: Loss = 0.372709184885025
Iteration 807: Loss = 0.3726904094219208
Iteration 808: Loss = 0.37267157435417175
Iteration 809: Loss = 0.3726527690887451
Iteration 810: Loss = 0.3726339042186737
Iteration 811: Loss = 0.3726150393486023
Iteration 812: Loss = 0.37259623408317566
Iteration 813: Loss = 0.37257733941078186
Iteration 814: Loss = 0.37255844473838806
Iteration 815: Loss = 0.37253960967063904
Iteration 816: Loss = 0.3725207448005676
Iteration 817: Loss = 0.3725019693374634
Iteration 818: Loss = 0.3724830448627472
Iteration 819: Loss = 0.3724641799926758
Iteration 820: Loss = 0.372445285320282
Iteration 821: Loss = 0.3724263906478882
Iteration 822: Loss = 0.3724074959754944
Iteration 823: Loss = 0.37238866090774536
Iteration 824: Loss = 0.37236979603767395
Iteration 825: Loss = 0.3723510205745697
Iteration 826: Loss = 0.37233221530914307
Iteration 827: Loss = 0.3723134398460388
Iteration 828: Loss = 0.3722946047782898
Iteration 829: Loss = 0.37227582931518555
Iteration 830: Loss = 0.3722571134567261
Iteration 831: Loss = 0.3722384572029114
Iteration 832: Loss = 0.3722197413444519
Iteration 833: Loss = 0.3722010552883148
Iteration 834: Loss = 0.37218230962753296
Iteration 835: Loss = 0.37216365337371826
Iteration 836: Loss = 0.37214499711990356
Iteration 837: Loss = 0.37212637066841125
Iteration 838: Loss = 0.3721078634262085
Iteration 839: Loss = 0.3720892369747162
Iteration 840: Loss = 0.3720706105232239
Iteration 841: Loss = 0.3720521032810211
Iteration 842: Loss = 0.3720335364341736
Iteration 843: Loss = 0.3720150291919708
Iteration 844: Loss = 0.3719964325428009
Iteration 845: Loss = 0.3719780147075653
Iteration 846: Loss = 0.3719596266746521
Iteration 847: Loss = 0.3719412684440613
Iteration 848: Loss = 0.37192288041114807
Iteration 849: Loss = 0.37190452218055725
Iteration 850: Loss = 0.37188616394996643
Iteration 851: Loss = 0.371867835521698
Iteration 852: Loss = 0.3718494772911072
Iteration 853: Loss = 0.37183117866516113
Iteration 854: Loss = 0.3718128502368927
Iteration 855: Loss = 0.37179455161094666
Iteration 856: Loss = 0.3717763125896454
Iteration 857: Loss = 0.3717580735683441
Iteration 858: Loss = 0.37173983454704285
Iteration 859: Loss = 0.3717215955257416
Iteration 860: Loss = 0.3717033565044403
Iteration 861: Loss = 0.37168508768081665
Iteration 862: Loss = 0.371666818857193
Iteration 863: Loss = 0.37164855003356934
Iteration 864: Loss = 0.3716302812099457
Iteration 865: Loss = 0.37161198258399963
Iteration 866: Loss = 0.3715936541557312
Iteration 867: Loss = 0.37157538533210754
Iteration 868: Loss = 0.3715570569038391
Iteration 869: Loss = 0.37153881788253784
Iteration 870: Loss = 0.3715204894542694
Iteration 871: Loss = 0.3715021312236786
Iteration 872: Loss = 0.37148383259773254
Iteration 873: Loss = 0.3714654743671417
Iteration 874: Loss = 0.3714470863342285
Iteration 875: Loss = 0.37142878770828247
Iteration 876: Loss = 0.3714105188846588
Iteration 877: Loss = 0.37139222025871277
Iteration 878: Loss = 0.37137386202812195
Iteration 879: Loss = 0.3713555932044983
Iteration 880: Loss = 0.37133729457855225
Iteration 881: Loss = 0.3713189363479614
Iteration 882: Loss = 0.37130066752433777
Iteration 883: Loss = 0.3712824583053589
Iteration 884: Loss = 0.37126418948173523
Iteration 885: Loss = 0.3712458908557892
Iteration 886: Loss = 0.37122759222984314
Iteration 887: Loss = 0.3712093234062195
Iteration 888: Loss = 0.37119096517562866
Iteration 889: Loss = 0.3711726665496826
Iteration 890: Loss = 0.3711545467376709
Iteration 891: Loss = 0.3711363971233368
Iteration 892: Loss = 0.3711181879043579
Iteration 893: Loss = 0.3711000382900238
Iteration 894: Loss = 0.3710819184780121
Iteration 895: Loss = 0.371063768863678
Iteration 896: Loss = 0.3710455894470215
Iteration 897: Loss = 0.371027410030365
Iteration 898: Loss = 0.37100932002067566
Iteration 899: Loss = 0.3709911108016968
Iteration 900: Loss = 0.37097305059432983
Iteration 901: Loss = 0.3709549009799957
Iteration 902: Loss = 0.370936781167984
Iteration 903: Loss = 0.3709186613559723
Iteration 904: Loss = 0.3709004521369934
Iteration 905: Loss = 0.37088239192962646
Iteration 906: Loss = 0.37086427211761475
Iteration 907: Loss = 0.37084612250328064
Iteration 908: Loss = 0.3708280026912689
Iteration 909: Loss = 0.3708098232746124
Iteration 910: Loss = 0.37079164385795593
Iteration 911: Loss = 0.3707734942436218
Iteration 912: Loss = 0.3707553744316101
Iteration 913: Loss = 0.3707372844219208
Iteration 914: Loss = 0.3707190752029419
Iteration 915: Loss = 0.370700865983963
Iteration 916: Loss = 0.3706826865673065
Iteration 917: Loss = 0.37066447734832764
Iteration 918: Loss = 0.37064629793167114
Iteration 919: Loss = 0.37062811851501465
Iteration 920: Loss = 0.37060999870300293
Iteration 921: Loss = 0.3705918788909912
Iteration 922: Loss = 0.3705737888813019
Iteration 923: Loss = 0.37055572867393494
Iteration 924: Loss = 0.370537668466568
Iteration 925: Loss = 0.3705195188522339
Iteration 926: Loss = 0.37050139904022217
Iteration 927: Loss = 0.37048330903053284
Iteration 928: Loss = 0.3704654276371002
Iteration 929: Loss = 0.37044742703437805
Iteration 930: Loss = 0.37042945623397827
Iteration 931: Loss = 0.3704114556312561
Iteration 932: Loss = 0.37039345502853394
Iteration 933: Loss = 0.37037551403045654
Iteration 934: Loss = 0.37035754323005676
Iteration 935: Loss = 0.37033969163894653
Iteration 936: Loss = 0.37032178044319153
Iteration 937: Loss = 0.3703039586544037
Iteration 938: Loss = 0.37028607726097107
Iteration 939: Loss = 0.37026819586753845
Iteration 940: Loss = 0.37025028467178345
Iteration 941: Loss = 0.37023237347602844
Iteration 942: Loss = 0.3702146112918854
Iteration 943: Loss = 0.37019678950309753
Iteration 944: Loss = 0.37017902731895447
Iteration 945: Loss = 0.3701612651348114
Iteration 946: Loss = 0.37014344334602356
Iteration 947: Loss = 0.3701256513595581
Iteration 948: Loss = 0.3701079189777374
Iteration 949: Loss = 0.37009021639823914
Iteration 950: Loss = 0.37007254362106323
Iteration 951: Loss = 0.37005487084388733
Iteration 952: Loss = 0.37003716826438904
Iteration 953: Loss = 0.3700195252895355
Iteration 954: Loss = 0.37000182271003723
Iteration 955: Loss = 0.36998412013053894
Iteration 956: Loss = 0.36996641755104065
Iteration 957: Loss = 0.3699488639831543
Iteration 958: Loss = 0.36993131041526794
Iteration 959: Loss = 0.36991381645202637
Iteration 960: Loss = 0.3698962330818176
Iteration 961: Loss = 0.36987873911857605
Iteration 962: Loss = 0.3698612153530121
Iteration 963: Loss = 0.3698436915874481
Iteration 964: Loss = 0.3698261082172394
Iteration 965: Loss = 0.3698086142539978
Iteration 966: Loss = 0.36979109048843384
Iteration 967: Loss = 0.3697735071182251
Iteration 968: Loss = 0.3697560131549835
Iteration 969: Loss = 0.3697384297847748
Iteration 970: Loss = 0.36972081661224365
Iteration 971: Loss = 0.3697032630443573
Iteration 972: Loss = 0.3696858286857605
Iteration 973: Loss = 0.3696683645248413
Iteration 974: Loss = 0.3696509003639221
Iteration 975: Loss = 0.3696334660053253
Iteration 976: Loss = 0.3696160614490509
Iteration 977: Loss = 0.3695985972881317
Iteration 978: Loss = 0.3695811629295349
Iteration 979: Loss = 0.3695637285709381
Iteration 980: Loss = 0.3695463538169861
Iteration 981: Loss = 0.3695289194583893
Iteration 982: Loss = 0.36951160430908203
Iteration 983: Loss = 0.36949422955513
Iteration 984: Loss = 0.369476854801178
Iteration 985: Loss = 0.36945948004722595
Iteration 986: Loss = 0.3694421350955963
Iteration 987: Loss = 0.3694249391555786
Iteration 988: Loss = 0.3694077134132385
Iteration 989: Loss = 0.369390606880188
Iteration 990: Loss = 0.3693733811378479
Iteration 991: Loss = 0.36935627460479736
Iteration 992: Loss = 0.36933910846710205
Iteration 993: Loss = 0.3693219721317291
Iteration 994: Loss = 0.3693048059940338
Iteration 995: Loss = 0.36928796768188477
Iteration 996: Loss = 0.36927103996276855
Iteration 997: Loss = 0.36925414204597473
Iteration 998: Loss = 0.3692373037338257
Iteration 999: Loss = 0.36922046542167664
Iteration 1000: Loss = 0.3692035377025604


Total training time (seconds): 10.91
